{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379ab926",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2326fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def load_and_shuffle_mnist():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5, ))])\n",
    "    mnist_train = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    mnist_test = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "    train_data = list(mnist_train)\n",
    "    test_data = list(mnist_test)\n",
    "\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(test_data)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a58577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(mnist_data, window_size):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(mnist_data) - window_size + 1):\n",
    "        window = mnist_data[i:i + window_size]\n",
    "        sequence_images = torch.stack([img for img, _ in window])\n",
    "\n",
    "        # Default label is 'null' (using a specific number to represent 'null', e.g., 10)\n",
    "        label = 10  # Assuming 10 represents 'null'\n",
    "\n",
    "        # Check for the condition in the last window_size elements\n",
    "        last_digit = window[-1][1]\n",
    "        for _, prev_label in window[:-1]:\n",
    "            if prev_label == last_digit:\n",
    "                label = last_digit  # Label is the digit itself if condition is met\n",
    "                break\n",
    "\n",
    "        sequences.append(sequence_images)\n",
    "        labels.append(label)\n",
    "\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a47803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels  # Labels are already numerical, no need for a map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        # Ensure label is a tensor of dtype torch.long\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return sequence, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465eb258",
   "metadata": {},
   "source": [
    "# LSMT over CNN Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "852ce7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMOverCNN(nn.Module):\n",
    "\n",
    "    \"\"\"A CNN is used to process each image in a sequence and the extracted features are passed to the LSTM,\n",
    "    which, therefore, processes sequences of CNN-extracted features.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(LSTMOverCNN, self).__init__()\n",
    "\n",
    "        # The CNN architecture is a standard one consisting of two\n",
    "        # convolutional layers, each followed by ReLU and max pooling.\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Compute the output size after the CNN. This is necessary to set the input size of the LSTM correctly.\n",
    "        cnn_output_size = self._get_cnn_output_size()\n",
    "\n",
    "        # LSTM part\n",
    "        self.lstm = nn.LSTM(cnn_output_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def _get_cnn_output_size(self):\n",
    "        # Dummy pass to compute CNN output size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 28, 28)\n",
    "            dummy_output = self.cnn(dummy_input)\n",
    "            return dummy_output.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, channels, height, width)\n",
    "        batch_size, sequence_length, _, _, _ = x.size()\n",
    "\n",
    "        # Process each frame with the CNN\n",
    "        cnn_features = []\n",
    "        for t in range(sequence_length):\n",
    "            # Extract features for each image in the sequence\n",
    "            img_features = self.cnn(x[:, t, :, :, :])\n",
    "            img_features = img_features.view(batch_size, -1)\n",
    "            cnn_features.append(img_features)\n",
    "        cnn_features = torch.stack(cnn_features, dim=1)\n",
    "\n",
    "        # LSTM output\n",
    "        lstm_out, _ = self.lstm(cnn_features)\n",
    "        lstm_out = self.dropout(lstm_out[:, -1, :])  # Apply dropout to the output of the last time step\n",
    "\n",
    "        # Classifier\n",
    "        out = self.fc(lstm_out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0774f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sampling(mnist_data, size, num_classes=11):\n",
    "    print('balanced_sampling')\n",
    "    # Group data by labels\n",
    "    grouped_data = {label: [] for label in range(num_classes)}\n",
    "    for img, label in mnist_data:\n",
    "        grouped_data[label].append((img, label))\n",
    "\n",
    "    # Calculate the number of samples per class\n",
    "    samples_per_class = size // num_classes\n",
    "\n",
    "    # Initialize list for sampled data\n",
    "    sampled_data = []\n",
    "\n",
    "    for label, data in grouped_data.items():\n",
    "        data_len = len(data)\n",
    "        if data_len == 0:\n",
    "            print(f\"Warning: No data for class {label}. Skipping this class.\")\n",
    "            continue\n",
    "        if data_len >= samples_per_class:\n",
    "            sampled_data.extend(random.sample(data, samples_per_class))\n",
    "        else:\n",
    "            # Efficiently replicate data to meet the required number of samples\n",
    "            repeats = samples_per_class // data_len\n",
    "            remainder = samples_per_class % data_len\n",
    "            sampled_data.extend(data * repeats + random.sample(data, remainder))\n",
    "\n",
    "    # Shuffle the final dataset using Python's random.shuffle for compatibility\n",
    "    random.shuffle(sampled_data)\n",
    "    print('Done sampling.')\n",
    "    return sampled_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f40f77",
   "metadata": {},
   "source": [
    "# Train and Testing without batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8524b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with dataset size: 32000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       877\n",
      "           1       0.00      0.00      0.00       880\n",
      "           2       0.00      0.00      0.00       901\n",
      "           3       0.00      0.00      0.00       871\n",
      "           4       0.00      0.00      0.00       897\n",
      "           5       0.00      0.00      0.00       879\n",
      "           6       0.00      0.00      0.00       892\n",
      "           7       0.06      1.00      0.12       897\n",
      "           8       0.00      0.00      0.00       885\n",
      "           9       0.00      0.00      0.00       902\n",
      "          10       0.00      0.00      0.00      5650\n",
      "\n",
      "    accuracy                           0.06     14531\n",
      "   macro avg       0.01      0.09      0.01     14531\n",
      "weighted avg       0.00      0.06      0.01     14531\n",
      "\n",
      "Epoch 1, Step 0, Loss: 2.280029296875, F1: 0.010571098592877177, Accuracy: 0.06173009428119194, Time Elapsed: 172.87274074554443 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.92      0.70       877\n",
      "           1       0.60      0.96      0.74       880\n",
      "           2       0.61      0.38      0.47       901\n",
      "           3       0.60      0.31      0.41       871\n",
      "           4       0.58      0.90      0.70       897\n",
      "           5       0.57      0.57      0.57       879\n",
      "           6       0.62      0.04      0.07       892\n",
      "           7       0.60      0.74      0.66       897\n",
      "           8       0.80      0.01      0.02       885\n",
      "           9       0.00      0.00      0.00       902\n",
      "          10       0.38      0.50      0.43      5650\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.48      0.43     14531\n",
      "weighted avg       0.49      0.49      0.43     14531\n",
      "\n",
      "Epoch 1, Step 1000, Loss: 1.410060167312622, F1: 0.4341099744373069, Accuracy: 0.4863395499277407, Time Elapsed: 400.2401030063629 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66       877\n",
      "           1       0.63      0.34      0.44       880\n",
      "           2       0.62      0.66      0.64       901\n",
      "           3       0.54      0.93      0.69       871\n",
      "           4       0.64      0.60      0.62       897\n",
      "           5       0.60      0.57      0.59       879\n",
      "           6       0.62      0.86      0.72       892\n",
      "           7       0.61      0.27      0.38       897\n",
      "           8       0.60      0.58      0.59       885\n",
      "           9       0.64      0.52      0.57       902\n",
      "          10       0.40      0.39      0.40      5650\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.59      0.59      0.57     14531\n",
      "weighted avg       0.53      0.52      0.51     14531\n",
      "\n",
      "Epoch 1, Step 2000, Loss: 2.7623791694641113, F1: 0.5721797372038758, Accuracy: 0.5246713921959948, Time Elapsed: 630.1006469726562 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.96      0.73       877\n",
      "           1       0.61      0.68      0.64       880\n",
      "           2       0.61      0.82      0.70       901\n",
      "           3       0.59      0.81      0.68       871\n",
      "           4       0.62      0.45      0.52       897\n",
      "           5       0.60      0.69      0.64       879\n",
      "           6       0.62      0.94      0.75       892\n",
      "           7       0.61      0.70      0.65       897\n",
      "           8       0.59      0.84      0.69       885\n",
      "           9       0.64      0.48      0.55       902\n",
      "          10       0.40      0.26      0.32      5650\n",
      "\n",
      "    accuracy                           0.55     14531\n",
      "   macro avg       0.59      0.69      0.62     14531\n",
      "weighted avg       0.53      0.55      0.52     14531\n",
      "\n",
      "Epoch 1, Step 3000, Loss: 0.3804278075695038, F1: 0.6248101164042158, Accuracy: 0.5518546555639667, Time Elapsed: 854.1086070537567 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.25      0.35       877\n",
      "           1       0.61      0.65      0.63       880\n",
      "           2       0.63      0.63      0.63       901\n",
      "           3       0.59      0.83      0.69       871\n",
      "           4       0.63      0.72      0.67       897\n",
      "           5       0.62      0.29      0.39       879\n",
      "           6       0.63      0.77      0.69       892\n",
      "           7       0.62      0.57      0.60       897\n",
      "           8       0.64      0.09      0.16       885\n",
      "           9       0.64      0.51      0.57       902\n",
      "          10       0.40      0.49      0.44      5650\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.60      0.53      0.53     14531\n",
      "weighted avg       0.54      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 4000, Loss: 0.5463504791259766, F1: 0.5288012448882308, Accuracy: 0.5160002752735531, Time Elapsed: 1054.7323789596558 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.35      0.44       877\n",
      "           1       0.60      0.94      0.74       880\n",
      "           2       0.62      0.82      0.70       901\n",
      "           3       0.62      0.56      0.59       871\n",
      "           4       0.62      0.92      0.74       897\n",
      "           5       0.61      0.59      0.60       879\n",
      "           6       0.62      0.93      0.74       892\n",
      "           7       0.65      0.43      0.52       897\n",
      "           8       0.60      0.71      0.65       885\n",
      "           9       0.63      0.55      0.59       902\n",
      "          10       0.41      0.34      0.37      5650\n",
      "\n",
      "    accuracy                           0.55     14531\n",
      "   macro avg       0.60      0.65      0.61     14531\n",
      "weighted avg       0.54      0.55      0.53     14531\n",
      "\n",
      "Epoch 1, Step 5000, Loss: 0.8704878687858582, F1: 0.6070746275787902, Accuracy: 0.5482760993737527, Time Elapsed: 1262.307090997696 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.45      0.52       877\n",
      "           1       0.60      0.97      0.74       880\n",
      "           2       0.62      0.80      0.70       901\n",
      "           3       0.59      0.95      0.72       871\n",
      "           4       0.62      0.80      0.70       897\n",
      "           5       0.65      0.42      0.51       879\n",
      "           6       0.63      0.91      0.74       892\n",
      "           7       0.61      0.88      0.72       897\n",
      "           8       0.62      0.23      0.33       885\n",
      "           9       0.68      0.13      0.21       902\n",
      "          10       0.41      0.37      0.39      5650\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.60      0.63      0.57     14531\n",
      "weighted avg       0.54      0.54      0.51     14531\n",
      "\n",
      "Epoch 1, Step 6000, Loss: 0.2235528826713562, F1: 0.5714196965525943, Accuracy: 0.541394260546418, Time Elapsed: 1449.0277256965637 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       877\n",
      "           1       0.67      0.47      0.56       880\n",
      "           2       0.63      0.72      0.67       901\n",
      "           3       0.61      0.65      0.63       871\n",
      "           4       0.61      0.94      0.74       897\n",
      "           5       0.60      0.67      0.63       879\n",
      "           6       0.62      0.88      0.72       892\n",
      "           7       0.62      0.84      0.71       897\n",
      "           8       0.60      0.62      0.61       885\n",
      "           9       0.64      0.56      0.60       902\n",
      "          10       0.41      0.30      0.35      5650\n",
      "\n",
      "    accuracy                           0.56     14531\n",
      "   macro avg       0.60      0.68      0.63     14531\n",
      "weighted avg       0.54      0.56      0.54     14531\n",
      "\n",
      "Epoch 1, Step 7000, Loss: 0.9776231050491333, F1: 0.6286357198382186, Accuracy: 0.5572224898492877, Time Elapsed: 1637.90159201622 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.68       877\n",
      "           1       0.68      0.59      0.63       880\n",
      "           2       0.63      0.67      0.65       901\n",
      "           3       0.61      0.62      0.62       871\n",
      "           4       0.63      0.72      0.68       897\n",
      "           5       0.60      0.70      0.65       879\n",
      "           6       0.62      0.94      0.75       892\n",
      "           7       0.62      0.83      0.71       897\n",
      "           8       0.60      0.79      0.69       885\n",
      "           9       0.60      0.88      0.72       902\n",
      "          10       0.43      0.28      0.34      5650\n",
      "\n",
      "    accuracy                           0.57     14531\n",
      "   macro avg       0.60      0.71      0.64     14531\n",
      "weighted avg       0.55      0.57      0.55     14531\n",
      "\n",
      "Epoch 1, Step 8000, Loss: 1.1279009580612183, F1: 0.644990365303283, Accuracy: 0.5697474365150368, Time Elapsed: 1826.940085887909 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.61       877\n",
      "           1       0.61      0.91      0.73       880\n",
      "           2       0.64      0.41      0.50       901\n",
      "           3       0.62      0.63      0.63       871\n",
      "           4       0.62      0.75      0.68       897\n",
      "           5       0.60      0.59      0.59       879\n",
      "           6       0.64      0.57      0.60       892\n",
      "           7       0.66      0.62      0.64       897\n",
      "           8       0.62      0.27      0.38       885\n",
      "           9       0.62      0.72      0.67       902\n",
      "          10       0.41      0.42      0.41      5650\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.60      0.59      0.58     14531\n",
      "weighted avg       0.54      0.54      0.53     14531\n",
      "\n",
      "Epoch 1, Step 9000, Loss: 3.3615167140960693, F1: 0.5848346559362387, Accuracy: 0.5350629688252702, Time Elapsed: 2050.743387937546 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70       877\n",
      "           1       0.79      0.21      0.33       880\n",
      "           2       0.63      0.72      0.67       901\n",
      "           3       0.64      0.30      0.41       871\n",
      "           4       0.61      0.62      0.61       897\n",
      "           5       0.60      0.89      0.72       879\n",
      "           6       0.65      0.74      0.69       892\n",
      "           7       0.62      0.83      0.71       897\n",
      "           8       0.60      0.51      0.55       885\n",
      "           9       0.61      0.83      0.70       902\n",
      "          10       0.41      0.38      0.40      5650\n",
      "\n",
      "    accuracy                           0.55     14531\n",
      "   macro avg       0.61      0.63      0.59     14531\n",
      "weighted avg       0.55      0.55      0.53     14531\n",
      "\n",
      "Epoch 1, Step 10000, Loss: 0.5536870360374451, F1: 0.591482970547691, Accuracy: 0.5464868212786457, Time Elapsed: 2315.19043302536 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.08      0.14       877\n",
      "           1       0.60      0.97      0.75       880\n",
      "           2       0.62      0.89      0.73       901\n",
      "           3       0.60      0.86      0.71       871\n",
      "           4       0.61      0.96      0.74       897\n",
      "           5       0.66      0.33      0.44       879\n",
      "           6       0.65      0.46      0.54       892\n",
      "           7       0.60      0.92      0.72       897\n",
      "           8       0.53      0.97      0.69       885\n",
      "           9       0.61      0.91      0.73       902\n",
      "          10       0.41      0.27      0.33      5650\n",
      "\n",
      "    accuracy                           0.55     14531\n",
      "   macro avg       0.60      0.69      0.59     14531\n",
      "weighted avg       0.54      0.55      0.51     14531\n",
      "\n",
      "Epoch 1, Step 11000, Loss: 0.8111541867256165, F1: 0.5919213840454208, Accuracy: 0.5535751152708004, Time Elapsed: 2573.4517278671265 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.69       877\n",
      "           1       0.64      0.94      0.76       880\n",
      "           2       0.63      0.81      0.71       901\n",
      "           3       0.65      0.36      0.47       871\n",
      "           4       0.68      0.46      0.55       897\n",
      "           5       0.65      0.51      0.57       879\n",
      "           6       0.65      0.75      0.70       892\n",
      "           7       0.62      0.75      0.68       897\n",
      "           8       0.62      0.44      0.51       885\n",
      "           9       0.62      0.72      0.67       902\n",
      "          10       0.43      0.40      0.42      5650\n",
      "\n",
      "    accuracy                           0.56     14531\n",
      "   macro avg       0.62      0.63      0.61     14531\n",
      "weighted avg       0.56      0.56      0.55     14531\n",
      "\n",
      "Epoch 1, Step 12000, Loss: 1.918680191040039, F1: 0.6110065851177334, Accuracy: 0.5585988576147547, Time Elapsed: 2833.8198211193085 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.97      0.73       877\n",
      "           1       0.64      0.95      0.77       880\n",
      "           2       0.66      0.41      0.50       901\n",
      "           3       0.62      0.73      0.67       871\n",
      "           4       0.66      0.65      0.66       897\n",
      "           5       0.61      0.51      0.56       879\n",
      "           6       0.68      0.68      0.68       892\n",
      "           7       0.69      0.71      0.70       897\n",
      "           8       0.61      0.72      0.66       885\n",
      "           9       0.62      0.69      0.65       902\n",
      "          10       0.45      0.37      0.41      5650\n",
      "\n",
      "    accuracy                           0.57     14531\n",
      "   macro avg       0.62      0.67      0.63     14531\n",
      "weighted avg       0.56      0.57      0.56     14531\n",
      "\n",
      "Epoch 1, Step 13000, Loss: 0.6582598090171814, F1: 0.6342388832761405, Accuracy: 0.5731195375404308, Time Elapsed: 3091.989742040634 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       877\n",
      "           1       0.71      0.85      0.77       880\n",
      "           2       0.62      0.91      0.73       901\n",
      "           3       0.60      0.86      0.71       871\n",
      "           4       0.74      0.43      0.54       897\n",
      "           5       0.60      0.71      0.65       879\n",
      "           6       0.72      0.58      0.64       892\n",
      "           7       0.66      0.84      0.74       897\n",
      "           8       0.59      0.89      0.71       885\n",
      "           9       0.61      0.72      0.66       902\n",
      "          10       0.48      0.32      0.38      5650\n",
      "\n",
      "    accuracy                           0.59     14531\n",
      "   macro avg       0.63      0.73      0.66     14531\n",
      "weighted avg       0.58      0.59      0.57     14531\n",
      "\n",
      "Epoch 1, Step 14000, Loss: 1.6066585779190063, F1: 0.6593344280483046, Accuracy: 0.5924575046452412, Time Elapsed: 3356.719733953476 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       877\n",
      "           1       0.68      0.90      0.78       880\n",
      "           2       0.63      0.83      0.71       901\n",
      "           3       0.64      0.67      0.66       871\n",
      "           4       0.62      0.86      0.72       897\n",
      "           5       0.60      0.83      0.69       879\n",
      "           6       0.60      0.97      0.74       892\n",
      "           7       0.80      0.55      0.65       897\n",
      "           8       0.59      0.67      0.63       885\n",
      "           9       0.60      0.84      0.70       902\n",
      "          10       0.48      0.28      0.35      5650\n",
      "\n",
      "    accuracy                           0.59     14531\n",
      "   macro avg       0.62      0.75      0.67     14531\n",
      "weighted avg       0.57      0.59      0.56     14531\n",
      "\n",
      "Epoch 1, Step 15000, Loss: 1.0016058683395386, F1: 0.6677044235855064, Accuracy: 0.5940403275755282, Time Elapsed: 3609.359766960144 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.30      0.40       877\n",
      "           1       0.67      0.93      0.78       880\n",
      "           2       0.66      0.42      0.51       901\n",
      "           3       0.61      0.86      0.72       871\n",
      "           4       0.61      0.89      0.73       897\n",
      "           5       0.60      0.77      0.67       879\n",
      "           6       0.65      0.70      0.67       892\n",
      "           7       0.81      0.61      0.69       897\n",
      "           8       0.60      0.75      0.67       885\n",
      "           9       0.62      0.26      0.37       902\n",
      "          10       0.44      0.43      0.44      5650\n",
      "\n",
      "    accuracy                           0.56     14531\n",
      "   macro avg       0.62      0.63      0.60     14531\n",
      "weighted avg       0.57      0.56      0.55     14531\n",
      "\n",
      "Epoch 1, Step 16000, Loss: 0.6186349987983704, F1: 0.6042226229537744, Accuracy: 0.5643796022297157, Time Elapsed: 3897.2507331371307 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68       877\n",
      "           1       0.70      0.93      0.80       880\n",
      "           2       0.62      0.88      0.73       901\n",
      "           3       0.62      0.67      0.65       871\n",
      "           4       0.69      0.64      0.67       897\n",
      "           5       0.60      0.85      0.70       879\n",
      "           6       0.65      0.64      0.65       892\n",
      "           7       0.63      0.89      0.74       897\n",
      "           8       0.60      0.56      0.58       885\n",
      "           9       0.62      0.75      0.68       902\n",
      "          10       0.47      0.32      0.38      5650\n",
      "\n",
      "    accuracy                           0.59     14531\n",
      "   macro avg       0.62      0.72      0.66     14531\n",
      "weighted avg       0.57      0.59      0.57     14531\n",
      "\n",
      "Epoch 1, Step 17000, Loss: 0.41220879554748535, F1: 0.6591218192488102, Accuracy: 0.5899112242791273, Time Elapsed: 4178.6285808086395 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73       877\n",
      "           1       0.74      0.91      0.82       880\n",
      "           2       0.60      0.92      0.72       901\n",
      "           3       0.61      0.80      0.69       871\n",
      "           4       0.64      0.83      0.73       897\n",
      "           5       0.63      0.37      0.47       879\n",
      "           6       0.61      0.97      0.75       892\n",
      "           7       0.65      0.88      0.75       897\n",
      "           8       0.58      0.74      0.65       885\n",
      "           9       0.61      0.88      0.72       902\n",
      "          10       0.48      0.24      0.32      5650\n",
      "\n",
      "    accuracy                           0.60     14531\n",
      "   macro avg       0.61      0.77      0.67     14531\n",
      "weighted avg       0.57      0.60      0.55     14531\n",
      "\n",
      "Epoch 1, Step 18000, Loss: 0.37237149477005005, F1: 0.6680537758045193, Accuracy: 0.5972059734361022, Time Elapsed: 4426.374353885651 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.14      0.23       877\n",
      "           1       0.86      0.74      0.79       880\n",
      "           2       0.63      0.80      0.71       901\n",
      "           3       0.61      0.91      0.73       871\n",
      "           4       0.68      0.65      0.67       897\n",
      "           5       0.61      0.77      0.68       879\n",
      "           6       0.65      0.65      0.65       892\n",
      "           7       0.62      0.95      0.75       897\n",
      "           8       0.59      0.93      0.72       885\n",
      "           9       0.65      0.48      0.55       902\n",
      "          10       0.47      0.40      0.43      5650\n",
      "\n",
      "    accuracy                           0.59     14531\n",
      "   macro avg       0.64      0.68      0.63     14531\n",
      "weighted avg       0.58      0.59      0.56     14531\n",
      "\n",
      "Epoch 1, Step 19000, Loss: 0.6541927456855774, F1: 0.6282986596923738, Accuracy: 0.5852315738765398, Time Elapsed: 4656.461076974869 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       877\n",
      "           1       0.75      0.95      0.84       880\n",
      "           2       0.67      0.65      0.66       901\n",
      "           3       0.61      0.84      0.71       871\n",
      "           4       0.63      0.91      0.74       897\n",
      "           5       0.60      0.65      0.63       879\n",
      "           6       0.79      0.21      0.34       892\n",
      "           7       0.83      0.76      0.79       897\n",
      "           8       0.58      0.89      0.70       885\n",
      "           9       0.62      0.54      0.58       902\n",
      "          10       0.49      0.39      0.43      5650\n",
      "\n",
      "    accuracy                           0.60     14531\n",
      "   macro avg       0.65      0.70      0.65     14531\n",
      "weighted avg       0.60      0.60      0.58     14531\n",
      "\n",
      "Epoch 1, Step 20000, Loss: 0.22004303336143494, F1: 0.6489639357191563, Accuracy: 0.5992705250843026, Time Elapsed: 4869.274452924728 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73       877\n",
      "           1       0.75      0.91      0.82       880\n",
      "           2       0.69      0.57      0.62       901\n",
      "           3       0.64      0.62      0.63       871\n",
      "           4       0.64      0.85      0.73       897\n",
      "           5       0.59      0.88      0.71       879\n",
      "           6       0.63      0.95      0.75       892\n",
      "           7       0.79      0.76      0.78       897\n",
      "           8       0.60      0.73      0.66       885\n",
      "           9       0.61      0.87      0.72       902\n",
      "          10       0.52      0.31      0.39      5650\n",
      "\n",
      "    accuracy                           0.62     14531\n",
      "   macro avg       0.64      0.76      0.68     14531\n",
      "weighted avg       0.60      0.62      0.59     14531\n",
      "\n",
      "Epoch 1, Step 21000, Loss: 1.096400499343872, F1: 0.6847897846988334, Accuracy: 0.6153052095519923, Time Elapsed: 5093.664903879166 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       877\n",
      "           1       0.89      0.81      0.84       880\n",
      "           2       0.65      0.72      0.68       901\n",
      "           3       0.62      0.68      0.65       871\n",
      "           4       0.62      0.95      0.75       897\n",
      "           5       0.60      0.77      0.67       879\n",
      "           6       0.64      0.88      0.74       892\n",
      "           7       0.83      0.73      0.78       897\n",
      "           8       0.61      0.59      0.60       885\n",
      "           9       0.62      0.84      0.71       902\n",
      "          10       0.52      0.35      0.42      5650\n",
      "\n",
      "    accuracy                           0.62     14531\n",
      "   macro avg       0.65      0.75      0.69     14531\n",
      "weighted avg       0.61      0.62      0.60     14531\n",
      "\n",
      "Epoch 1, Step 22000, Loss: 0.025506021454930305, F1: 0.6874788848615483, Accuracy: 0.6185396738008396, Time Elapsed: 5352.409469842911 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       877\n",
      "           1       0.81      0.90      0.85       880\n",
      "           2       0.61      0.92      0.73       901\n",
      "           3       0.58      0.60      0.59       871\n",
      "           4       0.83      0.43      0.57       897\n",
      "           5       0.65      0.43      0.52       879\n",
      "           6       0.64      0.91      0.75       892\n",
      "           7       0.71      0.86      0.78       897\n",
      "           8       0.62      0.39      0.48       885\n",
      "           9       0.64      0.63      0.64       902\n",
      "          10       0.49      0.44      0.47      5650\n",
      "\n",
      "    accuracy                           0.60     14531\n",
      "   macro avg       0.65      0.67      0.64     14531\n",
      "weighted avg       0.60      0.60      0.59     14531\n",
      "\n",
      "Epoch 1, Step 23000, Loss: 0.13968490064144135, F1: 0.6444412615323075, Accuracy: 0.5991328883077558, Time Elapsed: 5609.807474851608 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       877\n",
      "           1       0.88      0.81      0.84       880\n",
      "           2       0.68      0.77      0.72       901\n",
      "           3       0.63      0.68      0.65       871\n",
      "           4       0.67      0.86      0.75       897\n",
      "           5       0.61      0.74      0.66       879\n",
      "           6       0.80      0.54      0.64       892\n",
      "           7       0.83      0.67      0.74       897\n",
      "           8       0.60      0.86      0.71       885\n",
      "           9       0.64      0.74      0.69       902\n",
      "          10       0.53      0.47      0.50      5650\n",
      "\n",
      "    accuracy                           0.63     14531\n",
      "   macro avg       0.68      0.70      0.68     14531\n",
      "weighted avg       0.63      0.63      0.62     14531\n",
      "\n",
      "Epoch 1, Step 24000, Loss: 0.8115374445915222, F1: 0.68323286163625, Accuracy: 0.6278301562177414, Time Elapsed: 5804.056263923645 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73       877\n",
      "           1       0.89      0.86      0.87       880\n",
      "           2       0.63      0.92      0.75       901\n",
      "           3       0.62      0.70      0.66       871\n",
      "           4       0.72      0.80      0.76       897\n",
      "           5       0.61      0.71      0.65       879\n",
      "           6       0.72      0.82      0.77       892\n",
      "           7       0.78      0.82      0.80       897\n",
      "           8       0.59      0.67      0.63       885\n",
      "           9       0.64      0.76      0.69       902\n",
      "          10       0.57      0.40      0.47      5650\n",
      "\n",
      "    accuracy                           0.64     14531\n",
      "   macro avg       0.67      0.76      0.71     14531\n",
      "weighted avg       0.64      0.64      0.63     14531\n",
      "\n",
      "Epoch 1, Step 25000, Loss: 0.5395590662956238, F1: 0.7072160528083398, Accuracy: 0.643039020026151, Time Elapsed: 6025.454904794693 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       877\n",
      "           1       0.80      0.86      0.83       880\n",
      "           2       0.69      0.75      0.72       901\n",
      "           3       0.62      0.72      0.67       871\n",
      "           4       0.67      0.93      0.78       897\n",
      "           5       0.59      0.84      0.70       879\n",
      "           6       0.72      0.80      0.76       892\n",
      "           7       0.75      0.87      0.81       897\n",
      "           8       0.59      0.80      0.68       885\n",
      "           9       0.62      0.76      0.68       902\n",
      "          10       0.55      0.39      0.46      5650\n",
      "\n",
      "    accuracy                           0.63     14531\n",
      "   macro avg       0.66      0.75      0.70     14531\n",
      "weighted avg       0.62      0.63      0.62     14531\n",
      "\n",
      "Epoch 1, Step 26000, Loss: 0.6327193975448608, F1: 0.6957196923255226, Accuracy: 0.632922716949969, Time Elapsed: 6322.162854909897 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73       877\n",
      "           1       0.89      0.77      0.83       880\n",
      "           2       0.65      0.78      0.71       901\n",
      "           3       0.67      0.46      0.55       871\n",
      "           4       0.67      0.93      0.78       897\n",
      "           5       0.67      0.04      0.08       879\n",
      "           6       0.79      0.68      0.73       892\n",
      "           7       0.81      0.77      0.79       897\n",
      "           8       0.59      0.70      0.64       885\n",
      "           9       0.62      0.84      0.71       902\n",
      "          10       0.52      0.50      0.51      5650\n",
      "\n",
      "    accuracy                           0.62     14531\n",
      "   macro avg       0.68      0.68      0.64     14531\n",
      "weighted avg       0.63      0.62      0.60     14531\n",
      "\n",
      "Epoch 1, Step 27000, Loss: 0.377421110868454, F1: 0.6418040863256884, Accuracy: 0.6199848599545799, Time Elapsed: 6579.322856903076 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       877\n",
      "           1       0.83      0.93      0.88       880\n",
      "           2       0.68      0.73      0.70       901\n",
      "           3       0.58      0.91      0.71       871\n",
      "           4       0.68      0.94      0.78       897\n",
      "           5       0.58      0.94      0.72       879\n",
      "           6       0.71      0.84      0.77       892\n",
      "           7       0.80      0.81      0.81       897\n",
      "           8       0.60      0.56      0.58       885\n",
      "           9       0.69      0.15      0.25       902\n",
      "          10       0.54      0.43      0.48      5650\n",
      "\n",
      "    accuracy                           0.63     14531\n",
      "   macro avg       0.66      0.72      0.67     14531\n",
      "weighted avg       0.62      0.63      0.61     14531\n",
      "\n",
      "Epoch 1, Step 28000, Loss: 0.3115997314453125, F1: 0.6670651192375264, Accuracy: 0.6269355171701879, Time Elapsed: 6824.273740053177 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       877\n",
      "           1       0.92      0.86      0.89       880\n",
      "           2       0.67      0.83      0.74       901\n",
      "           3       0.63      0.62      0.63       871\n",
      "           4       0.67      0.92      0.78       897\n",
      "           5       0.60      0.78      0.68       879\n",
      "           6       0.70      0.80      0.75       892\n",
      "           7       0.79      0.78      0.79       897\n",
      "           8       0.59      0.50      0.54       885\n",
      "           9       0.62      0.76      0.69       902\n",
      "          10       0.54      0.45      0.49      5650\n",
      "\n",
      "    accuracy                           0.63     14531\n",
      "   macro avg       0.67      0.73      0.69     14531\n",
      "weighted avg       0.63      0.63      0.63     14531\n",
      "\n",
      "Epoch 1, Step 29000, Loss: 0.5512747764587402, F1: 0.691809913216544, Accuracy: 0.6344367214919826, Time Elapsed: 7129.156941890717 seconds\n",
      "Epoch 1 completed. Time: 7132.579725027084\n",
      "Logger {'time': {0: 0.12718892097473145, 1000: 208.92403507232666, 2000: 438.7362759113312, 3000: 671.7206408977509, 4000: 887.0647280216217, 5000: 1096.2220559120178, 6000: 1295.4826979637146, 7000: 1483.3596329689026, 8000: 1674.128101825714, 9000: 1864.3266727924347, 10000: 2084.532036781311, 11000: 2360.4735898971558, 12000: 2620.8994538784027, 13000: 2876.231901884079, 14000: 3136.8588819503784, 15000: 3390.017795085907, 16000: 3658.3459248542786, 17000: 3942.116487979889, 18000: 4234.813258886337, 19000: 4464.502335071564, 20000: 4694.331110954285, 21000: 4902.593225002289, 22000: 5139.481256008148, 23000: 5403.663449764252, 24000: 5648.759278059006, 25000: 5837.449553966522, 26000: 6082.928087949753, 27000: 6371.317516088486, 28000: 6619.35609793663, 29000: 6865.495372056961}, 'loss': {0: 2.280029296875, 1000: 1.410060167312622, 2000: 2.7623791694641113, 3000: 0.3804278075695038, 4000: 0.5463504791259766, 5000: 0.8704878687858582, 6000: 0.2235528826713562, 7000: 0.9776231050491333, 8000: 1.1279009580612183, 9000: 3.3615167140960693, 10000: 0.5536870360374451, 11000: 0.8111541867256165, 12000: 1.918680191040039, 13000: 0.6582598090171814, 14000: 1.6066585779190063, 15000: 1.0016058683395386, 16000: 0.6186349987983704, 17000: 0.41220879554748535, 18000: 0.37237149477005005, 19000: 0.6541927456855774, 20000: 0.22004303336143494, 21000: 1.096400499343872, 22000: 0.025506021454930305, 23000: 0.13968490064144135, 24000: 0.8115374445915222, 25000: 0.5395590662956238, 26000: 0.6327193975448608, 27000: 0.377421110868454, 28000: 0.3115997314453125, 29000: 0.5512747764587402}, 'F1': {0: 0.010571098592877177, 1000: 0.4341099744373069, 2000: 0.5721797372038758, 3000: 0.6248101164042158, 4000: 0.5288012448882308, 5000: 0.6070746275787902, 6000: 0.5714196965525943, 7000: 0.6286357198382186, 8000: 0.644990365303283, 9000: 0.5848346559362387, 10000: 0.591482970547691, 11000: 0.5919213840454208, 12000: 0.6110065851177334, 13000: 0.6342388832761405, 14000: 0.6593344280483046, 15000: 0.6677044235855064, 16000: 0.6042226229537744, 17000: 0.6591218192488102, 18000: 0.6680537758045193, 19000: 0.6282986596923738, 20000: 0.6489639357191563, 21000: 0.6847897846988334, 22000: 0.6874788848615483, 23000: 0.6444412615323075, 24000: 0.68323286163625, 25000: 0.7072160528083398, 26000: 0.6957196923255226, 27000: 0.6418040863256884, 28000: 0.6670651192375264, 29000: 0.691809913216544}, 'Accuracy': {0: 0.06173009428119194, 1000: 0.4863395499277407, 2000: 0.5246713921959948, 3000: 0.5518546555639667, 4000: 0.5160002752735531, 5000: 0.5482760993737527, 6000: 0.541394260546418, 7000: 0.5572224898492877, 8000: 0.5697474365150368, 9000: 0.5350629688252702, 10000: 0.5464868212786457, 11000: 0.5535751152708004, 12000: 0.5585988576147547, 13000: 0.5731195375404308, 14000: 0.5924575046452412, 15000: 0.5940403275755282, 16000: 0.5643796022297157, 17000: 0.5899112242791273, 18000: 0.5972059734361022, 19000: 0.5852315738765398, 20000: 0.5992705250843026, 21000: 0.6153052095519923, 22000: 0.6185396738008396, 23000: 0.5991328883077558, 24000: 0.6278301562177414, 25000: 0.643039020026151, 26000: 0.632922716949969, 27000: 0.6199848599545799, 28000: 0.6269355171701879, 29000: 0.6344367214919826}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       877\n",
      "           1       0.73      0.98      0.84       880\n",
      "           2       0.68      0.72      0.70       901\n",
      "           3       0.62      0.77      0.69       871\n",
      "           4       0.64      0.93      0.76       897\n",
      "           5       0.60      0.69      0.64       879\n",
      "           6       0.67      0.87      0.76       892\n",
      "           7       0.76      0.84      0.80       897\n",
      "           8       0.60      0.52      0.56       885\n",
      "           9       0.64      0.71      0.67       902\n",
      "          10       0.53      0.38      0.44      5650\n",
      "\n",
      "    accuracy                           0.62     14531\n",
      "   macro avg       0.64      0.74      0.68     14531\n",
      "weighted avg       0.61      0.62      0.60     14531\n",
      "\n",
      "Epoch 2, Step 0, Loss: 0.10287901759147644, F1: 0.6831978179405686, Accuracy: 0.6212235909435001, Time Elapsed: 237.63374710083008 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.90      0.73       877\n",
      "           1       0.91      0.82      0.87       880\n",
      "           2       0.68      0.75      0.72       901\n",
      "           3       0.65      0.44      0.52       871\n",
      "           4       0.66      0.90      0.77       897\n",
      "           5       0.60      0.87      0.71       879\n",
      "           6       0.84      0.65      0.73       892\n",
      "           7       0.72      0.88      0.79       897\n",
      "           8       0.60      0.66      0.63       885\n",
      "           9       0.65      0.58      0.61       902\n",
      "          10       0.54      0.46      0.50      5650\n",
      "\n",
      "    accuracy                           0.64     14531\n",
      "   macro avg       0.68      0.72      0.69     14531\n",
      "weighted avg       0.63      0.64      0.63     14531\n",
      "\n",
      "Epoch 2, Step 1000, Loss: 1.1300772428512573, F1: 0.6881360419751041, Accuracy: 0.6353313605395362, Time Elapsed: 505.01856994628906 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68       877\n",
      "           1       0.91      0.87      0.89       880\n",
      "           2       0.70      0.68      0.69       901\n",
      "           3       0.65      0.60      0.62       871\n",
      "           4       0.76      0.78      0.77       897\n",
      "           5       0.61      0.73      0.66       879\n",
      "           6       0.71      0.87      0.79       892\n",
      "           7       0.88      0.63      0.73       897\n",
      "           8       0.62      0.69      0.65       885\n",
      "           9       0.65      0.76      0.70       902\n",
      "          10       0.56      0.51      0.53      5650\n",
      "\n",
      "    accuracy                           0.65     14531\n",
      "   macro avg       0.70      0.72      0.70     14531\n",
      "weighted avg       0.65      0.65      0.65     14531\n",
      "\n",
      "Epoch 2, Step 2000, Loss: 1.428318738937378, F1: 0.7021051660716694, Accuracy: 0.6493014933590255, Time Elapsed: 712.8708040714264 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.96      0.74       877\n",
      "           1       0.88      0.85      0.86       880\n",
      "           2       0.63      0.88      0.74       901\n",
      "           3       0.65      0.77      0.70       871\n",
      "           4       0.78      0.74      0.76       897\n",
      "           5       0.61      0.79      0.69       879\n",
      "           6       0.69      0.82      0.75       892\n",
      "           7       0.76      0.74      0.75       897\n",
      "           8       0.60      0.67      0.63       885\n",
      "           9       0.68      0.65      0.66       902\n",
      "          10       0.57      0.42      0.49      5650\n",
      "\n",
      "    accuracy                           0.65     14531\n",
      "   macro avg       0.68      0.75      0.71     14531\n",
      "weighted avg       0.64      0.65      0.63     14531\n",
      "\n",
      "Epoch 2, Step 3000, Loss: 0.34623801708221436, F1: 0.7070222150540171, Accuracy: 0.6459982107219049, Time Elapsed: 910.1248121261597 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       877\n",
      "           1       0.85      0.81      0.83       880\n",
      "           2       0.68      0.77      0.72       901\n",
      "           3       0.62      0.87      0.72       871\n",
      "           4       0.71      0.90      0.79       897\n",
      "           5       0.71      0.25      0.37       879\n",
      "           6       0.74      0.84      0.78       892\n",
      "           7       0.74      0.83      0.78       897\n",
      "           8       0.62      0.64      0.63       885\n",
      "           9       0.62      0.87      0.72       902\n",
      "          10       0.55      0.47      0.50      5650\n",
      "\n",
      "    accuracy                           0.64     14531\n",
      "   macro avg       0.68      0.72      0.68     14531\n",
      "weighted avg       0.64      0.64      0.63     14531\n",
      "\n",
      "Epoch 2, Step 4000, Loss: 0.28522011637687683, F1: 0.6842608131307875, Accuracy: 0.6395292822242103, Time Elapsed: 1162.5951750278473 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58       877\n",
      "           1       0.83      0.89      0.86       880\n",
      "           2       0.69      0.76      0.72       901\n",
      "           3       0.62      0.56      0.59       871\n",
      "           4       0.71      0.88      0.79       897\n",
      "           5       0.64      0.62      0.63       879\n",
      "           6       0.64      0.93      0.76       892\n",
      "           7       0.84      0.63      0.72       897\n",
      "           8       0.61      0.87      0.72       885\n",
      "           9       0.66      0.75      0.70       902\n",
      "          10       0.54      0.47      0.50      5650\n",
      "\n",
      "    accuracy                           0.63     14531\n",
      "   macro avg       0.68      0.72      0.69     14531\n",
      "weighted avg       0.63      0.63      0.63     14531\n",
      "\n",
      "Epoch 2, Step 5000, Loss: 1.0546140670776367, F1: 0.6869871240172901, Accuracy: 0.634711995045076, Time Elapsed: 1385.8898289203644 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       877\n",
      "           1       0.75      0.94      0.83       880\n",
      "           2       0.66      0.77      0.71       901\n",
      "           3       0.59      0.93      0.72       871\n",
      "           4       0.80      0.75      0.77       897\n",
      "           5       0.66      0.41      0.51       879\n",
      "           6       0.72      0.79      0.75       892\n",
      "           7       0.68      0.87      0.76       897\n",
      "           8       0.61      0.60      0.60       885\n",
      "           9       0.71      0.19      0.30       902\n",
      "          10       0.51      0.49      0.50      5650\n",
      "\n",
      "    accuracy                           0.62     14531\n",
      "   macro avg       0.67      0.68      0.65     14531\n",
      "weighted avg       0.62      0.62      0.60     14531\n",
      "\n",
      "Epoch 2, Step 6000, Loss: 0.564067542552948, F1: 0.6487946837098794, Accuracy: 0.6153740279402656, Time Elapsed: 1580.365082025528 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       877\n",
      "           1       0.89      0.72      0.80       880\n",
      "           2       0.65      0.85      0.74       901\n",
      "           3       0.61      0.90      0.72       871\n",
      "           4       0.71      0.90      0.79       897\n",
      "           5       0.63      0.81      0.71       879\n",
      "           6       0.68      0.81      0.74       892\n",
      "           7       0.76      0.85      0.80       897\n",
      "           8       0.61      0.70      0.65       885\n",
      "           9       0.63      0.77      0.69       902\n",
      "          10       0.58      0.37      0.45      5650\n",
      "\n",
      "    accuracy                           0.64     14531\n",
      "   macro avg       0.67      0.78      0.71     14531\n",
      "weighted avg       0.64      0.64      0.63     14531\n",
      "\n",
      "Epoch 2, Step 7000, Loss: 0.31321650743484497, F1: 0.7105095519933727, Accuracy: 0.644621842956438, Time Elapsed: 1769.578752040863 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.57      0.62       877\n",
      "           1       0.82      0.91      0.87       880\n",
      "           2       0.69      0.77      0.73       901\n",
      "           3       0.64      0.75      0.69       871\n",
      "           4       0.75      0.83      0.79       897\n",
      "           5       0.65      0.76      0.70       879\n",
      "           6       0.66      0.92      0.76       892\n",
      "           7       0.71      0.84      0.77       897\n",
      "           8       0.61      0.81      0.70       885\n",
      "           9       0.62      0.89      0.73       902\n",
      "          10       0.59      0.42      0.49      5650\n",
      "\n",
      "    accuracy                           0.66     14531\n",
      "   macro avg       0.68      0.77      0.71     14531\n",
      "weighted avg       0.65      0.66      0.64     14531\n",
      "\n",
      "Epoch 2, Step 8000, Loss: 0.19963355362415314, F1: 0.7138029701547475, Accuracy: 0.6555639666919001, Time Elapsed: 1969.0455718040466 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       877\n",
      "           1       0.82      0.95      0.88       880\n",
      "           2       0.73      0.62      0.67       901\n",
      "           3       0.66      0.58      0.62       871\n",
      "           4       0.75      0.84      0.79       897\n",
      "           5       0.63      0.85      0.72       879\n",
      "           6       0.77      0.75      0.76       892\n",
      "           7       0.84      0.71      0.77       897\n",
      "           8       0.61      0.63      0.62       885\n",
      "           9       0.66      0.73      0.69       902\n",
      "          10       0.57      0.51      0.54      5650\n",
      "\n",
      "    accuracy                           0.66     14531\n",
      "   macro avg       0.70      0.73      0.71     14531\n",
      "weighted avg       0.66      0.66      0.65     14531\n",
      "\n",
      "Epoch 2, Step 9000, Loss: 5.0753045082092285, F1: 0.7067951622856253, Accuracy: 0.656940334457367, Time Elapsed: 2215.118796825409 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.89      0.73       877\n",
      "           1       0.89      0.94      0.91       880\n",
      "           2       0.68      0.77      0.73       901\n",
      "           3       0.71      0.43      0.54       871\n",
      "           4       0.78      0.74      0.76       897\n",
      "           5       0.62      0.89      0.73       879\n",
      "           6       0.75      0.83      0.79       892\n",
      "           7       0.77      0.77      0.77       897\n",
      "           8       0.61      0.74      0.67       885\n",
      "           9       0.63      0.83      0.72       902\n",
      "          10       0.59      0.47      0.52      5650\n",
      "\n",
      "    accuracy                           0.66     14531\n",
      "   macro avg       0.69      0.76      0.71     14531\n",
      "weighted avg       0.66      0.66      0.65     14531\n",
      "\n",
      "Epoch 2, Step 10000, Loss: 1.6686426401138306, F1: 0.7143679287819553, Accuracy: 0.6624458055192347, Time Elapsed: 2430.59716796875 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.55      0.62       877\n",
      "           1       0.92      0.85      0.88       880\n",
      "           2       0.65      0.88      0.75       901\n",
      "           3       0.62      0.90      0.73       871\n",
      "           4       0.73      0.85      0.79       897\n",
      "           5       0.67      0.78      0.72       879\n",
      "           6       0.76      0.79      0.78       892\n",
      "           7       0.70      0.88      0.78       897\n",
      "           8       0.60      0.91      0.72       885\n",
      "           9       0.63      0.83      0.72       902\n",
      "          10       0.62      0.43      0.51      5650\n",
      "\n",
      "    accuracy                           0.67     14531\n",
      "   macro avg       0.69      0.79      0.73     14531\n",
      "weighted avg       0.67      0.67      0.66     14531\n",
      "\n",
      "Epoch 2, Step 11000, Loss: 0.35252752900123596, F1: 0.7272957019672884, Accuracy: 0.6699470098410295, Time Elapsed: 2616.5310809612274 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.86      0.72       877\n",
      "           1       0.92      0.94      0.93       880\n",
      "           2       0.63      0.66      0.64       901\n",
      "           3       0.66      0.59      0.62       871\n",
      "           4       0.80      0.72      0.76       897\n",
      "           5       0.67      0.79      0.73       879\n",
      "           6       0.73      0.83      0.78       892\n",
      "           7       0.73      0.84      0.78       897\n",
      "           8       0.61      0.50      0.55       885\n",
      "           9       0.62      0.87      0.73       902\n",
      "          10       0.58      0.50      0.54      5650\n",
      "\n",
      "    accuracy                           0.66     14531\n",
      "   macro avg       0.69      0.74      0.71     14531\n",
      "weighted avg       0.65      0.66      0.65     14531\n",
      "\n",
      "Epoch 2, Step 12000, Loss: 2.254777193069458, F1: 0.7069526391237981, Accuracy: 0.6580414286697406, Time Elapsed: 2820.6988179683685 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       877\n",
      "           1       0.95      0.86      0.90       880\n",
      "           2       0.69      0.77      0.73       901\n",
      "           3       0.64      0.60      0.62       871\n",
      "           4       0.83      0.67      0.74       897\n",
      "           5       0.65      0.68      0.67       879\n",
      "           6       0.75      0.74      0.75       892\n",
      "           7       0.86      0.67      0.75       897\n",
      "           8       0.61      0.69      0.65       885\n",
      "           9       0.69      0.53      0.60       902\n",
      "          10       0.56      0.56      0.56      5650\n",
      "\n",
      "    accuracy                           0.65     14531\n",
      "   macro avg       0.71      0.70      0.70     14531\n",
      "weighted avg       0.66      0.65      0.65     14531\n",
      "\n",
      "Epoch 2, Step 13000, Loss: 0.6772577166557312, F1: 0.699733151078335, Accuracy: 0.6546005092560733, Time Elapsed: 3027.903263092041 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.94      0.74       877\n",
      "           1       0.86      0.95      0.90       880\n",
      "           2       0.69      0.85      0.76       901\n",
      "           3       0.64      0.84      0.73       871\n",
      "           4       0.83      0.75      0.79       897\n",
      "           5       0.62      0.89      0.73       879\n",
      "           6       0.77      0.71      0.74       892\n",
      "           7       0.78      0.82      0.80       897\n",
      "           8       0.60      0.87      0.71       885\n",
      "           9       0.67      0.67      0.67       902\n",
      "          10       0.64      0.44      0.52      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.70      0.79      0.74     14531\n",
      "weighted avg       0.68      0.68      0.67     14531\n",
      "\n",
      "Epoch 2, Step 14000, Loss: 1.349919319152832, F1: 0.7353251801612332, Accuracy: 0.6784804899869245, Time Elapsed: 3255.545261859894 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.73       877\n",
      "           1       0.90      0.84      0.87       880\n",
      "           2       0.66      0.80      0.73       901\n",
      "           3       0.67      0.84      0.74       871\n",
      "           4       0.75      0.89      0.81       897\n",
      "           5       0.66      0.83      0.73       879\n",
      "           6       0.64      0.94      0.76       892\n",
      "           7       0.84      0.78      0.81       897\n",
      "           8       0.62      0.57      0.60       885\n",
      "           9       0.65      0.74      0.69       902\n",
      "          10       0.62      0.45      0.52      5650\n",
      "\n",
      "    accuracy                           0.67     14531\n",
      "   macro avg       0.69      0.78      0.73     14531\n",
      "weighted avg       0.67      0.67      0.66     14531\n",
      "\n",
      "Epoch 2, Step 15000, Loss: 1.7990700006484985, F1: 0.7271223104704464, Accuracy: 0.6720115614892299, Time Elapsed: 3529.8726930618286 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       877\n",
      "           1       0.78      0.96      0.86       880\n",
      "           2       0.77      0.47      0.59       901\n",
      "           3       0.65      0.84      0.73       871\n",
      "           4       0.66      0.91      0.77       897\n",
      "           5       0.65      0.64      0.65       879\n",
      "           6       0.75      0.75      0.75       892\n",
      "           7       0.80      0.77      0.79       897\n",
      "           8       0.60      0.67      0.64       885\n",
      "           9       0.66      0.62      0.64       902\n",
      "          10       0.57      0.53      0.55      5650\n",
      "\n",
      "    accuracy                           0.65     14531\n",
      "   macro avg       0.69      0.71      0.70     14531\n",
      "weighted avg       0.65      0.65      0.65     14531\n",
      "\n",
      "Epoch 2, Step 16000, Loss: 0.25255098938941956, F1: 0.6966769095550513, Accuracy: 0.653361778267153, Time Elapsed: 3767.65141415596 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74       877\n",
      "           1       0.80      0.91      0.85       880\n",
      "           2       0.66      0.83      0.73       901\n",
      "           3       0.67      0.64      0.65       871\n",
      "           4       0.79      0.81      0.80       897\n",
      "           5       0.59      0.90      0.71       879\n",
      "           6       0.76      0.80      0.78       892\n",
      "           7       0.65      0.95      0.77       897\n",
      "           8       0.62      0.43      0.51       885\n",
      "           9       0.68      0.67      0.68       902\n",
      "          10       0.59      0.46      0.52      5650\n",
      "\n",
      "    accuracy                           0.65     14531\n",
      "   macro avg       0.68      0.75      0.70     14531\n",
      "weighted avg       0.65      0.65      0.64     14531\n",
      "\n",
      "Epoch 2, Step 17000, Loss: 0.7372279167175293, F1: 0.7038643086515489, Accuracy: 0.6546693276443466, Time Elapsed: 4020.7153639793396 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74       877\n",
      "           1       0.88      0.93      0.91       880\n",
      "           2       0.63      0.91      0.75       901\n",
      "           3       0.68      0.82      0.74       871\n",
      "           4       0.74      0.87      0.80       897\n",
      "           5       0.75      0.40      0.53       879\n",
      "           6       0.69      0.92      0.79       892\n",
      "           7       0.76      0.84      0.80       897\n",
      "           8       0.64      0.69      0.66       885\n",
      "           9       0.69      0.74      0.72       902\n",
      "          10       0.62      0.49      0.54      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.70      0.77      0.73     14531\n",
      "weighted avg       0.68      0.68      0.67     14531\n",
      "\n",
      "Epoch 2, Step 18000, Loss: 0.004264547023922205, F1: 0.7253037217341994, Accuracy: 0.6785493083751979, Time Elapsed: 4486.7278418540955 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       877\n",
      "           1       0.89      0.88      0.89       880\n",
      "           2       0.65      0.85      0.74       901\n",
      "           3       0.73      0.72      0.72       871\n",
      "           4       0.73      0.91      0.81       897\n",
      "           5       0.71      0.71      0.71       879\n",
      "           6       0.73      0.80      0.76       892\n",
      "           7       0.73      0.86      0.79       897\n",
      "           8       0.60      0.88      0.71       885\n",
      "           9       0.73      0.65      0.69       902\n",
      "          10       0.63      0.51      0.57      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.71      0.77      0.74     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 2, Step 19000, Loss: 0.37153932452201843, F1: 0.7360502109932668, Accuracy: 0.6877021540155529, Time Elapsed: 4675.712303876877 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.92      0.74       877\n",
      "           1       0.84      0.93      0.88       880\n",
      "           2       0.72      0.56      0.63       901\n",
      "           3       0.67      0.70      0.68       871\n",
      "           4       0.69      0.93      0.79       897\n",
      "           5       0.68      0.64      0.66       879\n",
      "           6       0.79      0.55      0.65       892\n",
      "           7       0.78      0.85      0.81       897\n",
      "           8       0.59      0.83      0.69       885\n",
      "           9       0.67      0.72      0.70       902\n",
      "          10       0.58      0.49      0.53      5650\n",
      "\n",
      "    accuracy                           0.66     14531\n",
      "   macro avg       0.69      0.74      0.71     14531\n",
      "weighted avg       0.66      0.66      0.65     14531\n",
      "\n",
      "Epoch 2, Step 20000, Loss: 0.005770690273493528, F1: 0.7052981519823466, Accuracy: 0.6563209689629069, Time Elapsed: 4873.996627092361 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.71       877\n",
      "           1       0.86      0.93      0.89       880\n",
      "           2       0.69      0.71      0.70       901\n",
      "           3       0.71      0.63      0.67       871\n",
      "           4       0.68      0.92      0.79       897\n",
      "           5       0.64      0.81      0.71       879\n",
      "           6       0.66      0.94      0.78       892\n",
      "           7       0.79      0.82      0.81       897\n",
      "           8       0.62      0.59      0.60       885\n",
      "           9       0.66      0.80      0.73       902\n",
      "          10       0.60      0.46      0.52      5650\n",
      "\n",
      "    accuracy                           0.67     14531\n",
      "   macro avg       0.69      0.76      0.72     14531\n",
      "weighted avg       0.66      0.67      0.65     14531\n",
      "\n",
      "Epoch 2, Step 21000, Loss: 1.1706221103668213, F1: 0.7191866307170678, Accuracy: 0.6660243617094488, Time Elapsed: 5062.946202993393 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.74       877\n",
      "           1       0.86      0.95      0.90       880\n",
      "           2       0.67      0.72      0.69       901\n",
      "           3       0.70      0.72      0.71       871\n",
      "           4       0.71      0.88      0.78       897\n",
      "           5       0.68      0.78      0.73       879\n",
      "           6       0.74      0.87      0.80       892\n",
      "           7       0.86      0.66      0.75       897\n",
      "           8       0.64      0.46      0.54       885\n",
      "           9       0.63      0.89      0.74       902\n",
      "          10       0.61      0.51      0.55      5650\n",
      "\n",
      "    accuracy                           0.67     14531\n",
      "   macro avg       0.70      0.76      0.72     14531\n",
      "weighted avg       0.67      0.67      0.67     14531\n",
      "\n",
      "Epoch 2, Step 22000, Loss: 0.0030441395938396454, F1: 0.7210900016410111, Accuracy: 0.6749707521849838, Time Elapsed: 5250.212333917618 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.93      0.74       877\n",
      "           1       0.89      0.90      0.90       880\n",
      "           2       0.62      0.91      0.74       901\n",
      "           3       0.68      0.77      0.72       871\n",
      "           4       0.84      0.69      0.75       897\n",
      "           5       0.68      0.71      0.69       879\n",
      "           6       0.74      0.85      0.79       892\n",
      "           7       0.79      0.84      0.82       897\n",
      "           8       0.64      0.61      0.63       885\n",
      "           9       0.66      0.84      0.74       902\n",
      "          10       0.62      0.48      0.54      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.71      0.78      0.73     14531\n",
      "weighted avg       0.68      0.68      0.67     14531\n",
      "\n",
      "Epoch 2, Step 23000, Loss: 0.2343408465385437, F1: 0.7325018639925794, Accuracy: 0.6790998554813846, Time Elapsed: 5436.480835914612 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69       877\n",
      "           1       0.93      0.85      0.89       880\n",
      "           2       0.69      0.72      0.70       901\n",
      "           3       0.69      0.79      0.73       871\n",
      "           4       0.74      0.90      0.81       897\n",
      "           5       0.64      0.83      0.73       879\n",
      "           6       0.73      0.88      0.80       892\n",
      "           7       0.85      0.78      0.81       897\n",
      "           8       0.60      0.83      0.70       885\n",
      "           9       0.68      0.76      0.72       902\n",
      "          10       0.64      0.52      0.57      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.72      0.78      0.74     14531\n",
      "weighted avg       0.69      0.69      0.69     14531\n",
      "\n",
      "Epoch 2, Step 24000, Loss: 0.4597536027431488, F1: 0.7415726365273823, Accuracy: 0.6914183469823136, Time Elapsed: 5624.99334692955 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.72       877\n",
      "           1       0.95      0.81      0.88       880\n",
      "           2       0.63      0.89      0.74       901\n",
      "           3       0.64      0.89      0.74       871\n",
      "           4       0.79      0.80      0.79       897\n",
      "           5       0.68      0.74      0.71       879\n",
      "           6       0.78      0.74      0.76       892\n",
      "           7       0.86      0.78      0.82       897\n",
      "           8       0.64      0.67      0.65       885\n",
      "           9       0.70      0.80      0.75       902\n",
      "          10       0.63      0.51      0.56      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.72      0.77      0.74     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 2, Step 25000, Loss: 0.3055524528026581, F1: 0.7387944513943414, Accuracy: 0.6867386965797261, Time Elapsed: 5812.839465141296 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65       877\n",
      "           1       0.82      0.94      0.88       880\n",
      "           2       0.73      0.66      0.69       901\n",
      "           3       0.71      0.72      0.72       871\n",
      "           4       0.75      0.90      0.82       897\n",
      "           5       0.67      0.83      0.74       879\n",
      "           6       0.73      0.87      0.80       892\n",
      "           7       0.82      0.84      0.83       897\n",
      "           8       0.62      0.84      0.71       885\n",
      "           9       0.67      0.81      0.73       902\n",
      "          10       0.64      0.53      0.58      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.71      0.77      0.74     14531\n",
      "weighted avg       0.69      0.69      0.69     14531\n",
      "\n",
      "Epoch 2, Step 26000, Loss: 0.22920577228069305, F1: 0.7393854329072805, Accuracy: 0.6932764434656941, Time Elapsed: 6001.1676189899445 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76       877\n",
      "           1       0.93      0.90      0.91       880\n",
      "           2       0.70      0.70      0.70       901\n",
      "           3       0.74      0.65      0.69       871\n",
      "           4       0.78      0.80      0.79       897\n",
      "           5       0.85      0.20      0.32       879\n",
      "           6       0.84      0.70      0.76       892\n",
      "           7       0.77      0.89      0.83       897\n",
      "           8       0.62      0.78      0.69       885\n",
      "           9       0.72      0.67      0.69       902\n",
      "          10       0.59      0.63      0.61      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.74      0.71      0.70     14531\n",
      "weighted avg       0.70      0.68      0.67     14531\n",
      "\n",
      "Epoch 2, Step 27000, Loss: 0.14911597967147827, F1: 0.7048850578525401, Accuracy: 0.682334319730232, Time Elapsed: 6187.625411987305 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.78      0.73       877\n",
      "           1       0.94      0.85      0.89       880\n",
      "           2       0.67      0.77      0.72       901\n",
      "           3       0.61      0.94      0.74       871\n",
      "           4       0.72      0.89      0.80       897\n",
      "           5       0.58      0.97      0.73       879\n",
      "           6       0.75      0.85      0.80       892\n",
      "           7       0.85      0.76      0.80       897\n",
      "           8       0.64      0.55      0.59       885\n",
      "           9       0.78      0.26      0.40       902\n",
      "          10       0.60      0.52      0.55      5650\n",
      "\n",
      "    accuracy                           0.67     14531\n",
      "   macro avg       0.71      0.74      0.70     14531\n",
      "weighted avg       0.67      0.67      0.65     14531\n",
      "\n",
      "Epoch 2, Step 28000, Loss: 0.04238159954547882, F1: 0.7037128802698874, Accuracy: 0.6665749088156355, Time Elapsed: 6374.592964887619 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.73       877\n",
      "           1       0.95      0.87      0.91       880\n",
      "           2       0.65      0.86      0.74       901\n",
      "           3       0.67      0.75      0.70       871\n",
      "           4       0.73      0.91      0.81       897\n",
      "           5       0.66      0.89      0.76       879\n",
      "           6       0.74      0.82      0.78       892\n",
      "           7       0.83      0.78      0.81       897\n",
      "           8       0.66      0.56      0.60       885\n",
      "           9       0.65      0.82      0.73       902\n",
      "          10       0.64      0.51      0.57      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.71      0.78      0.74     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 2, Step 29000, Loss: 1.1927471160888672, F1: 0.7388707435465546, Accuracy: 0.6903860711582135, Time Elapsed: 6563.047831773758 seconds\n",
      "Epoch 2 completed. Time: 6565.879503965378\n",
      "Logger {'time': {0: 0.04438304901123047, 1000: 298.70805311203003, 2000: 551.9582109451294, 3000: 743.0100178718567, 4000: 956.1607320308685, 5000: 1198.6289880275726, 6000: 1422.286427974701, 7000: 1615.559110879898, 8000: 1804.4732580184937, 9000: 2003.9667301177979, 10000: 2257.008826971054, 11000: 2473.992837905884, 12000: 2649.0732209682465, 13000: 2858.8945150375366, 14000: 3062.771139860153, 15000: 3307.4640510082245, 16000: 3562.132239818573, 17000: 3809.1583790779114, 18000: 4075.300420999527, 19000: 4520.095376968384, 20000: 4709.286844968796, 21000: 4907.354490995407, 22000: 5096.420914888382, 23000: 5283.451799869537, 24000: 5469.89145898819, 25000: 5658.4889879226685, 26000: 5845.960500001907, 27000: 6034.462641000748, 28000: 6220.583326101303, 29000: 6408.259156942368}, 'loss': {0: 0.10287901759147644, 1000: 1.1300772428512573, 2000: 1.428318738937378, 3000: 0.34623801708221436, 4000: 0.28522011637687683, 5000: 1.0546140670776367, 6000: 0.564067542552948, 7000: 0.31321650743484497, 8000: 0.19963355362415314, 9000: 5.0753045082092285, 10000: 1.6686426401138306, 11000: 0.35252752900123596, 12000: 2.254777193069458, 13000: 0.6772577166557312, 14000: 1.349919319152832, 15000: 1.7990700006484985, 16000: 0.25255098938941956, 17000: 0.7372279167175293, 18000: 0.004264547023922205, 19000: 0.37153932452201843, 20000: 0.005770690273493528, 21000: 1.1706221103668213, 22000: 0.0030441395938396454, 23000: 0.2343408465385437, 24000: 0.4597536027431488, 25000: 0.3055524528026581, 26000: 0.22920577228069305, 27000: 0.14911597967147827, 28000: 0.04238159954547882, 29000: 1.1927471160888672}, 'F1': {0: 0.6831978179405686, 1000: 0.6881360419751041, 2000: 0.7021051660716694, 3000: 0.7070222150540171, 4000: 0.6842608131307875, 5000: 0.6869871240172901, 6000: 0.6487946837098794, 7000: 0.7105095519933727, 8000: 0.7138029701547475, 9000: 0.7067951622856253, 10000: 0.7143679287819553, 11000: 0.7272957019672884, 12000: 0.7069526391237981, 13000: 0.699733151078335, 14000: 0.7353251801612332, 15000: 0.7271223104704464, 16000: 0.6966769095550513, 17000: 0.7038643086515489, 18000: 0.7253037217341994, 19000: 0.7360502109932668, 20000: 0.7052981519823466, 21000: 0.7191866307170678, 22000: 0.7210900016410111, 23000: 0.7325018639925794, 24000: 0.7415726365273823, 25000: 0.7387944513943414, 26000: 0.7393854329072805, 27000: 0.7048850578525401, 28000: 0.7037128802698874, 29000: 0.7388707435465546}, 'Accuracy': {0: 0.6212235909435001, 1000: 0.6353313605395362, 2000: 0.6493014933590255, 3000: 0.6459982107219049, 4000: 0.6395292822242103, 5000: 0.634711995045076, 6000: 0.6153740279402656, 7000: 0.644621842956438, 8000: 0.6555639666919001, 9000: 0.656940334457367, 10000: 0.6624458055192347, 11000: 0.6699470098410295, 12000: 0.6580414286697406, 13000: 0.6546005092560733, 14000: 0.6784804899869245, 15000: 0.6720115614892299, 16000: 0.653361778267153, 17000: 0.6546693276443466, 18000: 0.6785493083751979, 19000: 0.6877021540155529, 20000: 0.6563209689629069, 21000: 0.6660243617094488, 22000: 0.6749707521849838, 23000: 0.6790998554813846, 24000: 0.6914183469823136, 25000: 0.6867386965797261, 26000: 0.6932764434656941, 27000: 0.682334319730232, 28000: 0.6665749088156355, 29000: 0.6903860711582135}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       877\n",
      "           1       0.86      0.95      0.90       880\n",
      "           2       0.67      0.81      0.74       901\n",
      "           3       0.67      0.76      0.71       871\n",
      "           4       0.71      0.93      0.81       897\n",
      "           5       0.69      0.85      0.76       879\n",
      "           6       0.72      0.86      0.79       892\n",
      "           7       0.82      0.86      0.84       897\n",
      "           8       0.64      0.70      0.67       885\n",
      "           9       0.66      0.79      0.72       902\n",
      "          10       0.66      0.49      0.56      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.71      0.80      0.75     14531\n",
      "weighted avg       0.69      0.70      0.69     14531\n",
      "\n",
      "Epoch 3, Step 0, Loss: 0.08570307493209839, F1: 0.7473789299246939, Accuracy: 0.6963044525497213, Time Elapsed: 160.12109780311584 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.85      0.74       877\n",
      "           1       0.93      0.89      0.91       880\n",
      "           2       0.73      0.69      0.71       901\n",
      "           3       0.78      0.65      0.71       871\n",
      "           4       0.77      0.91      0.83       897\n",
      "           5       0.66      0.85      0.74       879\n",
      "           6       0.81      0.73      0.77       892\n",
      "           7       0.84      0.81      0.83       897\n",
      "           8       0.65      0.70      0.68       885\n",
      "           9       0.74      0.62      0.67       902\n",
      "          10       0.64      0.61      0.63      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.75      0.76      0.75     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 3, Step 1000, Loss: 0.6055867075920105, F1: 0.747635032487129, Accuracy: 0.7096552198747506, Time Elapsed: 350.8907639980316 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       877\n",
      "           1       0.91      0.79      0.85       880\n",
      "           2       0.71      0.76      0.73       901\n",
      "           3       0.75      0.73      0.74       871\n",
      "           4       0.72      0.93      0.81       897\n",
      "           5       0.72      0.70      0.71       879\n",
      "           6       0.71      0.80      0.75       892\n",
      "           7       0.89      0.70      0.78       897\n",
      "           8       0.64      0.76      0.70       885\n",
      "           9       0.65      0.81      0.73       902\n",
      "          10       0.62      0.55      0.59      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.73      0.76      0.74     14531\n",
      "weighted avg       0.69      0.69      0.69     14531\n",
      "\n",
      "Epoch 3, Step 2000, Loss: 1.5790361166000366, F1: 0.7376240266307801, Accuracy: 0.6907989814878536, Time Elapsed: 549.6347298622131 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.72       877\n",
      "           1       0.93      0.91      0.92       880\n",
      "           2       0.66      0.83      0.74       901\n",
      "           3       0.71      0.84      0.77       871\n",
      "           4       0.78      0.74      0.76       897\n",
      "           5       0.65      0.84      0.73       879\n",
      "           6       0.70      0.86      0.78       892\n",
      "           7       0.79      0.83      0.81       897\n",
      "           8       0.62      0.87      0.73       885\n",
      "           9       0.75      0.65      0.70       902\n",
      "          10       0.64      0.53      0.58      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.73      0.78      0.75     14531\n",
      "weighted avg       0.70      0.70      0.69     14531\n",
      "\n",
      "Epoch 3, Step 3000, Loss: 0.218458354473114, F1: 0.7478983613217051, Accuracy: 0.6990571880806552, Time Elapsed: 824.5411698818207 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       877\n",
      "           1       0.91      0.84      0.87       880\n",
      "           2       0.73      0.69      0.71       901\n",
      "           3       0.65      0.84      0.73       871\n",
      "           4       0.76      0.75      0.75       897\n",
      "           5       0.74      0.55      0.63       879\n",
      "           6       0.76      0.72      0.74       892\n",
      "           7       0.79      0.85      0.82       897\n",
      "           8       0.66      0.64      0.65       885\n",
      "           9       0.66      0.82      0.73       902\n",
      "          10       0.60      0.60      0.60      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.73      0.73      0.72     14531\n",
      "weighted avg       0.69      0.68      0.68     14531\n",
      "\n",
      "Epoch 3, Step 4000, Loss: 0.10603432357311249, F1: 0.7231438453930324, Accuracy: 0.6843988713784324, Time Elapsed: 1338.386808872223 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64       877\n",
      "           1       0.85      0.96      0.90       880\n",
      "           2       0.70      0.71      0.70       901\n",
      "           3       0.70      0.70      0.70       871\n",
      "           4       0.72      0.94      0.82       897\n",
      "           5       0.79      0.56      0.66       879\n",
      "           6       0.68      0.95      0.79       892\n",
      "           7       0.89      0.72      0.80       897\n",
      "           8       0.62      0.88      0.72       885\n",
      "           9       0.73      0.71      0.72       902\n",
      "          10       0.62      0.57      0.60      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.73      0.75      0.73     14531\n",
      "weighted avg       0.70      0.69      0.69     14531\n",
      "\n",
      "Epoch 3, Step 5000, Loss: 0.5703287124633789, F1: 0.731547671448092, Accuracy: 0.6923818044181406, Time Elapsed: 1554.2916958332062 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       877\n",
      "           1       0.93      0.90      0.92       880\n",
      "           2       0.67      0.81      0.73       901\n",
      "           3       0.67      0.73      0.70       871\n",
      "           4       0.77      0.89      0.83       897\n",
      "           5       0.74      0.56      0.64       879\n",
      "           6       0.77      0.73      0.75       892\n",
      "           7       0.85      0.80      0.83       897\n",
      "           8       0.69      0.58      0.63       885\n",
      "           9       0.75      0.68      0.71       902\n",
      "          10       0.61      0.65      0.63      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.75      0.73      0.73     14531\n",
      "weighted avg       0.70      0.70      0.70     14531\n",
      "\n",
      "Epoch 3, Step 6000, Loss: 0.5567823052406311, F1: 0.7337688282799136, Accuracy: 0.7001582822930287, Time Elapsed: 1826.0966708660126 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74       877\n",
      "           1       0.89      0.86      0.87       880\n",
      "           2       0.72      0.76      0.74       901\n",
      "           3       0.63      0.94      0.75       871\n",
      "           4       0.73      0.89      0.80       897\n",
      "           5       0.67      0.73      0.70       879\n",
      "           6       0.72      0.82      0.76       892\n",
      "           7       0.82      0.86      0.84       897\n",
      "           8       0.63      0.79      0.70       885\n",
      "           9       0.73      0.74      0.73       902\n",
      "          10       0.65      0.50      0.57      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.72      0.79      0.75     14531\n",
      "weighted avg       0.69      0.70      0.69     14531\n",
      "\n",
      "Epoch 3, Step 7000, Loss: 0.4372074007987976, F1: 0.7471359343313918, Accuracy: 0.6961668157731746, Time Elapsed: 2086.771404027939 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       877\n",
      "           1       0.86      0.83      0.85       880\n",
      "           2       0.72      0.75      0.74       901\n",
      "           3       0.71      0.72      0.72       871\n",
      "           4       0.77      0.79      0.78       897\n",
      "           5       0.70      0.69      0.70       879\n",
      "           6       0.75      0.74      0.75       892\n",
      "           7       0.77      0.90      0.83       897\n",
      "           8       0.62      0.87      0.72       885\n",
      "           9       0.66      0.79      0.72       902\n",
      "          10       0.62      0.54      0.57      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.72      0.76      0.73     14531\n",
      "weighted avg       0.68      0.69      0.68     14531\n",
      "\n",
      "Epoch 3, Step 8000, Loss: 0.601354718208313, F1: 0.7348209533500946, Accuracy: 0.6863946046383593, Time Elapsed: 2322.8220138549805 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.84      0.74       877\n",
      "           1       0.81      0.90      0.86       880\n",
      "           2       0.74      0.73      0.74       901\n",
      "           3       0.81      0.51      0.63       871\n",
      "           4       0.77      0.82      0.80       897\n",
      "           5       0.75      0.65      0.69       879\n",
      "           6       0.74      0.63      0.69       892\n",
      "           7       0.81      0.87      0.84       897\n",
      "           8       0.64      0.68      0.66       885\n",
      "           9       0.66      0.75      0.71       902\n",
      "          10       0.60      0.59      0.60      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.73      0.73      0.72     14531\n",
      "weighted avg       0.69      0.68      0.68     14531\n",
      "\n",
      "Epoch 3, Step 9000, Loss: 4.85299015045166, F1: 0.7211815717746325, Accuracy: 0.6826095932833253, Time Elapsed: 2580.5160138607025 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75       877\n",
      "           1       0.91      0.83      0.87       880\n",
      "           2       0.74      0.76      0.75       901\n",
      "           3       0.78      0.67      0.72       871\n",
      "           4       0.79      0.85      0.82       897\n",
      "           5       0.67      0.83      0.74       879\n",
      "           6       0.69      0.81      0.74       892\n",
      "           7       0.82      0.85      0.83       897\n",
      "           8       0.63      0.76      0.69       885\n",
      "           9       0.65      0.86      0.74       902\n",
      "          10       0.65      0.54      0.59      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.73      0.78      0.75     14531\n",
      "weighted avg       0.70      0.70      0.70     14531\n",
      "\n",
      "Epoch 3, Step 10000, Loss: 0.05130261555314064, F1: 0.7491290887957647, Accuracy: 0.7006400110109421, Time Elapsed: 2761.6470358371735 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       877\n",
      "           1       0.89      0.81      0.84       880\n",
      "           2       0.66      0.83      0.73       901\n",
      "           3       0.65      0.84      0.73       871\n",
      "           4       0.76      0.85      0.80       897\n",
      "           5       0.72      0.69      0.71       879\n",
      "           6       0.75      0.59      0.66       892\n",
      "           7       0.79      0.84      0.81       897\n",
      "           8       0.59      0.95      0.73       885\n",
      "           9       0.66      0.83      0.73       902\n",
      "          10       0.61      0.50      0.55      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.71      0.76      0.73     14531\n",
      "weighted avg       0.68      0.68      0.67     14531\n",
      "\n",
      "Epoch 3, Step 11000, Loss: 0.3197503983974457, F1: 0.7274351392116959, Accuracy: 0.6772417589980043, Time Elapsed: 2993.0280628204346 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       877\n",
      "           1       0.85      0.89      0.87       880\n",
      "           2       0.67      0.84      0.74       901\n",
      "           3       0.70      0.73      0.71       871\n",
      "           4       0.75      0.81      0.78       897\n",
      "           5       0.68      0.66      0.67       879\n",
      "           6       0.76      0.83      0.79       892\n",
      "           7       0.81      0.82      0.82       897\n",
      "           8       0.66      0.58      0.62       885\n",
      "           9       0.69      0.78      0.74       902\n",
      "          10       0.62      0.57      0.59      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.72      0.75      0.73     14531\n",
      "weighted avg       0.69      0.69      0.69     14531\n",
      "\n",
      "Epoch 3, Step 12000, Loss: 1.083000898361206, F1: 0.7331821394330565, Accuracy: 0.6901796159933934, Time Elapsed: 3205.3174438476562 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       877\n",
      "           1       0.85      0.95      0.90       880\n",
      "           2       0.81      0.58      0.68       901\n",
      "           3       0.70      0.62      0.66       871\n",
      "           4       0.82      0.79      0.80       897\n",
      "           5       0.66      0.65      0.66       879\n",
      "           6       0.78      0.82      0.80       892\n",
      "           7       0.81      0.84      0.82       897\n",
      "           8       0.63      0.79      0.70       885\n",
      "           9       0.75      0.46      0.57       902\n",
      "          10       0.61      0.62      0.61      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.74      0.73      0.72     14531\n",
      "weighted avg       0.70      0.69      0.69     14531\n",
      "\n",
      "Epoch 3, Step 13000, Loss: 0.5717561841011047, F1: 0.7245042070103688, Accuracy: 0.6914871653705871, Time Elapsed: 3429.7050857543945 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77       877\n",
      "           1       0.83      0.93      0.88       880\n",
      "           2       0.74      0.71      0.73       901\n",
      "           3       0.68      0.78      0.72       871\n",
      "           4       0.82      0.76      0.79       897\n",
      "           5       0.64      0.83      0.72       879\n",
      "           6       0.81      0.77      0.79       892\n",
      "           7       0.83      0.74      0.79       897\n",
      "           8       0.61      0.90      0.72       885\n",
      "           9       0.74      0.60      0.66       902\n",
      "          10       0.64      0.55      0.59      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.73      0.77      0.74     14531\n",
      "weighted avg       0.70      0.70      0.69     14531\n",
      "\n",
      "Epoch 3, Step 14000, Loss: 1.9242645502090454, F1: 0.7418996162343908, Accuracy: 0.6969926364324548, Time Elapsed: 4072.3914947509766 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       877\n",
      "           1       0.95      0.85      0.90       880\n",
      "           2       0.68      0.83      0.75       901\n",
      "           3       0.73      0.67      0.70       871\n",
      "           4       0.78      0.86      0.82       897\n",
      "           5       0.67      0.79      0.73       879\n",
      "           6       0.69      0.95      0.80       892\n",
      "           7       0.83      0.79      0.81       897\n",
      "           8       0.65      0.68      0.66       885\n",
      "           9       0.67      0.76      0.71       902\n",
      "          10       0.64      0.56      0.60      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.73      0.77      0.75     14531\n",
      "weighted avg       0.70      0.70      0.70     14531\n",
      "\n",
      "Epoch 3, Step 15000, Loss: 0.3409527838230133, F1: 0.7465790587747396, Accuracy: 0.7014658316702223, Time Elapsed: 4411.133076906204 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       877\n",
      "           1       0.92      0.89      0.91       880\n",
      "           2       0.84      0.54      0.66       901\n",
      "           3       0.62      0.94      0.75       871\n",
      "           4       0.76      0.91      0.83       897\n",
      "           5       0.70      0.75      0.72       879\n",
      "           6       0.84      0.69      0.76       892\n",
      "           7       0.89      0.75      0.81       897\n",
      "           8       0.62      0.88      0.73       885\n",
      "           9       0.68      0.78      0.73       902\n",
      "          10       0.64      0.59      0.61      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.75      0.77      0.75     14531\n",
      "weighted avg       0.72      0.71      0.71     14531\n",
      "\n",
      "Epoch 3, Step 16000, Loss: 0.29531383514404297, F1: 0.7495685944119426, Accuracy: 0.7080035785561902, Time Elapsed: 4626.460582733154 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       877\n",
      "           1       0.86      0.91      0.88       880\n",
      "           2       0.70      0.85      0.76       901\n",
      "           3       0.68      0.81      0.74       871\n",
      "           4       0.85      0.80      0.82       897\n",
      "           5       0.65      0.85      0.74       879\n",
      "           6       0.83      0.76      0.80       892\n",
      "           7       0.73      0.90      0.81       897\n",
      "           8       0.66      0.58      0.62       885\n",
      "           9       0.73      0.69      0.71       902\n",
      "          10       0.66      0.57      0.61      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.74      0.78      0.75     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 3, Step 17000, Loss: 0.22943778336048126, F1: 0.7529905195165014, Accuracy: 0.7109627692519441, Time Elapsed: 4802.405976057053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       877\n",
      "           1       0.97      0.80      0.88       880\n",
      "           2       0.65      0.89      0.75       901\n",
      "           3       0.64      0.86      0.73       871\n",
      "           4       0.85      0.82      0.84       897\n",
      "           5       0.71      0.64      0.67       879\n",
      "           6       0.73      0.87      0.79       892\n",
      "           7       0.81      0.78      0.79       897\n",
      "           8       0.66      0.69      0.67       885\n",
      "           9       0.70      0.75      0.72       902\n",
      "          10       0.65      0.57      0.61      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.74      0.77      0.75     14531\n",
      "weighted avg       0.71      0.70      0.70     14531\n",
      "\n",
      "Epoch 3, Step 18000, Loss: 0.0012804412981495261, F1: 0.7476461459103173, Accuracy: 0.7044250223659762, Time Elapsed: 4987.431418657303 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.56      0.67       877\n",
      "           1       0.88      0.89      0.89       880\n",
      "           2       0.73      0.77      0.75       901\n",
      "           3       0.69      0.70      0.69       871\n",
      "           4       0.88      0.72      0.79       897\n",
      "           5       0.64      0.83      0.72       879\n",
      "           6       0.82      0.80      0.81       892\n",
      "           7       0.74      0.89      0.81       897\n",
      "           8       0.61      0.85      0.71       885\n",
      "           9       0.72      0.73      0.73       902\n",
      "          10       0.64      0.59      0.61      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.74      0.76      0.74     14531\n",
      "weighted avg       0.71      0.70      0.70     14531\n",
      "\n",
      "Epoch 3, Step 19000, Loss: 0.6100584268569946, F1: 0.7427500982405933, Accuracy: 0.7022228339412291, Time Elapsed: 5210.252764940262 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79       877\n",
      "           1       0.83      0.94      0.88       880\n",
      "           2       0.78      0.67      0.72       901\n",
      "           3       0.66      0.74      0.70       871\n",
      "           4       0.70      0.96      0.81       897\n",
      "           5       0.63      0.76      0.69       879\n",
      "           6       0.90      0.57      0.70       892\n",
      "           7       0.72      0.92      0.81       897\n",
      "           8       0.63      0.73      0.68       885\n",
      "           9       0.72      0.71      0.71       902\n",
      "          10       0.64      0.55      0.59      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.72      0.77      0.73     14531\n",
      "weighted avg       0.70      0.69      0.69     14531\n",
      "\n",
      "Epoch 3, Step 20000, Loss: 0.0012837749673053622, F1: 0.7348461397578716, Accuracy: 0.6942399009015209, Time Elapsed: 5609.293812990189 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.91      0.76       877\n",
      "           1       0.94      0.88      0.91       880\n",
      "           2       0.75      0.78      0.77       901\n",
      "           3       0.74      0.65      0.69       871\n",
      "           4       0.79      0.92      0.85       897\n",
      "           5       0.65      0.87      0.74       879\n",
      "           6       0.78      0.87      0.82       892\n",
      "           7       0.83      0.82      0.83       897\n",
      "           8       0.66      0.70      0.68       885\n",
      "           9       0.70      0.81      0.75       902\n",
      "          10       0.68      0.57      0.62      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.74      0.80      0.77     14531\n",
      "weighted avg       0.72      0.72      0.72     14531\n",
      "\n",
      "Epoch 3, Step 21000, Loss: 0.8361506462097168, F1: 0.7661688380647159, Accuracy: 0.7239694446356066, Time Elapsed: 5809.168156862259 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       877\n",
      "           1       0.90      0.90      0.90       880\n",
      "           2       0.77      0.77      0.77       901\n",
      "           3       0.68      0.82      0.74       871\n",
      "           4       0.81      0.89      0.84       897\n",
      "           5       0.70      0.80      0.75       879\n",
      "           6       0.85      0.75      0.80       892\n",
      "           7       0.91      0.66      0.76       897\n",
      "           8       0.66      0.63      0.65       885\n",
      "           9       0.66      0.88      0.75       902\n",
      "          10       0.65      0.63      0.64      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.76      0.76      0.76     14531\n",
      "weighted avg       0.72      0.72      0.72     14531\n",
      "\n",
      "Epoch 3, Step 22000, Loss: 0.0010556369088590145, F1: 0.756242724217842, Accuracy: 0.7189457022916523, Time Elapsed: 5998.654284000397 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75       877\n",
      "           1       0.90      0.88      0.89       880\n",
      "           2       0.69      0.89      0.78       901\n",
      "           3       0.69      0.80      0.74       871\n",
      "           4       0.88      0.76      0.82       897\n",
      "           5       0.74      0.68      0.71       879\n",
      "           6       0.75      0.89      0.81       892\n",
      "           7       0.80      0.85      0.82       897\n",
      "           8       0.68      0.57      0.62       885\n",
      "           9       0.70      0.74      0.72       902\n",
      "          10       0.66      0.59      0.62      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.74      0.77      0.75     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 3, Step 23000, Loss: 0.37770020961761475, F1: 0.7536333525035412, Accuracy: 0.7147477806069782, Time Elapsed: 6185.185377836227 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78       877\n",
      "           1       0.91      0.91      0.91       880\n",
      "           2       0.77      0.80      0.79       901\n",
      "           3       0.73      0.74      0.73       871\n",
      "           4       0.79      0.86      0.82       897\n",
      "           5       0.69      0.80      0.74       879\n",
      "           6       0.86      0.71      0.78       892\n",
      "           7       0.81      0.86      0.84       897\n",
      "           8       0.61      0.89      0.73       885\n",
      "           9       0.69      0.82      0.75       902\n",
      "          10       0.69      0.57      0.63      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.75      0.80      0.77     14531\n",
      "weighted avg       0.73      0.73      0.72     14531\n",
      "\n",
      "Epoch 3, Step 24000, Loss: 0.3333159387111664, F1: 0.770992939966666, Accuracy: 0.727616819214094, Time Elapsed: 6374.209066867828 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77       877\n",
      "           1       0.90      0.95      0.93       880\n",
      "           2       0.74      0.87      0.80       901\n",
      "           3       0.73      0.73      0.73       871\n",
      "           4       0.80      0.87      0.84       897\n",
      "           5       0.72      0.72      0.72       879\n",
      "           6       0.81      0.86      0.84       892\n",
      "           7       0.88      0.79      0.83       897\n",
      "           8       0.65      0.66      0.65       885\n",
      "           9       0.70      0.75      0.72       902\n",
      "          10       0.68      0.61      0.64      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.75      0.79      0.77     14531\n",
      "weighted avg       0.73      0.73      0.73     14531\n",
      "\n",
      "Epoch 3, Step 25000, Loss: 0.05109841004014015, F1: 0.7695863239776771, Accuracy: 0.731195375404308, Time Elapsed: 6535.2857258319855 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.57      0.68       877\n",
      "           1       0.89      0.94      0.91       880\n",
      "           2       0.80      0.81      0.81       901\n",
      "           3       0.70      0.78      0.74       871\n",
      "           4       0.82      0.85      0.84       897\n",
      "           5       0.68      0.80      0.73       879\n",
      "           6       0.82      0.86      0.84       892\n",
      "           7       0.84      0.85      0.85       897\n",
      "           8       0.64      0.78      0.70       885\n",
      "           9       0.80      0.63      0.71       902\n",
      "          10       0.67      0.66      0.67      5650\n",
      "\n",
      "    accuracy                           0.74     14531\n",
      "   macro avg       0.77      0.78      0.77     14531\n",
      "weighted avg       0.74      0.74      0.74     14531\n",
      "\n",
      "Epoch 3, Step 26000, Loss: 0.34699612855911255, F1: 0.7696619760891171, Accuracy: 0.7371137567958158, Time Elapsed: 6708.556516647339 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78       877\n",
      "           1       0.91      0.95      0.93       880\n",
      "           2       0.79      0.79      0.79       901\n",
      "           3       0.75      0.69      0.72       871\n",
      "           4       0.79      0.90      0.84       897\n",
      "           5       0.85      0.52      0.64       879\n",
      "           6       0.85      0.78      0.82       892\n",
      "           7       0.74      0.94      0.83       897\n",
      "           8       0.68      0.66      0.67       885\n",
      "           9       0.72      0.81      0.77       902\n",
      "          10       0.68      0.64      0.66      5650\n",
      "\n",
      "    accuracy                           0.74     14531\n",
      "   macro avg       0.77      0.78      0.77     14531\n",
      "weighted avg       0.74      0.74      0.73     14531\n",
      "\n",
      "Epoch 3, Step 27000, Loss: 0.30812868475914, F1: 0.7667147578468639, Accuracy: 0.736150299359989, Time Elapsed: 6886.667636871338 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78       877\n",
      "           1       0.96      0.86      0.91       880\n",
      "           2       0.74      0.82      0.78       901\n",
      "           3       0.67      0.80      0.73       871\n",
      "           4       0.78      0.90      0.83       897\n",
      "           5       0.65      0.82      0.72       879\n",
      "           6       0.89      0.77      0.82       892\n",
      "           7       0.86      0.84      0.85       897\n",
      "           8       0.69      0.60      0.64       885\n",
      "           9       0.85      0.44      0.58       902\n",
      "          10       0.65      0.65      0.65      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.77      0.76      0.75     14531\n",
      "weighted avg       0.73      0.72      0.72     14531\n",
      "\n",
      "Epoch 3, Step 28000, Loss: 0.14005689322948456, F1: 0.7546667806396347, Accuracy: 0.722455440093593, Time Elapsed: 9319.093275785446 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       877\n",
      "           1       0.95      0.88      0.92       880\n",
      "           2       0.82      0.75      0.78       901\n",
      "           3       0.70      0.71      0.70       871\n",
      "           4       0.78      0.87      0.82       897\n",
      "           5       0.67      0.85      0.75       879\n",
      "           6       0.91      0.66      0.76       892\n",
      "           7       0.84      0.86      0.85       897\n",
      "           8       0.69      0.67      0.68       885\n",
      "           9       0.66      0.88      0.75       902\n",
      "          10       0.67      0.64      0.65      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.77      0.78      0.77     14531\n",
      "weighted avg       0.74      0.73      0.73     14531\n",
      "\n",
      "Epoch 3, Step 29000, Loss: 0.039338961243629456, F1: 0.7692801501966078, Accuracy: 0.7320900144518615, Time Elapsed: 13512.106528997421 seconds\n",
      "Epoch 3 completed. Time: 13514.640721797943\n",
      "Logger {'time': {0: 0.03742480278015137, 1000: 193.8876359462738, 2000: 384.63137888908386, 3000: 585.5741608142853, 4000: 893.3124368190765, 5000: 1372.6580038070679, 6000: 1591.7590267658234, 7000: 1877.4191789627075, 8000: 2131.3355119228363, 9000: 2363.865024805069, 10000: 2612.4172298908234, 11000: 2814.4468348026276, 12000: 3027.293067932129, 13000: 3243.3503658771515, 14000: 3464.146441936493, 15000: 4155.027290821075, 16000: 4449.248986721039, 17000: 4660.67468380928, 18000: 4834.313358783722, 19000: 5018.205748796463, 20000: 5265.634832859039, 21000: 5646.484454870224, 22000: 5843.248718738556, 23000: 6031.766233682632, 24000: 6218.417044878006, 25000: 6402.79984998703, 26000: 6563.514189958572, 27000: 6744.2551946640015, 28000: 6915.773521900177, 29000: 10427.245480775833}, 'loss': {0: 0.08570307493209839, 1000: 0.6055867075920105, 2000: 1.5790361166000366, 3000: 0.218458354473114, 4000: 0.10603432357311249, 5000: 0.5703287124633789, 6000: 0.5567823052406311, 7000: 0.4372074007987976, 8000: 0.601354718208313, 9000: 4.85299015045166, 10000: 0.05130261555314064, 11000: 0.3197503983974457, 12000: 1.083000898361206, 13000: 0.5717561841011047, 14000: 1.9242645502090454, 15000: 0.3409527838230133, 16000: 0.29531383514404297, 17000: 0.22943778336048126, 18000: 0.0012804412981495261, 19000: 0.6100584268569946, 20000: 0.0012837749673053622, 21000: 0.8361506462097168, 22000: 0.0010556369088590145, 23000: 0.37770020961761475, 24000: 0.3333159387111664, 25000: 0.05109841004014015, 26000: 0.34699612855911255, 27000: 0.30812868475914, 28000: 0.14005689322948456, 29000: 0.039338961243629456}, 'F1': {0: 0.7473789299246939, 1000: 0.747635032487129, 2000: 0.7376240266307801, 3000: 0.7478983613217051, 4000: 0.7231438453930324, 5000: 0.731547671448092, 6000: 0.7337688282799136, 7000: 0.7471359343313918, 8000: 0.7348209533500946, 9000: 0.7211815717746325, 10000: 0.7491290887957647, 11000: 0.7274351392116959, 12000: 0.7331821394330565, 13000: 0.7245042070103688, 14000: 0.7418996162343908, 15000: 0.7465790587747396, 16000: 0.7495685944119426, 17000: 0.7529905195165014, 18000: 0.7476461459103173, 19000: 0.7427500982405933, 20000: 0.7348461397578716, 21000: 0.7661688380647159, 22000: 0.756242724217842, 23000: 0.7536333525035412, 24000: 0.770992939966666, 25000: 0.7695863239776771, 26000: 0.7696619760891171, 27000: 0.7667147578468639, 28000: 0.7546667806396347, 29000: 0.7692801501966078}, 'Accuracy': {0: 0.6963044525497213, 1000: 0.7096552198747506, 2000: 0.6907989814878536, 3000: 0.6990571880806552, 4000: 0.6843988713784324, 5000: 0.6923818044181406, 6000: 0.7001582822930287, 7000: 0.6961668157731746, 8000: 0.6863946046383593, 9000: 0.6826095932833253, 10000: 0.7006400110109421, 11000: 0.6772417589980043, 12000: 0.6901796159933934, 13000: 0.6914871653705871, 14000: 0.6969926364324548, 15000: 0.7014658316702223, 16000: 0.7080035785561902, 17000: 0.7109627692519441, 18000: 0.7044250223659762, 19000: 0.7022228339412291, 20000: 0.6942399009015209, 21000: 0.7239694446356066, 22000: 0.7189457022916523, 23000: 0.7147477806069782, 24000: 0.727616819214094, 25000: 0.731195375404308, 26000: 0.7371137567958158, 27000: 0.736150299359989, 28000: 0.722455440093593, 29000: 0.7320900144518615}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.79       877\n",
      "           1       0.87      0.96      0.91       880\n",
      "           2       0.79      0.77      0.78       901\n",
      "           3       0.63      0.89      0.74       871\n",
      "           4       0.77      0.90      0.83       897\n",
      "           5       0.71      0.80      0.75       879\n",
      "           6       0.85      0.77      0.81       892\n",
      "           7       0.79      0.90      0.84       897\n",
      "           8       0.65      0.79      0.71       885\n",
      "           9       0.70      0.85      0.77       902\n",
      "          10       0.71      0.56      0.63      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.75      0.82      0.78     14531\n",
      "weighted avg       0.74      0.73      0.73     14531\n",
      "\n",
      "Epoch 4, Step 0, Loss: 0.02268320322036743, F1: 0.7779530959410624, Accuracy: 0.7342233844883352, Time Elapsed: 306.22058510780334 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       877\n",
      "           1       0.89      0.95      0.92       880\n",
      "           2       0.77      0.80      0.78       901\n",
      "           3       0.70      0.73      0.72       871\n",
      "           4       0.81      0.87      0.84       897\n",
      "           5       0.64      0.88      0.74       879\n",
      "           6       0.86      0.69      0.77       892\n",
      "           7       0.76      0.92      0.83       897\n",
      "           8       0.65      0.73      0.68       885\n",
      "           9       0.73      0.73      0.73       902\n",
      "          10       0.68      0.58      0.62      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.75      0.80      0.77     14531\n",
      "weighted avg       0.72      0.72      0.72     14531\n",
      "\n",
      "Epoch 4, Step 1000, Loss: 1.4113038778305054, F1: 0.7661252633044882, Accuracy: 0.7239694446356066, Time Elapsed: 465.0778441429138 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       877\n",
      "           1       0.91      0.94      0.93       880\n",
      "           2       0.78      0.76      0.77       901\n",
      "           3       0.67      0.79      0.72       871\n",
      "           4       0.79      0.89      0.84       897\n",
      "           5       0.72      0.70      0.71       879\n",
      "           6       0.87      0.75      0.81       892\n",
      "           7       0.92      0.72      0.80       897\n",
      "           8       0.64      0.83      0.72       885\n",
      "           9       0.69      0.78      0.73       902\n",
      "          10       0.68      0.63      0.65      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.77      0.78      0.77     14531\n",
      "weighted avg       0.74      0.73      0.73     14531\n",
      "\n",
      "Epoch 4, Step 2000, Loss: 1.3972818851470947, F1: 0.7707497984993208, Accuracy: 0.7329158351111417, Time Elapsed: 624.1576662063599 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       877\n",
      "           1       0.96      0.91      0.93       880\n",
      "           2       0.74      0.87      0.80       901\n",
      "           3       0.65      0.88      0.75       871\n",
      "           4       0.89      0.76      0.82       897\n",
      "           5       0.69      0.80      0.74       879\n",
      "           6       0.74      0.91      0.82       892\n",
      "           7       0.81      0.81      0.81       897\n",
      "           8       0.68      0.73      0.71       885\n",
      "           9       0.81      0.49      0.61       902\n",
      "          10       0.68      0.61      0.64      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.76      0.79      0.76     14531\n",
      "weighted avg       0.73      0.73      0.72     14531\n",
      "\n",
      "Epoch 4, Step 3000, Loss: 0.07040964812040329, F1: 0.7641208374554921, Accuracy: 0.7272727272727273, Time Elapsed: 782.4386451244354 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77       877\n",
      "           1       0.94      0.91      0.92       880\n",
      "           2       0.79      0.77      0.78       901\n",
      "           3       0.65      0.82      0.73       871\n",
      "           4       0.85      0.81      0.83       897\n",
      "           5       0.74      0.66      0.69       879\n",
      "           6       0.85      0.73      0.79       892\n",
      "           7       0.87      0.80      0.83       897\n",
      "           8       0.67      0.76      0.71       885\n",
      "           9       0.64      0.89      0.74       902\n",
      "          10       0.67      0.61      0.64      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.76      0.78      0.77     14531\n",
      "weighted avg       0.73      0.73      0.72     14531\n",
      "\n",
      "Epoch 4, Step 4000, Loss: 0.0629127249121666, F1: 0.7665798871586763, Accuracy: 0.7252081756245269, Time Elapsed: 1854.6513259410858 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70       877\n",
      "           1       0.94      0.85      0.89       880\n",
      "           2       0.72      0.77      0.75       901\n",
      "           3       0.67      0.70      0.69       871\n",
      "           4       0.91      0.75      0.82       897\n",
      "           5       0.78      0.56      0.65       879\n",
      "           6       0.73      0.90      0.80       892\n",
      "           7       0.91      0.58      0.71       897\n",
      "           8       0.66      0.77      0.71       885\n",
      "           9       0.71      0.81      0.75       902\n",
      "          10       0.62      0.66      0.64      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.76      0.73      0.74     14531\n",
      "weighted avg       0.72      0.70      0.70     14531\n",
      "\n",
      "Epoch 4, Step 5000, Loss: 0.93311607837677, F1: 0.7373191348957339, Accuracy: 0.7042185672011562, Time Elapsed: 3365.58496594429 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       877\n",
      "           1       0.94      0.90      0.92       880\n",
      "           2       0.75      0.82      0.78       901\n",
      "           3       0.64      0.83      0.72       871\n",
      "           4       0.77      0.88      0.82       897\n",
      "           5       0.73      0.64      0.68       879\n",
      "           6       0.76      0.86      0.81       892\n",
      "           7       0.82      0.83      0.82       897\n",
      "           8       0.69      0.53      0.60       885\n",
      "           9       0.76      0.67      0.71       902\n",
      "          10       0.65      0.63      0.64      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.75      0.76      0.75     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 4, Step 6000, Loss: 0.04227510094642639, F1: 0.7493559940321625, Accuracy: 0.7146101438304315, Time Elapsed: 3532.6486558914185 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       877\n",
      "           1       0.91      0.94      0.93       880\n",
      "           2       0.80      0.82      0.81       901\n",
      "           3       0.63      0.85      0.73       871\n",
      "           4       0.83      0.88      0.86       897\n",
      "           5       0.71      0.70      0.70       879\n",
      "           6       0.80      0.83      0.82       892\n",
      "           7       0.84      0.81      0.82       897\n",
      "           8       0.66      0.71      0.68       885\n",
      "           9       0.80      0.67      0.73       902\n",
      "          10       0.69      0.62      0.65      5650\n",
      "\n",
      "    accuracy                           0.74     14531\n",
      "   macro avg       0.76      0.79      0.77     14531\n",
      "weighted avg       0.74      0.74      0.73     14531\n",
      "\n",
      "Epoch 4, Step 7000, Loss: 0.3839164674282074, F1: 0.7726233856388042, Accuracy: 0.7351868419241622, Time Elapsed: 3696.3246858119965 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.76       877\n",
      "           1       0.92      0.92      0.92       880\n",
      "           2       0.80      0.77      0.79       901\n",
      "           3       0.73      0.71      0.72       871\n",
      "           4       0.85      0.86      0.86       897\n",
      "           5       0.69      0.83      0.75       879\n",
      "           6       0.71      0.93      0.80       892\n",
      "           7       0.78      0.85      0.82       897\n",
      "           8       0.60      0.93      0.73       885\n",
      "           9       0.66      0.88      0.75       902\n",
      "          10       0.72      0.54      0.61      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.74      0.82      0.77     14531\n",
      "weighted avg       0.73      0.73      0.72     14531\n",
      "\n",
      "Epoch 4, Step 8000, Loss: 0.08098182082176208, F1: 0.7742843571115485, Accuracy: 0.7286490950381942, Time Elapsed: 4334.139449834824 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.53      0.61       877\n",
      "           1       0.90      0.86      0.88       880\n",
      "           2       0.80      0.76      0.78       901\n",
      "           3       0.72      0.65      0.68       871\n",
      "           4       0.90      0.77      0.83       897\n",
      "           5       0.74      0.60      0.66       879\n",
      "           6       0.89      0.72      0.79       892\n",
      "           7       0.82      0.73      0.77       897\n",
      "           8       0.72      0.58      0.64       885\n",
      "           9       0.74      0.67      0.70       902\n",
      "          10       0.60      0.73      0.66      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.78      0.69      0.73     14531\n",
      "weighted avg       0.72      0.70      0.71     14531\n",
      "\n",
      "Epoch 4, Step 9000, Loss: 4.3879570960998535, F1: 0.728395544319429, Accuracy: 0.7044250223659762, Time Elapsed: 4501.444602966309 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76       877\n",
      "           1       0.93      0.86      0.89       880\n",
      "           2       0.81      0.71      0.76       901\n",
      "           3       0.77      0.47      0.58       871\n",
      "           4       0.86      0.78      0.82       897\n",
      "           5       0.67      0.87      0.75       879\n",
      "           6       0.85      0.78      0.81       892\n",
      "           7       0.83      0.77      0.80       897\n",
      "           8       0.65      0.81      0.72       885\n",
      "           9       0.65      0.90      0.76       902\n",
      "          10       0.65      0.60      0.62      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.76      0.77      0.75     14531\n",
      "weighted avg       0.72      0.71      0.71     14531\n",
      "\n",
      "Epoch 4, Step 10000, Loss: 0.8866158127784729, F1: 0.7529702080448282, Accuracy: 0.7138531415594247, Time Elapsed: 4665.445107936859 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       877\n",
      "           1       0.79      0.96      0.87       880\n",
      "           2       0.76      0.82      0.79       901\n",
      "           3       0.69      0.72      0.71       871\n",
      "           4       0.80      0.85      0.82       897\n",
      "           5       0.79      0.66      0.72       879\n",
      "           6       0.83      0.78      0.81       892\n",
      "           7       0.80      0.85      0.82       897\n",
      "           8       0.60      0.90      0.72       885\n",
      "           9       0.71      0.82      0.76       902\n",
      "          10       0.68      0.58      0.63      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.75      0.79      0.76     14531\n",
      "weighted avg       0.72      0.72      0.72     14531\n",
      "\n",
      "Epoch 4, Step 11000, Loss: 0.19995667040348053, F1: 0.7639204632788313, Accuracy: 0.7234188975294199, Time Elapsed: 4824.569683074951 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77       877\n",
      "           1       0.93      0.93      0.93       880\n",
      "           2       0.77      0.83      0.80       901\n",
      "           3       0.74      0.66      0.69       871\n",
      "           4       0.88      0.78      0.82       897\n",
      "           5       0.76      0.73      0.74       879\n",
      "           6       0.83      0.83      0.83       892\n",
      "           7       0.78      0.86      0.82       897\n",
      "           8       0.72      0.52      0.61       885\n",
      "           9       0.72      0.78      0.75       902\n",
      "          10       0.67      0.67      0.67      5650\n",
      "\n",
      "    accuracy                           0.74     14531\n",
      "   macro avg       0.77      0.77      0.77     14531\n",
      "weighted avg       0.74      0.74      0.73     14531\n",
      "\n",
      "Epoch 4, Step 12000, Loss: 1.8156726360321045, F1: 0.7667258075468827, Accuracy: 0.7362191177482623, Time Elapsed: 5570.672827005386 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.96      0.76       877\n",
      "           1       0.92      0.97      0.94       880\n",
      "           2       0.83      0.74      0.78       901\n",
      "           3       0.66      0.83      0.73       871\n",
      "           4       0.87      0.81      0.84       897\n",
      "           5       0.79      0.65      0.71       879\n",
      "           6       0.86      0.80      0.83       892\n",
      "           7       0.85      0.74      0.79       897\n",
      "           8       0.66      0.80      0.72       885\n",
      "           9       0.78      0.61      0.68       902\n",
      "          10       0.67      0.65      0.66      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.77      0.78      0.77     14531\n",
      "weighted avg       0.74      0.73      0.73     14531\n",
      "\n",
      "Epoch 4, Step 13000, Loss: 1.3055603504180908, F1: 0.7684891319095339, Accuracy: 0.7335352006056018, Time Elapsed: 5766.329290151596 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79       877\n",
      "           1       0.91      0.97      0.94       880\n",
      "           2       0.75      0.90      0.82       901\n",
      "           3       0.71      0.79      0.75       871\n",
      "           4       0.92      0.71      0.80       897\n",
      "           5       0.73      0.78      0.76       879\n",
      "           6       0.85      0.81      0.83       892\n",
      "           7       0.87      0.78      0.82       897\n",
      "           8       0.64      0.81      0.71       885\n",
      "           9       0.74      0.69      0.72       902\n",
      "          10       0.70      0.63      0.66      5650\n",
      "\n",
      "    accuracy                           0.75     14531\n",
      "   macro avg       0.77      0.80      0.78     14531\n",
      "weighted avg       0.75      0.75      0.74     14531\n",
      "\n",
      "Epoch 4, Step 14000, Loss: 1.5462788343429565, F1: 0.781991544492037, Accuracy: 0.7452343266120708, Time Elapsed: 5932.854468822479 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       877\n",
      "           1       0.91      0.94      0.92       880\n",
      "           2       0.76      0.89      0.82       901\n",
      "           3       0.71      0.61      0.66       871\n",
      "           4       0.82      0.92      0.86       897\n",
      "           5       0.73      0.59      0.65       879\n",
      "           6       0.71      0.96      0.82       892\n",
      "           7       0.85      0.84      0.85       897\n",
      "           8       0.74      0.60      0.66       885\n",
      "           9       0.69      0.85      0.76       902\n",
      "          10       0.68      0.62      0.65      5650\n",
      "\n",
      "    accuracy                           0.73     14531\n",
      "   macro avg       0.76      0.79      0.77     14531\n",
      "weighted avg       0.73      0.73      0.73     14531\n",
      "\n",
      "Epoch 4, Step 15000, Loss: 0.8733148574829102, F1: 0.7675853806542683, Accuracy: 0.7344298396531553, Time Elapsed: 6177.4060089588165 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       877\n",
      "           1       0.95      0.92      0.93       880\n",
      "           2       0.84      0.77      0.81       901\n",
      "           3       0.69      0.81      0.74       871\n",
      "           4       0.87      0.88      0.87       897\n",
      "           5       0.72      0.68      0.70       879\n",
      "           6       0.86      0.84      0.85       892\n",
      "           7       0.90      0.81      0.85       897\n",
      "           8       0.69      0.71      0.70       885\n",
      "           9       0.76      0.71      0.73       902\n",
      "          10       0.70      0.70      0.70      5650\n",
      "\n",
      "    accuracy                           0.76     14531\n",
      "   macro avg       0.79      0.79      0.79     14531\n",
      "weighted avg       0.76      0.76      0.76     14531\n",
      "\n",
      "Epoch 4, Step 16000, Loss: 0.06906771659851074, F1: 0.7894301205469578, Accuracy: 0.7598926433142936, Time Elapsed: 6352.745740175247 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       877\n",
      "           1       0.94      0.90      0.92       880\n",
      "           2       0.74      0.87      0.80       901\n",
      "           3       0.63      0.89      0.74       871\n",
      "           4       0.84      0.88      0.86       897\n",
      "           5       0.61      0.93      0.74       879\n",
      "           6       0.87      0.84      0.85       892\n",
      "           7       0.83      0.89      0.86       897\n",
      "           8       0.67      0.70      0.69       885\n",
      "           9       0.72      0.81      0.76       902\n",
      "          10       0.74      0.57      0.64      5650\n",
      "\n",
      "    accuracy                           0.74     14531\n",
      "   macro avg       0.76      0.83      0.79     14531\n",
      "weighted avg       0.75      0.74      0.74     14531\n",
      "\n",
      "Epoch 4, Step 17000, Loss: 0.12459255754947662, F1: 0.7859026433172015, Accuracy: 0.7444085059527906, Time Elapsed: 6534.205647945404 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       877\n",
      "           1       0.97      0.89      0.93       880\n",
      "           2       0.81      0.83      0.82       901\n",
      "           3       0.69      0.81      0.75       871\n",
      "           4       0.80      0.89      0.84       897\n",
      "           5       0.77      0.48      0.59       879\n",
      "           6       0.78      0.87      0.82       892\n",
      "           7       0.88      0.83      0.86       897\n",
      "           8       0.67      0.80      0.73       885\n",
      "           9       0.69      0.85      0.76       902\n",
      "          10       0.69      0.66      0.67      5650\n",
      "\n",
      "    accuracy                           0.74     14531\n",
      "   macro avg       0.77      0.78      0.77     14531\n",
      "weighted avg       0.75      0.74      0.74     14531\n",
      "\n",
      "Epoch 4, Step 18000, Loss: 0.00039939055568538606, F1: 0.7743474531830917, Accuracy: 0.7430321381873236, Time Elapsed: 6716.749824047089 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.51      0.62       877\n",
      "           1       0.86      0.96      0.91       880\n",
      "           2       0.80      0.86      0.83       901\n",
      "           3       0.65      0.86      0.74       871\n",
      "           4       0.83      0.74      0.78       897\n",
      "           5       0.66      0.80      0.72       879\n",
      "           6       0.87      0.66      0.75       892\n",
      "           7       0.78      0.92      0.84       897\n",
      "           8       0.65      0.82      0.72       885\n",
      "           9       0.78      0.60      0.68       902\n",
      "          10       0.65      0.62      0.63      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.76      0.76      0.75     14531\n",
      "weighted avg       0.72      0.71      0.71     14531\n",
      "\n",
      "Epoch 4, Step 19000, Loss: 0.21212391555309296, F1: 0.74883367450741, Accuracy: 0.7148165989952515, Time Elapsed: 6910.6130430698395 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.75       877\n",
      "           1       0.91      0.92      0.92       880\n",
      "           2       0.81      0.82      0.82       901\n",
      "           3       0.65      0.88      0.75       871\n",
      "           4       0.77      0.85      0.81       897\n",
      "           5       0.74      0.71      0.73       879\n",
      "           6       0.87      0.53      0.66       892\n",
      "           7       0.85      0.84      0.84       897\n",
      "           8       0.64      0.86      0.73       885\n",
      "           9       0.76      0.70      0.73       902\n",
      "          10       0.67      0.61      0.64      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.76      0.78      0.76     14531\n",
      "weighted avg       0.73      0.72      0.72     14531\n",
      "\n",
      "Epoch 4, Step 20000, Loss: 0.03938950225710869, F1: 0.7610629753594208, Accuracy: 0.7239006262473333, Time Elapsed: 7100.926315069199 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79       877\n",
      "           1       0.95      0.93      0.94       880\n",
      "           2       0.80      0.86      0.83       901\n",
      "           3       0.76      0.72      0.74       871\n",
      "           4       0.76      0.92      0.83       897\n",
      "           5       0.70      0.83      0.76       879\n",
      "           6       0.73      0.88      0.80       892\n",
      "           7       0.87      0.86      0.87       897\n",
      "           8       0.71      0.68      0.70       885\n",
      "           9       0.69      0.84      0.76       902\n",
      "          10       0.73      0.60      0.66      5650\n",
      "\n",
      "    accuracy                           0.75     14531\n",
      "   macro avg       0.76      0.82      0.79     14531\n",
      "weighted avg       0.75      0.75      0.74     14531\n",
      "\n",
      "Epoch 4, Step 21000, Loss: 2.022691249847412, F1: 0.7874930773747312, Accuracy: 0.7497075218498382, Time Elapsed: 7287.470314025879 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       877\n",
      "           1       0.95      0.89      0.92       880\n",
      "           2       0.85      0.79      0.82       901\n",
      "           3       0.72      0.73      0.72       871\n",
      "           4       0.76      0.91      0.83       897\n",
      "           5       0.70      0.83      0.76       879\n",
      "           6       0.83      0.85      0.84       892\n",
      "           7       0.85      0.82      0.84       897\n",
      "           8       0.69      0.72      0.71       885\n",
      "           9       0.65      0.86      0.74       902\n",
      "          10       0.71      0.63      0.67      5650\n",
      "\n",
      "    accuracy                           0.75     14531\n",
      "   macro avg       0.77      0.81      0.79     14531\n",
      "weighted avg       0.75      0.75      0.75     14531\n",
      "\n",
      "Epoch 4, Step 22000, Loss: 0.0003122795606032014, F1: 0.7865249938427616, Accuracy: 0.749845158626385, Time Elapsed: 7471.340439796448 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.77       877\n",
      "           1       0.95      0.74      0.83       880\n",
      "           2       0.70      0.92      0.79       901\n",
      "           3       0.69      0.81      0.74       871\n",
      "           4       0.91      0.60      0.72       897\n",
      "           5       0.74      0.72      0.73       879\n",
      "           6       0.77      0.82      0.80       892\n",
      "           7       0.87      0.81      0.84       897\n",
      "           8       0.72      0.55      0.63       885\n",
      "           9       0.73      0.71      0.72       902\n",
      "          10       0.65      0.68      0.66      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.77      0.74      0.75     14531\n",
      "weighted avg       0.73      0.72      0.72     14531\n",
      "\n",
      "Epoch 4, Step 23000, Loss: 0.2775215804576874, F1: 0.7485635615453007, Accuracy: 0.7199091597274792, Time Elapsed: 7646.1628251075745 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       877\n",
      "           1       0.88      0.85      0.86       880\n",
      "           2       0.77      0.74      0.76       901\n",
      "           3       0.65      0.90      0.75       871\n",
      "           4       0.86      0.77      0.81       897\n",
      "           5       0.72      0.77      0.75       879\n",
      "           6       0.85      0.75      0.79       892\n",
      "           7       0.89      0.79      0.84       897\n",
      "           8       0.62      0.82      0.71       885\n",
      "           9       0.72      0.74      0.73       902\n",
      "          10       0.67      0.63      0.65      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.76      0.77      0.76     14531\n",
      "weighted avg       0.73      0.72      0.72     14531\n",
      "\n",
      "Epoch 4, Step 24000, Loss: 0.17577439546585083, F1: 0.7625670315310145, Accuracy: 0.7245199917417934, Time Elapsed: 7834.309760093689 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       877\n",
      "           1       0.87      0.94      0.90       880\n",
      "           2       0.76      0.89      0.82       901\n",
      "           3       0.68      0.85      0.75       871\n",
      "           4       0.85      0.81      0.83       897\n",
      "           5       0.70      0.84      0.76       879\n",
      "           6       0.81      0.80      0.80       892\n",
      "           7       0.83      0.85      0.84       897\n",
      "           8       0.68      0.64      0.66       885\n",
      "           9       0.70      0.79      0.75       902\n",
      "          10       0.70      0.60      0.65      5650\n",
      "\n",
      "    accuracy                           0.74     14531\n",
      "   macro avg       0.76      0.81      0.78     14531\n",
      "weighted avg       0.74      0.74      0.74     14531\n",
      "\n",
      "Epoch 4, Step 25000, Loss: 0.08579421788454056, F1: 0.7786805453045009, Accuracy: 0.7403482210446631, Time Elapsed: 8028.419661998749 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.60       877\n",
      "           1       0.87      0.92      0.89       880\n",
      "           2       0.73      0.79      0.76       901\n",
      "           3       0.78      0.69      0.73       871\n",
      "           4       0.80      0.91      0.85       897\n",
      "           5       0.72      0.78      0.75       879\n",
      "           6       0.88      0.70      0.78       892\n",
      "           7       0.77      0.93      0.84       897\n",
      "           8       0.66      0.71      0.68       885\n",
      "           9       0.75      0.73      0.74       902\n",
      "          10       0.65      0.66      0.65      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.76      0.76      0.75     14531\n",
      "weighted avg       0.73      0.72      0.72     14531\n",
      "\n",
      "Epoch 4, Step 26000, Loss: 0.17133021354675293, F1: 0.7530763115441385, Accuracy: 0.7231436239763265, Time Elapsed: 8215.253196001053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       877\n",
      "           1       0.88      0.91      0.89       880\n",
      "           2       0.77      0.68      0.73       901\n",
      "           3       0.68      0.85      0.76       871\n",
      "           4       0.83      0.86      0.84       897\n",
      "           5       0.82      0.57      0.67       879\n",
      "           6       0.90      0.56      0.69       892\n",
      "           7       0.73      0.95      0.83       897\n",
      "           8       0.66      0.75      0.70       885\n",
      "           9       0.64      0.91      0.75       902\n",
      "          10       0.64      0.62      0.63      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.76      0.76      0.75     14531\n",
      "weighted avg       0.72      0.71      0.71     14531\n",
      "\n",
      "Epoch 4, Step 27000, Loss: 1.408090591430664, F1: 0.7463667465095387, Accuracy: 0.712339137017411, Time Elapsed: 8391.117410898209 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74       877\n",
      "           1       0.87      0.96      0.91       880\n",
      "           2       0.73      0.69      0.71       901\n",
      "           3       0.60      0.93      0.73       871\n",
      "           4       0.82      0.85      0.84       897\n",
      "           5       0.63      0.93      0.75       879\n",
      "           6       0.86      0.75      0.80       892\n",
      "           7       0.77      0.81      0.79       897\n",
      "           8       0.72      0.32      0.44       885\n",
      "           9       0.92      0.05      0.10       902\n",
      "          10       0.60      0.63      0.61      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.75      0.70      0.67     14531\n",
      "weighted avg       0.70      0.68      0.65     14531\n",
      "\n",
      "Epoch 4, Step 28000, Loss: 0.18655943870544434, F1: 0.6749914839560757, Accuracy: 0.6766912118918175, Time Elapsed: 8572.279147148132 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       877\n",
      "           1       0.94      0.87      0.91       880\n",
      "           2       0.70      0.77      0.74       901\n",
      "           3       0.69      0.77      0.73       871\n",
      "           4       0.78      0.90      0.84       897\n",
      "           5       0.74      0.78      0.76       879\n",
      "           6       0.82      0.79      0.81       892\n",
      "           7       0.84      0.78      0.81       897\n",
      "           8       0.67      0.62      0.64       885\n",
      "           9       0.70      0.73      0.71       902\n",
      "          10       0.65      0.62      0.63      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.75      0.76      0.75     14531\n",
      "weighted avg       0.72      0.72      0.71     14531\n",
      "\n",
      "Epoch 4, Step 29000, Loss: 0.48386481404304504, F1: 0.7543123510280041, Accuracy: 0.7155736012662584, Time Elapsed: 8765.499326944351 seconds\n",
      "Epoch 4 completed. Time: 8767.912439107895\n",
      "Logger {'time': {0: 0.029722929000854492, 1000: 334.2763841152191, 2000: 493.8386790752411, 3000: 652.8713009357452, 4000: 811.1735470294952, 5000: 2821.5802068710327, 6000: 3400.9337270259857, 7000: 3561.9844019412994, 8000: 3725.1477699279785, 9000: 4368.957135915756, 10000: 4531.882097005844, 11000: 4694.301826953888, 12000: 4852.451639175415, 13000: 5599.252817869186, 14000: 5794.789590120316, 15000: 5963.474285840988, 16000: 6208.2597279548645, 17000: 6384.704669952393, 18000: 6568.527428865433, 19000: 6750.755568981171, 20000: 6943.7426109313965, 21000: 7136.610872030258, 22000: 7320.414000988007, 23000: 7503.233011007309, 24000: 7679.035396814346, 25000: 7865.876941919327, 26000: 8059.208943843842, 27000: 8245.117985010147, 28000: 8423.287949085236, 29000: 8605.653303146362}, 'loss': {0: 0.02268320322036743, 1000: 1.4113038778305054, 2000: 1.3972818851470947, 3000: 0.07040964812040329, 4000: 0.0629127249121666, 5000: 0.93311607837677, 6000: 0.04227510094642639, 7000: 0.3839164674282074, 8000: 0.08098182082176208, 9000: 4.3879570960998535, 10000: 0.8866158127784729, 11000: 0.19995667040348053, 12000: 1.8156726360321045, 13000: 1.3055603504180908, 14000: 1.5462788343429565, 15000: 0.8733148574829102, 16000: 0.06906771659851074, 17000: 0.12459255754947662, 18000: 0.00039939055568538606, 19000: 0.21212391555309296, 20000: 0.03938950225710869, 21000: 2.022691249847412, 22000: 0.0003122795606032014, 23000: 0.2775215804576874, 24000: 0.17577439546585083, 25000: 0.08579421788454056, 26000: 0.17133021354675293, 27000: 1.408090591430664, 28000: 0.18655943870544434, 29000: 0.48386481404304504}, 'F1': {0: 0.7779530959410624, 1000: 0.7661252633044882, 2000: 0.7707497984993208, 3000: 0.7641208374554921, 4000: 0.7665798871586763, 5000: 0.7373191348957339, 6000: 0.7493559940321625, 7000: 0.7726233856388042, 8000: 0.7742843571115485, 9000: 0.728395544319429, 10000: 0.7529702080448282, 11000: 0.7639204632788313, 12000: 0.7667258075468827, 13000: 0.7684891319095339, 14000: 0.781991544492037, 15000: 0.7675853806542683, 16000: 0.7894301205469578, 17000: 0.7859026433172015, 18000: 0.7743474531830917, 19000: 0.74883367450741, 20000: 0.7610629753594208, 21000: 0.7874930773747312, 22000: 0.7865249938427616, 23000: 0.7485635615453007, 24000: 0.7625670315310145, 25000: 0.7786805453045009, 26000: 0.7530763115441385, 27000: 0.7463667465095387, 28000: 0.6749914839560757, 29000: 0.7543123510280041}, 'Accuracy': {0: 0.7342233844883352, 1000: 0.7239694446356066, 2000: 0.7329158351111417, 3000: 0.7272727272727273, 4000: 0.7252081756245269, 5000: 0.7042185672011562, 6000: 0.7146101438304315, 7000: 0.7351868419241622, 8000: 0.7286490950381942, 9000: 0.7044250223659762, 10000: 0.7138531415594247, 11000: 0.7234188975294199, 12000: 0.7362191177482623, 13000: 0.7335352006056018, 14000: 0.7452343266120708, 15000: 0.7344298396531553, 16000: 0.7598926433142936, 17000: 0.7444085059527906, 18000: 0.7430321381873236, 19000: 0.7148165989952515, 20000: 0.7239006262473333, 21000: 0.7497075218498382, 22000: 0.749845158626385, 23000: 0.7199091597274792, 24000: 0.7245199917417934, 25000: 0.7403482210446631, 26000: 0.7231436239763265, 27000: 0.712339137017411, 28000: 0.6766912118918175, 29000: 0.7155736012662584}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       877\n",
      "           1       0.89      0.94      0.91       880\n",
      "           2       0.71      0.76      0.74       901\n",
      "           3       0.64      0.88      0.74       871\n",
      "           4       0.77      0.93      0.84       897\n",
      "           5       0.76      0.75      0.76       879\n",
      "           6       0.75      0.88      0.81       892\n",
      "           7       0.80      0.81      0.81       897\n",
      "           8       0.63      0.74      0.68       885\n",
      "           9       0.70      0.71      0.70       902\n",
      "          10       0.66      0.55      0.60      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.73      0.79      0.76     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 5, Step 0, Loss: 0.09986153244972229, F1: 0.7561139429266851, Accuracy: 0.7110315876402175, Time Elapsed: 132.52881503105164 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       877\n",
      "           1       0.87      0.95      0.91       880\n",
      "           2       0.70      0.66      0.68       901\n",
      "           3       0.72      0.61      0.66       871\n",
      "           4       0.91      0.79      0.85       897\n",
      "           5       0.67      0.83      0.74       879\n",
      "           6       0.87      0.72      0.79       892\n",
      "           7       0.76      0.87      0.82       897\n",
      "           8       0.67      0.51      0.58       885\n",
      "           9       0.68      0.79      0.73       902\n",
      "          10       0.62      0.63      0.63      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.75      0.74      0.74     14531\n",
      "weighted avg       0.71      0.70      0.70     14531\n",
      "\n",
      "Epoch 5, Step 1000, Loss: 4.804351806640625, F1: 0.7391152831181412, Accuracy: 0.7037368384832428, Time Elapsed: 297.4241180419922 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       877\n",
      "           1       0.96      0.78      0.86       880\n",
      "           2       0.70      0.63      0.67       901\n",
      "           3       0.65      0.83      0.73       871\n",
      "           4       0.82      0.88      0.85       897\n",
      "           5       0.73      0.82      0.77       879\n",
      "           6       0.83      0.76      0.79       892\n",
      "           7       0.79      0.80      0.79       897\n",
      "           8       0.63      0.78      0.70       885\n",
      "           9       0.62      0.85      0.72       902\n",
      "          10       0.64      0.58      0.61      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.74      0.76      0.74     14531\n",
      "weighted avg       0.71      0.70      0.70     14531\n",
      "\n",
      "Epoch 5, Step 2000, Loss: 1.0768399238586426, F1: 0.7446249511211497, Accuracy: 0.7014658316702223, Time Elapsed: 460.104376077652 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       877\n",
      "           1       0.91      0.87      0.89       880\n",
      "           2       0.66      0.80      0.72       901\n",
      "           3       0.65      0.87      0.74       871\n",
      "           4       0.91      0.78      0.84       897\n",
      "           5       0.69      0.87      0.77       879\n",
      "           6       0.75      0.89      0.81       892\n",
      "           7       0.78      0.81      0.80       897\n",
      "           8       0.63      0.70      0.66       885\n",
      "           9       0.68      0.70      0.69       902\n",
      "          10       0.67      0.54      0.60      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.73      0.79      0.75     14531\n",
      "weighted avg       0.71      0.71      0.70     14531\n",
      "\n",
      "Epoch 5, Step 3000, Loss: 0.21144349873065948, F1: 0.7533421380974447, Accuracy: 0.7076594866148235, Time Elapsed: 1225.899752855301 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       877\n",
      "           1       0.93      0.84      0.88       880\n",
      "           2       0.70      0.68      0.69       901\n",
      "           3       0.61      0.93      0.73       871\n",
      "           4       0.85      0.90      0.87       897\n",
      "           5       0.82      0.65      0.72       879\n",
      "           6       0.87      0.75      0.80       892\n",
      "           7       0.81      0.80      0.80       897\n",
      "           8       0.68      0.61      0.64       885\n",
      "           9       0.64      0.84      0.73       902\n",
      "          10       0.65      0.61      0.63      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.75      0.76      0.75     14531\n",
      "weighted avg       0.72      0.71      0.71     14531\n",
      "\n",
      "Epoch 5, Step 4000, Loss: 0.023003391921520233, F1: 0.753305146912281, Accuracy: 0.7146789622187049, Time Elapsed: 3320.559298992157 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73       877\n",
      "           1       0.80      0.97      0.88       880\n",
      "           2       0.70      0.79      0.74       901\n",
      "           3       0.71      0.70      0.71       871\n",
      "           4       0.89      0.75      0.81       897\n",
      "           5       0.83      0.61      0.70       879\n",
      "           6       0.70      0.94      0.80       892\n",
      "           7       0.88      0.72      0.79       897\n",
      "           8       0.65      0.76      0.70       885\n",
      "           9       0.72      0.61      0.66       902\n",
      "          10       0.64      0.63      0.63      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.75      0.75      0.74     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 5, Step 5000, Loss: 0.8617908358573914, F1: 0.7419449651203358, Accuracy: 0.7075218498382768, Time Elapsed: 5403.658645868301 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.56      0.66       877\n",
      "           1       0.90      0.87      0.89       880\n",
      "           2       0.70      0.78      0.74       901\n",
      "           3       0.62      0.89      0.73       871\n",
      "           4       0.81      0.92      0.86       897\n",
      "           5       0.77      0.71      0.74       879\n",
      "           6       0.79      0.87      0.83       892\n",
      "           7       0.79      0.83      0.81       897\n",
      "           8       0.68      0.51      0.58       885\n",
      "           9       0.73      0.57      0.64       902\n",
      "          10       0.63      0.63      0.63      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.75      0.74      0.74     14531\n",
      "weighted avg       0.71      0.71      0.70     14531\n",
      "\n",
      "Epoch 5, Step 6000, Loss: 0.653708815574646, F1: 0.7365181398403124, Accuracy: 0.7053884798018031, Time Elapsed: 5564.311121940613 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74       877\n",
      "           1       0.82      0.95      0.88       880\n",
      "           2       0.69      0.79      0.74       901\n",
      "           3       0.66      0.82      0.73       871\n",
      "           4       0.88      0.81      0.85       897\n",
      "           5       0.75      0.76      0.75       879\n",
      "           6       0.84      0.82      0.83       892\n",
      "           7       0.83      0.78      0.80       897\n",
      "           8       0.66      0.70      0.68       885\n",
      "           9       0.71      0.65      0.68       902\n",
      "          10       0.66      0.61      0.63      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.74      0.77      0.75     14531\n",
      "weighted avg       0.72      0.72      0.71     14531\n",
      "\n",
      "Epoch 5, Step 7000, Loss: 0.161010280251503, F1: 0.754924241201729, Accuracy: 0.7156424196545317, Time Elapsed: 10637.956228017807 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       877\n",
      "           1       0.89      0.88      0.88       880\n",
      "           2       0.74      0.70      0.72       901\n",
      "           3       0.69      0.76      0.73       871\n",
      "           4       0.90      0.82      0.86       897\n",
      "           5       0.65      0.87      0.74       879\n",
      "           6       0.79      0.82      0.80       892\n",
      "           7       0.75      0.87      0.81       897\n",
      "           8       0.63      0.74      0.68       885\n",
      "           9       0.65      0.78      0.71       902\n",
      "          10       0.66      0.57      0.61      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.73      0.77      0.75     14531\n",
      "weighted avg       0.71      0.71      0.70     14531\n",
      "\n",
      "Epoch 5, Step 8000, Loss: 0.05184696242213249, F1: 0.7504459634802653, Accuracy: 0.70676484756727, Time Elapsed: 14727.216219902039 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.70       877\n",
      "           1       0.92      0.84      0.88       880\n",
      "           2       0.75      0.56      0.64       901\n",
      "           3       0.73      0.59      0.65       871\n",
      "           4       0.90      0.78      0.84       897\n",
      "           5       0.81      0.62      0.70       879\n",
      "           6       0.88      0.64      0.74       892\n",
      "           7       0.83      0.80      0.81       897\n",
      "           8       0.68      0.49      0.57       885\n",
      "           9       0.71      0.66      0.68       902\n",
      "          10       0.60      0.73      0.65      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.77      0.68      0.72     14531\n",
      "weighted avg       0.71      0.69      0.70     14531\n",
      "\n",
      "Epoch 5, Step 9000, Loss: 1.9250589609146118, F1: 0.716279804393078, Accuracy: 0.694652811231161, Time Elapsed: 15873.000576019287 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77       877\n",
      "           1       0.89      0.91      0.90       880\n",
      "           2       0.84      0.69      0.76       901\n",
      "           3       0.77      0.48      0.59       871\n",
      "           4       0.80      0.92      0.86       897\n",
      "           5       0.66      0.89      0.76       879\n",
      "           6       0.84      0.76      0.80       892\n",
      "           7       0.80      0.87      0.83       897\n",
      "           8       0.65      0.75      0.69       885\n",
      "           9       0.63      0.84      0.72       902\n",
      "          10       0.66      0.58      0.62      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.75      0.78      0.76     14531\n",
      "weighted avg       0.72      0.72      0.71     14531\n",
      "\n",
      "Epoch 5, Step 10000, Loss: 0.5241780281066895, F1: 0.7554053927213628, Accuracy: 0.7168123322551786, Time Elapsed: 16027.833452939987 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.69       877\n",
      "           1       0.78      0.93      0.85       880\n",
      "           2       0.77      0.82      0.79       901\n",
      "           3       0.61      0.91      0.73       871\n",
      "           4       0.78      0.89      0.83       897\n",
      "           5       0.76      0.70      0.73       879\n",
      "           6       0.83      0.75      0.78       892\n",
      "           7       0.64      0.94      0.77       897\n",
      "           8       0.60      0.90      0.72       885\n",
      "           9       0.65      0.82      0.73       902\n",
      "          10       0.67      0.49      0.56      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.72      0.80      0.74     14531\n",
      "weighted avg       0.70      0.70      0.68     14531\n",
      "\n",
      "Epoch 5, Step 11000, Loss: 0.6154911518096924, F1: 0.7433780304010007, Accuracy: 0.695065721560801, Time Elapsed: 17176.198769807816 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.76      0.70       877\n",
      "           1       0.79      0.94      0.86       880\n",
      "           2       0.78      0.82      0.80       901\n",
      "           3       0.72      0.63      0.67       871\n",
      "           4       0.85      0.82      0.84       897\n",
      "           5       0.77      0.77      0.77       879\n",
      "           6       0.83      0.75      0.79       892\n",
      "           7       0.75      0.75      0.75       897\n",
      "           8       0.67      0.44      0.53       885\n",
      "           9       0.68      0.77      0.72       902\n",
      "          10       0.63      0.63      0.63      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.74      0.73      0.73     14531\n",
      "weighted avg       0.70      0.70      0.70     14531\n",
      "\n",
      "Epoch 5, Step 12000, Loss: 1.487850308418274, F1: 0.732898970882395, Accuracy: 0.7018787419998623, Time Elapsed: 18645.02551293373 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74       877\n",
      "           1       0.79      0.82      0.80       880\n",
      "           2       0.76      0.57      0.65       901\n",
      "           3       0.64      0.82      0.72       871\n",
      "           4       0.86      0.75      0.80       897\n",
      "           5       0.75      0.66      0.71       879\n",
      "           6       0.80      0.76      0.78       892\n",
      "           7       0.75      0.66      0.70       897\n",
      "           8       0.64      0.74      0.68       885\n",
      "           9       0.71      0.68      0.69       902\n",
      "          10       0.58      0.57      0.58      5650\n",
      "\n",
      "    accuracy                           0.67     14531\n",
      "   macro avg       0.72      0.72      0.71     14531\n",
      "weighted avg       0.68      0.67      0.67     14531\n",
      "\n",
      "Epoch 5, Step 13000, Loss: 0.120131716132164, F1: 0.7144993970765288, Accuracy: 0.6710481040534031, Time Elapsed: 21953.87821316719 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.91      0.76       877\n",
      "           1       0.84      0.89      0.87       880\n",
      "           2       0.78      0.79      0.78       901\n",
      "           3       0.66      0.79      0.72       871\n",
      "           4       0.85      0.74      0.79       897\n",
      "           5       0.69      0.85      0.76       879\n",
      "           6       0.79      0.81      0.80       892\n",
      "           7       0.73      0.82      0.77       897\n",
      "           8       0.63      0.71      0.67       885\n",
      "           9       0.74      0.64      0.68       902\n",
      "          10       0.64      0.55      0.59      5650\n",
      "\n",
      "    accuracy                           0.70     14531\n",
      "   macro avg       0.73      0.77      0.74     14531\n",
      "weighted avg       0.70      0.70      0.69     14531\n",
      "\n",
      "Epoch 5, Step 14000, Loss: 1.2932300567626953, F1: 0.7449255336430753, Accuracy: 0.6991260064689285, Time Elapsed: 25011.30933880806 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       877\n",
      "           1       0.83      0.89      0.86       880\n",
      "           2       0.69      0.88      0.78       901\n",
      "           3       0.70      0.63      0.66       871\n",
      "           4       0.81      0.76      0.79       897\n",
      "           5       0.73      0.69      0.71       879\n",
      "           6       0.68      0.93      0.79       892\n",
      "           7       0.81      0.71      0.76       897\n",
      "           8       0.68      0.58      0.62       885\n",
      "           9       0.67      0.77      0.71       902\n",
      "          10       0.62      0.56      0.59      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.72      0.75      0.73     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 5, Step 15000, Loss: 0.2513750493526459, F1: 0.7297865653075757, Accuracy: 0.6882527011217398, Time Elapsed: 28064.31219100952 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.75       877\n",
      "           1       0.79      0.85      0.82       880\n",
      "           2       0.85      0.66      0.74       901\n",
      "           3       0.65      0.75      0.70       871\n",
      "           4       0.81      0.89      0.85       897\n",
      "           5       0.74      0.55      0.63       879\n",
      "           6       0.77      0.84      0.80       892\n",
      "           7       0.84      0.62      0.71       897\n",
      "           8       0.65      0.70      0.67       885\n",
      "           9       0.68      0.74      0.71       902\n",
      "          10       0.61      0.60      0.60      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.73      0.73      0.73     14531\n",
      "weighted avg       0.69      0.69      0.69     14531\n",
      "\n",
      "Epoch 5, Step 16000, Loss: 0.1360238939523697, F1: 0.7268882227343697, Accuracy: 0.6874956988507329, Time Elapsed: 29213.896082878113 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.69       877\n",
      "           1       0.76      0.87      0.81       880\n",
      "           2       0.74      0.80      0.77       901\n",
      "           3       0.64      0.78      0.70       871\n",
      "           4       0.80      0.90      0.84       897\n",
      "           5       0.63      0.84      0.72       879\n",
      "           6       0.80      0.77      0.79       892\n",
      "           7       0.70      0.87      0.78       897\n",
      "           8       0.66      0.54      0.59       885\n",
      "           9       0.72      0.67      0.70       902\n",
      "          10       0.61      0.54      0.58      5650\n",
      "\n",
      "    accuracy                           0.68     14531\n",
      "   macro avg       0.71      0.75      0.72     14531\n",
      "weighted avg       0.68      0.68      0.68     14531\n",
      "\n",
      "Epoch 5, Step 17000, Loss: 0.32716605067253113, F1: 0.7244902753780932, Accuracy: 0.681370862294405, Time Elapsed: 33991.52493214607 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.76       877\n",
      "           1       0.82      0.81      0.82       880\n",
      "           2       0.70      0.92      0.80       901\n",
      "           3       0.64      0.86      0.73       871\n",
      "           4       0.81      0.81      0.81       897\n",
      "           5       0.72      0.63      0.67       879\n",
      "           6       0.74      0.84      0.78       892\n",
      "           7       0.73      0.83      0.78       897\n",
      "           8       0.65      0.72      0.68       885\n",
      "           9       0.70      0.70      0.70       902\n",
      "          10       0.63      0.52      0.57      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.71      0.77      0.74     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 5, Step 18000, Loss: 0.03420649468898773, F1: 0.7358859984956428, Accuracy: 0.6885279746748331, Time Elapsed: 36927.06940793991 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77       877\n",
      "           1       0.85      0.68      0.75       880\n",
      "           2       0.81      0.75      0.78       901\n",
      "           3       0.65      0.79      0.71       871\n",
      "           4       0.80      0.79      0.80       897\n",
      "           5       0.70      0.73      0.72       879\n",
      "           6       0.84      0.74      0.78       892\n",
      "           7       0.66      0.91      0.76       897\n",
      "           8       0.66      0.73      0.69       885\n",
      "           9       0.79      0.43      0.56       902\n",
      "          10       0.60      0.61      0.61      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.74      0.72      0.72     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 5, Step 19000, Loss: 0.15236254036426544, F1: 0.7207776296191057, Accuracy: 0.6856376023673526, Time Elapsed: 40919.73982214928 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72       877\n",
      "           1       0.74      0.85      0.79       880\n",
      "           2       0.76      0.68      0.72       901\n",
      "           3       0.61      0.75      0.67       871\n",
      "           4       0.69      0.85      0.76       897\n",
      "           5       0.65      0.73      0.69       879\n",
      "           6       0.85      0.57      0.68       892\n",
      "           7       0.75      0.77      0.76       897\n",
      "           8       0.62      0.66      0.64       885\n",
      "           9       0.70      0.47      0.56       902\n",
      "          10       0.57      0.55      0.56      5650\n",
      "\n",
      "    accuracy                           0.65     14531\n",
      "   macro avg       0.69      0.70      0.69     14531\n",
      "weighted avg       0.65      0.65      0.65     14531\n",
      "\n",
      "Epoch 5, Step 20000, Loss: 0.0064801559783518314, F1: 0.6877438092175656, Accuracy: 0.6504025875713991, Time Elapsed: 42124.26510095596 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80       877\n",
      "           1       0.86      0.90      0.88       880\n",
      "           2       0.82      0.75      0.78       901\n",
      "           3       0.63      0.74      0.68       871\n",
      "           4       0.77      0.88      0.82       897\n",
      "           5       0.65      0.84      0.73       879\n",
      "           6       0.78      0.85      0.81       892\n",
      "           7       0.75      0.80      0.78       897\n",
      "           8       0.66      0.71      0.68       885\n",
      "           9       0.69      0.77      0.73       902\n",
      "          10       0.66      0.55      0.60      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.73      0.79      0.75     14531\n",
      "weighted avg       0.71      0.71      0.70     14531\n",
      "\n",
      "Epoch 5, Step 21000, Loss: 1.4658818244934082, F1: 0.7542745555665582, Accuracy: 0.7084164888858303, Time Elapsed: 42369.493798971176 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       877\n",
      "           1       0.79      0.93      0.86       880\n",
      "           2       0.72      0.87      0.79       901\n",
      "           3       0.67      0.78      0.72       871\n",
      "           4       0.81      0.92      0.86       897\n",
      "           5       0.69      0.75      0.72       879\n",
      "           6       0.80      0.80      0.80       892\n",
      "           7       0.90      0.57      0.70       897\n",
      "           8       0.66      0.68      0.67       885\n",
      "           9       0.69      0.83      0.75       902\n",
      "          10       0.65      0.58      0.61      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.74      0.78      0.75     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 5, Step 22000, Loss: 0.0016155298799276352, F1: 0.75257351474036, Accuracy: 0.7116509531346776, Time Elapsed: 42519.424052000046 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.77       877\n",
      "           1       0.86      0.73      0.79       880\n",
      "           2       0.67      0.84      0.75       901\n",
      "           3       0.64      0.83      0.73       871\n",
      "           4       0.84      0.86      0.85       897\n",
      "           5       0.66      0.83      0.73       879\n",
      "           6       0.70      0.90      0.79       892\n",
      "           7       0.75      0.85      0.80       897\n",
      "           8       0.70      0.59      0.64       885\n",
      "           9       0.69      0.75      0.72       902\n",
      "          10       0.64      0.51      0.57      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.71      0.78      0.74     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 5, Step 23000, Loss: 0.2276487499475479, F1: 0.7395447171753865, Accuracy: 0.6914871653705871, Time Elapsed: 42669.89010310173 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72       877\n",
      "           1       0.86      0.67      0.75       880\n",
      "           2       0.71      0.78      0.74       901\n",
      "           3       0.65      0.80      0.72       871\n",
      "           4       0.79      0.86      0.82       897\n",
      "           5       0.68      0.73      0.70       879\n",
      "           6       0.79      0.76      0.78       892\n",
      "           7       0.79      0.78      0.79       897\n",
      "           8       0.61      0.84      0.70       885\n",
      "           9       0.72      0.67      0.70       902\n",
      "          10       0.61      0.57      0.59      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.73      0.74      0.73     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 5, Step 24000, Loss: 0.32102516293525696, F1: 0.7283808335264284, Accuracy: 0.6851558736494391, Time Elapsed: 42821.81555891037 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       877\n",
      "           1       0.84      0.88      0.86       880\n",
      "           2       0.66      0.87      0.75       901\n",
      "           3       0.63      0.83      0.72       871\n",
      "           4       0.78      0.88      0.82       897\n",
      "           5       0.68      0.72      0.70       879\n",
      "           6       0.72      0.91      0.80       892\n",
      "           7       0.82      0.78      0.80       897\n",
      "           8       0.66      0.60      0.62       885\n",
      "           9       0.69      0.73      0.71       902\n",
      "          10       0.65      0.51      0.57      5650\n",
      "\n",
      "    accuracy                           0.69     14531\n",
      "   macro avg       0.71      0.78      0.74     14531\n",
      "weighted avg       0.69      0.69      0.68     14531\n",
      "\n",
      "Epoch 5, Step 25000, Loss: 0.0807732492685318, F1: 0.7380082673598544, Accuracy: 0.6907989814878536, Time Elapsed: 42989.20273089409 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       877\n",
      "           1       0.86      0.84      0.85       880\n",
      "           2       0.76      0.77      0.77       901\n",
      "           3       0.73      0.60      0.66       871\n",
      "           4       0.81      0.85      0.83       897\n",
      "           5       0.66      0.78      0.72       879\n",
      "           6       0.82      0.83      0.83       892\n",
      "           7       0.74      0.88      0.81       897\n",
      "           8       0.65      0.67      0.66       885\n",
      "           9       0.75      0.65      0.69       902\n",
      "          10       0.64      0.62      0.63      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.74      0.75      0.74     14531\n",
      "weighted avg       0.71      0.71      0.71     14531\n",
      "\n",
      "Epoch 5, Step 26000, Loss: 0.565284013748169, F1: 0.7449320230366467, Accuracy: 0.7091734911568371, Time Elapsed: 43250.280045986176 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.78       877\n",
      "           1       0.86      0.86      0.86       880\n",
      "           2       0.82      0.76      0.79       901\n",
      "           3       0.68      0.76      0.72       871\n",
      "           4       0.79      0.89      0.84       897\n",
      "           5       0.81      0.48      0.60       879\n",
      "           6       0.80      0.88      0.84       892\n",
      "           7       0.70      0.92      0.80       897\n",
      "           8       0.65      0.77      0.71       885\n",
      "           9       0.65      0.85      0.74       902\n",
      "          10       0.66      0.55      0.60      5650\n",
      "\n",
      "    accuracy                           0.71     14531\n",
      "   macro avg       0.74      0.79      0.75     14531\n",
      "weighted avg       0.71      0.71      0.70     14531\n",
      "\n",
      "Epoch 5, Step 27000, Loss: 1.7531567811965942, F1: 0.7508736172828634, Accuracy: 0.710343403757484, Time Elapsed: 43456.4055018425 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77       877\n",
      "           1       0.89      0.89      0.89       880\n",
      "           2       0.77      0.81      0.79       901\n",
      "           3       0.68      0.81      0.74       871\n",
      "           4       0.74      0.91      0.82       897\n",
      "           5       0.61      0.92      0.73       879\n",
      "           6       0.80      0.88      0.84       892\n",
      "           7       0.80      0.85      0.82       897\n",
      "           8       0.69      0.61      0.65       885\n",
      "           9       0.83      0.56      0.67       902\n",
      "          10       0.67      0.58      0.62      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.74      0.78      0.76     14531\n",
      "weighted avg       0.72      0.72      0.71     14531\n",
      "\n",
      "Epoch 5, Step 28000, Loss: 0.023971840739250183, F1: 0.7570946345271544, Accuracy: 0.7178446080792787, Time Elapsed: 43865.14809012413 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67       877\n",
      "           1       0.94      0.85      0.89       880\n",
      "           2       0.83      0.71      0.76       901\n",
      "           3       0.71      0.70      0.70       871\n",
      "           4       0.78      0.87      0.82       897\n",
      "           5       0.71      0.80      0.75       879\n",
      "           6       0.79      0.88      0.83       892\n",
      "           7       0.90      0.70      0.79       897\n",
      "           8       0.68      0.69      0.68       885\n",
      "           9       0.69      0.80      0.74       902\n",
      "          10       0.64      0.67      0.66      5650\n",
      "\n",
      "    accuracy                           0.72     14531\n",
      "   macro avg       0.77      0.75      0.75     14531\n",
      "weighted avg       0.73      0.72      0.72     14531\n",
      "\n",
      "Epoch 5, Step 29000, Loss: 0.03402503579854965, F1: 0.754061644310152, Accuracy: 0.7216296194343128, Time Elapsed: 44320.691995859146 seconds\n",
      "Epoch 5 completed. Time: 44326.41514015198\n",
      "Logger {'time': {0: 0.025650978088378906, 1000: 160.9389669895172, 2000: 327.2523639202118, 3000: 489.1448471546173, 4000: 1254.7254078388214, 5000: 3349.805500984192, 6000: 5431.999707937241, 7000: 8522.940056085587, 8000: 11620.820446014404, 9000: 15739.743696928024, 10000: 15901.05029296875, 11000: 16067.45740699768, 12000: 17204.15908408165, 13000: 18973.779888868332, 14000: 21984.375041007996, 15000: 26029.697537899017, 16000: 28096.6928460598, 17000: 30172.137146949768, 18000: 34025.61450791359, 19000: 37882.36828494072, 20000: 41870.92963194847, 21000: 42181.10757613182, 22000: 42396.374671936035, 23000: 42546.528192043304, 24000: 42696.62056708336, 25000: 42848.64104294777, 26000: 43034.66680288315, 27000: 43302.745085954666, 28000: 43492.07658791542, 29000: 43932.28278183937}, 'loss': {0: 0.09986153244972229, 1000: 4.804351806640625, 2000: 1.0768399238586426, 3000: 0.21144349873065948, 4000: 0.023003391921520233, 5000: 0.8617908358573914, 6000: 0.653708815574646, 7000: 0.161010280251503, 8000: 0.05184696242213249, 9000: 1.9250589609146118, 10000: 0.5241780281066895, 11000: 0.6154911518096924, 12000: 1.487850308418274, 13000: 0.120131716132164, 14000: 1.2932300567626953, 15000: 0.2513750493526459, 16000: 0.1360238939523697, 17000: 0.32716605067253113, 18000: 0.03420649468898773, 19000: 0.15236254036426544, 20000: 0.0064801559783518314, 21000: 1.4658818244934082, 22000: 0.0016155298799276352, 23000: 0.2276487499475479, 24000: 0.32102516293525696, 25000: 0.0807732492685318, 26000: 0.565284013748169, 27000: 1.7531567811965942, 28000: 0.023971840739250183, 29000: 0.03402503579854965}, 'F1': {0: 0.7561139429266851, 1000: 0.7391152831181412, 2000: 0.7446249511211497, 3000: 0.7533421380974447, 4000: 0.753305146912281, 5000: 0.7419449651203358, 6000: 0.7365181398403124, 7000: 0.754924241201729, 8000: 0.7504459634802653, 9000: 0.716279804393078, 10000: 0.7554053927213628, 11000: 0.7433780304010007, 12000: 0.732898970882395, 13000: 0.7144993970765288, 14000: 0.7449255336430753, 15000: 0.7297865653075757, 16000: 0.7268882227343697, 17000: 0.7244902753780932, 18000: 0.7358859984956428, 19000: 0.7207776296191057, 20000: 0.6877438092175656, 21000: 0.7542745555665582, 22000: 0.75257351474036, 23000: 0.7395447171753865, 24000: 0.7283808335264284, 25000: 0.7380082673598544, 26000: 0.7449320230366467, 27000: 0.7508736172828634, 28000: 0.7570946345271544, 29000: 0.754061644310152}, 'Accuracy': {0: 0.7110315876402175, 1000: 0.7037368384832428, 2000: 0.7014658316702223, 3000: 0.7076594866148235, 4000: 0.7146789622187049, 5000: 0.7075218498382768, 6000: 0.7053884798018031, 7000: 0.7156424196545317, 8000: 0.70676484756727, 9000: 0.694652811231161, 10000: 0.7168123322551786, 11000: 0.695065721560801, 12000: 0.7018787419998623, 13000: 0.6710481040534031, 14000: 0.6991260064689285, 15000: 0.6882527011217398, 16000: 0.6874956988507329, 17000: 0.681370862294405, 18000: 0.6885279746748331, 19000: 0.6856376023673526, 20000: 0.6504025875713991, 21000: 0.7084164888858303, 22000: 0.7116509531346776, 23000: 0.6914871653705871, 24000: 0.6851558736494391, 25000: 0.6907989814878536, 26000: 0.7091734911568371, 27000: 0.710343403757484, 28000: 0.7178446080792787, 29000: 0.7216296194343128}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "def train_model(model, train_data, criterion, optimizer, num_epochs, test_data, eval_interval=100):\n",
    "    logger = {'time': {}, 'loss': {}, 'F1': {}, 'Accuracy': {}}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for i, (sequence, label) in enumerate(train_data):\n",
    "            # Convert sequence and label to tensors if they are not already\n",
    "            if not isinstance(sequence, torch.Tensor):\n",
    "                sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "            if not isinstance(label, torch.Tensor):\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sequence.unsqueeze(0))\n",
    "            loss = criterion(outputs, label.unsqueeze(0))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Logging\n",
    "            if i % 1000 == 0:\n",
    "                logger['time'][i] = time.time() - epoch_start_time\n",
    "                logger['loss'][i] = loss.item()\n",
    "\n",
    "                # Evaluate model performance on test data\n",
    "                f1_score_value, accuracy = evaluate_model(model, test_data)\n",
    "                logger['F1'][i] = f1_score_value\n",
    "                logger['Accuracy'][i] = accuracy\n",
    "\n",
    "                print(f\"Epoch {epoch + 1}, Step {i}, Loss: {loss.item()}, F1: {f1_score_value}, Accuracy: {accuracy}, Time Elapsed: {time.time() - epoch_start_time} seconds\")\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        print(f\"Epoch {epoch + 1} completed. Time: {epoch_end_time - epoch_start_time}\")\n",
    "\n",
    "        # Print detailed logger information\n",
    "        print(\"Logger\", logger)\n",
    "        \n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_data):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence, label in test_data:\n",
    "            # Ensure label is a tensor\n",
    "            if not isinstance(label, torch.Tensor):\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            outputs = model(sequence.unsqueeze(0))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_predictions.append(predicted.item())\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "    # Calculate confusion matrix and metrics\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    f1_score_value = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "    return f1_score_value, accuracy\n",
    "\n",
    "# Load and shuffle MNIST dataset\n",
    "train_data, test_data = load_and_shuffle_mnist()\n",
    "\n",
    "# Set LSTM parameters\n",
    "input_size = 784  # 28x28\n",
    "hidden_size = 128\n",
    "num_classes = 11  # Digits 0-9 and 'null'\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "window_size = 10  # Example window size\n",
    "\n",
    "# Create model\n",
    "# model = SimpleLSTM(input_size, hidden_size, num_classes)\n",
    "model = LSTMOverCNN(hidden_size, num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Example of training with a single data point\n",
    "for size in [32000]:\n",
    "    print(f\"Training with dataset size: {size}\")\n",
    "    sampled_train_data = balanced_sampling(train_data, size)\n",
    "    sampled_test_data = balanced_sampling(test_data, size // 2)\n",
    "\n",
    "    train_sequences, train_labels = create_sequences(sampled_train_data, window_size)\n",
    "    test_sequences, test_labels = create_sequences(sampled_test_data, window_size)\n",
    "\n",
    "    # Convert sequences and labels into a list of tuples for easier iteration\n",
    "    train_data_tuples = list(zip(train_sequences, train_labels))\n",
    "    test_data_tuples = list(zip(test_sequences, test_labels))\n",
    "\n",
    "    train_model(model, train_data_tuples, criterion, optimizer, num_epochs, test_data_tuples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
