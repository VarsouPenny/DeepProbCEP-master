{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379ab926",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2326fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def load_and_shuffle_mnist():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5, ))])\n",
    "    mnist_train = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    mnist_test = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "    train_data = list(mnist_train)\n",
    "    test_data = list(mnist_test)\n",
    "\n",
    "    random.shuffle(train_data)\n",
    "    random.shuffle(test_data)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96a58577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(mnist_data, window_size):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(mnist_data) - window_size + 1):\n",
    "        window = mnist_data[i:i + window_size]\n",
    "        sequence_images = torch.stack([img for img, _ in window])\n",
    "\n",
    "        # Default label is 'null' (using a specific number to represent 'null', e.g., 10)\n",
    "        label = 10  # Assuming 10 represents 'null'\n",
    "\n",
    "        # Check for the condition in the last window_size elements\n",
    "        last_digit = window[-1][1]\n",
    "        for _, prev_label in window[:-1]:\n",
    "            if prev_label == last_digit:\n",
    "                label = last_digit  # Label is the digit itself if condition is met\n",
    "                break\n",
    "\n",
    "        sequences.append(sequence_images)\n",
    "        labels.append(label)\n",
    "\n",
    "    return sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a47803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTSequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels  # Labels are already numerical, no need for a map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        # Ensure label is a tensor of dtype torch.long\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return sequence, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465eb258",
   "metadata": {},
   "source": [
    "# LSMT Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "852ce7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, window_size, 28*28)  # Reshape x\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e0774f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sampling(mnist_data, size, num_classes=11):\n",
    "    print('balanced_sampling')\n",
    "    # Group data by labels\n",
    "    grouped_data = {label: [] for label in range(num_classes)}\n",
    "    for img, label in mnist_data:\n",
    "        grouped_data[label].append((img, label))\n",
    "\n",
    "    # Calculate the number of samples per class\n",
    "    samples_per_class = size // num_classes\n",
    "\n",
    "    # Initialize list for sampled data\n",
    "    sampled_data = []\n",
    "\n",
    "    for label, data in grouped_data.items():\n",
    "        data_len = len(data)\n",
    "        if data_len == 0:\n",
    "            print(f\"Warning: No data for class {label}. Skipping this class.\")\n",
    "            continue\n",
    "        if data_len >= samples_per_class:\n",
    "            sampled_data.extend(random.sample(data, samples_per_class))\n",
    "        else:\n",
    "            # Efficiently replicate data to meet the required number of samples\n",
    "            repeats = samples_per_class // data_len\n",
    "            remainder = samples_per_class % data_len\n",
    "            sampled_data.extend(data * repeats + random.sample(data, remainder))\n",
    "\n",
    "    # Shuffle the final dataset using Python's random.shuffle for compatibility\n",
    "    random.shuffle(sampled_data)\n",
    "    print('Done sampling.')\n",
    "    return sampled_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723749df",
   "metadata": {},
   "source": [
    "# Train and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fee76e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs,test_loader):\n",
    "    model = model.to(device)  # Move model to GPU\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        logger = {'time': {}, 'loss': {}, 'F1': {}, 'Accuracy': {}}\n",
    "        print(f\"Starting Epoch {epoch + 1}/{num_epochs}\")  # Print at the start of each epoch\n",
    "\n",
    "\n",
    "        for i, (sequences, labels) in enumerate(train_loader):\n",
    "            sequences, labels = sequences.to(device), labels.to(device)  # Move data to GPU\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Logging\n",
    "            if i % 100 == 0:\n",
    "                logger['time'][i] = time.time() - epoch_start_time\n",
    "                logger['loss'][i] = loss.item()\n",
    "                print(f\"Epoch {epoch + 1}, Step {i}, Loss: {loss.item()}, Time Elapsed: {time.time() - epoch_start_time} seconds\")\n",
    "\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        print(f\"Epoch {epoch + 1}\\n\")\n",
    "        print(f\"Writing snapshot to model_iter_{(epoch + 1) * len(train_loader):06d}.mdl\")\n",
    "        print(f\"Epoch time: {epoch_end_time - epoch_start_time}\")\n",
    "\n",
    "        # Evaluate at the end of the epoch\n",
    "        f1_score, accuracy = evaluate_model(model, test_loader)\n",
    "        logger['F1'][len(test_loader) * (epoch + 1)] = f1_score\n",
    "        logger['Accuracy'][len(test_loader) * (epoch + 1)] = accuracy\n",
    "\n",
    "        # Print detailed logger information\n",
    "        print(\"Logger\", logger)\n",
    "\n",
    "# Update the evaluate_model function to return F1 score and accuracy\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            outputs = model(sequences)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "    # Compute F1 score and accuracy\n",
    "    f1_score_value = f1_score(all_labels, all_predictions, average='macro')  # Change average as needed\n",
    "    accuracy = correct / total  # Corrected accuracy calculation\n",
    "    return f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ed04d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with dataset size: 1000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Done sample data.\n",
      "Starting Epoch 1/10\n",
      "Epoch 1, Step 0, Loss: 2.2875936031341553, Time Elapsed: 0.1277780532836914 seconds\n",
      "Epoch 1\n",
      "\n",
      "Writing snapshot to model_iter_000009.mdl\n",
      "Epoch time: 0.9980049133300781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.00      0.00      0.00        29\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.00      0.00      0.00        26\n",
      "           7       0.00      0.00      0.00        27\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.41      1.00      0.58       179\n",
      "\n",
      "    accuracy                           0.41       441\n",
      "   macro avg       0.04      0.09      0.05       441\n",
      "weighted avg       0.16      0.41      0.23       441\n",
      "\n",
      "Logger {'time': {0: 0.12775707244873047}, 'loss': {0: 2.2875936031341553}, 'F1': {5: 0.05249266862170088}, 'Accuracy': {5: 0.40589569160997735}}\n",
      "Starting Epoch 2/10\n",
      "Epoch 2, Step 0, Loss: 1.961031436920166, Time Elapsed: 0.06719732284545898 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "\n",
      "Writing snapshot to model_iter_000018.mdl\n",
      "Epoch time: 0.6590173244476318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.00      0.00      0.00        29\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.00      0.00      0.00        26\n",
      "           7       0.00      0.00      0.00        27\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.41      1.00      0.58       179\n",
      "\n",
      "    accuracy                           0.41       441\n",
      "   macro avg       0.04      0.09      0.05       441\n",
      "weighted avg       0.16      0.41      0.23       441\n",
      "\n",
      "Logger {'time': {0: 0.06718325614929199}, 'loss': {0: 1.961031436920166}, 'F1': {10: 0.05249266862170088}, 'Accuracy': {10: 0.40589569160997735}}\n",
      "Starting Epoch 3/10\n",
      "Epoch 3, Step 0, Loss: 1.7852561473846436, Time Elapsed: 0.05475211143493652 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "\n",
      "Writing snapshot to model_iter_000027.mdl\n",
      "Epoch time: 0.4717540740966797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.00      0.00      0.00        29\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.50      0.04      0.07        26\n",
      "           7       0.00      0.00      0.00        27\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.41      0.99      0.58       179\n",
      "\n",
      "    accuracy                           0.41       441\n",
      "   macro avg       0.08      0.09      0.06       441\n",
      "weighted avg       0.19      0.41      0.24       441\n",
      "\n",
      "Logger {'time': {0: 0.05473208427429199}, 'loss': {0: 1.7852561473846436}, 'F1': {15: 0.05886185012398604}, 'Accuracy': {15: 0.40589569160997735}}\n",
      "Starting Epoch 4/10\n",
      "Epoch 4, Step 0, Loss: 1.6081671714782715, Time Elapsed: 0.04738306999206543 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "\n",
      "Writing snapshot to model_iter_000036.mdl\n",
      "Epoch time: 0.4778261184692383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.11      0.17        28\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.00      0.00      0.00        29\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.60      0.12      0.19        26\n",
      "           7       0.00      0.00      0.00        27\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.40      0.97      0.57       179\n",
      "\n",
      "    accuracy                           0.41       441\n",
      "   macro avg       0.13      0.11      0.08       441\n",
      "weighted avg       0.23      0.41      0.25       441\n",
      "\n",
      "Logger {'time': {0: 0.04736614227294922}, 'loss': {0: 1.6081671714782715}, 'F1': {20: 0.0849141732630697}, 'Accuracy': {20: 0.40589569160997735}}\n",
      "Starting Epoch 5/10\n",
      "Epoch 5, Step 0, Loss: 1.4979350566864014, Time Elapsed: 0.05806303024291992 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "\n",
      "Writing snapshot to model_iter_000045.mdl\n",
      "Epoch time: 0.471494197845459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.29      0.40        28\n",
      "           1       0.75      0.21      0.33        28\n",
      "           2       0.00      0.00      0.00        29\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.67      0.31      0.42        26\n",
      "           7       0.40      0.07      0.12        27\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.41      0.93      0.57       179\n",
      "\n",
      "    accuracy                           0.43       441\n",
      "   macro avg       0.26      0.16      0.17       441\n",
      "weighted avg       0.32      0.43      0.31       441\n",
      "\n",
      "Logger {'time': {0: 0.05804610252380371}, 'loss': {0: 1.4979350566864014}, 'F1': {25: 0.16807765749943238}, 'Accuracy': {25: 0.4308390022675737}}\n",
      "Starting Epoch 6/10\n",
      "Epoch 6, Step 0, Loss: 1.401717185974121, Time Elapsed: 0.04977989196777344 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "\n",
      "Writing snapshot to model_iter_000054.mdl\n",
      "Epoch time: 0.47171783447265625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59        28\n",
      "           1       0.60      0.75      0.67        28\n",
      "           2       0.67      0.07      0.12        29\n",
      "           3       0.00      0.00      0.00        25\n",
      "           4       0.67      0.18      0.29        22\n",
      "           5       0.50      0.05      0.08        22\n",
      "           6       0.58      0.42      0.49        26\n",
      "           7       0.47      0.30      0.36        27\n",
      "           8       1.00      0.04      0.07        27\n",
      "           9       0.50      0.04      0.07        28\n",
      "          10       0.40      0.72      0.51       179\n",
      "\n",
      "    accuracy                           0.44       441\n",
      "   macro avg       0.54      0.29      0.30       441\n",
      "weighted avg       0.49      0.44      0.37       441\n",
      "\n",
      "Logger {'time': {0: 0.0497589111328125}, 'loss': {0: 1.401717185974121}, 'F1': {30: 0.2952274392953682}, 'Accuracy': {30: 0.4399092970521542}}\n",
      "Starting Epoch 7/10\n",
      "Epoch 7, Step 0, Loss: 1.2701380252838135, Time Elapsed: 0.05144810676574707 seconds\n",
      "Epoch 7\n",
      "\n",
      "Writing snapshot to model_iter_000063.mdl\n",
      "Epoch time: 0.49964404106140137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.39      0.46        28\n",
      "           1       0.61      0.71      0.66        28\n",
      "           2       0.50      0.07      0.12        29\n",
      "           3       0.17      0.04      0.06        25\n",
      "           4       0.78      0.32      0.45        22\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.63      0.46      0.53        26\n",
      "           7       0.61      0.63      0.62        27\n",
      "           8       1.00      0.07      0.14        27\n",
      "           9       0.60      0.11      0.18        28\n",
      "          10       0.41      0.72      0.52       179\n",
      "\n",
      "    accuracy                           0.46       441\n",
      "   macro avg       0.53      0.32      0.34       441\n",
      "weighted avg       0.50      0.46      0.41       441\n",
      "\n",
      "Logger {'time': {0: 0.05142998695373535}, 'loss': {0: 1.2701380252838135}, 'F1': {35: 0.3405457392314324}, 'Accuracy': {35: 0.46258503401360546}}\n",
      "Starting Epoch 8/10\n",
      "Epoch 8, Step 0, Loss: 1.2162054777145386, Time Elapsed: 0.05370521545410156 seconds\n",
      "Epoch 8\n",
      "\n",
      "Writing snapshot to model_iter_000072.mdl\n",
      "Epoch time: 0.4984118938446045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.43      0.46        28\n",
      "           1       0.59      0.86      0.70        28\n",
      "           2       0.43      0.10      0.17        29\n",
      "           3       0.50      0.32      0.39        25\n",
      "           4       0.60      0.14      0.22        22\n",
      "           5       0.44      0.18      0.26        22\n",
      "           6       0.65      0.58      0.61        26\n",
      "           7       0.62      0.67      0.64        27\n",
      "           8       0.86      0.22      0.35        27\n",
      "           9       0.62      0.46      0.53        28\n",
      "          10       0.41      0.59      0.48       179\n",
      "\n",
      "    accuracy                           0.48       441\n",
      "   macro avg       0.57      0.41      0.44       441\n",
      "weighted avg       0.51      0.48      0.46       441\n",
      "\n",
      "Logger {'time': {0: 0.05368804931640625}, 'loss': {0: 1.2162054777145386}, 'F1': {40: 0.4379146972666824}, 'Accuracy': {40: 0.48072562358276644}}\n",
      "Starting Epoch 9/10\n",
      "Epoch 9, Step 0, Loss: 1.1085114479064941, Time Elapsed: 0.06062889099121094 seconds\n",
      "Epoch 9\n",
      "\n",
      "Writing snapshot to model_iter_000081.mdl\n",
      "Epoch time: 0.5198080539703369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63        28\n",
      "           1       0.59      0.86      0.70        28\n",
      "           2       0.56      0.34      0.43        29\n",
      "           3       0.38      0.20      0.26        25\n",
      "           4       0.67      0.55      0.60        22\n",
      "           5       0.38      0.14      0.20        22\n",
      "           6       0.62      0.58      0.60        26\n",
      "           7       0.59      0.74      0.66        27\n",
      "           8       0.88      0.26      0.40        27\n",
      "           9       0.62      0.71      0.67        28\n",
      "          10       0.42      0.50      0.45       179\n",
      "\n",
      "    accuracy                           0.51       441\n",
      "   macro avg       0.57      0.50      0.51       441\n",
      "weighted avg       0.52      0.51      0.49       441\n",
      "\n",
      "Logger {'time': {0: 0.060613155364990234}, 'loss': {0: 1.1085114479064941}, 'F1': {45: 0.508560120101327}, 'Accuracy': {45: 0.5079365079365079}}\n",
      "Starting Epoch 10/10\n",
      "Epoch 10, Step 0, Loss: 1.0220950841903687, Time Elapsed: 0.05530381202697754 seconds\n",
      "Epoch 10\n",
      "\n",
      "Writing snapshot to model_iter_000090.mdl\n",
      "Epoch time: 0.5099978446960449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54        28\n",
      "           1       0.61      0.82      0.70        28\n",
      "           2       0.54      0.24      0.33        29\n",
      "           3       0.58      0.44      0.50        25\n",
      "           4       0.69      0.41      0.51        22\n",
      "           5       0.47      0.32      0.38        22\n",
      "           6       0.61      0.54      0.57        26\n",
      "           7       0.57      0.63      0.60        27\n",
      "           8       0.88      0.26      0.40        27\n",
      "           9       0.73      0.39      0.51        28\n",
      "          10       0.41      0.55      0.47       179\n",
      "\n",
      "    accuracy                           0.50       441\n",
      "   macro avg       0.60      0.47      0.50       441\n",
      "weighted avg       0.54      0.50      0.49       441\n",
      "\n",
      "Logger {'time': {0: 0.055287837982177734}, 'loss': {0: 1.0220950841903687}, 'F1': {50: 0.5010830296075651}, 'Accuracy': {50: 0.4988662131519274}}\n",
      "Training with dataset size: 5000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Done sample data.\n",
      "Starting Epoch 1/10\n",
      "Epoch 1, Step 0, Loss: 1.2205967903137207, Time Elapsed: 0.04185891151428223 seconds\n",
      "Epoch 1\n",
      "\n",
      "Writing snapshot to model_iter_000046.mdl\n",
      "Epoch time: 2.8753767013549805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74       144\n",
      "           1       0.78      0.54      0.64       147\n",
      "           2       0.72      0.32      0.44       144\n",
      "           3       0.92      0.09      0.16       129\n",
      "           4       0.62      0.46      0.53       143\n",
      "           5       0.61      0.32      0.42       131\n",
      "           6       0.71      0.46      0.56       142\n",
      "           7       0.67      0.71      0.69       140\n",
      "           8       0.63      0.41      0.50       137\n",
      "           9       0.64      0.67      0.66       141\n",
      "          10       0.44      0.63      0.52       863\n",
      "\n",
      "    accuracy                           0.54      2261\n",
      "   macro avg       0.67      0.49      0.53      2261\n",
      "weighted avg       0.60      0.54      0.53      2261\n",
      "\n",
      "Logger {'time': {0: 0.04184603691101074}, 'loss': {0: 1.2205967903137207}, 'F1': {23: 0.5316554847581957}, 'Accuracy': {23: 0.541795665634675}}\n",
      "Starting Epoch 2/10\n",
      "Epoch 2, Step 0, Loss: 1.0267547369003296, Time Elapsed: 0.05380606651306152 seconds\n",
      "Epoch 2\n",
      "\n",
      "Writing snapshot to model_iter_000092.mdl\n",
      "Epoch time: 2.70497989654541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71       144\n",
      "           1       0.71      0.75      0.73       147\n",
      "           2       0.63      0.50      0.56       144\n",
      "           3       0.74      0.31      0.44       129\n",
      "           4       0.62      0.31      0.41       143\n",
      "           5       0.62      0.53      0.57       131\n",
      "           6       0.67      0.63      0.65       142\n",
      "           7       0.80      0.40      0.53       140\n",
      "           8       0.62      0.62      0.62       137\n",
      "           9       0.71      0.68      0.70       141\n",
      "          10       0.46      0.62      0.53       863\n",
      "\n",
      "    accuracy                           0.57      2261\n",
      "   macro avg       0.67      0.54      0.59      2261\n",
      "weighted avg       0.60      0.57      0.57      2261\n",
      "\n",
      "Logger {'time': {0: 0.05379033088684082}, 'loss': {0: 1.0267547369003296}, 'F1': {46: 0.5854361704682938}, 'Accuracy': {46: 0.5701017249004865}}\n",
      "Starting Epoch 3/10\n",
      "Epoch 3, Step 0, Loss: 0.9792246222496033, Time Elapsed: 0.049993276596069336 seconds\n",
      "Epoch 3\n",
      "\n",
      "Writing snapshot to model_iter_000138.mdl\n",
      "Epoch time: 2.331008195877075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       144\n",
      "           1       0.70      0.82      0.75       147\n",
      "           2       0.66      0.55      0.60       144\n",
      "           3       0.63      0.57      0.60       129\n",
      "           4       0.64      0.68      0.66       143\n",
      "           5       0.67      0.46      0.54       131\n",
      "           6       0.62      0.85      0.71       142\n",
      "           7       0.68      0.74      0.71       140\n",
      "           8       0.68      0.25      0.36       137\n",
      "           9       0.71      0.62      0.66       141\n",
      "          10       0.47      0.51      0.49       863\n",
      "\n",
      "    accuracy                           0.59      2261\n",
      "   macro avg       0.65      0.62      0.62      2261\n",
      "weighted avg       0.60      0.59      0.58      2261\n",
      "\n",
      "Logger {'time': {0: 0.04997134208679199}, 'loss': {0: 0.9792246222496033}, 'F1': {69: 0.6232088831131386}, 'Accuracy': {69: 0.5886775762936753}}\n",
      "Starting Epoch 4/10\n",
      "Epoch 4, Step 0, Loss: 0.9188303351402283, Time Elapsed: 0.047425031661987305 seconds\n",
      "Epoch 4\n",
      "\n",
      "Writing snapshot to model_iter_000184.mdl\n",
      "Epoch time: 2.3321568965911865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       144\n",
      "           1       0.87      0.46      0.60       147\n",
      "           2       0.71      0.53      0.61       144\n",
      "           3       0.61      0.60      0.61       129\n",
      "           4       0.65      0.59      0.62       143\n",
      "           5       0.61      0.63      0.62       131\n",
      "           6       0.69      0.81      0.74       142\n",
      "           7       0.63      0.82      0.71       140\n",
      "           8       0.61      0.58      0.59       137\n",
      "           9       0.72      0.62      0.67       141\n",
      "          10       0.49      0.52      0.51       863\n",
      "\n",
      "    accuracy                           0.60      2261\n",
      "   macro avg       0.67      0.64      0.64      2261\n",
      "weighted avg       0.61      0.60      0.60      2261\n",
      "\n",
      "Logger {'time': {0: 0.04740786552429199}, 'loss': {0: 0.9188303351402283}, 'F1': {92: 0.6424543832333153}, 'Accuracy': {92: 0.599734630694383}}\n",
      "Starting Epoch 5/10\n",
      "Epoch 5, Step 0, Loss: 0.8607943058013916, Time Elapsed: 0.04468202590942383 seconds\n",
      "Epoch 5\n",
      "\n",
      "Writing snapshot to model_iter_000230.mdl\n",
      "Epoch time: 2.4631710052490234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       144\n",
      "           1       0.76      0.73      0.74       147\n",
      "           2       0.72      0.55      0.62       144\n",
      "           3       0.60      0.61      0.61       129\n",
      "           4       0.72      0.39      0.51       143\n",
      "           5       0.66      0.40      0.50       131\n",
      "           6       0.76      0.68      0.71       142\n",
      "           7       0.65      0.81      0.72       140\n",
      "           8       0.59      0.55      0.57       137\n",
      "           9       0.71      0.68      0.70       141\n",
      "          10       0.48      0.56      0.52       863\n",
      "\n",
      "    accuracy                           0.60      2261\n",
      "   macro avg       0.67      0.61      0.63      2261\n",
      "weighted avg       0.61      0.60      0.60      2261\n",
      "\n",
      "Logger {'time': {0: 0.04466581344604492}, 'loss': {0: 0.8607943058013916}, 'F1': {115: 0.6337270958345388}, 'Accuracy': {115: 0.5992923485183547}}\n",
      "Starting Epoch 6/10\n",
      "Epoch 6, Step 0, Loss: 0.7925148010253906, Time Elapsed: 0.05427885055541992 seconds\n",
      "Epoch 6\n",
      "\n",
      "Writing snapshot to model_iter_000276.mdl\n",
      "Epoch time: 2.6412527561187744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       144\n",
      "           1       0.74      0.68      0.71       147\n",
      "           2       0.68      0.69      0.68       144\n",
      "           3       0.56      0.78      0.65       129\n",
      "           4       0.67      0.49      0.57       143\n",
      "           5       0.72      0.44      0.54       131\n",
      "           6       0.67      0.77      0.72       142\n",
      "           7       0.77      0.60      0.67       140\n",
      "           8       0.63      0.53      0.58       137\n",
      "           9       0.82      0.51      0.63       141\n",
      "          10       0.50      0.57      0.53       863\n",
      "\n",
      "    accuracy                           0.61      2261\n",
      "   macro avg       0.68      0.62      0.64      2261\n",
      "weighted avg       0.62      0.61      0.61      2261\n",
      "\n",
      "Logger {'time': {0: 0.05426287651062012}, 'loss': {0: 0.7925148010253906}, 'F1': {138: 0.641741055594217}, 'Accuracy': {138: 0.6072534276868642}}\n",
      "Starting Epoch 7/10\n",
      "Epoch 7, Step 0, Loss: 0.7897536754608154, Time Elapsed: 0.049852848052978516 seconds\n",
      "Epoch 7\n",
      "\n",
      "Writing snapshot to model_iter_000322.mdl\n",
      "Epoch time: 2.9910519123077393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.75       144\n",
      "           1       0.76      0.61      0.68       147\n",
      "           2       0.73      0.40      0.51       144\n",
      "           3       0.66      0.53      0.59       129\n",
      "           4       0.62      0.73      0.67       143\n",
      "           5       0.77      0.28      0.41       131\n",
      "           6       0.78      0.54      0.64       142\n",
      "           7       0.73      0.73      0.73       140\n",
      "           8       0.70      0.17      0.27       137\n",
      "           9       0.82      0.53      0.64       141\n",
      "          10       0.48      0.70      0.57       863\n",
      "\n",
      "    accuracy                           0.59      2261\n",
      "   macro avg       0.71      0.54      0.59      2261\n",
      "weighted avg       0.64      0.59      0.58      2261\n",
      "\n",
      "Logger {'time': {0: 0.0498349666595459}, 'loss': {0: 0.7897536754608154}, 'F1': {161: 0.5880606392416419}, 'Accuracy': {161: 0.5935426802299867}}\n",
      "Starting Epoch 8/10\n",
      "Epoch 8, Step 0, Loss: 0.7321598529815674, Time Elapsed: 0.058860063552856445 seconds\n",
      "Epoch 8\n",
      "\n",
      "Writing snapshot to model_iter_000368.mdl\n",
      "Epoch time: 3.4993860721588135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       144\n",
      "           1       0.80      0.67      0.73       147\n",
      "           2       0.75      0.43      0.55       144\n",
      "           3       0.66      0.67      0.66       129\n",
      "           4       0.65      0.62      0.64       143\n",
      "           5       0.58      0.74      0.65       131\n",
      "           6       0.71      0.79      0.75       142\n",
      "           7       0.66      0.78      0.72       140\n",
      "           8       0.61      0.46      0.52       137\n",
      "           9       0.82      0.58      0.68       141\n",
      "          10       0.51      0.54      0.53       863\n",
      "\n",
      "    accuracy                           0.62      2261\n",
      "   macro avg       0.68      0.65      0.66      2261\n",
      "weighted avg       0.63      0.62      0.61      2261\n",
      "\n",
      "Logger {'time': {0: 0.05884218215942383}, 'loss': {0: 0.7321598529815674}, 'F1': {184: 0.6551626035564361}, 'Accuracy': {184: 0.616983635559487}}\n",
      "Starting Epoch 9/10\n",
      "Epoch 9, Step 0, Loss: 0.7741443514823914, Time Elapsed: 0.04888319969177246 seconds\n",
      "Epoch 9\n",
      "\n",
      "Writing snapshot to model_iter_000414.mdl\n",
      "Epoch time: 2.5697100162506104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       144\n",
      "           1       0.74      0.78      0.76       147\n",
      "           2       0.75      0.47      0.58       144\n",
      "           3       0.74      0.53      0.62       129\n",
      "           4       0.67      0.56      0.61       143\n",
      "           5       0.72      0.54      0.62       131\n",
      "           6       0.71      0.80      0.75       142\n",
      "           7       0.73      0.69      0.71       140\n",
      "           8       0.64      0.60      0.62       137\n",
      "           9       0.77      0.70      0.73       141\n",
      "          10       0.53      0.62      0.57       863\n",
      "\n",
      "    accuracy                           0.64      2261\n",
      "   macro avg       0.71      0.64      0.67      2261\n",
      "weighted avg       0.65      0.64      0.64      2261\n",
      "\n",
      "Logger {'time': {0: 0.04886603355407715}, 'loss': {0: 0.7741443514823914}, 'F1': {207: 0.6670870478595734}, 'Accuracy': {207: 0.6355594869526758}}\n",
      "Starting Epoch 10/10\n",
      "Epoch 10, Step 0, Loss: 0.6793205142021179, Time Elapsed: 0.05186605453491211 seconds\n",
      "Epoch 10\n",
      "\n",
      "Writing snapshot to model_iter_000460.mdl\n",
      "Epoch time: 2.5973901748657227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       144\n",
      "           1       0.71      0.85      0.78       147\n",
      "           2       0.72      0.58      0.64       144\n",
      "           3       0.55      0.74      0.63       129\n",
      "           4       0.64      0.58      0.61       143\n",
      "           5       0.65      0.68      0.66       131\n",
      "           6       0.78      0.72      0.75       142\n",
      "           7       0.69      0.81      0.75       140\n",
      "           8       0.64      0.54      0.58       137\n",
      "           9       0.73      0.71      0.72       141\n",
      "          10       0.54      0.51      0.53       863\n",
      "\n",
      "    accuracy                           0.63      2261\n",
      "   macro avg       0.67      0.69      0.68      2261\n",
      "weighted avg       0.63      0.63      0.63      2261\n",
      "\n",
      "Logger {'time': {0: 0.051850318908691406}, 'loss': {0: 0.6793205142021179}, 'F1': {230: 0.6758815917440683}, 'Accuracy': {230: 0.6324635117204777}}\n",
      "Training with dataset size: 10000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Done sample data.\n",
      "Starting Epoch 1/10\n",
      "Epoch 1, Step 0, Loss: 0.849873423576355, Time Elapsed: 0.0567929744720459 seconds\n",
      "Epoch 1\n",
      "\n",
      "Writing snapshot to model_iter_000091.mdl\n",
      "Epoch time: 4.733844041824341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       277\n",
      "           1       0.71      0.89      0.79       276\n",
      "           2       0.85      0.52      0.65       284\n",
      "           3       0.70      0.56      0.63       293\n",
      "           4       0.65      0.71      0.68       276\n",
      "           5       0.63      0.71      0.67       277\n",
      "           6       0.71      0.80      0.75       291\n",
      "           7       0.66      0.74      0.70       279\n",
      "           8       0.62      0.74      0.67       275\n",
      "           9       0.64      0.74      0.69       274\n",
      "          10       0.55      0.48      0.51      1729\n",
      "\n",
      "    accuracy                           0.64      4531\n",
      "   macro avg       0.67      0.71      0.68      4531\n",
      "weighted avg       0.64      0.64      0.63      4531\n",
      "\n",
      "Logger {'time': {0: 0.05676412582397461}, 'loss': {0: 0.849873423576355}, 'F1': {46: 0.6835453092829931}, 'Accuracy': {46: 0.6360626793202384}}\n",
      "Starting Epoch 2/10\n",
      "Epoch 2, Step 0, Loss: 0.7434381246566772, Time Elapsed: 0.054162025451660156 seconds\n",
      "Epoch 2\n",
      "\n",
      "Writing snapshot to model_iter_000182.mdl\n",
      "Epoch time: 4.743933916091919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       277\n",
      "           1       0.77      0.84      0.80       276\n",
      "           2       0.78      0.60      0.68       284\n",
      "           3       0.71      0.67      0.69       293\n",
      "           4       0.67      0.76      0.71       276\n",
      "           5       0.82      0.47      0.60       277\n",
      "           6       0.75      0.78      0.77       291\n",
      "           7       0.65      0.77      0.70       279\n",
      "           8       0.63      0.70      0.66       275\n",
      "           9       0.60      0.79      0.68       274\n",
      "          10       0.58      0.56      0.57      1729\n",
      "\n",
      "    accuracy                           0.66      4531\n",
      "   macro avg       0.71      0.70      0.70      4531\n",
      "weighted avg       0.66      0.66      0.66      4531\n",
      "\n",
      "Logger {'time': {0: 0.054145097732543945}, 'loss': {0: 0.7434381246566772}, 'F1': {92: 0.6971957272401468}, 'Accuracy': {92: 0.6581328625027588}}\n",
      "Starting Epoch 3/10\n",
      "Epoch 3, Step 0, Loss: 0.761451780796051, Time Elapsed: 0.049388885498046875 seconds\n",
      "Epoch 3\n",
      "\n",
      "Writing snapshot to model_iter_000273.mdl\n",
      "Epoch time: 4.586755037307739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       277\n",
      "           1       0.91      0.68      0.78       276\n",
      "           2       0.85      0.55      0.67       284\n",
      "           3       0.72      0.60      0.66       293\n",
      "           4       0.67      0.79      0.73       276\n",
      "           5       0.61      0.81      0.69       277\n",
      "           6       0.73      0.77      0.75       291\n",
      "           7       0.70      0.64      0.67       279\n",
      "           8       0.63      0.75      0.69       275\n",
      "           9       0.60      0.78      0.68       274\n",
      "          10       0.59      0.57      0.58      1729\n",
      "\n",
      "    accuracy                           0.66      4531\n",
      "   macro avg       0.71      0.71      0.70      4531\n",
      "weighted avg       0.67      0.66      0.66      4531\n",
      "\n",
      "Logger {'time': {0: 0.04937291145324707}, 'loss': {0: 0.761451780796051}, 'F1': {138: 0.6998545093416152}, 'Accuracy': {138: 0.6616640918119621}}\n",
      "Starting Epoch 4/10\n",
      "Epoch 4, Step 0, Loss: 0.7718244791030884, Time Elapsed: 0.04790210723876953 seconds\n",
      "Epoch 4\n",
      "\n",
      "Writing snapshot to model_iter_000364.mdl\n",
      "Epoch time: 4.598376989364624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       277\n",
      "           1       0.72      0.91      0.80       276\n",
      "           2       0.85      0.55      0.67       284\n",
      "           3       0.63      0.76      0.69       293\n",
      "           4       0.76      0.58      0.66       276\n",
      "           5       0.73      0.60      0.66       277\n",
      "           6       0.75      0.80      0.78       291\n",
      "           7       0.67      0.71      0.69       279\n",
      "           8       0.69      0.53      0.60       275\n",
      "           9       0.81      0.43      0.56       274\n",
      "          10       0.55      0.61      0.58      1729\n",
      "\n",
      "    accuracy                           0.65      4531\n",
      "   macro avg       0.72      0.67      0.68      4531\n",
      "weighted avg       0.67      0.65      0.65      4531\n",
      "\n",
      "Logger {'time': {0: 0.047884225845336914}, 'loss': {0: 0.7718244791030884}, 'F1': {184: 0.6829023416825336}, 'Accuracy': {184: 0.65393952769808}}\n",
      "Starting Epoch 5/10\n",
      "Epoch 5, Step 0, Loss: 0.6896913647651672, Time Elapsed: 0.05350518226623535 seconds\n",
      "Epoch 5\n",
      "\n",
      "Writing snapshot to model_iter_000455.mdl\n",
      "Epoch time: 4.87243390083313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       277\n",
      "           1       0.69      0.93      0.79       276\n",
      "           2       0.77      0.67      0.72       284\n",
      "           3       0.66      0.71      0.68       293\n",
      "           4       0.64      0.79      0.71       276\n",
      "           5       0.64      0.74      0.69       277\n",
      "           6       0.79      0.80      0.80       291\n",
      "           7       0.68      0.80      0.73       279\n",
      "           8       0.67      0.63      0.65       275\n",
      "           9       0.71      0.62      0.66       274\n",
      "          10       0.60      0.53      0.56      1729\n",
      "\n",
      "    accuracy                           0.67      4531\n",
      "   macro avg       0.70      0.74      0.71      4531\n",
      "weighted avg       0.67      0.67      0.67      4531\n",
      "\n",
      "Logger {'time': {0: 0.05348801612854004}, 'loss': {0: 0.6896913647651672}, 'F1': {230: 0.7131596529537801}, 'Accuracy': {230: 0.6700507614213198}}\n",
      "Starting Epoch 6/10\n",
      "Epoch 6, Step 0, Loss: 0.5835741758346558, Time Elapsed: 0.05670499801635742 seconds\n",
      "Epoch 6\n",
      "\n",
      "Writing snapshot to model_iter_000546.mdl\n",
      "Epoch time: 4.538954019546509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       277\n",
      "           1       0.65      0.96      0.78       276\n",
      "           2       0.73      0.71      0.72       284\n",
      "           3       0.67      0.72      0.70       293\n",
      "           4       0.57      0.88      0.69       276\n",
      "           5       0.67      0.74      0.70       277\n",
      "           6       0.68      0.89      0.77       291\n",
      "           7       0.72      0.68      0.70       279\n",
      "           8       0.69      0.64      0.66       275\n",
      "           9       0.65      0.72      0.69       274\n",
      "          10       0.61      0.45      0.52      1729\n",
      "\n",
      "    accuracy                           0.66      4531\n",
      "   macro avg       0.68      0.75      0.71      4531\n",
      "weighted avg       0.65      0.66      0.65      4531\n",
      "\n",
      "Logger {'time': {0: 0.05668783187866211}, 'loss': {0: 0.5835741758346558}, 'F1': {276: 0.705706741329862}, 'Accuracy': {276: 0.6570293533436328}}\n",
      "Starting Epoch 7/10\n",
      "Epoch 7, Step 0, Loss: 0.7759042978286743, Time Elapsed: 0.05129384994506836 seconds\n",
      "Epoch 7\n",
      "\n",
      "Writing snapshot to model_iter_000637.mdl\n",
      "Epoch time: 4.510154724121094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84       277\n",
      "           1       0.88      0.81      0.84       276\n",
      "           2       0.83      0.63      0.71       284\n",
      "           3       0.66      0.77      0.71       293\n",
      "           4       0.70      0.75      0.72       276\n",
      "           5       0.70      0.70      0.70       277\n",
      "           6       0.80      0.75      0.77       291\n",
      "           7       0.64      0.85      0.73       279\n",
      "           8       0.68      0.68      0.68       275\n",
      "           9       0.64      0.77      0.70       274\n",
      "          10       0.62      0.59      0.61      1729\n",
      "\n",
      "    accuracy                           0.69      4531\n",
      "   macro avg       0.73      0.74      0.73      4531\n",
      "weighted avg       0.70      0.69      0.69      4531\n",
      "\n",
      "Logger {'time': {0: 0.05127763748168945}, 'loss': {0: 0.7759042978286743}, 'F1': {322: 0.7287855647648084}, 'Accuracy': {322: 0.6903553299492385}}\n",
      "Starting Epoch 8/10\n",
      "Epoch 8, Step 0, Loss: 0.6152119636535645, Time Elapsed: 0.05057406425476074 seconds\n",
      "Epoch 8\n",
      "\n",
      "Writing snapshot to model_iter_000728.mdl\n",
      "Epoch time: 4.595077037811279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84       277\n",
      "           1       0.89      0.84      0.86       276\n",
      "           2       0.81      0.68      0.74       284\n",
      "           3       0.67      0.71      0.69       293\n",
      "           4       0.82      0.60      0.69       276\n",
      "           5       0.67      0.74      0.70       277\n",
      "           6       0.78      0.79      0.79       291\n",
      "           7       0.68      0.80      0.73       279\n",
      "           8       0.69      0.67      0.68       275\n",
      "           9       0.70      0.68      0.69       274\n",
      "          10       0.62      0.64      0.63      1729\n",
      "\n",
      "    accuracy                           0.70      4531\n",
      "   macro avg       0.74      0.72      0.73      4531\n",
      "weighted avg       0.70      0.70      0.70      4531\n",
      "\n",
      "Logger {'time': {0: 0.05055809020996094}, 'loss': {0: 0.6152119636535645}, 'F1': {368: 0.7315714186253593}, 'Accuracy': {368: 0.698300595894946}}\n",
      "Starting Epoch 9/10\n",
      "Epoch 9, Step 0, Loss: 0.5447084903717041, Time Elapsed: 0.04982781410217285 seconds\n",
      "Epoch 9\n",
      "\n",
      "Writing snapshot to model_iter_000819.mdl\n",
      "Epoch time: 4.706763982772827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81       277\n",
      "           1       0.72      0.95      0.81       276\n",
      "           2       0.71      0.79      0.74       284\n",
      "           3       0.73      0.55      0.62       293\n",
      "           4       0.68      0.78      0.72       276\n",
      "           5       0.70      0.64      0.67       277\n",
      "           6       0.74      0.83      0.78       291\n",
      "           7       0.68      0.80      0.73       279\n",
      "           8       0.67      0.73      0.70       275\n",
      "           9       0.59      0.80      0.68       274\n",
      "          10       0.61      0.53      0.57      1729\n",
      "\n",
      "    accuracy                           0.67      4531\n",
      "   macro avg       0.70      0.74      0.71      4531\n",
      "weighted avg       0.67      0.67      0.67      4531\n",
      "\n",
      "Logger {'time': {0: 0.049809932708740234}, 'loss': {0: 0.5447084903717041}, 'F1': {414: 0.7140540003907717}, 'Accuracy': {414: 0.6731405870668726}}\n",
      "Starting Epoch 10/10\n",
      "Epoch 10, Step 0, Loss: 0.5120734572410583, Time Elapsed: 0.054343223571777344 seconds\n",
      "Epoch 10\n",
      "\n",
      "Writing snapshot to model_iter_000910.mdl\n",
      "Epoch time: 4.650156021118164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       277\n",
      "           1       0.93      0.77      0.84       276\n",
      "           2       0.77      0.72      0.74       284\n",
      "           3       0.67      0.71      0.69       293\n",
      "           4       0.63      0.88      0.73       276\n",
      "           5       0.63      0.81      0.71       277\n",
      "           6       0.85      0.69      0.76       291\n",
      "           7       0.73      0.71      0.72       279\n",
      "           8       0.71      0.68      0.69       275\n",
      "           9       0.65      0.75      0.69       274\n",
      "          10       0.64      0.59      0.61      1729\n",
      "\n",
      "    accuracy                           0.70      4531\n",
      "   macro avg       0.73      0.74      0.73      4531\n",
      "weighted avg       0.70      0.70      0.69      4531\n",
      "\n",
      "Logger {'time': {0: 0.05432605743408203}, 'loss': {0: 0.5120734572410583}, 'F1': {460: 0.7329303860171271}, 'Accuracy': {460: 0.6954314720812182}}\n",
      "Training with dataset size: 20000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Done sample data.\n",
      "Starting Epoch 1/10\n",
      "Epoch 1, Step 0, Loss: 0.7091171741485596, Time Elapsed: 0.06009507179260254 seconds\n",
      "Epoch 1, Step 100, Loss: 0.6957259178161621, Time Elapsed: 5.069836139678955 seconds\n",
      "Epoch 1\n",
      "\n",
      "Writing snapshot to model_iter_000182.mdl\n",
      "Epoch time: 9.176456928253174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84       530\n",
      "           1       0.87      0.87      0.87       557\n",
      "           2       0.65      0.81      0.72       559\n",
      "           3       0.79      0.42      0.55       538\n",
      "           4       0.73      0.85      0.79       568\n",
      "           5       0.71      0.60      0.65       575\n",
      "           6       0.74      0.90      0.81       554\n",
      "           7       0.87      0.43      0.57       554\n",
      "           8       0.77      0.46      0.57       560\n",
      "           9       0.73      0.72      0.73       562\n",
      "          10       0.60      0.69      0.64      3524\n",
      "\n",
      "    accuracy                           0.69      9081\n",
      "   macro avg       0.76      0.69      0.70      9081\n",
      "weighted avg       0.71      0.69      0.68      9081\n",
      "\n",
      "Logger {'time': {0: 0.06008005142211914, 100: 5.069815158843994}, 'loss': {0: 0.7091171741485596, 100: 0.6957259178161621}, 'F1': {91: 0.7033487629462656}, 'Accuracy': {91: 0.6886906728333884}}\n",
      "Starting Epoch 2/10\n",
      "Epoch 2, Step 0, Loss: 0.5665620565414429, Time Elapsed: 0.05198788642883301 seconds\n",
      "Epoch 2, Step 100, Loss: 0.7746623158454895, Time Elapsed: 5.178118944168091 seconds\n",
      "Epoch 2\n",
      "\n",
      "Writing snapshot to model_iter_000364.mdl\n",
      "Epoch time: 9.412813901901245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       530\n",
      "           1       0.90      0.85      0.88       557\n",
      "           2       0.73      0.78      0.76       559\n",
      "           3       0.70      0.77      0.73       538\n",
      "           4       0.77      0.84      0.80       568\n",
      "           5       0.68      0.71      0.69       575\n",
      "           6       0.82      0.84      0.83       554\n",
      "           7       0.74      0.75      0.74       554\n",
      "           8       0.67      0.68      0.67       560\n",
      "           9       0.73      0.73      0.73       562\n",
      "          10       0.68      0.63      0.65      3524\n",
      "\n",
      "    accuracy                           0.72      9081\n",
      "   macro avg       0.74      0.77      0.76      9081\n",
      "weighted avg       0.72      0.72      0.72      9081\n",
      "\n",
      "Logger {'time': {0: 0.05196499824523926, 100: 5.17809796333313}, 'loss': {0: 0.5665620565414429, 100: 0.7746623158454895}, 'F1': {182: 0.7555484508543514}, 'Accuracy': {182: 0.7238189626693096}}\n",
      "Starting Epoch 3/10\n",
      "Epoch 3, Step 0, Loss: 0.7479287981987, Time Elapsed: 0.06457901000976562 seconds\n",
      "Epoch 3, Step 100, Loss: 0.6703240871429443, Time Elapsed: 5.808516025543213 seconds\n",
      "Epoch 3\n",
      "\n",
      "Writing snapshot to model_iter_000546.mdl\n",
      "Epoch time: 10.803946256637573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       530\n",
      "           1       0.92      0.86      0.89       557\n",
      "           2       0.76      0.74      0.75       559\n",
      "           3       0.67      0.81      0.73       538\n",
      "           4       0.78      0.85      0.81       568\n",
      "           5       0.69      0.69      0.69       575\n",
      "           6       0.88      0.76      0.81       554\n",
      "           7       0.76      0.77      0.77       554\n",
      "           8       0.77      0.46      0.57       560\n",
      "           9       0.72      0.79      0.75       562\n",
      "          10       0.67      0.68      0.68      3524\n",
      "\n",
      "    accuracy                           0.73      9081\n",
      "   macro avg       0.76      0.76      0.75      9081\n",
      "weighted avg       0.73      0.73      0.73      9081\n",
      "\n",
      "Logger {'time': {0: 0.06455421447753906, 100: 5.808459043502808}, 'loss': {0: 0.7479287981987, 100: 0.6703240871429443}, 'F1': {273: 0.7549370620783633}, 'Accuracy': {273: 0.7308666446426605}}\n",
      "Starting Epoch 4/10\n",
      "Epoch 4, Step 0, Loss: 0.542924702167511, Time Elapsed: 0.057933807373046875 seconds\n",
      "Epoch 4, Step 100, Loss: 0.6038506031036377, Time Elapsed: 5.85712194442749 seconds\n",
      "Epoch 4\n",
      "\n",
      "Writing snapshot to model_iter_000728.mdl\n",
      "Epoch time: 10.061795711517334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84       530\n",
      "           1       0.84      0.96      0.90       557\n",
      "           2       0.79      0.70      0.75       559\n",
      "           3       0.74      0.74      0.74       538\n",
      "           4       0.79      0.80      0.79       568\n",
      "           5       0.68      0.76      0.72       575\n",
      "           6       0.81      0.85      0.83       554\n",
      "           7       0.80      0.71      0.75       554\n",
      "           8       0.76      0.59      0.66       560\n",
      "           9       0.72      0.77      0.75       562\n",
      "          10       0.69      0.67      0.68      3524\n",
      "\n",
      "    accuracy                           0.74      9081\n",
      "   macro avg       0.76      0.77      0.76      9081\n",
      "weighted avg       0.74      0.74      0.74      9081\n",
      "\n",
      "Logger {'time': {0: 0.05789899826049805, 100: 5.85708475112915}, 'loss': {0: 0.542924702167511, 100: 0.6038506031036377}, 'F1': {364: 0.7636048638554968}, 'Accuracy': {364: 0.7380244466468451}}\n",
      "Starting Epoch 5/10\n",
      "Epoch 5, Step 0, Loss: 0.4838210344314575, Time Elapsed: 0.047406911849975586 seconds\n",
      "Epoch 5, Step 100, Loss: 0.5854911208152771, Time Elapsed: 4.9743030071258545 seconds\n",
      "Epoch 5\n",
      "\n",
      "Writing snapshot to model_iter_000910.mdl\n",
      "Epoch time: 8.978055953979492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       530\n",
      "           1       0.90      0.90      0.90       557\n",
      "           2       0.81      0.71      0.76       559\n",
      "           3       0.78      0.65      0.71       538\n",
      "           4       0.82      0.76      0.79       568\n",
      "           5       0.78      0.59      0.67       575\n",
      "           6       0.87      0.80      0.83       554\n",
      "           7       0.72      0.79      0.76       554\n",
      "           8       0.73      0.63      0.68       560\n",
      "           9       0.72      0.77      0.75       562\n",
      "          10       0.67      0.74      0.70      3524\n",
      "\n",
      "    accuracy                           0.74      9081\n",
      "   macro avg       0.79      0.75      0.77      9081\n",
      "weighted avg       0.75      0.74      0.74      9081\n",
      "\n",
      "Logger {'time': {0: 0.04737210273742676, 100: 4.97428297996521}, 'loss': {0: 0.4838210344314575, 100: 0.5854911208152771}, 'F1': {455: 0.7655021571999772}, 'Accuracy': {455: 0.7447417685276951}}\n",
      "Starting Epoch 6/10\n",
      "Epoch 6, Step 0, Loss: 0.4532938301563263, Time Elapsed: 0.05539369583129883 seconds\n",
      "Epoch 6, Step 100, Loss: 0.46826305985450745, Time Elapsed: 5.133257865905762 seconds\n",
      "Epoch 6\n",
      "\n",
      "Writing snapshot to model_iter_001092.mdl\n",
      "Epoch time: 9.176325798034668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       530\n",
      "           1       0.87      0.90      0.88       557\n",
      "           2       0.78      0.71      0.75       559\n",
      "           3       0.73      0.67      0.70       538\n",
      "           4       0.83      0.79      0.81       568\n",
      "           5       0.66      0.78      0.72       575\n",
      "           6       0.91      0.69      0.78       554\n",
      "           7       0.73      0.80      0.77       554\n",
      "           8       0.67      0.79      0.72       560\n",
      "           9       0.77      0.72      0.75       562\n",
      "          10       0.69      0.68      0.69      3524\n",
      "\n",
      "    accuracy                           0.74      9081\n",
      "   macro avg       0.77      0.77      0.77      9081\n",
      "weighted avg       0.74      0.74      0.74      9081\n",
      "\n",
      "Logger {'time': {0: 0.055371761322021484, 100: 5.133228778839111}, 'loss': {0: 0.4532938301563263, 100: 0.46826305985450745}, 'F1': {546: 0.7664341255320838}, 'Accuracy': {546: 0.7397863671401828}}\n",
      "Starting Epoch 7/10\n",
      "Epoch 7, Step 0, Loss: 0.4788263738155365, Time Elapsed: 0.04703402519226074 seconds\n",
      "Epoch 7, Step 100, Loss: 0.4717448055744171, Time Elapsed: 4.992588043212891 seconds\n",
      "Epoch 7\n",
      "\n",
      "Writing snapshot to model_iter_001274.mdl\n",
      "Epoch time: 9.093770027160645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       530\n",
      "           1       0.89      0.88      0.89       557\n",
      "           2       0.65      0.88      0.75       559\n",
      "           3       0.69      0.79      0.73       538\n",
      "           4       0.87      0.72      0.79       568\n",
      "           5       0.76      0.68      0.71       575\n",
      "           6       0.89      0.80      0.84       554\n",
      "           7       0.78      0.74      0.76       554\n",
      "           8       0.67      0.80      0.73       560\n",
      "           9       0.75      0.80      0.77       562\n",
      "          10       0.72      0.67      0.69      3524\n",
      "\n",
      "    accuracy                           0.75      9081\n",
      "   macro avg       0.77      0.79      0.78      9081\n",
      "weighted avg       0.75      0.75      0.75      9081\n",
      "\n",
      "Logger {'time': {0: 0.047017812728881836, 100: 4.992548942565918}, 'loss': {0: 0.4788263738155365, 100: 0.4717448055744171}, 'F1': {637: 0.7763953826134653}, 'Accuracy': {637: 0.7491465697610395}}\n",
      "Starting Epoch 8/10\n",
      "Epoch 8, Step 0, Loss: 0.49226292967796326, Time Elapsed: 0.049569129943847656 seconds\n",
      "Epoch 8, Step 100, Loss: 0.4771093726158142, Time Elapsed: 4.977273941040039 seconds\n",
      "Epoch 8\n",
      "\n",
      "Writing snapshot to model_iter_001456.mdl\n",
      "Epoch time: 8.970664024353027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       530\n",
      "           1       0.90      0.88      0.89       557\n",
      "           2       0.77      0.75      0.76       559\n",
      "           3       0.71      0.75      0.73       538\n",
      "           4       0.83      0.77      0.80       568\n",
      "           5       0.75      0.69      0.72       575\n",
      "           6       0.88      0.80      0.84       554\n",
      "           7       0.72      0.82      0.77       554\n",
      "           8       0.66      0.80      0.73       560\n",
      "           9       0.75      0.77      0.76       562\n",
      "          10       0.71      0.69      0.70      3524\n",
      "\n",
      "    accuracy                           0.75      9081\n",
      "   macro avg       0.78      0.78      0.78      9081\n",
      "weighted avg       0.75      0.75      0.75      9081\n",
      "\n",
      "Logger {'time': {0: 0.049551963806152344, 100: 4.977250099182129}, 'loss': {0: 0.49226292967796326, 100: 0.4771093726158142}, 'F1': {728: 0.7789877173958821}, 'Accuracy': {728: 0.7527805307785487}}\n",
      "Starting Epoch 9/10\n",
      "Epoch 9, Step 0, Loss: 0.46536415815353394, Time Elapsed: 0.047570228576660156 seconds\n",
      "Epoch 9, Step 100, Loss: 0.3921983242034912, Time Elapsed: 4.854825973510742 seconds\n",
      "Epoch 9\n",
      "\n",
      "Writing snapshot to model_iter_001638.mdl\n",
      "Epoch time: 8.768047094345093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82       530\n",
      "           1       0.92      0.87      0.89       557\n",
      "           2       0.76      0.81      0.78       559\n",
      "           3       0.73      0.76      0.74       538\n",
      "           4       0.88      0.68      0.77       568\n",
      "           5       0.78      0.58      0.67       575\n",
      "           6       0.85      0.84      0.84       554\n",
      "           7       0.72      0.83      0.77       554\n",
      "           8       0.72      0.67      0.69       560\n",
      "           9       0.78      0.71      0.74       562\n",
      "          10       0.68      0.74      0.71      3524\n",
      "\n",
      "    accuracy                           0.75      9081\n",
      "   macro avg       0.79      0.75      0.77      9081\n",
      "weighted avg       0.75      0.75      0.75      9081\n",
      "\n",
      "Logger {'time': {0: 0.04754829406738281, 100: 4.854804992675781}, 'loss': {0: 0.46536415815353394, 100: 0.3921983242034912}, 'F1': {819: 0.7664580787850838}, 'Accuracy': {819: 0.7468340491135338}}\n",
      "Starting Epoch 10/10\n",
      "Epoch 10, Step 0, Loss: 0.3443271517753601, Time Elapsed: 0.04726386070251465 seconds\n",
      "Epoch 10, Step 100, Loss: 0.5371966361999512, Time Elapsed: 4.8971569538116455 seconds\n",
      "Epoch 10\n",
      "\n",
      "Writing snapshot to model_iter_001820.mdl\n",
      "Epoch time: 8.81177806854248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       530\n",
      "           1       0.88      0.93      0.90       557\n",
      "           2       0.69      0.87      0.77       559\n",
      "           3       0.77      0.66      0.71       538\n",
      "           4       0.86      0.71      0.78       568\n",
      "           5       0.75      0.68      0.71       575\n",
      "           6       0.85      0.83      0.84       554\n",
      "           7       0.77      0.76      0.77       554\n",
      "           8       0.74      0.65      0.69       560\n",
      "           9       0.74      0.78      0.76       562\n",
      "          10       0.70      0.70      0.70      3524\n",
      "\n",
      "    accuracy                           0.75      9081\n",
      "   macro avg       0.78      0.77      0.77      9081\n",
      "weighted avg       0.75      0.75      0.75      9081\n",
      "\n",
      "Logger {'time': {0: 0.0472412109375, 100: 4.897120952606201}, 'loss': {0: 0.3443271517753601, 100: 0.5371966361999512}, 'F1': {910: 0.7719162025485296}, 'Accuracy': {910: 0.7494769298535403}}\n",
      "Training with dataset size: 30000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Done sample data.\n",
      "Starting Epoch 1/10\n",
      "Epoch 1, Step 0, Loss: 0.6512227058410645, Time Elapsed: 0.08202004432678223 seconds\n",
      "Epoch 1, Step 100, Loss: 0.5505866408348083, Time Elapsed: 6.055646181106567 seconds\n",
      "Epoch 1, Step 200, Loss: 0.7585636377334595, Time Elapsed: 13.041070222854614 seconds\n",
      "Epoch 1\n",
      "\n",
      "Writing snapshot to model_iter_000273.mdl\n",
      "Epoch time: 20.946742057800293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       856\n",
      "           1       0.92      0.84      0.88       831\n",
      "           2       0.79      0.71      0.75       854\n",
      "           3       0.69      0.80      0.74       828\n",
      "           4       0.83      0.80      0.82       838\n",
      "           5       0.78      0.65      0.71       834\n",
      "           6       0.79      0.87      0.83       839\n",
      "           7       0.85      0.77      0.81       846\n",
      "           8       0.74      0.76      0.75       868\n",
      "           9       0.74      0.78      0.76       828\n",
      "          10       0.70      0.70      0.70      5199\n",
      "\n",
      "    accuracy                           0.76     13621\n",
      "   macro avg       0.78      0.78      0.78     13621\n",
      "weighted avg       0.76      0.76      0.76     13621\n",
      "\n",
      "Logger {'time': {0: 0.08199334144592285, 100: 6.055569171905518, 200: 13.040987253189087}, 'loss': {0: 0.6512227058410645, 100: 0.5505866408348083, 200: 0.7585636377334595}, 'F1': {137: 0.7818315738418528}, 'Accuracy': {137: 0.7561118860582924}}\n",
      "Starting Epoch 2/10\n",
      "Epoch 2, Step 0, Loss: 0.5231983065605164, Time Elapsed: 0.09287333488464355 seconds\n",
      "Epoch 2, Step 100, Loss: 0.42167824506759644, Time Elapsed: 5.607763290405273 seconds\n",
      "Epoch 2, Step 200, Loss: 0.5090112686157227, Time Elapsed: 10.838075160980225 seconds\n",
      "Epoch 2\n",
      "\n",
      "Writing snapshot to model_iter_000546.mdl\n",
      "Epoch time: 14.775970220565796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       856\n",
      "           1       0.93      0.84      0.88       831\n",
      "           2       0.76      0.78      0.77       854\n",
      "           3       0.73      0.73      0.73       828\n",
      "           4       0.71      0.91      0.80       838\n",
      "           5       0.77      0.70      0.73       834\n",
      "           6       0.86      0.86      0.86       839\n",
      "           7       0.75      0.87      0.81       846\n",
      "           8       0.72      0.78      0.75       868\n",
      "           9       0.82      0.66      0.73       828\n",
      "          10       0.72      0.70      0.71      5199\n",
      "\n",
      "    accuracy                           0.76     13621\n",
      "   macro avg       0.79      0.79      0.79     13621\n",
      "weighted avg       0.77      0.76      0.76     13621\n",
      "\n",
      "Logger {'time': {0: 0.0928351879119873, 100: 5.607718229293823, 200: 10.838032245635986}, 'loss': {0: 0.5231983065605164, 100: 0.42167824506759644, 200: 0.5090112686157227}, 'F1': {274: 0.7883247936942056}, 'Accuracy': {274: 0.7627927464943837}}\n",
      "Starting Epoch 3/10\n",
      "Epoch 3, Step 0, Loss: 0.5301233530044556, Time Elapsed: 0.04578900337219238 seconds\n",
      "Epoch 3, Step 100, Loss: 0.6135368347167969, Time Elapsed: 5.41910195350647 seconds\n",
      "Epoch 3, Step 200, Loss: 0.42584532499313354, Time Elapsed: 10.732524156570435 seconds\n",
      "Epoch 3\n",
      "\n",
      "Writing snapshot to model_iter_000819.mdl\n",
      "Epoch time: 14.799912929534912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       856\n",
      "           1       0.95      0.81      0.88       831\n",
      "           2       0.78      0.71      0.74       854\n",
      "           3       0.78      0.62      0.69       828\n",
      "           4       0.78      0.88      0.83       838\n",
      "           5       0.70      0.81      0.75       834\n",
      "           6       0.84      0.85      0.84       839\n",
      "           7       0.85      0.78      0.81       846\n",
      "           8       0.88      0.47      0.61       868\n",
      "           9       0.71      0.82      0.76       828\n",
      "          10       0.68      0.73      0.70      5199\n",
      "\n",
      "    accuracy                           0.75     13621\n",
      "   macro avg       0.80      0.76      0.77     13621\n",
      "weighted avg       0.76      0.75      0.75     13621\n",
      "\n",
      "Logger {'time': {0: 0.04577374458312988, 100: 5.419039011001587, 200: 10.732493162155151}, 'loss': {0: 0.5301233530044556, 100: 0.6135368347167969, 200: 0.42584532499313354}, 'F1': {411: 0.7735175468615686}, 'Accuracy': {411: 0.7526613317671242}}\n",
      "Starting Epoch 4/10\n",
      "Epoch 4, Step 0, Loss: 0.5408377647399902, Time Elapsed: 0.053488731384277344 seconds\n",
      "Epoch 4, Step 100, Loss: 0.43949905037879944, Time Elapsed: 5.6407928466796875 seconds\n",
      "Epoch 4, Step 200, Loss: 0.5232357382774353, Time Elapsed: 11.37968897819519 seconds\n",
      "Epoch 4\n",
      "\n",
      "Writing snapshot to model_iter_001092.mdl\n",
      "Epoch time: 15.429526805877686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       856\n",
      "           1       0.90      0.91      0.90       831\n",
      "           2       0.81      0.73      0.77       854\n",
      "           3       0.81      0.63      0.70       828\n",
      "           4       0.85      0.76      0.80       838\n",
      "           5       0.72      0.80      0.76       834\n",
      "           6       0.80      0.89      0.84       839\n",
      "           7       0.87      0.78      0.82       846\n",
      "           8       0.75      0.71      0.73       868\n",
      "           9       0.71      0.81      0.76       828\n",
      "          10       0.71      0.72      0.71      5199\n",
      "\n",
      "    accuracy                           0.77     13621\n",
      "   macro avg       0.80      0.79      0.79     13621\n",
      "weighted avg       0.77      0.77      0.77     13621\n",
      "\n",
      "Logger {'time': {0: 0.05346274375915527, 100: 5.640728712081909, 200: 11.379647016525269}, 'loss': {0: 0.5408377647399902, 100: 0.43949905037879944, 200: 0.5232357382774353}, 'F1': {548: 0.7902791399237248}, 'Accuracy': {548: 0.7664635489317965}}\n",
      "Starting Epoch 5/10\n",
      "Epoch 5, Step 0, Loss: 0.4178801476955414, Time Elapsed: 0.04996681213378906 seconds\n",
      "Epoch 5, Step 100, Loss: 0.3828093707561493, Time Elapsed: 5.439250946044922 seconds\n",
      "Epoch 5, Step 200, Loss: 0.46237099170684814, Time Elapsed: 10.826180934906006 seconds\n",
      "Epoch 5\n",
      "\n",
      "Writing snapshot to model_iter_001365.mdl\n",
      "Epoch time: 14.500542879104614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.90       856\n",
      "           1       0.92      0.91      0.92       831\n",
      "           2       0.82      0.72      0.77       854\n",
      "           3       0.70      0.82      0.76       828\n",
      "           4       0.82      0.84      0.83       838\n",
      "           5       0.76      0.71      0.73       834\n",
      "           6       0.84      0.85      0.84       839\n",
      "           7       0.82      0.87      0.84       846\n",
      "           8       0.83      0.63      0.72       868\n",
      "           9       0.76      0.78      0.77       828\n",
      "          10       0.72      0.75      0.73      5199\n",
      "\n",
      "    accuracy                           0.78     13621\n",
      "   macro avg       0.81      0.79      0.80     13621\n",
      "weighted avg       0.78      0.78      0.78     13621\n",
      "\n",
      "Logger {'time': {0: 0.049942731857299805, 100: 5.439168691635132, 200: 10.826159954071045}, 'loss': {0: 0.4178801476955414, 100: 0.3828093707561493, 200: 0.46237099170684814}, 'F1': {685: 0.8010609627321198}, 'Accuracy': {685: 0.7796784377064826}}\n",
      "Starting Epoch 6/10\n",
      "Epoch 6, Step 0, Loss: 0.5437868237495422, Time Elapsed: 0.049993276596069336 seconds\n",
      "Epoch 6, Step 100, Loss: 0.4125015139579773, Time Elapsed: 5.207519292831421 seconds\n",
      "Epoch 6, Step 200, Loss: 0.4706382751464844, Time Elapsed: 10.62358021736145 seconds\n",
      "Epoch 6\n",
      "\n",
      "Writing snapshot to model_iter_001638.mdl\n",
      "Epoch time: 14.453167200088501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       856\n",
      "           1       0.83      0.96      0.89       831\n",
      "           2       0.84      0.71      0.77       854\n",
      "           3       0.71      0.80      0.75       828\n",
      "           4       0.84      0.76      0.80       838\n",
      "           5       0.75      0.77      0.76       834\n",
      "           6       0.83      0.84      0.84       839\n",
      "           7       0.91      0.72      0.81       846\n",
      "           8       0.76      0.75      0.76       868\n",
      "           9       0.75      0.81      0.78       828\n",
      "          10       0.73      0.73      0.73      5199\n",
      "\n",
      "    accuracy                           0.78     13621\n",
      "   macro avg       0.80      0.80      0.80     13621\n",
      "weighted avg       0.78      0.78      0.78     13621\n",
      "\n",
      "Logger {'time': {0: 0.049979209899902344, 100: 5.207474231719971, 200: 10.623555183410645}, 'loss': {0: 0.5437868237495422, 100: 0.4125015139579773, 200: 0.4706382751464844}, 'F1': {822: 0.7994291537396833}, 'Accuracy': {822: 0.7765949636590559}}\n",
      "Starting Epoch 7/10\n",
      "Epoch 7, Step 0, Loss: 0.3521343469619751, Time Elapsed: 0.05269503593444824 seconds\n",
      "Epoch 7, Step 100, Loss: 0.4041043817996979, Time Elapsed: 5.715120792388916 seconds\n",
      "Epoch 7, Step 200, Loss: 0.4017062485218048, Time Elapsed: 10.941179037094116 seconds\n",
      "Epoch 7\n",
      "\n",
      "Writing snapshot to model_iter_001911.mdl\n",
      "Epoch time: 14.768347024917603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       856\n",
      "           1       0.95      0.79      0.86       831\n",
      "           2       0.84      0.68      0.75       854\n",
      "           3       0.79      0.71      0.75       828\n",
      "           4       0.83      0.82      0.83       838\n",
      "           5       0.72      0.80      0.76       834\n",
      "           6       0.93      0.76      0.83       839\n",
      "           7       0.91      0.75      0.82       846\n",
      "           8       0.72      0.79      0.75       868\n",
      "           9       0.82      0.66      0.73       828\n",
      "          10       0.69      0.78      0.73      5199\n",
      "\n",
      "    accuracy                           0.77     13621\n",
      "   macro avg       0.83      0.77      0.79     13621\n",
      "weighted avg       0.78      0.77      0.77     13621\n",
      "\n",
      "Logger {'time': {0: 0.052658796310424805, 100: 5.715073823928833, 200: 10.941158056259155}, 'loss': {0: 0.3521343469619751, 100: 0.4041043817996979, 200: 0.4017062485218048}, 'F1': {959: 0.792716872662729}, 'Accuracy': {959: 0.7716760883929227}}\n",
      "Starting Epoch 8/10\n",
      "Epoch 8, Step 0, Loss: 0.485189288854599, Time Elapsed: 0.0768592357635498 seconds\n",
      "Epoch 8, Step 100, Loss: 0.42098096013069153, Time Elapsed: 5.313162088394165 seconds\n",
      "Epoch 8, Step 200, Loss: 0.4044591188430786, Time Elapsed: 10.477203130722046 seconds\n",
      "Epoch 8\n",
      "\n",
      "Writing snapshot to model_iter_002184.mdl\n",
      "Epoch time: 14.299926996231079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87       856\n",
      "           1       0.95      0.84      0.89       831\n",
      "           2       0.80      0.79      0.80       854\n",
      "           3       0.71      0.82      0.76       828\n",
      "           4       0.80      0.86      0.83       838\n",
      "           5       0.81      0.67      0.73       834\n",
      "           6       0.80      0.89      0.84       839\n",
      "           7       0.81      0.87      0.84       846\n",
      "           8       0.81      0.66      0.73       868\n",
      "           9       0.81      0.71      0.76       828\n",
      "          10       0.72      0.75      0.73      5199\n",
      "\n",
      "    accuracy                           0.78     13621\n",
      "   macro avg       0.81      0.79      0.80     13621\n",
      "weighted avg       0.78      0.78      0.78     13621\n",
      "\n",
      "Logger {'time': {0: 0.07683706283569336, 100: 5.313135147094727, 200: 10.477168083190918}, 'loss': {0: 0.485189288854599, 100: 0.42098096013069153, 200: 0.4044591188430786}, 'F1': {1096: 0.7977572175627887}, 'Accuracy': {1096: 0.7771088760002937}}\n",
      "Starting Epoch 9/10\n",
      "Epoch 9, Step 0, Loss: 0.34537142515182495, Time Elapsed: 0.06720089912414551 seconds\n",
      "Epoch 9, Step 100, Loss: 0.33433806896209717, Time Elapsed: 5.262479782104492 seconds\n",
      "Epoch 9, Step 200, Loss: 0.34183502197265625, Time Elapsed: 10.452270746231079 seconds\n",
      "Epoch 9\n",
      "\n",
      "Writing snapshot to model_iter_002457.mdl\n",
      "Epoch time: 14.163091897964478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       856\n",
      "           1       0.88      0.94      0.91       831\n",
      "           2       0.75      0.83      0.79       854\n",
      "           3       0.79      0.72      0.75       828\n",
      "           4       0.82      0.84      0.83       838\n",
      "           5       0.78      0.74      0.76       834\n",
      "           6       0.82      0.87      0.84       839\n",
      "           7       0.81      0.88      0.84       846\n",
      "           8       0.77      0.73      0.75       868\n",
      "           9       0.78      0.79      0.78       828\n",
      "          10       0.75      0.73      0.74      5199\n",
      "\n",
      "    accuracy                           0.79     13621\n",
      "   macro avg       0.81      0.82      0.81     13621\n",
      "weighted avg       0.79      0.79      0.79     13621\n",
      "\n",
      "Logger {'time': {0: 0.06718277931213379, 100: 5.262455701828003, 200: 10.452224016189575}, 'loss': {0: 0.34537142515182495, 100: 0.33433806896209717, 200: 0.34183502197265625}, 'F1': {1233: 0.8099887029508384}, 'Accuracy': {1233: 0.7876073709712943}}\n",
      "Starting Epoch 10/10\n",
      "Epoch 10, Step 0, Loss: 0.39052727818489075, Time Elapsed: 0.04919314384460449 seconds\n",
      "Epoch 10, Step 100, Loss: 0.3725321590900421, Time Elapsed: 5.173685073852539 seconds\n",
      "Epoch 10, Step 200, Loss: 0.2706400156021118, Time Elapsed: 10.604471206665039 seconds\n",
      "Epoch 10\n",
      "\n",
      "Writing snapshot to model_iter_002730.mdl\n",
      "Epoch time: 14.364334106445312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       856\n",
      "           1       0.90      0.93      0.92       831\n",
      "           2       0.79      0.80      0.80       854\n",
      "           3       0.74      0.79      0.77       828\n",
      "           4       0.83      0.79      0.81       838\n",
      "           5       0.77      0.73      0.75       834\n",
      "           6       0.86      0.84      0.85       839\n",
      "           7       0.83      0.85      0.84       846\n",
      "           8       0.80      0.68      0.74       868\n",
      "           9       0.74      0.83      0.78       828\n",
      "          10       0.73      0.75      0.74      5199\n",
      "\n",
      "    accuracy                           0.78     13621\n",
      "   macro avg       0.81      0.80      0.81     13621\n",
      "weighted avg       0.79      0.78      0.78     13621\n",
      "\n",
      "Logger {'time': {0: 0.04916715621948242, 100: 5.173657178878784, 200: 10.604424953460693}, 'loss': {0: 0.39052727818489075, 100: 0.3725321590900421, 200: 0.2706400156021118}, 'F1': {1370: 0.8061206001959558}, 'Accuracy': {1370: 0.7837163203876367}}\n",
      "Training with dataset size: 40000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Done sample data.\n",
      "Starting Epoch 1/10\n",
      "Epoch 1, Step 0, Loss: 0.5107313394546509, Time Elapsed: 0.07933282852172852 seconds\n",
      "Epoch 1, Step 100, Loss: 0.7005743980407715, Time Elapsed: 5.535878896713257 seconds\n",
      "Epoch 1, Step 200, Loss: 0.6405250430107117, Time Elapsed: 10.746068000793457 seconds\n",
      "Epoch 1, Step 300, Loss: 0.4876876473426819, Time Elapsed: 15.927670955657959 seconds\n",
      "Epoch 1\n",
      "\n",
      "Writing snapshot to model_iter_000364.mdl\n",
      "Epoch time: 19.204750061035156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      1117\n",
      "           1       0.92      0.94      0.93      1100\n",
      "           2       0.82      0.73      0.78      1106\n",
      "           3       0.72      0.83      0.77      1113\n",
      "           4       0.87      0.79      0.83      1126\n",
      "           5       0.78      0.70      0.74      1106\n",
      "           6       0.88      0.82      0.85      1096\n",
      "           7       0.86      0.78      0.81      1112\n",
      "           8       0.77      0.71      0.74      1107\n",
      "           9       0.78      0.74      0.76      1096\n",
      "          10       0.73      0.77      0.75      7092\n",
      "\n",
      "    accuracy                           0.79     18171\n",
      "   macro avg       0.82      0.79      0.80     18171\n",
      "weighted avg       0.79      0.79      0.79     18171\n",
      "\n",
      "Logger {'time': {0: 0.07931995391845703, 100: 5.53581690788269, 200: 10.746047019958496, 300: 15.927640914916992}, 'loss': {0: 0.5107313394546509, 100: 0.7005743980407715, 200: 0.6405250430107117, 300: 0.4876876473426819}, 'F1': {182: 0.8040180931548129}, 'Accuracy': {182: 0.785812558472291}}\n",
      "Starting Epoch 2/10\n",
      "Epoch 2, Step 0, Loss: 0.5378877520561218, Time Elapsed: 0.05278801918029785 seconds\n",
      "Epoch 2, Step 100, Loss: 0.4607282876968384, Time Elapsed: 5.336359024047852 seconds\n",
      "Epoch 2, Step 200, Loss: 0.6381309032440186, Time Elapsed: 10.575331926345825 seconds\n",
      "Epoch 2, Step 300, Loss: 0.48329463601112366, Time Elapsed: 15.706605911254883 seconds\n",
      "Epoch 2\n",
      "\n",
      "Writing snapshot to model_iter_000728.mdl\n",
      "Epoch time: 19.169439792633057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90      1117\n",
      "           1       0.92      0.94      0.93      1100\n",
      "           2       0.79      0.83      0.81      1106\n",
      "           3       0.78      0.76      0.77      1113\n",
      "           4       0.88      0.75      0.81      1126\n",
      "           5       0.76      0.76      0.76      1106\n",
      "           6       0.82      0.90      0.86      1096\n",
      "           7       0.84      0.82      0.83      1112\n",
      "           8       0.78      0.69      0.73      1107\n",
      "           9       0.84      0.68      0.75      1096\n",
      "          10       0.74      0.77      0.75      7092\n",
      "\n",
      "    accuracy                           0.79     18171\n",
      "   macro avg       0.82      0.80      0.81     18171\n",
      "weighted avg       0.79      0.79      0.79     18171\n",
      "\n",
      "Logger {'time': {0: 0.05276989936828613, 100: 5.336338043212891, 200: 10.575280904769897, 300: 15.706584930419922}, 'loss': {0: 0.5378877520561218, 100: 0.4607282876968384, 200: 0.6381309032440186, 300: 0.48329463601112366}, 'F1': {364: 0.8091097790047989}, 'Accuracy': {364: 0.7913708656650708}}\n",
      "Starting Epoch 3/10\n",
      "Epoch 3, Step 0, Loss: 0.41653332114219666, Time Elapsed: 0.06745791435241699 seconds\n",
      "Epoch 3, Step 100, Loss: 0.4961729347705841, Time Elapsed: 5.518420219421387 seconds\n",
      "Epoch 3, Step 200, Loss: 0.3902733325958252, Time Elapsed: 10.79790997505188 seconds\n",
      "Epoch 3, Step 300, Loss: 0.5103485584259033, Time Elapsed: 16.058591842651367 seconds\n",
      "Epoch 3\n",
      "\n",
      "Writing snapshot to model_iter_001092.mdl\n",
      "Epoch time: 19.31902813911438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89      1117\n",
      "           1       0.96      0.87      0.91      1100\n",
      "           2       0.79      0.83      0.81      1106\n",
      "           3       0.78      0.76      0.77      1113\n",
      "           4       0.87      0.83      0.85      1126\n",
      "           5       0.78      0.75      0.77      1106\n",
      "           6       0.86      0.85      0.85      1096\n",
      "           7       0.86      0.81      0.84      1112\n",
      "           8       0.73      0.78      0.76      1107\n",
      "           9       0.80      0.76      0.78      1096\n",
      "          10       0.75      0.76      0.76      7092\n",
      "\n",
      "    accuracy                           0.80     18171\n",
      "   macro avg       0.82      0.81      0.82     18171\n",
      "weighted avg       0.80      0.80      0.80     18171\n",
      "\n",
      "Logger {'time': {0: 0.06744217872619629, 100: 5.5183751583099365, 200: 10.797858953475952, 300: 16.05852723121643}, 'loss': {0: 0.41653332114219666, 100: 0.4961729347705841, 200: 0.3902733325958252, 300: 0.5103485584259033}, 'F1': {546: 0.8165773781179635}, 'Accuracy': {546: 0.7969291728578505}}\n",
      "Starting Epoch 4/10\n",
      "Epoch 4, Step 0, Loss: 0.472258597612381, Time Elapsed: 0.06765103340148926 seconds\n",
      "Epoch 4, Step 100, Loss: 0.449283629655838, Time Elapsed: 5.412170886993408 seconds\n",
      "Epoch 4, Step 200, Loss: 0.5715461373329163, Time Elapsed: 10.990360021591187 seconds\n",
      "Epoch 4, Step 300, Loss: 0.48219195008277893, Time Elapsed: 16.254320859909058 seconds\n",
      "Epoch 4\n",
      "\n",
      "Writing snapshot to model_iter_001456.mdl\n",
      "Epoch time: 19.474014043807983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      1117\n",
      "           1       0.96      0.89      0.92      1100\n",
      "           2       0.84      0.78      0.81      1106\n",
      "           3       0.74      0.80      0.77      1113\n",
      "           4       0.84      0.86      0.85      1126\n",
      "           5       0.78      0.75      0.76      1106\n",
      "           6       0.88      0.86      0.87      1096\n",
      "           7       0.80      0.87      0.83      1112\n",
      "           8       0.75      0.75      0.75      1107\n",
      "           9       0.88      0.59      0.71      1096\n",
      "          10       0.75      0.78      0.76      7092\n",
      "\n",
      "    accuracy                           0.80     18171\n",
      "   macro avg       0.83      0.81      0.81     18171\n",
      "weighted avg       0.80      0.80      0.80     18171\n",
      "\n",
      "Logger {'time': {0: 0.067626953125, 100: 5.412144184112549, 200: 10.990304946899414, 300: 16.254268884658813}, 'loss': {0: 0.472258597612381, 100: 0.449283629655838, 200: 0.5715461373329163, 300: 0.48219195008277893}, 'F1': {728: 0.8149849112525729}, 'Accuracy': {728: 0.7985801551923395}}\n",
      "Starting Epoch 5/10\n",
      "Epoch 5, Step 0, Loss: 0.4092494249343872, Time Elapsed: 0.053208112716674805 seconds\n",
      "Epoch 5, Step 100, Loss: 0.45193710923194885, Time Elapsed: 5.232411861419678 seconds\n",
      "Epoch 5, Step 200, Loss: 0.47453540563583374, Time Elapsed: 10.664350986480713 seconds\n",
      "Epoch 5, Step 300, Loss: 0.4524174928665161, Time Elapsed: 15.828108072280884 seconds\n",
      "Epoch 5\n",
      "\n",
      "Writing snapshot to model_iter_001820.mdl\n",
      "Epoch time: 19.10690402984619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1117\n",
      "           1       0.93      0.91      0.92      1100\n",
      "           2       0.85      0.78      0.81      1106\n",
      "           3       0.78      0.81      0.79      1113\n",
      "           4       0.86      0.85      0.86      1126\n",
      "           5       0.81      0.76      0.78      1106\n",
      "           6       0.86      0.87      0.87      1096\n",
      "           7       0.81      0.84      0.83      1112\n",
      "           8       0.71      0.85      0.77      1107\n",
      "           9       0.73      0.87      0.79      1096\n",
      "          10       0.79      0.74      0.76      7092\n",
      "\n",
      "    accuracy                           0.81     18171\n",
      "   macro avg       0.82      0.84      0.83     18171\n",
      "weighted avg       0.81      0.81      0.81     18171\n",
      "\n",
      "Logger {'time': {0: 0.05319404602050781, 100: 5.2323668003082275, 200: 10.664305925369263, 300: 15.828063011169434}, 'loss': {0: 0.4092494249343872, 100: 0.45193710923194885, 200: 0.47453540563583374, 300: 0.4524174928665161}, 'F1': {910: 0.8273348644933329}, 'Accuracy': {910: 0.8068350668647846}}\n",
      "Starting Epoch 6/10\n",
      "Epoch 6, Step 0, Loss: 0.3858237564563751, Time Elapsed: 0.054327964782714844 seconds\n",
      "Epoch 6, Step 100, Loss: 0.3228267729282379, Time Elapsed: 5.37648606300354 seconds\n",
      "Epoch 6, Step 200, Loss: 0.4827796518802643, Time Elapsed: 10.800414085388184 seconds\n",
      "Epoch 6, Step 300, Loss: 0.3984242379665375, Time Elapsed: 15.972782135009766 seconds\n",
      "Epoch 6\n",
      "\n",
      "Writing snapshot to model_iter_002184.mdl\n",
      "Epoch time: 19.36787700653076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1117\n",
      "           1       0.93      0.96      0.94      1100\n",
      "           2       0.84      0.78      0.81      1106\n",
      "           3       0.76      0.82      0.79      1113\n",
      "           4       0.85      0.89      0.87      1126\n",
      "           5       0.79      0.73      0.76      1106\n",
      "           6       0.88      0.86      0.87      1096\n",
      "           7       0.85      0.82      0.83      1112\n",
      "           8       0.75      0.79      0.77      1107\n",
      "           9       0.78      0.81      0.80      1096\n",
      "          10       0.78      0.77      0.77      7092\n",
      "\n",
      "    accuracy                           0.81     18171\n",
      "   macro avg       0.83      0.83      0.83     18171\n",
      "weighted avg       0.81      0.81      0.81     18171\n",
      "\n",
      "Logger {'time': {0: 0.05429697036743164, 100: 5.376461982727051, 200: 10.80035924911499, 300: 15.972735166549683}, 'loss': {0: 0.3858237564563751, 100: 0.3228267729282379, 200: 0.4827796518802643, 300: 0.3984242379665375}, 'F1': {1092: 0.8297020344002027}, 'Accuracy': {1092: 0.8120631775906665}}\n",
      "Starting Epoch 7/10\n",
      "Epoch 7, Step 0, Loss: 0.26870641112327576, Time Elapsed: 0.06707477569580078 seconds\n",
      "Epoch 7, Step 100, Loss: 0.44660159945487976, Time Elapsed: 5.347095012664795 seconds\n",
      "Epoch 7, Step 200, Loss: 0.41564956307411194, Time Elapsed: 10.61217212677002 seconds\n",
      "Epoch 7, Step 300, Loss: 0.2866078317165375, Time Elapsed: 15.867543935775757 seconds\n",
      "Epoch 7\n",
      "\n",
      "Writing snapshot to model_iter_002548.mdl\n",
      "Epoch time: 19.1463680267334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      1117\n",
      "           1       0.92      0.94      0.93      1100\n",
      "           2       0.77      0.86      0.81      1106\n",
      "           3       0.73      0.81      0.77      1113\n",
      "           4       0.77      0.92      0.84      1126\n",
      "           5       0.74      0.83      0.78      1106\n",
      "           6       0.84      0.88      0.85      1096\n",
      "           7       0.86      0.81      0.84      1112\n",
      "           8       0.81      0.70      0.75      1107\n",
      "           9       0.75      0.84      0.79      1096\n",
      "          10       0.79      0.72      0.75      7092\n",
      "\n",
      "    accuracy                           0.80     18171\n",
      "   macro avg       0.80      0.84      0.82     18171\n",
      "weighted avg       0.80      0.80      0.80     18171\n",
      "\n",
      "Logger {'time': {0: 0.06705212593078613, 100: 5.34703803062439, 200: 10.612130880355835, 300: 15.867478132247925}, 'loss': {0: 0.26870641112327576, 100: 0.44660159945487976, 200: 0.41564956307411194, 300: 0.2866078317165375}, 'F1': {1274: 0.8203590962573206}, 'Accuracy': {1274: 0.7998459083154477}}\n",
      "Starting Epoch 8/10\n",
      "Epoch 8, Step 0, Loss: 0.33042046427726746, Time Elapsed: 0.08143997192382812 seconds\n",
      "Epoch 8, Step 100, Loss: 0.35726726055145264, Time Elapsed: 5.494064092636108 seconds\n",
      "Epoch 8, Step 200, Loss: 0.3293934762477875, Time Elapsed: 11.641072034835815 seconds\n",
      "Epoch 8, Step 300, Loss: 0.38372641801834106, Time Elapsed: 16.82050108909607 seconds\n",
      "Epoch 8\n",
      "\n",
      "Writing snapshot to model_iter_002912.mdl\n",
      "Epoch time: 20.005691051483154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      1117\n",
      "           1       0.91      0.94      0.92      1100\n",
      "           2       0.84      0.79      0.81      1106\n",
      "           3       0.78      0.75      0.76      1113\n",
      "           4       0.88      0.85      0.86      1126\n",
      "           5       0.82      0.69      0.75      1106\n",
      "           6       0.87      0.85      0.86      1096\n",
      "           7       0.86      0.81      0.84      1112\n",
      "           8       0.75      0.79      0.77      1107\n",
      "           9       0.72      0.85      0.78      1096\n",
      "          10       0.75      0.77      0.76      7092\n",
      "\n",
      "    accuracy                           0.80     18171\n",
      "   macro avg       0.83      0.82      0.82     18171\n",
      "weighted avg       0.80      0.80      0.80     18171\n",
      "\n",
      "Logger {'time': {0: 0.08142590522766113, 100: 5.494004964828491, 200: 11.640988826751709, 300: 16.820478916168213}, 'loss': {0: 0.33042046427726746, 100: 0.35726726055145264, 200: 0.3293934762477875, 300: 0.38372641801834106}, 'F1': {1456: 0.8197448606221189}, 'Accuracy': {1456: 0.8005613339937263}}\n",
      "Starting Epoch 9/10\n",
      "Epoch 9, Step 0, Loss: 0.3277750313282013, Time Elapsed: 0.07170629501342773 seconds\n",
      "Epoch 9, Step 100, Loss: 0.4032038152217865, Time Elapsed: 5.262782096862793 seconds\n",
      "Epoch 9, Step 200, Loss: 0.3023073077201843, Time Elapsed: 10.41731309890747 seconds\n",
      "Epoch 9, Step 300, Loss: 0.34468284249305725, Time Elapsed: 15.71828007698059 seconds\n",
      "Epoch 9\n",
      "\n",
      "Writing snapshot to model_iter_003276.mdl\n",
      "Epoch time: 18.934720039367676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1117\n",
      "           1       0.91      0.96      0.94      1100\n",
      "           2       0.86      0.79      0.82      1106\n",
      "           3       0.76      0.83      0.79      1113\n",
      "           4       0.90      0.80      0.85      1126\n",
      "           5       0.80      0.75      0.77      1106\n",
      "           6       0.85      0.88      0.87      1096\n",
      "           7       0.84      0.82      0.83      1112\n",
      "           8       0.72      0.82      0.77      1107\n",
      "           9       0.83      0.73      0.78      1096\n",
      "          10       0.77      0.77      0.77      7092\n",
      "\n",
      "    accuracy                           0.81     18171\n",
      "   macro avg       0.83      0.83      0.83     18171\n",
      "weighted avg       0.81      0.81      0.81     18171\n",
      "\n",
      "Logger {'time': {0: 0.07168698310852051, 100: 5.2627363204956055, 200: 10.417268991470337, 300: 15.718225955963135}, 'loss': {0: 0.3277750313282013, 100: 0.4032038152217865, 200: 0.3023073077201843, 300: 0.34468284249305725}, 'F1': {1638: 0.8272357344622816}, 'Accuracy': {1638: 0.8088712784106543}}\n",
      "Starting Epoch 10/10\n",
      "Epoch 10, Step 0, Loss: 0.3367834985256195, Time Elapsed: 0.06913995742797852 seconds\n",
      "Epoch 10, Step 100, Loss: 0.35220563411712646, Time Elapsed: 5.220038890838623 seconds\n",
      "Epoch 10, Step 200, Loss: 0.2599853575229645, Time Elapsed: 10.386455059051514 seconds\n",
      "Epoch 10, Step 300, Loss: 0.3339040279388428, Time Elapsed: 15.572053909301758 seconds\n",
      "Epoch 10\n",
      "\n",
      "Writing snapshot to model_iter_003640.mdl\n",
      "Epoch time: 18.782509088516235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      1117\n",
      "           1       0.91      0.96      0.93      1100\n",
      "           2       0.94      0.62      0.75      1106\n",
      "           3       0.75      0.81      0.78      1113\n",
      "           4       0.88      0.79      0.84      1126\n",
      "           5       0.84      0.70      0.76      1106\n",
      "           6       0.87      0.87      0.87      1096\n",
      "           7       0.87      0.81      0.84      1112\n",
      "           8       0.84      0.60      0.70      1107\n",
      "           9       0.83      0.71      0.77      1096\n",
      "          10       0.72      0.83      0.77      7092\n",
      "\n",
      "    accuracy                           0.80     18171\n",
      "   macro avg       0.85      0.78      0.81     18171\n",
      "weighted avg       0.81      0.80      0.80     18171\n",
      "\n",
      "Logger {'time': {0: 0.06912684440612793, 100: 5.21998405456543, 200: 10.386399984359741, 300: 15.571994066238403}, 'loss': {0: 0.3367834985256195, 100: 0.35220563411712646, 200: 0.2599853575229645, 300: 0.3339040279388428}, 'F1': {1820: 0.8106643376501832}, 'Accuracy': {1820: 0.7985251224478565}}\n",
      "Training with dataset size: 50000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Done sample data.\n",
      "Starting Epoch 1/10\n",
      "Epoch 1, Step 0, Loss: 0.46343281865119934, Time Elapsed: 0.07824158668518066 seconds\n",
      "Epoch 1, Step 100, Loss: 0.41207969188690186, Time Elapsed: 5.382245779037476 seconds\n",
      "Epoch 1, Step 200, Loss: 0.4876713454723358, Time Elapsed: 10.817237854003906 seconds\n",
      "Epoch 1, Step 300, Loss: 0.5533339977264404, Time Elapsed: 16.052459716796875 seconds\n",
      "Epoch 1, Step 400, Loss: 0.40933284163475037, Time Elapsed: 21.24038290977478 seconds\n",
      "Epoch 1\n",
      "\n",
      "Writing snapshot to model_iter_000455.mdl\n",
      "Epoch time: 23.99841570854187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1364\n",
      "           1       0.96      0.93      0.94      1401\n",
      "           2       0.82      0.82      0.82      1372\n",
      "           3       0.76      0.78      0.77      1384\n",
      "           4       0.82      0.89      0.85      1389\n",
      "           5       0.79      0.77      0.78      1397\n",
      "           6       0.91      0.76      0.83      1409\n",
      "           7       0.86      0.83      0.85      1402\n",
      "           8       0.80      0.69      0.74      1393\n",
      "           9       0.81      0.81      0.81      1399\n",
      "          10       0.76      0.78      0.77      8801\n",
      "\n",
      "    accuracy                           0.81     22711\n",
      "   macro avg       0.83      0.82      0.82     22711\n",
      "weighted avg       0.81      0.81      0.81     22711\n",
      "\n",
      "Logger {'time': {0: 0.07822060585021973, 100: 5.3821775913238525, 200: 10.817179679870605, 300: 16.052395582199097, 400: 21.240347862243652}, 'loss': {0: 0.46343281865119934, 100: 0.41207969188690186, 200: 0.4876713454723358, 300: 0.5533339977264404, 400: 0.40933284163475037}, 'F1': {228: 0.8246818687384063}, 'Accuracy': {228: 0.8072299766632909}}\n",
      "Starting Epoch 2/10\n",
      "Epoch 2, Step 0, Loss: 0.5100186467170715, Time Elapsed: 0.0632169246673584 seconds\n",
      "Epoch 2, Step 100, Loss: 0.4696601927280426, Time Elapsed: 5.293926954269409 seconds\n",
      "Epoch 2, Step 200, Loss: 0.4694184958934784, Time Elapsed: 10.44780707359314 seconds\n",
      "Epoch 2, Step 300, Loss: 0.43973278999328613, Time Elapsed: 15.63471007347107 seconds\n",
      "Epoch 2, Step 400, Loss: 0.47136345505714417, Time Elapsed: 20.848600149154663 seconds\n",
      "Epoch 2\n",
      "\n",
      "Writing snapshot to model_iter_000910.mdl\n",
      "Epoch time: 23.658355951309204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      1364\n",
      "           1       0.90      0.97      0.93      1401\n",
      "           2       0.82      0.83      0.83      1372\n",
      "           3       0.68      0.87      0.76      1384\n",
      "           4       0.84      0.88      0.86      1389\n",
      "           5       0.81      0.69      0.75      1397\n",
      "           6       0.88      0.89      0.88      1409\n",
      "           7       0.87      0.81      0.84      1402\n",
      "           8       0.79      0.70      0.74      1393\n",
      "           9       0.82      0.77      0.79      1399\n",
      "          10       0.77      0.77      0.77      8801\n",
      "\n",
      "    accuracy                           0.81     22711\n",
      "   macro avg       0.83      0.82      0.82     22711\n",
      "weighted avg       0.81      0.81      0.81     22711\n",
      "\n",
      "Logger {'time': {0: 0.06319284439086914, 100: 5.293871879577637, 200: 10.447773933410645, 300: 15.634680271148682, 400: 20.848569869995117}, 'loss': {0: 0.5100186467170715, 100: 0.4696601927280426, 200: 0.4694184958934784, 300: 0.43973278999328613, 400: 0.47136345505714417}, 'F1': {456: 0.8231805958177758}, 'Accuracy': {456: 0.8061291884989653}}\n",
      "Starting Epoch 3/10\n",
      "Epoch 3, Step 0, Loss: 0.3874897062778473, Time Elapsed: 0.04767584800720215 seconds\n",
      "Epoch 3, Step 100, Loss: 0.3960302770137787, Time Elapsed: 5.429769992828369 seconds\n",
      "Epoch 3, Step 200, Loss: 0.4050791263580322, Time Elapsed: 10.710829973220825 seconds\n",
      "Epoch 3, Step 300, Loss: 0.4344410300254822, Time Elapsed: 15.990060091018677 seconds\n",
      "Epoch 3, Step 400, Loss: 0.3082011342048645, Time Elapsed: 21.233978986740112 seconds\n",
      "Epoch 3\n",
      "\n",
      "Writing snapshot to model_iter_001365.mdl\n",
      "Epoch time: 24.03218412399292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1364\n",
      "           1       0.95      0.93      0.94      1401\n",
      "           2       0.77      0.89      0.82      1372\n",
      "           3       0.77      0.80      0.78      1384\n",
      "           4       0.86      0.88      0.87      1389\n",
      "           5       0.84      0.70      0.76      1397\n",
      "           6       0.84      0.90      0.87      1409\n",
      "           7       0.77      0.90      0.83      1402\n",
      "           8       0.74      0.79      0.76      1393\n",
      "           9       0.78      0.82      0.80      1399\n",
      "          10       0.79      0.73      0.76      8801\n",
      "\n",
      "    accuracy                           0.81     22711\n",
      "   macro avg       0.82      0.85      0.83     22711\n",
      "weighted avg       0.81      0.81      0.81     22711\n",
      "\n",
      "Logger {'time': {0: 0.04764199256896973, 100: 5.429738998413086, 200: 10.710744857788086, 300: 15.99001407623291, 400: 21.233890056610107}, 'loss': {0: 0.3874897062778473, 100: 0.3960302770137787, 200: 0.4050791263580322, 300: 0.4344410300254822, 400: 0.3082011342048645}, 'F1': {684: 0.8289039378785592}, 'Accuracy': {684: 0.8084628594073356}}\n",
      "Starting Epoch 4/10\n",
      "Epoch 4, Step 0, Loss: 0.29602041840553284, Time Elapsed: 0.07930183410644531 seconds\n",
      "Epoch 4, Step 100, Loss: 0.35389915108680725, Time Elapsed: 5.316388845443726 seconds\n",
      "Epoch 4, Step 200, Loss: 0.48297080397605896, Time Elapsed: 10.691228866577148 seconds\n",
      "Epoch 4, Step 300, Loss: 0.44819754362106323, Time Elapsed: 16.3869309425354 seconds\n",
      "Epoch 4, Step 400, Loss: 0.3616482615470886, Time Elapsed: 21.472270965576172 seconds\n",
      "Epoch 4\n",
      "\n",
      "Writing snapshot to model_iter_001820.mdl\n",
      "Epoch time: 24.313995122909546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      1364\n",
      "           1       0.97      0.90      0.93      1401\n",
      "           2       0.87      0.78      0.82      1372\n",
      "           3       0.87      0.61      0.72      1384\n",
      "           4       0.90      0.85      0.87      1389\n",
      "           5       0.81      0.75      0.78      1397\n",
      "           6       0.90      0.88      0.89      1409\n",
      "           7       0.89      0.79      0.84      1402\n",
      "           8       0.75      0.79      0.77      1393\n",
      "           9       0.84      0.79      0.81      1399\n",
      "          10       0.75      0.81      0.78      8801\n",
      "\n",
      "    accuracy                           0.81     22711\n",
      "   macro avg       0.85      0.81      0.83     22711\n",
      "weighted avg       0.82      0.81      0.81     22711\n",
      "\n",
      "Logger {'time': {0: 0.07927393913269043, 100: 5.316339015960693, 200: 10.69116497039795, 300: 16.386889934539795, 400: 21.4722261428833}, 'loss': {0: 0.29602041840553284, 100: 0.35389915108680725, 200: 0.48297080397605896, 300: 0.44819754362106323, 400: 0.3616482615470886}, 'F1': {912: 0.8266281986788143}, 'Accuracy': {912: 0.8118532869534587}}\n",
      "Starting Epoch 5/10\n",
      "Epoch 5, Step 0, Loss: 0.4556412398815155, Time Elapsed: 0.0645439624786377 seconds\n",
      "Epoch 5, Step 100, Loss: 0.3325178027153015, Time Elapsed: 5.505868911743164 seconds\n",
      "Epoch 5, Step 200, Loss: 0.4476453363895416, Time Elapsed: 10.623662948608398 seconds\n",
      "Epoch 5, Step 300, Loss: 0.4530750513076782, Time Elapsed: 16.00576090812683 seconds\n",
      "Epoch 5, Step 400, Loss: 0.398781955242157, Time Elapsed: 21.159443855285645 seconds\n",
      "Epoch 5\n",
      "\n",
      "Writing snapshot to model_iter_002275.mdl\n",
      "Epoch time: 23.92234492301941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1364\n",
      "           1       0.95      0.94      0.94      1401\n",
      "           2       0.89      0.78      0.83      1372\n",
      "           3       0.74      0.83      0.78      1384\n",
      "           4       0.87      0.87      0.87      1389\n",
      "           5       0.84      0.71      0.77      1397\n",
      "           6       0.87      0.86      0.87      1409\n",
      "           7       0.81      0.89      0.85      1402\n",
      "           8       0.78      0.78      0.78      1393\n",
      "           9       0.78      0.84      0.81      1399\n",
      "          10       0.78      0.78      0.78      8801\n",
      "\n",
      "    accuracy                           0.82     22711\n",
      "   macro avg       0.84      0.84      0.84     22711\n",
      "weighted avg       0.82      0.82      0.82     22711\n",
      "\n",
      "Logger {'time': {0: 0.06450104713439941, 100: 5.505849123001099, 200: 10.623569965362549, 300: 16.005741119384766, 400: 21.159332990646362}, 'loss': {0: 0.4556412398815155, 100: 0.3325178027153015, 200: 0.4476453363895416, 300: 0.4530750513076782, 400: 0.398781955242157}, 'F1': {1140: 0.8357615492508991}, 'Accuracy': {1140: 0.818942362731716}}\n",
      "Starting Epoch 6/10\n",
      "Epoch 6, Step 0, Loss: 0.29995375871658325, Time Elapsed: 0.0700531005859375 seconds\n",
      "Epoch 6, Step 100, Loss: 0.2912743091583252, Time Elapsed: 5.251158952713013 seconds\n",
      "Epoch 6, Step 200, Loss: 0.46472781896591187, Time Elapsed: 10.40762996673584 seconds\n",
      "Epoch 6, Step 300, Loss: 0.383407324552536, Time Elapsed: 15.62010407447815 seconds\n",
      "Epoch 6, Step 400, Loss: 0.35748472809791565, Time Elapsed: 21.11601495742798 seconds\n",
      "Epoch 6\n",
      "\n",
      "Writing snapshot to model_iter_002730.mdl\n",
      "Epoch time: 24.062917947769165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      1364\n",
      "           1       0.93      0.97      0.95      1401\n",
      "           2       0.85      0.81      0.83      1372\n",
      "           3       0.72      0.86      0.79      1384\n",
      "           4       0.91      0.84      0.87      1389\n",
      "           5       0.83      0.75      0.78      1397\n",
      "           6       0.91      0.84      0.87      1409\n",
      "           7       0.86      0.85      0.85      1402\n",
      "           8       0.76      0.78      0.77      1393\n",
      "           9       0.78      0.86      0.82      1399\n",
      "          10       0.79      0.78      0.79      8801\n",
      "\n",
      "    accuracy                           0.82     22711\n",
      "   macro avg       0.84      0.84      0.84     22711\n",
      "weighted avg       0.82      0.82      0.82     22711\n",
      "\n",
      "Logger {'time': {0: 0.07003092765808105, 100: 5.2511138916015625, 200: 10.407546043395996, 300: 15.620055913925171, 400: 21.115934133529663}, 'loss': {0: 0.29995375871658325, 100: 0.2912743091583252, 200: 0.46472781896591187, 300: 0.383407324552536, 400: 0.35748472809791565}, 'F1': {1368: 0.8383474616263924}, 'Accuracy': {1368: 0.8212320021135133}}\n",
      "Starting Epoch 7/10\n",
      "Epoch 7, Step 0, Loss: 0.36300504207611084, Time Elapsed: 0.06522393226623535 seconds\n",
      "Epoch 7, Step 100, Loss: 0.2533581256866455, Time Elapsed: 5.230481863021851 seconds\n",
      "Epoch 7, Step 200, Loss: 0.3314974308013916, Time Elapsed: 10.531354665756226 seconds\n",
      "Epoch 7, Step 300, Loss: 0.35575079917907715, Time Elapsed: 15.87309193611145 seconds\n",
      "Epoch 7, Step 400, Loss: 0.4590740501880646, Time Elapsed: 21.30080485343933 seconds\n",
      "Epoch 7\n",
      "\n",
      "Writing snapshot to model_iter_003185.mdl\n",
      "Epoch time: 24.166748762130737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1364\n",
      "           1       0.95      0.95      0.95      1401\n",
      "           2       0.85      0.82      0.83      1372\n",
      "           3       0.78      0.77      0.78      1384\n",
      "           4       0.86      0.89      0.87      1389\n",
      "           5       0.78      0.79      0.79      1397\n",
      "           6       0.90      0.85      0.88      1409\n",
      "           7       0.86      0.84      0.85      1402\n",
      "           8       0.73      0.83      0.78      1393\n",
      "           9       0.76      0.84      0.80      1399\n",
      "          10       0.79      0.77      0.78      8801\n",
      "\n",
      "    accuracy                           0.82     22711\n",
      "   macro avg       0.83      0.84      0.84     22711\n",
      "weighted avg       0.82      0.82      0.82     22711\n",
      "\n",
      "Logger {'time': {0: 0.0651848316192627, 100: 5.2304298877716064, 200: 10.531261920928955, 300: 15.873044967651367, 400: 21.300723791122437}, 'loss': {0: 0.36300504207611084, 100: 0.2533581256866455, 200: 0.3314974308013916, 300: 0.35575079917907715, 400: 0.4590740501880646}, 'F1': {1596: 0.8374613656256777}, 'Accuracy': {1596: 0.8193386464708732}}\n",
      "Starting Epoch 8/10\n",
      "Epoch 8, Step 0, Loss: 0.36756667494773865, Time Elapsed: 0.06756019592285156 seconds\n",
      "Epoch 8, Step 100, Loss: 0.3612784445285797, Time Elapsed: 5.256086826324463 seconds\n",
      "Epoch 8, Step 200, Loss: 0.26190900802612305, Time Elapsed: 10.515886068344116 seconds\n",
      "Epoch 8, Step 300, Loss: 0.2851828634738922, Time Elapsed: 15.727077960968018 seconds\n",
      "Epoch 8, Step 400, Loss: 0.3550126254558563, Time Elapsed: 20.91783118247986 seconds\n",
      "Epoch 8\n",
      "\n",
      "Writing snapshot to model_iter_003640.mdl\n",
      "Epoch time: 23.718432903289795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1364\n",
      "           1       0.88      0.97      0.92      1401\n",
      "           2       0.85      0.83      0.84      1372\n",
      "           3       0.82      0.69      0.75      1384\n",
      "           4       0.82      0.93      0.87      1389\n",
      "           5       0.84      0.74      0.79      1397\n",
      "           6       0.89      0.87      0.88      1409\n",
      "           7       0.85      0.85      0.85      1402\n",
      "           8       0.70      0.84      0.77      1393\n",
      "           9       0.79      0.83      0.81      1399\n",
      "          10       0.79      0.76      0.77      8801\n",
      "\n",
      "    accuracy                           0.81     22711\n",
      "   macro avg       0.83      0.84      0.83     22711\n",
      "weighted avg       0.81      0.81      0.81     22711\n",
      "\n",
      "Logger {'time': {0: 0.06752300262451172, 100: 5.256032943725586, 200: 10.515794038772583, 300: 15.727038145065308, 400: 20.917705059051514}, 'loss': {0: 0.36756667494773865, 100: 0.3612784445285797, 200: 0.26190900802612305, 300: 0.2851828634738922, 400: 0.3550126254558563}, 'F1': {1824: 0.8322659032012495}, 'Accuracy': {1824: 0.8136585795429527}}\n",
      "Starting Epoch 9/10\n",
      "Epoch 9, Step 0, Loss: 0.3875369727611542, Time Elapsed: 0.04481101036071777 seconds\n",
      "Epoch 9, Step 100, Loss: 0.25115731358528137, Time Elapsed: 5.268448114395142 seconds\n",
      "Epoch 9, Step 200, Loss: 0.4294542968273163, Time Elapsed: 10.522900104522705 seconds\n",
      "Epoch 9, Step 300, Loss: 0.36550354957580566, Time Elapsed: 15.766141176223755 seconds\n",
      "Epoch 9, Step 400, Loss: 0.24114613234996796, Time Elapsed: 21.148941040039062 seconds\n",
      "Epoch 9\n",
      "\n",
      "Writing snapshot to model_iter_004095.mdl\n",
      "Epoch time: 23.930922031402588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1364\n",
      "           1       0.98      0.88      0.93      1401\n",
      "           2       0.90      0.76      0.82      1372\n",
      "           3       0.79      0.75      0.77      1384\n",
      "           4       0.87      0.87      0.87      1389\n",
      "           5       0.80      0.79      0.80      1397\n",
      "           6       0.92      0.83      0.87      1409\n",
      "           7       0.86      0.82      0.84      1402\n",
      "           8       0.71      0.83      0.77      1393\n",
      "           9       0.84      0.79      0.81      1399\n",
      "          10       0.77      0.81      0.79      8801\n",
      "\n",
      "    accuracy                           0.82     22711\n",
      "   macro avg       0.85      0.82      0.83     22711\n",
      "weighted avg       0.82      0.82      0.82     22711\n",
      "\n",
      "Logger {'time': {0: 0.04474329948425293, 100: 5.2684149742126465, 200: 10.52288007736206, 300: 15.766071081161499, 400: 21.148905992507935}, 'loss': {0: 0.3875369727611542, 100: 0.25115731358528137, 200: 0.4294542968273163, 300: 0.36550354957580566, 400: 0.24114613234996796}, 'F1': {2052: 0.8339177188949128}, 'Accuracy': {2052: 0.8179736691471093}}\n",
      "Starting Epoch 10/10\n",
      "Epoch 10, Step 0, Loss: 0.2843031883239746, Time Elapsed: 0.06351113319396973 seconds\n",
      "Epoch 10, Step 100, Loss: 0.3092847764492035, Time Elapsed: 5.279193878173828 seconds\n",
      "Epoch 10, Step 200, Loss: 0.2954320013523102, Time Elapsed: 10.49990200996399 seconds\n",
      "Epoch 10, Step 300, Loss: 0.27612608671188354, Time Elapsed: 15.788658857345581 seconds\n",
      "Epoch 10, Step 400, Loss: 0.3457893133163452, Time Elapsed: 20.998323917388916 seconds\n",
      "Epoch 10\n",
      "\n",
      "Writing snapshot to model_iter_004550.mdl\n",
      "Epoch time: 23.78002405166626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1364\n",
      "           1       0.92      0.97      0.94      1401\n",
      "           2       0.88      0.75      0.81      1372\n",
      "           3       0.76      0.81      0.78      1384\n",
      "           4       0.85      0.89      0.87      1389\n",
      "           5       0.81      0.79      0.80      1397\n",
      "           6       0.92      0.83      0.87      1409\n",
      "           7       0.84      0.87      0.86      1402\n",
      "           8       0.75      0.76      0.76      1393\n",
      "           9       0.83      0.78      0.81      1399\n",
      "          10       0.78      0.79      0.79      8801\n",
      "\n",
      "    accuracy                           0.82     22711\n",
      "   macro avg       0.84      0.83      0.84     22711\n",
      "weighted avg       0.82      0.82      0.82     22711\n",
      "\n",
      "Logger {'time': {0: 0.06347084045410156, 100: 5.279162883758545, 200: 10.499839067459106, 300: 15.78860592842102, 400: 20.998228073120117}, 'loss': {0: 0.2843031883239746, 100: 0.3092847764492035, 200: 0.2954320013523102, 300: 0.27612608671188354, 400: 0.3457893133163452}, 'F1': {2280: 0.8360866808475476}, 'Accuracy': {2280: 0.8204834661617718}}\n"
     ]
    }
   ],
   "source": [
    "# Load and shuffle MNIST dataset\n",
    "train_data, test_data = load_and_shuffle_mnist()\n",
    "\n",
    "# Set LSTM parameters\n",
    "input_size = 784  # 28x28\n",
    "hidden_size = 128\n",
    "num_classes = 11  # Digits 0-9 and 'null'\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "window_size = 10  # Example window size\n",
    "\n",
    "# Create model\n",
    "model = SimpleLSTM(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Iterate over different dataset sizes\n",
    "for size in [1000, 5000, 10000, 20000, 30000, 40000, 50000]:\n",
    "    print(f\"Training with dataset size: {size}\")\n",
    "\n",
    "    # Balanced sampling\n",
    "    sampled_train_data = balanced_sampling(train_data, size)\n",
    "    sampled_test_data = balanced_sampling(test_data, size // 2)\n",
    "    print('Done sample data.')\n",
    "\n",
    "    # Create sequences\n",
    "    train_sequences, train_labels = create_sequences(sampled_train_data, window_size)\n",
    "    test_sequences, test_labels = create_sequences(sampled_test_data, window_size)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = MNISTSequenceDataset(train_sequences, train_labels)\n",
    "    test_dataset = MNISTSequenceDataset(test_sequences, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f40f77",
   "metadata": {},
   "source": [
    "# Train without batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51c09b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with dataset size: 1000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Epoch 1\n",
      "\n",
      "Epoch time: 4.595603942871094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59        27\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.00      0.00      0.00        29\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        28\n",
      "           5       0.00      0.00      0.00        30\n",
      "           6       0.00      0.00      0.00        25\n",
      "           7       0.00      0.00      0.00        28\n",
      "           8       0.00      0.00      0.00        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.37      0.93      0.53       164\n",
      "\n",
      "    accuracy                           0.38       441\n",
      "   macro avg       0.09      0.14      0.10       441\n",
      "weighted avg       0.17      0.38      0.23       441\n",
      "\n",
      "Logger {'time': {0: 0.015468835830688477, 100: 0.5594398975372314, 200: 1.0551037788391113, 300: 1.6020641326904297, 400: 2.1452648639678955, 500: 2.70550274848938, 600: 3.1959316730499268, 700: 3.696408987045288, 800: 4.167155742645264}, 'loss': {0: 2.1169803142547607, 100: 1.0138664245605469, 200: 3.1746888160705566, 300: 2.175368070602417, 400: 1.4269038438796997, 500: 2.762244701385498, 600: 0.9571136832237244, 700: 1.3773188591003418, 800: 2.635209083557129}, 'F1': {1: 0.101768697955873}, 'Accuracy': {1: 0.38095238095238093}}\n",
      "Epoch 2\n",
      "\n",
      "Epoch time: 4.426859140396118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        27\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.60      0.10      0.18        29\n",
      "           3       0.50      0.15      0.23        27\n",
      "           4       0.59      0.36      0.44        28\n",
      "           5       0.00      0.00      0.00        30\n",
      "           6       0.65      0.60      0.63        25\n",
      "           7       0.00      0.00      0.00        28\n",
      "           8       0.37      0.26      0.30        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.36      0.75      0.49       164\n",
      "\n",
      "    accuracy                           0.40       441\n",
      "   macro avg       0.33      0.25      0.26       441\n",
      "weighted avg       0.34      0.40      0.32       441\n",
      "\n",
      "Logger {'time': {0: 0.006639242172241211, 100: 0.4898984432220459, 200: 0.9854342937469482, 300: 1.4615452289581299, 400: 2.018139362335205, 500: 2.5223193168640137, 600: 3.0571072101593018, 700: 3.5359580516815186, 800: 4.000373363494873}, 'loss': {0: 1.8032593727111816, 100: 1.0689173936843872, 200: 2.5419199466705322, 300: 1.6153793334960938, 400: 0.9150887727737427, 500: 3.0735933780670166, 600: 0.9142391085624695, 700: 1.3839107751846313, 800: 1.9193285703659058}, 'F1': {2: 0.25727992034353603}, 'Accuracy': {2: 0.4013605442176871}}\n",
      "Epoch 3\n",
      "\n",
      "Epoch time: 4.323276996612549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.70      0.61        27\n",
      "           1       0.80      0.43      0.56        28\n",
      "           2       0.75      0.31      0.44        29\n",
      "           3       0.50      0.41      0.45        27\n",
      "           4       0.67      0.36      0.47        28\n",
      "           5       1.00      0.03      0.06        30\n",
      "           6       0.59      0.68      0.63        25\n",
      "           7       0.62      0.36      0.45        28\n",
      "           8       0.41      0.52      0.46        27\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.36      0.58      0.45       164\n",
      "\n",
      "    accuracy                           0.45       441\n",
      "   macro avg       0.57      0.40      0.42       441\n",
      "weighted avg       0.51      0.45      0.42       441\n",
      "\n",
      "Logger {'time': {0: 0.005797863006591797, 100: 0.510612964630127, 200: 0.967383861541748, 300: 1.4508631229400635, 400: 1.9122979640960693, 500: 2.401071071624756, 600: 2.860825777053833, 700: 3.343277931213379, 800: 3.83028507232666}, 'loss': {0: 1.6052656173706055, 100: 1.069319486618042, 200: 1.8650896549224854, 300: 1.2536747455596924, 400: 0.8370615839958191, 500: 2.5171866416931152, 600: 0.8475841879844666, 700: 1.35646390914917, 800: 1.421177625656128}, 'F1': {3: 0.4161709107419913}, 'Accuracy': {3: 0.4489795918367347}}\n",
      "Epoch 4\n",
      "\n",
      "Epoch time: 4.674302101135254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61        27\n",
      "           1       0.73      0.39      0.51        28\n",
      "           2       0.71      0.52      0.60        29\n",
      "           3       0.53      0.30      0.38        27\n",
      "           4       0.56      0.32      0.41        28\n",
      "           5       1.00      0.03      0.06        30\n",
      "           6       0.58      0.60      0.59        25\n",
      "           7       0.65      0.39      0.49        28\n",
      "           8       0.47      0.56      0.51        27\n",
      "           9       1.00      0.07      0.13        28\n",
      "          10       0.37      0.60      0.46       164\n",
      "\n",
      "    accuracy                           0.46       441\n",
      "   macro avg       0.65      0.40      0.43       441\n",
      "weighted avg       0.57      0.46      0.44       441\n",
      "\n",
      "Logger {'time': {0: 0.005451202392578125, 100: 0.5346512794494629, 200: 1.0405523777008057, 300: 1.529123067855835, 400: 2.1262431144714355, 500: 2.6684651374816895, 600: 3.2219691276550293, 700: 3.7236433029174805, 800: 4.25228214263916}, 'loss': {0: 1.2361252307891846, 100: 0.9776474237442017, 200: 1.5735512971878052, 300: 0.9272435903549194, 400: 0.7393025755882263, 500: 2.516925811767578, 600: 0.72287517786026, 700: 1.4078541994094849, 800: 1.2364455461502075}, 'F1': {4: 0.4319690025042131}, 'Accuracy': {4: 0.4603174603174603}}\n",
      "Epoch 5\n",
      "\n",
      "Epoch time: 4.63496994972229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70        27\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.74      0.59      0.65        29\n",
      "           3       0.47      0.26      0.33        27\n",
      "           4       0.56      0.36      0.43        28\n",
      "           5       0.50      0.07      0.12        30\n",
      "           6       0.64      0.64      0.64        25\n",
      "           7       0.58      0.39      0.47        28\n",
      "           8       0.58      0.56      0.57        27\n",
      "           9       0.60      0.11      0.18        28\n",
      "          10       0.37      0.60      0.46       164\n",
      "\n",
      "    accuracy                           0.46       441\n",
      "   macro avg       0.51      0.40      0.41       441\n",
      "weighted avg       0.47      0.46      0.42       441\n",
      "\n",
      "Logger {'time': {0: 0.006541013717651367, 100: 0.5629189014434814, 200: 1.082840919494629, 300: 1.577406883239746, 400: 2.0495429039001465, 500: 2.521696090698242, 600: 3.042526960372925, 700: 3.5871801376342773, 800: 4.1355109214782715}, 'loss': {0: 1.2631475925445557, 100: 0.894921064376831, 200: 1.3909380435943604, 300: 0.8771323561668396, 400: 0.7015430331230164, 500: 2.314845561981201, 600: 0.6168094277381897, 700: 1.537688970565796, 800: 1.0821830034255981}, 'F1': {5: 0.41365309775620607}, 'Accuracy': {5: 0.4580498866213152}}\n",
      "Epoch 6\n",
      "\n",
      "Epoch time: 4.601041793823242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68        27\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.74      0.59      0.65        29\n",
      "           3       0.62      0.56      0.59        27\n",
      "           4       0.62      0.29      0.39        28\n",
      "           5       0.57      0.13      0.22        30\n",
      "           6       0.70      0.56      0.62        25\n",
      "           7       0.60      0.43      0.50        28\n",
      "           8       0.58      0.56      0.57        27\n",
      "           9       0.56      0.18      0.27        28\n",
      "          10       0.38      0.62      0.47       164\n",
      "\n",
      "    accuracy                           0.48       441\n",
      "   macro avg       0.54      0.43      0.45       441\n",
      "weighted avg       0.49      0.48      0.45       441\n",
      "\n",
      "Logger {'time': {0: 0.006830930709838867, 100: 0.5513668060302734, 200: 1.0657899379730225, 300: 1.5965559482574463, 400: 2.1696767807006836, 500: 2.69647479057312, 600: 3.2258529663085938, 700: 3.7053558826446533, 800: 4.185520887374878}, 'loss': {0: 1.2966015338897705, 100: 1.0639033317565918, 200: 1.7322863340377808, 300: 0.6455510258674622, 400: 0.760735034942627, 500: 2.2741472721099854, 600: 0.6976934671401978, 700: 1.5677255392074585, 800: 0.9034785032272339}, 'F1': {6: 0.45058670605652096}, 'Accuracy': {6: 0.48072562358276644}}\n",
      "Epoch 7\n",
      "\n",
      "Epoch time: 4.329017162322998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.68        27\n",
      "           1       1.00      0.11      0.19        28\n",
      "           2       0.65      0.69      0.67        29\n",
      "           3       0.53      0.37      0.43        27\n",
      "           4       0.52      0.39      0.45        28\n",
      "           5       0.75      0.40      0.52        30\n",
      "           6       0.59      0.64      0.62        25\n",
      "           7       0.63      0.43      0.51        28\n",
      "           8       0.52      0.52      0.52        27\n",
      "           9       0.64      0.25      0.36        28\n",
      "          10       0.36      0.52      0.43       164\n",
      "\n",
      "    accuracy                           0.48       441\n",
      "   macro avg       0.62      0.46      0.49       441\n",
      "weighted avg       0.54      0.48      0.47       441\n",
      "\n",
      "Logger {'time': {0: 0.005442142486572266, 100: 0.5215463638305664, 200: 0.9966552257537842, 300: 1.489995002746582, 400: 1.9616601467132568, 500: 2.4495480060577393, 600: 2.9014742374420166, 700: 3.3831772804260254, 800: 3.8451192378997803}, 'loss': {0: 1.1405128240585327, 100: 0.864571213722229, 200: 1.1389923095703125, 300: 0.47415632009506226, 400: 0.8120211362838745, 500: 2.509488344192505, 600: 0.4296344816684723, 700: 1.3331644535064697, 800: 0.7509084939956665}, 'F1': {7: 0.4884784945529661}, 'Accuracy': {7: 0.47619047619047616}}\n",
      "Epoch 8\n",
      "\n",
      "Epoch time: 4.808247804641724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68        27\n",
      "           1       1.00      0.07      0.13        28\n",
      "           2       0.68      0.66      0.67        29\n",
      "           3       0.62      0.59      0.60        27\n",
      "           4       0.65      0.39      0.49        28\n",
      "           5       0.67      0.33      0.44        30\n",
      "           6       0.57      0.64      0.60        25\n",
      "           7       0.65      0.54      0.59        28\n",
      "           8       0.50      0.63      0.56        27\n",
      "           9       0.60      0.32      0.42        28\n",
      "          10       0.38      0.51      0.43       164\n",
      "\n",
      "    accuracy                           0.50       441\n",
      "   macro avg       0.63      0.50      0.51       441\n",
      "weighted avg       0.55      0.50      0.49       441\n",
      "\n",
      "Logger {'time': {0: 0.0070989131927490234, 100: 0.5006461143493652, 200: 1.0126049518585205, 300: 1.5157220363616943, 400: 2.096449851989746, 500: 2.6485300064086914, 600: 3.215118885040283, 700: 3.771423101425171, 800: 4.349494218826294}, 'loss': {0: 1.1597094535827637, 100: 0.8382668495178223, 200: 1.0481089353561401, 300: 0.5590707659721375, 400: 0.8435726761817932, 500: 2.196439266204834, 600: 0.566061794757843, 700: 1.5338070392608643, 800: 0.9204837083816528}, 'F1': {8: 0.5106428932969199}, 'Accuracy': {8: 0.4965986394557823}}\n",
      "Epoch 9\n",
      "\n",
      "Epoch time: 4.472323656082153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.63        27\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.71      0.69      0.70        29\n",
      "           3       0.60      0.44      0.51        27\n",
      "           4       0.58      0.25      0.35        28\n",
      "           5       0.62      0.17      0.26        30\n",
      "           6       0.60      0.60      0.60        25\n",
      "           7       0.64      0.32      0.43        28\n",
      "           8       0.52      0.48      0.50        27\n",
      "           9       0.56      0.36      0.43        28\n",
      "          10       0.37      0.58      0.45       164\n",
      "\n",
      "    accuracy                           0.46       441\n",
      "   macro avg       0.53      0.42      0.44       441\n",
      "weighted avg       0.48      0.46      0.44       441\n",
      "\n",
      "Logger {'time': {0: 0.0058460235595703125, 100: 0.5240237712860107, 200: 1.0793049335479736, 300: 1.631138801574707, 400: 2.1448137760162354, 500: 2.6149168014526367, 600: 3.098568916320801, 700: 3.5645158290863037, 800: 4.043931722640991}, 'loss': {0: 1.0622832775115967, 100: 0.9304373860359192, 200: 1.053755760192871, 300: 0.4392155110836029, 400: 0.6392877101898193, 500: 2.124919891357422, 600: 0.5204646587371826, 700: 2.0004422664642334, 800: 0.44163548946380615}, 'F1': {9: 0.44295226509083213}, 'Accuracy': {9: 0.46485260770975056}}\n",
      "Epoch 10\n",
      "\n",
      "Epoch time: 4.596246957778931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67        27\n",
      "           1       0.00      0.00      0.00        28\n",
      "           2       0.73      0.66      0.69        29\n",
      "           3       0.65      0.56      0.60        27\n",
      "           4       0.69      0.32      0.44        28\n",
      "           5       0.60      0.10      0.17        30\n",
      "           6       0.56      0.40      0.47        25\n",
      "           7       0.62      0.46      0.53        28\n",
      "           8       0.56      0.52      0.54        27\n",
      "           9       0.60      0.32      0.42        28\n",
      "          10       0.38      0.60      0.46       164\n",
      "\n",
      "    accuracy                           0.48       441\n",
      "   macro avg       0.54      0.43      0.45       441\n",
      "weighted avg       0.49      0.48      0.45       441\n",
      "\n",
      "Logger {'time': {0: 0.00569605827331543, 100: 0.5752592086791992, 200: 1.130937099456787, 300: 1.626847267150879, 400: 2.136575222015381, 500: 2.6297051906585693, 600: 3.130347967147827, 700: 3.650297164916992, 800: 4.139811038970947}, 'loss': {0: 1.086751937866211, 100: 0.8431727886199951, 200: 1.0542831420898438, 300: 0.46065467596054077, 400: 0.5583846569061279, 500: 1.9982762336730957, 600: 0.5625782608985901, 700: 1.3460787534713745, 800: 0.35750526189804077}, 'F1': {10: 0.45310730971232355}, 'Accuracy': {10: 0.47845804988662133}}\n",
      "Training with dataset size: 5000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Epoch 1\n",
      "\n",
      "Epoch time: 23.127092838287354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.67       136\n",
      "           1       0.61      0.40      0.49       134\n",
      "           2       0.65      0.44      0.53       140\n",
      "           3       0.57      0.24      0.34       135\n",
      "           4       0.57      0.29      0.38       142\n",
      "           5       0.62      0.39      0.48       142\n",
      "           6       0.59      0.76      0.66       141\n",
      "           7       0.65      0.21      0.32       149\n",
      "           8       0.62      0.24      0.35       145\n",
      "           9       0.47      0.30      0.37       128\n",
      "          10       0.39      0.55      0.46       869\n",
      "\n",
      "    accuracy                           0.47      2261\n",
      "   macro avg       0.57      0.44      0.46      2261\n",
      "weighted avg       0.51      0.47      0.46      2261\n",
      "\n",
      "Logger {'time': {0: 0.009802103042602539, 100: 0.5389080047607422, 200: 1.0678880214691162, 300: 1.6622052192687988, 400: 2.167663097381592, 500: 2.657405138015747, 600: 3.2255048751831055, 700: 3.752992868423462, 800: 4.262624025344849, 900: 4.731649875640869, 1000: 5.281770944595337, 1100: 5.768373012542725, 1200: 6.251768112182617, 1300: 6.724776029586792, 1400: 7.270815849304199, 1500: 7.752440929412842, 1600: 8.240869045257568, 1700: 8.7555570602417, 1800: 9.323461055755615, 1900: 9.843158960342407, 2000: 10.329303979873657, 2100: 10.806550979614258, 2200: 11.269695281982422, 2300: 11.792285203933716, 2400: 12.265639066696167, 2500: 12.760781049728394, 2600: 13.250258207321167, 2700: 13.733769178390503, 2800: 14.216727018356323, 2900: 14.70278811454773, 3000: 15.17577600479126, 3100: 15.63173508644104, 3200: 16.100991249084473, 3300: 16.586742877960205, 3400: 17.135930061340332, 3500: 17.635910034179688, 3600: 18.216073274612427, 3700: 18.761415004730225, 3800: 19.349208116531372, 3900: 19.915199279785156, 4000: 20.457123041152954, 4100: 20.97585105895996, 4200: 21.486257076263428, 4300: 21.97927498817444, 4400: 22.488868951797485, 4500: 22.97711706161499}, 'loss': {0: 2.2174572944641113, 100: 1.1222903728485107, 200: 1.1708900928497314, 300: 2.689250946044922, 400: 0.5675750970840454, 500: 1.514204740524292, 600: 0.456771582365036, 700: 0.4877309203147888, 800: 1.2208747863769531, 900: 3.7337238788604736, 1000: 1.8546621799468994, 1100: 0.9206516146659851, 1200: 3.737257242202759, 1300: 0.6861689686775208, 1400: 0.6003194451332092, 1500: 1.5656523704528809, 1600: 1.4758715629577637, 1700: 0.8905681371688843, 1800: 1.105461835861206, 1900: 0.6335697174072266, 2000: 1.0839987993240356, 2100: 1.7685221433639526, 2200: 0.38817912340164185, 2300: 1.0637556314468384, 2400: 0.6919665336608887, 2500: 1.2798112630844116, 2600: 4.1422200202941895, 2700: 0.6282936334609985, 2800: 1.284339427947998, 2900: 2.4583120346069336, 3000: 0.7204490900039673, 3100: 0.6028048396110535, 3200: 1.4650788307189941, 3300: 1.1782150268554688, 3400: 1.1771447658538818, 3500: 0.35618993639945984, 3600: 1.137478232383728, 3700: 0.9884746670722961, 3800: 0.727595329284668, 3900: 0.716357946395874, 4000: 0.2941924035549164, 4100: 1.0872472524642944, 4200: 0.5112013220787048, 4300: 0.6932215690612793, 4400: 0.9053205251693726, 4500: 0.6981146931648254}, 'F1': {1: 0.45843285464547434}, 'Accuracy': {1: 0.4727996461742592}}\n",
      "Epoch 2\n",
      "\n",
      "Epoch time: 25.814368724822998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       136\n",
      "           1       0.61      0.49      0.54       134\n",
      "           2       0.67      0.51      0.58       140\n",
      "           3       0.62      0.54      0.58       135\n",
      "           4       0.59      0.38      0.46       142\n",
      "           5       0.60      0.61      0.60       142\n",
      "           6       0.59      0.78      0.67       141\n",
      "           7       0.61      0.21      0.31       149\n",
      "           8       0.67      0.56      0.61       145\n",
      "           9       0.56      0.48      0.52       128\n",
      "          10       0.40      0.46      0.43       869\n",
      "\n",
      "    accuracy                           0.52      2261\n",
      "   macro avg       0.59      0.54      0.55      2261\n",
      "weighted avg       0.53      0.52      0.51      2261\n",
      "\n",
      "Logger {'time': {0: 0.005753755569458008, 100: 0.6482529640197754, 200: 1.1383779048919678, 300: 1.7016358375549316, 400: 2.2051069736480713, 500: 2.725344657897949, 600: 3.3569726943969727, 700: 3.921567678451538, 800: 4.494585752487183, 900: 5.041143894195557, 1000: 5.5673508644104, 1100: 6.146965026855469, 1200: 6.689487934112549, 1300: 7.320468902587891, 1400: 8.002737998962402, 1500: 8.713373899459839, 1600: 9.404103994369507, 1700: 10.128599882125854, 1800: 10.784308910369873, 1900: 11.372609853744507, 2000: 11.905998945236206, 2100: 12.436292886734009, 2200: 12.925601720809937, 2300: 13.429884910583496, 2400: 13.931089878082275, 2500: 14.478801965713501, 2600: 15.058465719223022, 2700: 15.678709030151367, 2800: 16.223623991012573, 2900: 16.79642677307129, 3000: 17.389423847198486, 3100: 17.970189809799194, 3200: 18.528910875320435, 3300: 19.07235884666443, 3400: 19.638000965118408, 3500: 20.150768995285034, 3600: 20.696828842163086, 3700: 21.267060041427612, 3800: 21.79096293449402, 3900: 22.35242986679077, 4000: 22.941873788833618, 4100: 23.505528926849365, 4200: 24.069016933441162, 4300: 24.62812876701355, 4400: 25.163588762283325, 4500: 25.669474840164185}, 'loss': {0: 2.1751770973205566, 100: 0.7462736964225769, 200: 1.0605665445327759, 300: 2.223360061645508, 400: 0.45825523138046265, 500: 0.8476160764694214, 600: 0.811134397983551, 700: 1.1460011005401611, 800: 1.8999167680740356, 900: 2.335792064666748, 1000: 1.6408406496047974, 1100: 0.9422800540924072, 1200: 1.9312355518341064, 1300: 0.6556311249732971, 1400: 1.1325513124465942, 1500: 1.4122071266174316, 1600: 1.073112964630127, 1700: 0.4691700339317322, 1800: 1.6545313596725464, 1900: 0.9919097423553467, 2000: 1.137827754020691, 2100: 1.1129717826843262, 2200: 0.25403356552124023, 2300: 1.1619696617126465, 2400: 0.31117722392082214, 2500: 1.2451478242874146, 2600: 4.439910411834717, 2700: 0.8502328991889954, 2800: 0.8505635857582092, 2900: 2.2144243717193604, 3000: 0.5061438083648682, 3100: 1.0451005697250366, 3200: 1.083406686782837, 3300: 0.6148141026496887, 3400: 0.8993150591850281, 3500: 0.32870185375213623, 3600: 2.0272350311279297, 3700: 1.455669641494751, 3800: 0.5868716239929199, 3900: 0.6387269496917725, 4000: 0.27544307708740234, 4100: 1.2256382703781128, 4200: 0.5110623836517334, 4300: 0.858352780342102, 4400: 0.4710264503955841, 4500: 0.4919140040874481}, 'F1': {2: 0.5474998405655082}, 'Accuracy': {2: 0.5157010172490049}}\n",
      "Epoch 3\n",
      "\n",
      "Epoch time: 22.627593994140625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       136\n",
      "           1       0.57      0.47      0.51       134\n",
      "           2       0.64      0.54      0.58       140\n",
      "           3       0.60      0.53      0.56       135\n",
      "           4       0.62      0.61      0.61       142\n",
      "           5       0.56      0.56      0.56       142\n",
      "           6       0.58      0.81      0.67       141\n",
      "           7       0.67      0.19      0.30       149\n",
      "           8       0.58      0.66      0.62       145\n",
      "           9       0.55      0.47      0.50       128\n",
      "          10       0.40      0.41      0.40       869\n",
      "\n",
      "    accuracy                           0.51      2261\n",
      "   macro avg       0.58      0.56      0.55      2261\n",
      "weighted avg       0.52      0.51      0.50      2261\n",
      "\n",
      "Logger {'time': {0: 0.008234977722167969, 100: 0.5644869804382324, 200: 1.1102018356323242, 300: 1.6234540939331055, 400: 2.1077280044555664, 500: 2.5835139751434326, 600: 3.04300594329834, 700: 3.5293359756469727, 800: 4.001218795776367, 900: 4.4873270988464355, 1000: 5.010227918624878, 1100: 5.5069358348846436, 1200: 5.976212978363037, 1300: 6.462006092071533, 1400: 6.9275641441345215, 1500: 7.43352198600769, 1600: 7.9186718463897705, 1700: 8.387446165084839, 1800: 8.870256900787354, 1900: 9.434850215911865, 2000: 9.97330379486084, 2100: 10.53640103340149, 2200: 11.059002876281738, 2300: 11.578176975250244, 2400: 12.089680910110474, 2500: 12.594657182693481, 2600: 13.120949029922485, 2700: 13.583789825439453, 2800: 14.079009056091309, 2900: 14.548240900039673, 3000: 15.035704851150513, 3100: 15.502534866333008, 3200: 15.972630977630615, 3300: 16.476882934570312, 3400: 16.94721007347107, 3500: 17.46286392211914, 3600: 17.9862060546875, 3700: 18.489099979400635, 3800: 18.959049940109253, 3900: 19.449939966201782, 4000: 19.90893793106079, 4100: 20.424415111541748, 4200: 20.93130874633789, 4300: 21.44025492668152, 4400: 21.940764904022217, 4500: 22.47559094429016}, 'loss': {0: 2.1216068267822266, 100: 0.5630726218223572, 200: 0.6010835766792297, 300: 2.3938896656036377, 400: 0.34394943714141846, 500: 0.5826832056045532, 600: 1.0027854442596436, 700: 1.161949634552002, 800: 1.753758430480957, 900: 1.955939531326294, 1000: 3.2840464115142822, 1100: 0.7901633381843567, 1200: 3.258185386657715, 1300: 0.47295618057250977, 1400: 0.9184322953224182, 1500: 1.1977124214172363, 1600: 1.4951400756835938, 1700: 0.2979452908039093, 1800: 1.6805071830749512, 1900: 0.7002878785133362, 2000: 1.129786729812622, 2100: 0.6649371385574341, 2200: 0.1922808438539505, 2300: 1.2291245460510254, 2400: 0.2861514389514923, 2500: 1.2097713947296143, 2600: 3.880441665649414, 2700: 0.6341307759284973, 2800: 0.9437557458877563, 2900: 1.1836185455322266, 3000: 0.5557693243026733, 3100: 1.1187632083892822, 3200: 1.4614307880401611, 3300: 0.632601797580719, 3400: 0.8737585544586182, 3500: 0.2710154056549072, 3600: 1.6795785427093506, 3700: 1.3302603960037231, 3800: 0.527829110622406, 3900: 1.054513931274414, 4000: 0.2500726878643036, 4100: 1.2065279483795166, 4200: 1.005741834640503, 4300: 0.7885163426399231, 4400: 0.6100000143051147, 4500: 0.5679755806922913}, 'F1': {3: 0.5495724927225033}, 'Accuracy': {3: 0.5117204776647502}}\n",
      "Epoch 4\n",
      "\n",
      "Epoch time: 27.91063094139099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       136\n",
      "           1       0.58      0.34      0.42       134\n",
      "           2       0.61      0.56      0.59       140\n",
      "           3       0.61      0.39      0.48       135\n",
      "           4       0.60      0.51      0.55       142\n",
      "           5       0.53      0.63      0.58       142\n",
      "           6       0.58      0.79      0.67       141\n",
      "           7       0.62      0.13      0.22       149\n",
      "           8       0.59      0.61      0.60       145\n",
      "           9       0.56      0.39      0.46       128\n",
      "          10       0.39      0.45      0.42       869\n",
      "\n",
      "    accuracy                           0.50      2261\n",
      "   macro avg       0.57      0.52      0.52      2261\n",
      "weighted avg       0.51      0.50      0.48      2261\n",
      "\n",
      "Logger {'time': {0: 0.008587837219238281, 100: 0.48535990715026855, 200: 0.9800708293914795, 300: 1.6302080154418945, 400: 2.1802496910095215, 500: 2.752044916152954, 600: 3.4206888675689697, 700: 3.984048843383789, 800: 4.576831817626953, 900: 5.130748748779297, 1000: 5.70134973526001, 1100: 6.212585926055908, 1200: 6.7085959911346436, 1300: 7.311330080032349, 1400: 7.900710821151733, 1500: 8.577306747436523, 1600: 9.447435855865479, 1700: 10.150964975357056, 1800: 10.753262042999268, 1900: 11.324004888534546, 2000: 11.889233827590942, 2100: 12.982887744903564, 2200: 13.680057048797607, 2300: 14.357531785964966, 2400: 15.007548809051514, 2500: 15.725693941116333, 2600: 16.238329887390137, 2700: 16.796350955963135, 2800: 17.429386854171753, 2900: 18.081527948379517, 3000: 18.71700406074524, 3100: 19.277467727661133, 3200: 19.84648585319519, 3300: 20.392284870147705, 3400: 20.932477951049805, 3500: 21.53493094444275, 3600: 22.21911072731018, 3700: 22.915782928466797, 3800: 23.630847930908203, 3900: 24.298702716827393, 4000: 24.79963994026184, 4100: 25.434308767318726, 4200: 26.04790496826172, 4300: 26.58395290374756, 4400: 27.103834867477417, 4500: 27.681574821472168}, 'loss': {0: 2.071078062057495, 100: 0.7666895985603333, 200: 0.6206232309341431, 300: 2.169046640396118, 400: 0.2826620042324066, 500: 0.8068756461143494, 600: 0.7228026986122131, 700: 0.8616491556167603, 800: 1.6429247856140137, 900: 1.8976893424987793, 1000: 2.321366310119629, 1100: 1.9224165678024292, 1200: 1.8916438817977905, 1300: 0.7570024728775024, 1400: 0.7022414207458496, 1500: 1.0508935451507568, 1600: 1.6353871822357178, 1700: 0.1642986238002777, 1800: 1.6893556118011475, 1900: 0.7760698795318604, 2000: 1.4721150398254395, 2100: 0.6890276670455933, 2200: 0.14474910497665405, 2300: 0.9695730805397034, 2400: 0.3341433107852936, 2500: 0.7885761260986328, 2600: 4.989949703216553, 2700: 0.9202236533164978, 2800: 0.5320025086402893, 2900: 1.7376201152801514, 3000: 0.4610767960548401, 3100: 1.1614047288894653, 3200: 0.9966569542884827, 3300: 0.9855320453643799, 3400: 0.45611995458602905, 3500: 0.3109681308269501, 3600: 1.8390142917633057, 3700: 1.3412114381790161, 3800: 0.5963950157165527, 3900: 0.5330734252929688, 4000: 0.1677047312259674, 4100: 1.4261291027069092, 4200: 0.9651135206222534, 4300: 0.6448820233345032, 4400: 0.8583535552024841, 4500: 0.6602421998977661}, 'F1': {4: 0.5174916762652312}, 'Accuracy': {4: 0.4966828836797877}}\n",
      "Epoch 5\n",
      "\n",
      "Epoch time: 29.566109895706177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69       136\n",
      "           1       0.63      0.28      0.38       134\n",
      "           2       0.58      0.42      0.49       140\n",
      "           3       0.56      0.56      0.56       135\n",
      "           4       0.60      0.67      0.63       142\n",
      "           5       0.58      0.63      0.60       142\n",
      "           6       0.56      0.89      0.69       141\n",
      "           7       0.56      0.10      0.17       149\n",
      "           8       0.54      0.71      0.61       145\n",
      "           9       0.56      0.59      0.57       128\n",
      "          10       0.40      0.41      0.40       869\n",
      "\n",
      "    accuracy                           0.51      2261\n",
      "   macro avg       0.56      0.56      0.53      2261\n",
      "weighted avg       0.51      0.51      0.49      2261\n",
      "\n",
      "Logger {'time': {0: 0.007127046585083008, 100: 0.5616030693054199, 200: 1.0772738456726074, 300: 1.5811347961425781, 400: 2.0897629261016846, 500: 2.581937789916992, 600: 3.292268991470337, 700: 3.9162650108337402, 800: 4.570105791091919, 900: 5.09089994430542, 1000: 5.677019834518433, 1100: 6.302191734313965, 1200: 6.844623804092407, 1300: 7.426194906234741, 1400: 8.043179035186768, 1500: 8.605838775634766, 1600: 9.102244853973389, 1700: 9.746229887008667, 1800: 10.258510112762451, 1900: 10.76625370979309, 2000: 11.58850884437561, 2100: 12.178977012634277, 2200: 12.749070882797241, 2300: 13.331965923309326, 2400: 13.87611174583435, 2500: 14.422557830810547, 2600: 14.968219757080078, 2700: 15.52999496459961, 2800: 16.095310926437378, 2900: 16.688775777816772, 3000: 17.334659099578857, 3100: 17.83889102935791, 3200: 18.35622787475586, 3300: 18.955076932907104, 3400: 19.726427793502808, 3500: 20.320088863372803, 3600: 21.279557943344116, 3700: 22.105682849884033, 3800: 22.841837882995605, 3900: 23.4456467628479, 4000: 23.968912839889526, 4100: 24.640583992004395, 4200: 27.69397783279419, 4300: 28.32738208770752, 4400: 28.897178888320923, 4500: 29.413037061691284}, 'loss': {0: 2.5250492095947266, 100: 0.7808628082275391, 200: 0.42403653264045715, 300: 2.0621824264526367, 400: 0.32007116079330444, 500: 1.302872657775879, 600: 0.8122019171714783, 700: 0.7955806255340576, 800: 2.0599417686462402, 900: 1.0577270984649658, 1000: 1.8949308395385742, 1100: 0.8242388963699341, 1200: 1.5588915348052979, 1300: 0.6903714537620544, 1400: 0.5535112619400024, 1500: 1.2112281322479248, 1600: 1.9618443250656128, 1700: 0.7986084818840027, 1800: 1.2653377056121826, 1900: 0.8040304780006409, 2000: 1.1464864015579224, 2100: 0.5876141786575317, 2200: 0.23769381642341614, 2300: 0.6481529474258423, 2400: 0.2913583815097809, 2500: 1.0170936584472656, 2600: 4.925380229949951, 2700: 1.1596134901046753, 2800: 0.8338117599487305, 2900: 1.4269635677337646, 3000: 0.4817080497741699, 3100: 0.8421596884727478, 3200: 0.9968202710151672, 3300: 1.0651649236679077, 3400: 0.33399540185928345, 3500: 0.18788498640060425, 3600: 0.7590380311012268, 3700: 1.4940457344055176, 3800: 0.9087598919868469, 3900: 0.7881321907043457, 4000: 0.23775547742843628, 4100: 1.1334524154663086, 4200: 0.8739034533500671, 4300: 0.7116104960441589, 4400: 0.517024040222168, 4500: 0.40077701210975647}, 'F1': {5: 0.5277636139878988}, 'Accuracy': {5: 0.5059708093763822}}\n",
      "Epoch 6\n",
      "\n",
      "Epoch time: 26.76087522506714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.79      0.67       136\n",
      "           1       0.79      0.16      0.27       134\n",
      "           2       0.58      0.41      0.48       140\n",
      "           3       0.58      0.46      0.51       135\n",
      "           4       0.60      0.63      0.61       142\n",
      "           5       0.61      0.49      0.55       142\n",
      "           6       0.59      0.87      0.70       141\n",
      "           7       0.61      0.18      0.28       149\n",
      "           8       0.57      0.62      0.59       145\n",
      "           9       0.52      0.77      0.62       128\n",
      "          10       0.40      0.45      0.43       869\n",
      "\n",
      "    accuracy                           0.50      2261\n",
      "   macro avg       0.58      0.53      0.52      2261\n",
      "weighted avg       0.53      0.50      0.49      2261\n",
      "\n",
      "Logger {'time': {0: 0.0231781005859375, 100: 0.67742919921875, 200: 1.3688058853149414, 300: 1.9260969161987305, 400: 2.452458143234253, 500: 3.055788993835449, 600: 3.6005971431732178, 700: 4.145096063613892, 800: 4.75062108039856, 900: 5.367692947387695, 1000: 5.896520137786865, 1100: 6.612389087677002, 1200: 7.28435492515564, 1300: 8.162293195724487, 1400: 8.691538095474243, 1500: 9.693768978118896, 1600: 10.253998041152954, 1700: 10.834497928619385, 1800: 11.413615942001343, 1900: 12.652375936508179, 2000: 13.192993879318237, 2100: 13.754294157028198, 2200: 14.252569913864136, 2300: 14.769372940063477, 2400: 15.281134843826294, 2500: 15.813410997390747, 2600: 16.314182996749878, 2700: 16.864568948745728, 2800: 17.374989986419678, 2900: 17.906702995300293, 3000: 18.40270495414734, 3100: 18.914220809936523, 3200: 19.409389972686768, 3300: 19.933104038238525, 3400: 20.47202205657959, 3500: 21.00330090522766, 3600: 21.571923971176147, 3700: 22.091408014297485, 3800: 22.588943004608154, 3900: 23.099913120269775, 4000: 23.600441932678223, 4100: 24.10456895828247, 4200: 24.75609302520752, 4300: 25.47226309776306, 4400: 25.988086938858032, 4500: 26.54385805130005}, 'loss': {0: 2.8571696281433105, 100: 0.6446766257286072, 200: 0.7999229431152344, 300: 2.1491386890411377, 400: 0.21199294924736023, 500: 1.0512207746505737, 600: 0.7051018476486206, 700: 1.3947190046310425, 800: 1.8280739784240723, 900: 1.8330934047698975, 1000: 2.188516616821289, 1100: 0.9264332056045532, 1200: 1.5421558618545532, 1300: 0.7111200094223022, 1400: 0.9967502951622009, 1500: 0.9432687163352966, 1600: 1.4198346138000488, 1700: 0.24334849417209625, 1800: 1.5406250953674316, 1900: 0.8275817036628723, 2000: 0.9369602203369141, 2100: 0.6398221850395203, 2200: 0.12528209388256073, 2300: 0.9955736994743347, 2400: 0.345272421836853, 2500: 0.7623303532600403, 2600: 4.56573486328125, 2700: 0.9412151575088501, 2800: 0.5335782170295715, 2900: 2.1901566982269287, 3000: 0.4281626343727112, 3100: 0.687027633190155, 3200: 0.9193974733352661, 3300: 0.5910869240760803, 3400: 0.3163180947303772, 3500: 0.12318349629640579, 3600: 0.9689498543739319, 3700: 1.6429764032363892, 3800: 0.7683461904525757, 3900: 0.5376831293106079, 4000: 0.24584197998046875, 4100: 0.691627562046051, 4200: 1.0701137781143188, 4300: 0.4812365770339966, 4400: 1.191954493522644, 4500: 0.5555850863456726}, 'F1': {6: 0.5191870933633417}, 'Accuracy': {6: 0.5033171163202123}}\n",
      "Epoch 7\n",
      "\n",
      "Epoch time: 26.62394094467163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       136\n",
      "           1       0.65      0.35      0.46       134\n",
      "           2       0.63      0.48      0.54       140\n",
      "           3       0.56      0.59      0.57       135\n",
      "           4       0.64      0.69      0.66       142\n",
      "           5       0.54      0.77      0.64       142\n",
      "           6       0.61      0.79      0.69       141\n",
      "           7       0.67      0.19      0.30       149\n",
      "           8       0.58      0.63      0.61       145\n",
      "           9       0.54      0.65      0.59       128\n",
      "          10       0.41      0.40      0.40       869\n",
      "\n",
      "    accuracy                           0.52      2261\n",
      "   macro avg       0.58      0.59      0.56      2261\n",
      "weighted avg       0.53      0.52      0.51      2261\n",
      "\n",
      "Logger {'time': {0: 0.007677793502807617, 100: 0.5122630596160889, 200: 1.011141061782837, 300: 1.5077989101409912, 400: 1.997122049331665, 500: 2.5083329677581787, 600: 3.005664825439453, 700: 3.514914035797119, 800: 4.008999824523926, 900: 4.554086685180664, 1000: 5.107348918914795, 1100: 5.680749893188477, 1200: 6.186008930206299, 1300: 6.769632816314697, 1400: 7.554325819015503, 1500: 8.425435066223145, 1600: 9.266841888427734, 1700: 9.82660984992981, 1800: 10.394750833511353, 1900: 10.916457891464233, 2000: 11.433847904205322, 2100: 11.960672855377197, 2200: 12.495468854904175, 2300: 13.081157922744751, 2400: 13.973023891448975, 2500: 14.640950918197632, 2600: 15.72353196144104, 2700: 16.43754005432129, 2800: 16.99530792236328, 2900: 17.637162923812866, 3000: 18.210100889205933, 3100: 18.71079993247986, 3200: 19.427951097488403, 3300: 19.94304609298706, 3400: 20.467732906341553, 3500: 20.956029891967773, 3600: 21.4737069606781, 3700: 21.96338987350464, 3800: 22.487014055252075, 3900: 22.987884998321533, 4000: 23.49556279182434, 4100: 23.982804775238037, 4200: 24.49277091026306, 4300: 25.033615112304688, 4400: 25.682859897613525, 4500: 26.393697023391724}, 'loss': {0: 1.3901875019073486, 100: 0.6947436928749084, 200: 0.4252815842628479, 300: 2.4195730686187744, 400: 0.217342346906662, 500: 0.8359742164611816, 600: 0.6495332717895508, 700: 1.3771300315856934, 800: 2.096667528152466, 900: 3.003033399581909, 1000: 1.4738490581512451, 1100: 1.1834726333618164, 1200: 0.9398476481437683, 1300: 0.749675989151001, 1400: 0.8949903249740601, 1500: 0.9768824577331543, 1600: 0.7963434457778931, 1700: 0.20450852811336517, 1800: 1.7847460508346558, 1900: 0.8493329882621765, 2000: 1.24018132686615, 2100: 0.3634633719921112, 2200: 0.1680970937013626, 2300: 0.5094524621963501, 2400: 0.2841305434703827, 2500: 0.8878281116485596, 2600: 5.179632663726807, 2700: 0.8963338136672974, 2800: 0.783551812171936, 2900: 0.8723533749580383, 3000: 0.12603789567947388, 3100: 1.2284529209136963, 3200: 1.4469881057739258, 3300: 0.44974562525749207, 3400: 0.3477931618690491, 3500: 0.22436313331127167, 3600: 0.585380494594574, 3700: 1.2031782865524292, 3800: 0.9215628504753113, 3900: 0.5977783203125, 4000: 0.2987455725669861, 4100: 0.722108006477356, 4200: 0.9541282653808594, 4300: 0.7662617564201355, 4400: 0.845152735710144, 4500: 0.5278307199478149}, 'F1': {7: 0.5613592400270999}, 'Accuracy': {7: 0.5236620964175144}}\n",
      "Epoch 8\n",
      "\n",
      "Epoch time: 27.51789164543152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       136\n",
      "           1       0.60      0.61      0.61       134\n",
      "           2       0.57      0.71      0.63       140\n",
      "           3       0.59      0.61      0.60       135\n",
      "           4       0.60      0.74      0.66       142\n",
      "           5       0.56      0.73      0.63       142\n",
      "           6       0.59      0.84      0.70       141\n",
      "           7       0.64      0.26      0.37       149\n",
      "           8       0.61      0.61      0.61       145\n",
      "           9       0.56      0.72      0.63       128\n",
      "          10       0.42      0.32      0.37       869\n",
      "\n",
      "    accuracy                           0.54      2261\n",
      "   macro avg       0.57      0.64      0.59      2261\n",
      "weighted avg       0.53      0.54      0.52      2261\n",
      "\n",
      "Logger {'time': {0: 0.006680011749267578, 100: 0.5427818298339844, 200: 1.057541847229004, 300: 1.562973976135254, 400: 2.10575795173645, 500: 2.652216911315918, 600: 3.176095962524414, 700: 3.681321859359741, 800: 4.1801698207855225, 900: 4.6826417446136475, 1000: 5.185338735580444, 1100: 5.770693778991699, 1200: 6.687023878097534, 1300: 7.260493993759155, 1400: 7.841639757156372, 1500: 8.470417737960815, 1600: 9.110208988189697, 1700: 9.770073652267456, 1800: 10.356405019760132, 1900: 10.986097812652588, 2000: 11.554663896560669, 2100: 12.275560855865479, 2200: 12.950344800949097, 2300: 13.675137042999268, 2400: 14.63294267654419, 2500: 15.161393880844116, 2600: 15.853615760803223, 2700: 16.583845853805542, 2800: 17.099854707717896, 2900: 17.62816095352173, 3000: 18.15506887435913, 3100: 18.672770023345947, 3200: 19.276533842086792, 3300: 19.886265754699707, 3400: 20.471303939819336, 3500: 21.095033884048462, 3600: 21.687134981155396, 3700: 22.35872197151184, 3800: 23.392749071121216, 3900: 24.10495376586914, 4000: 24.627550840377808, 4100: 25.182117700576782, 4200: 25.814444065093994, 4300: 26.33048176765442, 4400: 26.841234922409058, 4500: 27.36193299293518}, 'loss': {0: 2.7625157833099365, 100: 0.5543574690818787, 200: 0.8943290114402771, 300: 2.3784496784210205, 400: 0.37448251247406006, 500: 0.9880107641220093, 600: 0.7207757830619812, 700: 1.4622703790664673, 800: 1.5732197761535645, 900: 1.2614874839782715, 1000: 1.4350000619888306, 1100: 0.9273977875709534, 1200: 0.858724057674408, 1300: 1.5581003427505493, 1400: 0.7477644085884094, 1500: 1.105926275253296, 1600: 0.6334132552146912, 1700: 0.36694347858428955, 1800: 1.253930926322937, 1900: 0.6558505892753601, 2000: 1.6286386251449585, 2100: 0.4587482810020447, 2200: 0.05630435794591904, 2300: 0.7650423049926758, 2400: 0.2900470793247223, 2500: 1.1003084182739258, 2600: 5.598546504974365, 2700: 0.6595370769500732, 2800: 0.5844013094902039, 2900: 1.078269362449646, 3000: 0.138914555311203, 3100: 1.8304164409637451, 3200: 1.3697261810302734, 3300: 0.5431755781173706, 3400: 0.32965871691703796, 3500: 0.188927561044693, 3600: 1.346959114074707, 3700: 1.7124228477478027, 3800: 1.101657509803772, 3900: 0.41813090443611145, 4000: 0.2504575252532959, 4100: 1.136750340461731, 4200: 0.8924608826637268, 4300: 0.7619639039039612, 4400: 0.7895736694335938, 4500: 0.6024186611175537}, 'F1': {8: 0.5925364497722129}, 'Accuracy': {8: 0.5382574082264485}}\n",
      "Epoch 9\n",
      "\n",
      "Epoch time: 27.413169860839844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71       136\n",
      "           1       0.58      0.68      0.62       134\n",
      "           2       0.61      0.56      0.59       140\n",
      "           3       0.58      0.64      0.61       135\n",
      "           4       0.58      0.74      0.65       142\n",
      "           5       0.57      0.75      0.65       142\n",
      "           6       0.60      0.84      0.70       141\n",
      "           7       0.64      0.24      0.35       149\n",
      "           8       0.58      0.70      0.64       145\n",
      "           9       0.51      0.85      0.64       128\n",
      "          10       0.40      0.29      0.34       869\n",
      "\n",
      "    accuracy                           0.53      2261\n",
      "   macro avg       0.57      0.65      0.59      2261\n",
      "weighted avg       0.52      0.53      0.51      2261\n",
      "\n",
      "Logger {'time': {0: 0.005580902099609375, 100: 0.514685869216919, 200: 1.0645298957824707, 300: 1.7731478214263916, 400: 2.328065872192383, 500: 2.9102978706359863, 600: 3.483690023422241, 700: 4.121300935745239, 800: 5.130064010620117, 900: 5.82300877571106, 1000: 6.410297870635986, 1100: 7.158843994140625, 1200: 7.789158821105957, 1300: 8.486095905303955, 1400: 9.196934938430786, 1500: 10.06085205078125, 1600: 10.652023792266846, 1700: 11.175895929336548, 1800: 11.671893119812012, 1900: 12.191203832626343, 2000: 12.695786952972412, 2100: 13.259679079055786, 2200: 13.83434772491455, 2300: 14.377932786941528, 2400: 14.899406909942627, 2500: 15.416230916976929, 2600: 15.939626932144165, 2700: 16.478741884231567, 2800: 17.003598928451538, 2900: 17.557272911071777, 3000: 18.143754720687866, 3100: 18.85306978225708, 3200: 19.377596855163574, 3300: 19.89723777770996, 3400: 20.4002628326416, 3500: 21.17437982559204, 3600: 21.834846019744873, 3700: 22.539475917816162, 3800: 23.178385972976685, 3900: 23.702641010284424, 4000: 24.36785101890564, 4100: 24.948587894439697, 4200: 25.471035957336426, 4300: 26.003679990768433, 4400: 26.52369785308838, 4500: 27.22160005569458}, 'loss': {0: 1.4533722400665283, 100: 0.5592586398124695, 200: 0.6556309461593628, 300: 1.9677798748016357, 400: 0.3371608555316925, 500: 0.5708353519439697, 600: 0.757618248462677, 700: 1.3292806148529053, 800: 1.6780632734298706, 900: 1.7620552778244019, 1000: 1.0982284545898438, 1100: 0.6874799132347107, 1200: 1.8066973686218262, 1300: 0.731951117515564, 1400: 0.6389645934104919, 1500: 1.152855634689331, 1600: 0.5616380572319031, 1700: 0.188943549990654, 1800: 1.5012058019638062, 1900: 0.9293158650398254, 2000: 1.178737759590149, 2100: 0.3701539635658264, 2200: 0.1980138123035431, 2300: 0.8238673210144043, 2400: 0.42452383041381836, 2500: 1.209223747253418, 2600: 3.6443045139312744, 2700: 0.5729013085365295, 2800: 0.9970514178276062, 2900: 2.6867856979370117, 3000: 0.27196478843688965, 3100: 2.383472204208374, 3200: 1.221402645111084, 3300: 0.46755343675613403, 3400: 0.6318683624267578, 3500: 0.9222791790962219, 3600: 1.7254879474639893, 3700: 1.6178956031799316, 3800: 1.26045823097229, 3900: 0.7813746929168701, 4000: 0.33368104696273804, 4100: 0.8289409279823303, 4200: 1.0885136127471924, 4300: 0.5343101024627686, 4400: 0.6377145648002625, 4500: 0.5216642618179321}, 'F1': {9: 0.5893635922096933}, 'Accuracy': {9: 0.5298540468819106}}\n",
      "Epoch 10\n",
      "\n",
      "Epoch time: 24.88838791847229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       136\n",
      "           1       0.64      0.51      0.57       134\n",
      "           2       0.63      0.64      0.63       140\n",
      "           3       0.57      0.58      0.57       135\n",
      "           4       0.57      0.65      0.61       142\n",
      "           5       0.59      0.68      0.63       142\n",
      "           6       0.59      0.84      0.69       141\n",
      "           7       0.70      0.11      0.19       149\n",
      "           8       0.61      0.66      0.64       145\n",
      "           9       0.55      0.75      0.63       128\n",
      "          10       0.41      0.38      0.39       869\n",
      "\n",
      "    accuracy                           0.53      2261\n",
      "   macro avg       0.59      0.60      0.57      2261\n",
      "weighted avg       0.53      0.53      0.51      2261\n",
      "\n",
      "Logger {'time': {0: 0.006283998489379883, 100: 0.5375938415527344, 200: 1.0406761169433594, 300: 1.5540249347686768, 400: 2.052096128463745, 500: 2.5907649993896484, 600: 3.0915160179138184, 700: 3.5982558727264404, 800: 4.0966432094573975, 900: 4.7547619342803955, 1000: 5.412313222885132, 1100: 5.92690110206604, 1200: 6.454807996749878, 1300: 7.086976051330566, 1400: 7.593652009963989, 1500: 8.38004207611084, 1600: 9.096548080444336, 1700: 9.716667890548706, 1800: 10.24051308631897, 1900: 10.742748022079468, 2000: 11.259979963302612, 2100: 11.762140035629272, 2200: 12.268877029418945, 2300: 12.761720180511475, 2400: 13.275992155075073, 2500: 13.823731899261475, 2600: 14.586182832717896, 2700: 15.196317911148071, 2800: 15.885209798812866, 2900: 16.46481704711914, 3000: 17.05032992362976, 3100: 17.602177143096924, 3200: 18.13610005378723, 3300: 18.691639184951782, 3400: 19.19082283973694, 3500: 19.692366123199463, 3600: 20.19837498664856, 3700: 20.70776915550232, 3800: 21.2139790058136, 3900: 21.713890075683594, 4000: 22.21260905265808, 4100: 22.72512698173523, 4200: 23.239507913589478, 4300: 23.737030029296875, 4400: 24.249764919281006, 4500: 24.7426860332489}, 'loss': {0: 1.832619309425354, 100: 0.5097578763961792, 200: 0.5843878984451294, 300: 2.04105806350708, 400: 0.362676739692688, 500: 0.3815203607082367, 600: 0.7932190299034119, 700: 1.5112789869308472, 800: 1.5100611448287964, 900: 0.5054739117622375, 1000: 0.9779214859008789, 1100: 1.3327149152755737, 1200: 1.3428072929382324, 1300: 0.9010335803031921, 1400: 0.5596227645874023, 1500: 1.2406266927719116, 1600: 1.2464451789855957, 1700: 0.18678168952465057, 1800: 2.2496559619903564, 1900: 1.4413566589355469, 2000: 1.9250702857971191, 2100: 0.4144599735736847, 2200: 0.31427624821662903, 2300: 0.5171898007392883, 2400: 0.3170787990093231, 2500: 1.0233757495880127, 2600: 4.147807598114014, 2700: 0.5560267567634583, 2800: 0.870877206325531, 2900: 2.5041136741638184, 3000: 0.23882800340652466, 3100: 2.252232074737549, 3200: 1.3427627086639404, 3300: 0.7914255857467651, 3400: 0.3428606390953064, 3500: 0.093174509704113, 3600: 0.7414646744728088, 3700: 1.3978173732757568, 3800: 1.3059691190719604, 3900: 0.38803890347480774, 4000: 0.3590834140777588, 4100: 1.3533508777618408, 4200: 1.046586036682129, 4300: 0.620701253414154, 4400: 0.6487547755241394, 4500: 1.0459843873977661}, 'F1': {10: 0.569101449707168}, 'Accuracy': {10: 0.5289694825298541}}\n",
      "Training with dataset size: 10000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Epoch 1\n",
      "\n",
      "Epoch time: 52.33392691612244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.70       280\n",
      "           1       0.61      0.79      0.69       277\n",
      "           2       0.61      0.57      0.59       293\n",
      "           3       0.60      0.71      0.65       283\n",
      "           4       0.55      0.78      0.64       274\n",
      "           5       0.55      0.61      0.58       275\n",
      "           6       0.57      0.80      0.67       268\n",
      "           7       0.58      0.81      0.67       280\n",
      "           8       0.54      0.74      0.62       272\n",
      "           9       0.49      0.83      0.62       272\n",
      "          10       0.39      0.18      0.25      1757\n",
      "\n",
      "    accuracy                           0.53      4531\n",
      "   macro avg       0.55      0.70      0.61      4531\n",
      "weighted avg       0.50      0.53      0.49      4531\n",
      "\n",
      "Logger {'time': {0: 0.026654958724975586, 100: 0.5590531826019287, 200: 1.055988073348999, 300: 1.5350940227508545, 400: 2.0454931259155273, 500: 2.575279951095581, 600: 3.0789661407470703, 700: 3.5675809383392334, 800: 4.072298049926758, 900: 4.580089092254639, 1000: 5.0804150104522705, 1100: 5.631267070770264, 1200: 6.152827978134155, 1300: 6.650030136108398, 1400: 7.141036033630371, 1500: 7.619906187057495, 1600: 8.081757068634033, 1700: 8.642243146896362, 1800: 9.124749183654785, 1900: 9.796987056732178, 2000: 10.553376197814941, 2100: 11.047184944152832, 2200: 11.590992212295532, 2300: 12.220972061157227, 2400: 12.792805910110474, 2500: 13.412788152694702, 2600: 14.003576040267944, 2700: 14.580303192138672, 2800: 15.112075090408325, 2900: 15.676959037780762, 3000: 16.24394917488098, 3100: 17.06185030937195, 3200: 17.854498147964478, 3300: 18.450412034988403, 3400: 19.02700114250183, 3500: 19.685792207717896, 3600: 20.53037118911743, 3700: 21.413460969924927, 3800: 22.092281103134155, 3900: 22.784997940063477, 4000: 23.460578203201294, 4100: 24.108355045318604, 4200: 24.75439691543579, 4300: 25.415539026260376, 4400: 26.04598617553711, 4500: 26.772983074188232, 4600: 27.494445085525513, 4700: 28.14782214164734, 4800: 28.95086121559143, 4900: 29.567034244537354, 5000: 30.100184202194214, 5100: 30.60253596305847, 5200: 31.133742094039917, 5300: 31.69398307800293, 5400: 32.25005221366882, 5500: 32.83542990684509, 5600: 33.4067120552063, 5700: 33.994746923446655, 5800: 34.55871319770813, 5900: 35.09909510612488, 6000: 35.629749059677124, 6100: 36.13399004936218, 6200: 36.647634983062744, 6300: 37.17280316352844, 6400: 37.66883111000061, 6500: 38.243372201919556, 6600: 38.8504159450531, 6700: 39.409239053726196, 6800: 39.92342829704285, 6900: 40.477725982666016, 7000: 41.05730891227722, 7100: 41.64540505409241, 7200: 42.18772315979004, 7300: 42.71941113471985, 7400: 43.27991819381714, 7500: 43.86096000671387, 7600: 44.48876214027405, 7700: 45.0391891002655, 7800: 45.61483407020569, 7900: 46.12018799781799, 8000: 46.66847205162048, 8100: 47.146470069885254, 8200: 47.64979910850525, 8300: 48.16501712799072, 8400: 48.68200612068176, 8500: 49.19151711463928, 8600: 49.707563161849976, 8700: 50.24449706077576, 8800: 50.7417471408844, 8900: 51.26632618904114, 9000: 51.85925626754761}, 'loss': {0: 4.5537638664245605, 100: 0.6217858195304871, 200: 1.4675579071044922, 300: 0.539139449596405, 400: 1.0467448234558105, 500: 3.115494966506958, 600: 1.6327723264694214, 700: 0.14982391893863678, 800: 2.542248487472534, 900: 0.5409665703773499, 1000: 0.4567424952983856, 1100: 4.495481491088867, 1200: 0.737966001033783, 1300: 0.44839730858802795, 1400: 1.159963846206665, 1500: 0.20466580986976624, 1600: 1.476233959197998, 1700: 1.4638416767120361, 1800: 5.84174108505249, 1900: 1.2203974723815918, 2000: 1.1405017375946045, 2100: 1.6589617729187012, 2200: 2.043272018432617, 2300: 1.371005654335022, 2400: 0.781484842300415, 2500: 1.2331534624099731, 2600: 1.42988920211792, 2700: 1.3548624515533447, 2800: 0.34516453742980957, 2900: 1.4768633842468262, 3000: 0.4373127818107605, 3100: 3.977012872695923, 3200: 0.9027520418167114, 3300: 0.305754154920578, 3400: 3.0095889568328857, 3500: 2.025237798690796, 3600: 0.7916570901870728, 3700: 2.4124441146850586, 3800: 0.8727487325668335, 3900: 0.6469184756278992, 4000: 0.3585551679134369, 4100: 0.9102193117141724, 4200: 0.5306968688964844, 4300: 1.1809788942337036, 4400: 0.8590269088745117, 4500: 0.7830696105957031, 4600: 0.45960748195648193, 4700: 2.2617292404174805, 4800: 0.7533377408981323, 4900: 0.5331509113311768, 5000: 0.9388784170150757, 5100: 6.337549209594727, 5200: 0.13971921801567078, 5300: 0.36722615361213684, 5400: 0.515572190284729, 5500: 4.007978916168213, 5600: 0.5615139007568359, 5700: 0.8872417211532593, 5800: 1.0715965032577515, 5900: 0.5153723359107971, 6000: 0.33999714255332947, 6100: 0.9065454602241516, 6200: 1.0490155220031738, 6300: 0.2816029489040375, 6400: 0.3489801287651062, 6500: 0.3804742395877838, 6600: 0.29692596197128296, 6700: 1.961191177368164, 6800: 2.768920421600342, 6900: 0.3635038137435913, 7000: 0.5661031603813171, 7100: 0.44718924164772034, 7200: 0.807532012462616, 7300: 10.579634666442871, 7400: 0.3736056685447693, 7500: 1.1882891654968262, 7600: 0.5584419369697571, 7700: 0.7321719527244568, 7800: 1.0135915279388428, 7900: 1.4451491832733154, 8000: 0.30711475014686584, 8100: 1.2880887985229492, 8200: 0.40531665086746216, 8300: 1.378279209136963, 8400: 0.44127586483955383, 8500: 0.333915650844574, 8600: 0.1802855134010315, 8700: 1.591182827949524, 8800: 1.1692014932632446, 8900: 0.6526460647583008, 9000: 0.858493447303772}, 'F1': {1: 0.6056928452961622}, 'Accuracy': {1: 0.5305672037077908}}\n",
      "Epoch 2\n",
      "\n",
      "Epoch time: 52.50790810585022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       280\n",
      "           1       0.61      0.77      0.68       277\n",
      "           2       0.61      0.63      0.62       293\n",
      "           3       0.64      0.52      0.57       283\n",
      "           4       0.55      0.80      0.65       274\n",
      "           5       0.53      0.58      0.55       275\n",
      "           6       0.55      0.86      0.67       268\n",
      "           7       0.56      0.82      0.66       280\n",
      "           8       0.55      0.75      0.64       272\n",
      "           9       0.51      0.79      0.62       272\n",
      "          10       0.41      0.21      0.28      1757\n",
      "\n",
      "    accuracy                           0.54      4531\n",
      "   macro avg       0.56      0.69      0.61      4531\n",
      "weighted avg       0.51      0.54      0.50      4531\n",
      "\n",
      "Logger {'time': {0: 0.005816936492919922, 100: 0.5555839538574219, 200: 1.0536010265350342, 300: 1.5511119365692139, 400: 2.0621519088745117, 500: 2.575978994369507, 600: 3.0860979557037354, 700: 3.5950677394866943, 800: 4.085367918014526, 900: 4.606310844421387, 1000: 5.098341941833496, 1100: 5.607501029968262, 1200: 6.093583106994629, 1300: 6.611652135848999, 1400: 7.1135029792785645, 1500: 7.633086919784546, 1600: 8.158309936523438, 1700: 8.695116996765137, 1800: 9.273613929748535, 1900: 9.861605167388916, 2000: 10.472440958023071, 2100: 11.034024000167847, 2200: 11.63764500617981, 2300: 12.18244194984436, 2400: 13.208236932754517, 2500: 13.695019006729126, 2600: 14.390653848648071, 2700: 14.923074960708618, 2800: 15.483414888381958, 2900: 16.07487678527832, 3000: 16.617427825927734, 3100: 17.192593812942505, 3200: 17.79827308654785, 3300: 18.45418381690979, 3400: 19.07342004776001, 3500: 19.64132809638977, 3600: 20.170356035232544, 3700: 20.70963406562805, 3800: 21.20675492286682, 3900: 21.756114959716797, 4000: 22.324604988098145, 4100: 22.952527046203613, 4200: 23.506224870681763, 4300: 24.19400691986084, 4400: 24.889477014541626, 4500: 25.987158060073853, 4600: 27.325700998306274, 4700: 28.006045818328857, 4800: 28.700512886047363, 4900: 29.465874910354614, 5000: 29.993485927581787, 5100: 30.52350401878357, 5200: 31.087244033813477, 5300: 31.637187957763672, 5400: 32.193403005599976, 5500: 32.74358296394348, 5600: 33.262913942337036, 5700: 33.78086304664612, 5800: 34.29844403266907, 5900: 34.82027292251587, 6000: 35.34203290939331, 6100: 35.852489948272705, 6200: 36.369844913482666, 6300: 36.93015503883362, 6400: 37.48195195198059, 6500: 38.011914014816284, 6600: 38.53809094429016, 6700: 39.08964705467224, 6800: 39.625962018966675, 6900: 40.42240881919861, 7000: 40.982975006103516, 7100: 41.49982786178589, 7200: 42.10464406013489, 7300: 42.626460790634155, 7400: 43.15632510185242, 7500: 43.68694710731506, 7600: 44.20473909378052, 7700: 44.708954095840454, 7800: 45.342682123184204, 7900: 45.886059045791626, 8000: 46.442911863327026, 8100: 46.980496883392334, 8200: 47.49615788459778, 8300: 48.05769896507263, 8400: 48.621357917785645, 8500: 49.189873933792114, 8600: 49.797096967697144, 8700: 50.31316876411438, 8800: 50.86473083496094, 8900: 51.45151209831238, 9000: 52.02618193626404}, 'loss': {0: 2.8109076023101807, 100: 1.0625739097595215, 200: 1.398810625076294, 300: 0.25574395060539246, 400: 1.6560595035552979, 500: 1.718920350074768, 600: 1.9736292362213135, 700: 0.2110876739025116, 800: 2.145711660385132, 900: 0.9533278346061707, 1000: 0.5094470381736755, 1100: 4.539966106414795, 1200: 0.8258999586105347, 1300: 0.31412702798843384, 1400: 1.6424347162246704, 1500: 0.5398436784744263, 1600: 1.0273053646087646, 1700: 2.716092824935913, 1800: 5.02696418762207, 1900: 1.3382186889648438, 2000: 2.285405158996582, 2100: 0.5156917572021484, 2200: 2.027707815170288, 2300: 0.41532382369041443, 2400: 1.1330857276916504, 2500: 1.438970685005188, 2600: 1.4263262748718262, 2700: 2.4673192501068115, 2800: 0.5671474933624268, 2900: 1.6628459692001343, 3000: 0.6071974635124207, 3100: 1.827895998954773, 3200: 0.9777247309684753, 3300: 0.4714016020298004, 3400: 1.223714828491211, 3500: 1.7402818202972412, 3600: 0.6181125640869141, 3700: 1.8576796054840088, 3800: 0.727476954460144, 3900: 0.7884663343429565, 4000: 0.516512930393219, 4100: 0.4833536446094513, 4200: 0.32870134711265564, 4300: 1.1967190504074097, 4400: 1.0035881996154785, 4500: 0.4354475438594818, 4600: 0.30542466044425964, 4700: 1.328432559967041, 4800: 0.6682724356651306, 4900: 0.47522372007369995, 5000: 0.8010126352310181, 5100: 6.683356761932373, 5200: 0.1972706913948059, 5300: 0.5215358138084412, 5400: 0.8008676767349243, 5500: 2.122130870819092, 5600: 1.0178093910217285, 5700: 0.6169238090515137, 5800: 0.9191234111785889, 5900: 0.5686927437782288, 6000: 0.5598123669624329, 6100: 0.6674897074699402, 6200: 0.6017659902572632, 6300: 0.5489934682846069, 6400: 0.6436595916748047, 6500: 0.3133322298526764, 6600: 0.39194801449775696, 6700: 1.4393696784973145, 6800: 2.927091121673584, 6900: 0.6810798645019531, 7000: 0.506039023399353, 7100: 0.4116811752319336, 7200: 0.6021345853805542, 7300: 9.157779693603516, 7400: 0.596638560295105, 7500: 1.3344368934631348, 7600: 0.4269222617149353, 7700: 0.5066977739334106, 7800: 0.4058225154876709, 7900: 0.9937295317649841, 8000: 0.2381712645292282, 8100: 0.7424678206443787, 8200: 0.33080369234085083, 8300: 1.9857717752456665, 8400: 0.4722555875778198, 8500: 0.35207200050354004, 8600: 0.32029470801353455, 8700: 1.6662293672561646, 8800: 1.2178256511688232, 8900: 1.0207308530807495, 9000: 0.8296693563461304}, 'F1': {2: 0.6067240176668389}, 'Accuracy': {2: 0.5354226440079453}}\n",
      "Epoch 3\n",
      "\n",
      "Epoch time: 54.38919806480408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.71       280\n",
      "           1       0.62      0.77      0.69       277\n",
      "           2       0.62      0.61      0.61       293\n",
      "           3       0.62      0.58      0.60       283\n",
      "           4       0.55      0.76      0.64       274\n",
      "           5       0.48      0.76      0.59       275\n",
      "           6       0.58      0.80      0.68       268\n",
      "           7       0.57      0.82      0.68       280\n",
      "           8       0.53      0.74      0.62       272\n",
      "           9       0.52      0.81      0.63       272\n",
      "          10       0.39      0.18      0.25      1757\n",
      "\n",
      "    accuracy                           0.53      4531\n",
      "   macro avg       0.55      0.70      0.61      4531\n",
      "weighted avg       0.50      0.53      0.49      4531\n",
      "\n",
      "Logger {'time': {0: 0.010281085968017578, 100: 0.6712892055511475, 200: 1.4617102146148682, 300: 2.1257591247558594, 400: 2.8202850818634033, 500: 3.5042083263397217, 600: 4.192106008529663, 700: 4.876215219497681, 800: 5.575338125228882, 900: 6.261559247970581, 1000: 6.856157064437866, 1100: 7.501059293746948, 1200: 8.181227207183838, 1300: 8.855922937393188, 1400: 9.468498945236206, 1500: 10.176167011260986, 1600: 10.87830924987793, 1700: 11.566500186920166, 1800: 12.27860713005066, 1900: 12.957386016845703, 2000: 13.556814193725586, 2100: 14.08589506149292, 2200: 14.624104022979736, 2300: 15.154920101165771, 2400: 15.689427137374878, 2500: 16.21861720085144, 2600: 16.803596019744873, 2700: 17.424278020858765, 2800: 18.178574085235596, 2900: 18.866322994232178, 3000: 19.54221510887146, 3100: 20.156086206436157, 3200: 20.806763172149658, 3300: 21.44827699661255, 3400: 22.123828172683716, 3500: 22.81493306159973, 3600: 23.401539087295532, 3700: 24.001028299331665, 3800: 24.77484703063965, 3900: 25.466772079467773, 4000: 25.98685121536255, 4100: 26.575372219085693, 4200: 27.191052198410034, 4300: 27.819533109664917, 4400: 28.35667324066162, 4500: 29.045783042907715, 4600: 29.72273015975952, 4700: 30.33340334892273, 4800: 30.91134524345398, 4900: 31.53718113899231, 5000: 32.087780237197876, 5100: 32.7034592628479, 5200: 33.36036992073059, 5300: 33.944807052612305, 5400: 34.55037021636963, 5500: 35.10633826255798, 5600: 35.665032148361206, 5700: 36.16940498352051, 5800: 36.684171199798584, 5900: 37.201290130615234, 6000: 37.71614217758179, 6100: 38.2338182926178, 6200: 38.74341917037964, 6300: 39.2356071472168, 6400: 39.73333930969238, 6500: 40.25808525085449, 6600: 40.76278305053711, 6700: 41.27163124084473, 6800: 41.793222188949585, 6900: 42.3103301525116, 7000: 42.83684301376343, 7100: 43.447646141052246, 7200: 44.06401515007019, 7300: 44.68237900733948, 7400: 45.252944231033325, 7500: 45.76444602012634, 7600: 46.29644513130188, 7700: 46.79888319969177, 7800: 47.34407305717468, 7900: 47.85510516166687, 8000: 48.434911012649536, 8100: 49.02204704284668, 8200: 49.64934706687927, 8300: 50.236135959625244, 8400: 50.86909317970276, 8500: 51.38371515274048, 8600: 51.91199016571045, 8700: 52.410102128982544, 8800: 52.9268741607666, 8900: 53.45964813232422, 9000: 53.97019910812378}, 'loss': {0: 3.8797519207000732, 100: 0.7710258364677429, 200: 1.330838680267334, 300: 0.4264485239982605, 400: 1.6356196403503418, 500: 1.7281904220581055, 600: 1.3902173042297363, 700: 0.3576424717903137, 800: 1.5568674802780151, 900: 0.5941466093063354, 1000: 0.614997148513794, 1100: 4.060079097747803, 1200: 0.7971388101577759, 1300: 0.2805904746055603, 1400: 1.899662733078003, 1500: 0.6705974340438843, 1600: 1.8024524450302124, 1700: 1.7927377223968506, 1800: 4.188896656036377, 1900: 1.3732521533966064, 2000: 0.8632540106773376, 2100: 0.5885612368583679, 2200: 1.555017352104187, 2300: 0.4411575496196747, 2400: 1.2077345848083496, 2500: 1.0246975421905518, 2600: 1.517547607421875, 2700: 1.8051292896270752, 2800: 0.46506303548812866, 2900: 2.7153639793395996, 3000: 0.7373475432395935, 3100: 0.48435232043266296, 3200: 0.9112287163734436, 3300: 0.6578013896942139, 3400: 2.5200090408325195, 3500: 1.509751796722412, 3600: 0.8061029314994812, 3700: 1.7647430896759033, 3800: 0.5830714106559753, 3900: 0.4445694088935852, 4000: 0.5775179862976074, 4100: 0.3552965521812439, 4200: 1.0258846282958984, 4300: 0.9590651392936707, 4400: 1.0608274936676025, 4500: 0.3933064639568329, 4600: 0.556627094745636, 4700: 1.1927690505981445, 4800: 0.6702119708061218, 4900: 0.5259912610054016, 5000: 0.4100535809993744, 5100: 5.9944562911987305, 5200: 0.47768548130989075, 5300: 0.34312668442726135, 5400: 0.49547290802001953, 5500: 1.5031609535217285, 5600: 0.45983466506004333, 5700: 0.4600033462047577, 5800: 0.3725655972957611, 5900: 1.5894672870635986, 6000: 0.6003645062446594, 6100: 1.274865984916687, 6200: 1.9777849912643433, 6300: 0.5876771211624146, 6400: 0.7477288246154785, 6500: 0.23253940045833588, 6600: 0.3034866452217102, 6700: 1.0378787517547607, 6800: 1.8623379468917847, 6900: 0.2061825692653656, 7000: 0.5954753160476685, 7100: 0.5313020348548889, 7200: 0.5793538689613342, 7300: 9.938272476196289, 7400: 0.3060498535633087, 7500: 1.8816972970962524, 7600: 0.26440146565437317, 7700: 0.6804301738739014, 7800: 0.7205313444137573, 7900: 1.0196433067321777, 8000: 0.6407743096351624, 8100: 0.8018143773078918, 8200: 0.5328072309494019, 8300: 1.1085865497589111, 8400: 0.3058120012283325, 8500: 0.36881428956985474, 8600: 0.2041778266429901, 8700: 1.2053699493408203, 8800: 1.532404899597168, 8900: 0.624238908290863, 9000: 0.7377679944038391}, 'F1': {3: 0.6072902913949494}, 'Accuracy': {3: 0.531891414698742}}\n",
      "Epoch 4\n",
      "\n",
      "Epoch time: 48.999366760253906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70       280\n",
      "           1       0.60      0.82      0.70       277\n",
      "           2       0.63      0.65      0.64       293\n",
      "           3       0.60      0.64      0.62       283\n",
      "           4       0.57      0.82      0.67       274\n",
      "           5       0.53      0.67      0.59       275\n",
      "           6       0.58      0.84      0.68       268\n",
      "           7       0.59      0.88      0.70       280\n",
      "           8       0.50      0.80      0.62       272\n",
      "           9       0.51      0.80      0.63       272\n",
      "          10       0.39      0.15      0.22      1757\n",
      "\n",
      "    accuracy                           0.54      4531\n",
      "   macro avg       0.55      0.73      0.61      4531\n",
      "weighted avg       0.50      0.54      0.48      4531\n",
      "\n",
      "Logger {'time': {0: 0.010280847549438477, 100: 0.6291110515594482, 200: 1.1438567638397217, 300: 1.7935817241668701, 400: 2.436325788497925, 500: 3.0914857387542725, 600: 3.773313045501709, 700: 4.385534763336182, 800: 4.903564691543579, 900: 5.442359685897827, 1000: 6.056319952011108, 1100: 6.669902801513672, 1200: 7.172797918319702, 1300: 7.747835874557495, 1400: 8.360185861587524, 1500: 9.037532806396484, 1600: 9.573372840881348, 1700: 10.076071739196777, 1800: 10.709767818450928, 1900: 11.419387817382812, 2000: 11.983714818954468, 2100: 12.535623788833618, 2200: 13.13840103149414, 2300: 13.758981704711914, 2400: 14.300779819488525, 2500: 14.792987823486328, 2600: 15.302090883255005, 2700: 15.79834270477295, 2800: 16.31583571434021, 2900: 16.806753873825073, 3000: 17.330566883087158, 3100: 17.833330869674683, 3200: 18.35692596435547, 3300: 18.83965277671814, 3400: 19.369861841201782, 3500: 19.875662803649902, 3600: 20.411325931549072, 3700: 20.917682886123657, 3800: 21.44170880317688, 3900: 21.935504913330078, 4000: 22.460362911224365, 4100: 22.97236394882202, 4200: 23.50291872024536, 4300: 24.053258895874023, 4400: 24.568609952926636, 4500: 25.05813980102539, 4600: 25.568557739257812, 4700: 26.084401845932007, 4800: 26.583886861801147, 4900: 27.09161067008972, 5000: 27.6000497341156, 5100: 28.116553783416748, 5200: 28.639001846313477, 5300: 29.157713890075684, 5400: 29.649191856384277, 5500: 30.167473793029785, 5600: 30.668153762817383, 5700: 31.1953547000885, 5800: 31.685171842575073, 5900: 32.20260572433472, 6000: 32.700289726257324, 6100: 33.21051383018494, 6200: 33.71724891662598, 6300: 34.227614879608154, 6400: 34.72671890258789, 6500: 35.23483085632324, 6600: 35.73231887817383, 6700: 36.248700857162476, 6800: 36.75443363189697, 6900: 37.26752591133118, 7000: 37.77991485595703, 7100: 38.27561283111572, 7200: 38.779296875, 7300: 39.28107786178589, 7400: 39.7888457775116, 7500: 40.291372776031494, 7600: 40.80689573287964, 7700: 41.306392669677734, 7800: 41.83018374443054, 7900: 42.35274863243103, 8000: 42.86233377456665, 8100: 43.432642698287964, 8200: 43.95761585235596, 8300: 44.47276592254639, 8400: 45.091219902038574, 8500: 45.66280174255371, 8600: 46.31853270530701, 8700: 46.899996757507324, 8800: 47.485148906707764, 8900: 48.04611086845398, 9000: 48.59371280670166}, 'loss': {0: 3.6572206020355225, 100: 0.7126653790473938, 200: 1.3908867835998535, 300: 0.4364627003669739, 400: 1.8104422092437744, 500: 1.287110686302185, 600: 1.049926996231079, 700: 0.4577011168003082, 800: 1.7731257677078247, 900: 0.941114604473114, 1000: 0.5184585452079773, 1100: 4.375426292419434, 1200: 0.7327380180358887, 1300: 0.2476108819246292, 1400: 1.7046340703964233, 1500: 0.4151781499385834, 1600: 1.7471622228622437, 1700: 1.384284496307373, 1800: 4.594808578491211, 1900: 1.2345248460769653, 2000: 0.2213754951953888, 2100: 0.9313887357711792, 2200: 1.983124017715454, 2300: 0.2471952736377716, 2400: 1.3417309522628784, 2500: 1.5741188526153564, 2600: 1.4153207540512085, 2700: 3.632045030593872, 2800: 0.6191700100898743, 2900: 1.4122767448425293, 3000: 0.4554227292537689, 3100: 0.2838437557220459, 3200: 1.1788864135742188, 3300: 0.9092721343040466, 3400: 2.830005645751953, 3500: 1.6129002571105957, 3600: 0.5320820212364197, 3700: 0.3518403470516205, 3800: 0.6332247853279114, 3900: 0.6970319151878357, 4000: 0.320066899061203, 4100: 0.3613530397415161, 4200: 0.5413336157798767, 4300: 0.7850435376167297, 4400: 0.7079830169677734, 4500: 0.4993683397769928, 4600: 0.41726118326187134, 4700: 1.0194082260131836, 4800: 0.7109603881835938, 4900: 0.562907874584198, 5000: 0.42620348930358887, 5100: 10.538721084594727, 5200: 0.07508143782615662, 5300: 0.6567711234092712, 5400: 0.3762451112270355, 5500: 1.0545365810394287, 5600: 0.8549901247024536, 5700: 0.3865555226802826, 5800: 0.8209757804870605, 5900: 0.4167952537536621, 6000: 0.4520663321018219, 6100: 0.9067288637161255, 6200: 1.8982654809951782, 6300: 0.6386723518371582, 6400: 0.5349113941192627, 6500: 0.2614131271839142, 6600: 0.39072534441947937, 6700: 2.4711756706237793, 6800: 2.8291001319885254, 6900: 0.1330142468214035, 7000: 0.6422677040100098, 7100: 0.5207638144493103, 7200: 0.6164534687995911, 7300: 9.566198348999023, 7400: 0.38683807849884033, 7500: 2.1155426502227783, 7600: 0.46501609683036804, 7700: 0.697847843170166, 7800: 0.7229390740394592, 7900: 1.1446222066879272, 8000: 0.8058356046676636, 8100: 1.0619062185287476, 8200: 1.1018496751785278, 8300: 0.9295246601104736, 8400: 0.23668065667152405, 8500: 0.6671618819236755, 8600: 0.19129738211631775, 8700: 1.1777195930480957, 8800: 1.4390789270401, 8900: 0.44351089000701904, 9000: 0.7855668067932129}, 'F1': {4: 0.6142563854159262}, 'Accuracy': {4: 0.5376296623261974}}\n",
      "Epoch 5\n",
      "\n",
      "Epoch time: 52.55214524269104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.92      0.65       280\n",
      "           1       0.51      0.22      0.30       277\n",
      "           2       0.63      0.60      0.61       293\n",
      "           3       0.58      0.49      0.54       283\n",
      "           4       0.54      0.90      0.67       274\n",
      "           5       0.50      0.57      0.53       275\n",
      "           6       0.56      0.85      0.68       268\n",
      "           7       0.59      0.81      0.68       280\n",
      "           8       0.56      0.75      0.64       272\n",
      "           9       0.51      0.85      0.64       272\n",
      "          10       0.39      0.22      0.28      1757\n",
      "\n",
      "    accuracy                           0.51      4531\n",
      "   macro avg       0.53      0.65      0.57      4531\n",
      "weighted avg       0.49      0.51      0.47      4531\n",
      "\n",
      "Logger {'time': {0: 0.024341106414794922, 100: 0.5945720672607422, 200: 1.1285791397094727, 300: 1.63863205909729, 400: 2.189268112182617, 500: 2.6994099617004395, 600: 3.1946611404418945, 700: 3.716978073120117, 800: 4.21680212020874, 900: 4.728870153427124, 1000: 5.245573282241821, 1100: 5.739808082580566, 1200: 6.25408411026001, 1300: 6.755185127258301, 1400: 7.261604070663452, 1500: 7.7615580558776855, 1600: 8.278364896774292, 1700: 8.792720079421997, 1800: 9.303637027740479, 1900: 9.81230902671814, 2000: 10.330928087234497, 2100: 10.824499130249023, 2200: 11.381479978561401, 2300: 11.950273036956787, 2400: 12.571716070175171, 2500: 13.611912965774536, 2600: 14.241408109664917, 2700: 14.84547209739685, 2800: 15.793162107467651, 2900: 16.54657220840454, 3000: 17.14572310447693, 3100: 17.87373423576355, 3200: 18.63674020767212, 3300: 19.16744112968445, 3400: 19.927524089813232, 3500: 20.580063104629517, 3600: 21.151741981506348, 3700: 21.72921109199524, 3800: 22.387260913848877, 3900: 22.877207040786743, 4000: 23.412631034851074, 4100: 23.925352096557617, 4200: 24.5171000957489, 4300: 25.06705904006958, 4400: 25.64113211631775, 4500: 26.166445016860962, 4600: 26.755195140838623, 4700: 27.340925931930542, 4800: 27.96968412399292, 4900: 28.516927003860474, 5000: 29.0519540309906, 5100: 29.59726595878601, 5200: 30.283278226852417, 5300: 30.795100927352905, 5400: 31.286823272705078, 5500: 31.807781219482422, 5600: 32.512280225753784, 5700: 33.06395125389099, 5800: 33.559192180633545, 5900: 34.07439708709717, 6000: 34.60205793380737, 6100: 35.114513874053955, 6200: 35.74705100059509, 6300: 36.25073528289795, 6400: 36.762686014175415, 6500: 37.52815914154053, 6600: 38.178497076034546, 6700: 38.74307298660278, 6800: 39.264156341552734, 6900: 39.93428611755371, 7000: 40.582123041152954, 7100: 41.103461265563965, 7200: 41.68378806114197, 7300: 42.20234513282776, 7400: 42.717347145080566, 7500: 43.20356297492981, 7600: 43.854877948760986, 7700: 44.42597508430481, 7800: 45.06284809112549, 7900: 45.79422116279602, 8000: 46.47299933433533, 8100: 46.994649171829224, 8200: 47.50068521499634, 8300: 47.998023986816406, 8400: 48.50107717514038, 8500: 49.007275104522705, 8600: 49.506585121154785, 8700: 50.08344030380249, 8800: 50.59068489074707, 8900: 51.28866410255432, 9000: 52.011991024017334}, 'loss': {0: 4.14634370803833, 100: 1.0834715366363525, 200: 1.6797130107879639, 300: 0.2759709358215332, 400: 1.0600576400756836, 500: 1.1610071659088135, 600: 1.6983778476715088, 700: 0.2883894145488739, 800: 1.7696504592895508, 900: 0.640129804611206, 1000: 0.5574477910995483, 1100: 3.510948657989502, 1200: 0.7066832780838013, 1300: 0.43295273184776306, 1400: 1.308471918106079, 1500: 0.320650577545166, 1600: 1.449354648590088, 1700: 0.8030024766921997, 1800: 5.281711578369141, 1900: 1.055352807044983, 2000: 0.8052526712417603, 2100: 0.4422706365585327, 2200: 1.4932684898376465, 2300: 0.3556046187877655, 2400: 1.1710034608840942, 2500: 1.3714693784713745, 2600: 1.3606609106063843, 2700: 2.9054362773895264, 2800: 0.4287637770175934, 2900: 1.3812674283981323, 3000: 0.6309025287628174, 3100: 0.36230790615081787, 3200: 1.0814852714538574, 3300: 0.8133119344711304, 3400: 0.9802832007408142, 3500: 0.8834835886955261, 3600: 0.4475439488887787, 3700: 0.5022764801979065, 3800: 0.6562818884849548, 3900: 0.7218775153160095, 4000: 0.2644471228122711, 4100: 0.2749822735786438, 4200: 0.9058821201324463, 4300: 0.7776286602020264, 4400: 1.0633494853973389, 4500: 0.2422076314687729, 4600: 0.3982841372489929, 4700: 1.433157205581665, 4800: 0.6001402139663696, 4900: 0.42960476875305176, 5000: 0.47503671050071716, 5100: 7.143101692199707, 5200: 0.12667696177959442, 5300: 0.6076770424842834, 5400: 0.5506869554519653, 5500: 1.8245373964309692, 5600: 0.7718521356582642, 5700: 0.7437908053398132, 5800: 0.7155271172523499, 5900: 1.3286190032958984, 6000: 0.28453898429870605, 6100: 0.6069241166114807, 6200: 0.38553932309150696, 6300: 0.7370655536651611, 6400: 0.9648423790931702, 6500: 0.27719151973724365, 6600: 0.3950676918029785, 6700: 2.05674147605896, 6800: 1.710813045501709, 6900: 0.8746739029884338, 7000: 0.7600582838058472, 7100: 0.5420132875442505, 7200: 0.7159630060195923, 7300: 9.186245918273926, 7400: 0.6523135304450989, 7500: 2.3233823776245117, 7600: 0.3630313575267792, 7700: 1.6804721355438232, 7800: 0.5166246294975281, 7900: 1.0583091974258423, 8000: 0.28563392162323, 8100: 0.7929272651672363, 8200: 0.680885374546051, 8300: 1.2688417434692383, 8400: 0.2506299316883087, 8500: 0.41133353114128113, 8600: 0.17595596611499786, 8700: 1.165644645690918, 8800: 1.3981153964996338, 8900: 0.40355873107910156, 9000: 0.9370189309120178}, 'F1': {5: 0.5663379578923826}, 'Accuracy': {5: 0.5109247406753477}}\n",
      "Epoch 6\n",
      "\n",
      "Epoch time: 50.14507293701172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       280\n",
      "           1       0.59      0.83      0.69       277\n",
      "           2       0.62      0.70      0.66       293\n",
      "           3       0.60      0.46      0.52       283\n",
      "           4       0.55      0.89      0.68       274\n",
      "           5       0.46      0.77      0.58       275\n",
      "           6       0.56      0.91      0.69       268\n",
      "           7       0.60      0.82      0.69       280\n",
      "           8       0.57      0.73      0.64       272\n",
      "           9       0.55      0.79      0.65       272\n",
      "          10       0.40      0.15      0.22      1757\n",
      "\n",
      "    accuracy                           0.54      4531\n",
      "   macro avg       0.55      0.73      0.61      4531\n",
      "weighted avg       0.50      0.54      0.48      4531\n",
      "\n",
      "Logger {'time': {0: 0.007156848907470703, 100: 0.7174715995788574, 200: 1.4434418678283691, 300: 2.1462247371673584, 400: 2.936448574066162, 500: 3.6827828884124756, 600: 4.327877759933472, 700: 4.871285676956177, 800: 5.429757833480835, 900: 6.01329779624939, 1000: 6.553953647613525, 1100: 7.1302809715271, 1200: 7.620449781417847, 1300: 8.115657806396484, 1400: 8.641962766647339, 1500: 9.183974742889404, 1600: 9.686302900314331, 1700: 10.23177194595337, 1800: 10.908347845077515, 1900: 11.655622720718384, 2000: 12.327787637710571, 2100: 12.998677015304565, 2200: 13.754766702651978, 2300: 14.365853786468506, 2400: 14.933193922042847, 2500: 15.499302864074707, 2600: 16.030232667922974, 2700: 16.550248861312866, 2800: 17.043900966644287, 2900: 17.580840826034546, 3000: 18.06813073158264, 3100: 18.5927836894989, 3200: 19.101499795913696, 3300: 19.6410129070282, 3400: 20.26317596435547, 3500: 20.954675912857056, 3600: 21.455363750457764, 3700: 21.965577840805054, 3800: 22.46250581741333, 3900: 22.98265767097473, 4000: 23.489433765411377, 4100: 23.98690176010132, 4200: 24.49173665046692, 4300: 25.01921582221985, 4400: 25.526147842407227, 4500: 26.022835969924927, 4600: 26.5598726272583, 4700: 27.070382833480835, 4800: 27.585648775100708, 4900: 28.08406972885132, 5000: 28.613030910491943, 5100: 29.116695642471313, 5200: 29.65769863128662, 5300: 30.156749725341797, 5400: 30.685625791549683, 5500: 31.273537635803223, 5600: 31.843989610671997, 5700: 32.44046974182129, 5800: 32.96379065513611, 5900: 33.56388568878174, 6000: 34.05952262878418, 6100: 34.62234663963318, 6200: 35.193941593170166, 6300: 35.7750825881958, 6400: 36.310221672058105, 6500: 36.87974572181702, 6600: 37.396230936050415, 6700: 37.97063875198364, 6800: 38.4988477230072, 6900: 39.03866982460022, 7000: 39.57796096801758, 7100: 40.086829662323, 7200: 40.59844088554382, 7300: 41.10257577896118, 7400: 41.61521792411804, 7500: 42.125651836395264, 7600: 42.62384366989136, 7700: 43.130472898483276, 7800: 43.651304960250854, 7900: 44.15630388259888, 8000: 44.6708128452301, 8100: 45.18154287338257, 8200: 45.67862296104431, 8300: 46.169838666915894, 8400: 46.67005276679993, 8500: 47.172757625579834, 8600: 47.684170722961426, 8700: 48.1901638507843, 8800: 48.71526288986206, 8900: 49.2253258228302, 9000: 49.74536085128784}, 'loss': {0: 3.8440842628479004, 100: 1.0795402526855469, 200: 1.32754647731781, 300: 0.41571173071861267, 400: 1.9597545862197876, 500: 1.130845069885254, 600: 1.4210915565490723, 700: 0.5712379217147827, 800: 1.3064935207366943, 900: 0.4166460931301117, 1000: 0.649467945098877, 1100: 6.349660873413086, 1200: 0.5980150699615479, 1300: 0.6036807894706726, 1400: 1.6190614700317383, 1500: 0.501418948173523, 1600: 2.200747489929199, 1700: 0.6283179521560669, 1800: 5.170361042022705, 1900: 1.123483657836914, 2000: 1.31734299659729, 2100: 0.6181691884994507, 2200: 1.7464091777801514, 2300: 0.5928058624267578, 2400: 0.6898364424705505, 2500: 1.4323155879974365, 2600: 1.564015507698059, 2700: 0.9936588406562805, 2800: 0.24575947225093842, 2900: 2.7937076091766357, 3000: 0.779909074306488, 3100: 0.3676436245441437, 3200: 1.035569429397583, 3300: 0.7894706726074219, 3400: 1.3947902917861938, 3500: 0.58372962474823, 3600: 0.4266674816608429, 3700: 0.48396092653274536, 3800: 0.38507580757141113, 3900: 0.29663190245628357, 4000: 0.22764258086681366, 4100: 0.4840317666530609, 4200: 1.1860300302505493, 4300: 0.9876334071159363, 4400: 1.0238617658615112, 4500: 0.5033370852470398, 4600: 0.6557397842407227, 4700: 1.6807507276535034, 4800: 0.9734268188476562, 4900: 0.4788021147251129, 5000: 0.6998904943466187, 5100: 5.9560136795043945, 5200: 0.17801684141159058, 5300: 0.6000198721885681, 5400: 0.46085914969444275, 5500: 1.4746105670928955, 5600: 0.8806100487709045, 5700: 0.3203682601451874, 5800: 0.7898590564727783, 5900: 2.09045672416687, 6000: 0.5659676194190979, 6100: 0.9118208289146423, 6200: 0.8416488170623779, 6300: 0.39730140566825867, 6400: 0.542439341545105, 6500: 0.1612713485956192, 6600: 0.23467585444450378, 6700: 2.4480979442596436, 6800: 2.0600035190582275, 6900: 1.0065696239471436, 7000: 0.8090990781784058, 7100: 0.3936026990413666, 7200: 0.8413251042366028, 7300: 9.160606384277344, 7400: 0.3641163408756256, 7500: 2.0754048824310303, 7600: 0.9026185274124146, 7700: 0.6318890452384949, 7800: 0.7049784064292908, 7900: 0.8033379912376404, 8000: 0.3216647803783417, 8100: 0.7153116464614868, 8200: 0.8047653436660767, 8300: 1.2505762577056885, 8400: 0.3518045246601105, 8500: 0.1628129780292511, 8600: 0.15256622433662415, 8700: 1.0814175605773926, 8800: 1.0292868614196777, 8900: 0.28803589940071106, 9000: 0.7887827754020691}, 'F1': {6: 0.612241712610428}, 'Accuracy': {6: 0.5387331714853233}}\n",
      "Epoch 7\n",
      "\n",
      "Epoch time: 54.77310585975647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.93      0.74       280\n",
      "           1       0.62      0.85      0.71       277\n",
      "           2       0.60      0.74      0.66       293\n",
      "           3       0.60      0.47      0.52       283\n",
      "           4       0.55      0.91      0.69       274\n",
      "           5       0.52      0.66      0.59       275\n",
      "           6       0.57      0.88      0.69       268\n",
      "           7       0.59      0.80      0.68       280\n",
      "           8       0.55      0.65      0.60       272\n",
      "           9       0.53      0.80      0.64       272\n",
      "          10       0.40      0.19      0.26      1757\n",
      "\n",
      "    accuracy                           0.54      4531\n",
      "   macro avg       0.56      0.72      0.62      4531\n",
      "weighted avg       0.51      0.54      0.50      4531\n",
      "\n",
      "Logger {'time': {0: 0.018980741500854492, 100: 0.8428568840026855, 200: 1.8147966861724854, 300: 2.4614927768707275, 400: 3.1009669303894043, 500: 3.758175849914551, 600: 4.374868869781494, 700: 4.967314958572388, 800: 5.661410808563232, 900: 6.320574760437012, 1000: 6.884401798248291, 1100: 7.483250856399536, 1200: 8.068832874298096, 1300: 8.63720965385437, 1400: 9.270894765853882, 1500: 10.002235889434814, 1600: 10.82233190536499, 1700: 11.542994737625122, 1800: 12.291426658630371, 1900: 13.050004959106445, 2000: 13.632287979125977, 2100: 14.236356735229492, 2200: 14.781765699386597, 2300: 15.37451982498169, 2400: 15.894113779067993, 2500: 16.42770481109619, 2600: 17.014355897903442, 2700: 17.602271795272827, 2800: 18.213026762008667, 2900: 18.811786890029907, 3000: 19.39337968826294, 3100: 20.009604692459106, 3200: 20.647876739501953, 3300: 21.26767063140869, 3400: 21.935393810272217, 3500: 22.545120000839233, 3600: 23.115253925323486, 3700: 23.736920833587646, 3800: 24.32304573059082, 3900: 24.908021926879883, 4000: 25.50021767616272, 4100: 26.146968841552734, 4200: 26.75445866584778, 4300: 27.366437673568726, 4400: 28.063297033309937, 4500: 28.757033824920654, 4600: 29.406495809555054, 4700: 30.008323669433594, 4800: 30.60201382637024, 4900: 31.18399167060852, 5000: 31.798208951950073, 5100: 32.473026752471924, 5200: 33.11710000038147, 5300: 33.798380613327026, 5400: 34.404735803604126, 5500: 35.004671812057495, 5600: 35.61938786506653, 5700: 36.232643842697144, 5800: 36.851900815963745, 5900: 37.44859170913696, 6000: 37.976486921310425, 6100: 38.546565771102905, 6200: 39.051007986068726, 6300: 39.5766966342926, 6400: 40.06881380081177, 6500: 40.562511682510376, 6600: 41.07643270492554, 6700: 41.571741819381714, 6800: 42.085301876068115, 6900: 42.590903759002686, 7000: 43.105265855789185, 7100: 43.61781072616577, 7200: 44.251829862594604, 7300: 44.79332184791565, 7400: 45.44727659225464, 7500: 46.01092576980591, 7600: 46.608492612838745, 7700: 47.19738984107971, 7800: 47.77424693107605, 7900: 48.371790647506714, 8000: 48.90844488143921, 8100: 49.44141483306885, 8200: 49.932819843292236, 8300: 50.544461727142334, 8400: 51.162678718566895, 8500: 51.70715594291687, 8600: 52.19973182678223, 8700: 52.77340793609619, 8800: 53.330299854278564, 8900: 53.85655093193054, 9000: 54.37023687362671}, 'loss': {0: 3.491154909133911, 100: 0.7751015424728394, 200: 1.1819077730178833, 300: 0.3636983036994934, 400: 1.8436111211776733, 500: 1.7522248029708862, 600: 1.2089625597000122, 700: 0.12861689925193787, 800: 1.1032217741012573, 900: 0.23081639409065247, 1000: 0.7485559582710266, 1100: 2.26898193359375, 1200: 0.5827410221099854, 1300: 0.49287524819374084, 1400: 1.5489600896835327, 1500: 0.5510838031768799, 1600: 1.1500928401947021, 1700: 1.1725441217422485, 1800: 4.298456192016602, 1900: 2.0666210651397705, 2000: 0.647090494632721, 2100: 1.00178861618042, 2200: 1.6915122270584106, 2300: 0.18845978379249573, 2400: 0.46913430094718933, 2500: 1.5558854341506958, 2600: 1.4458526372909546, 2700: 0.9202554821968079, 2800: 0.8132150173187256, 2900: 1.3231303691864014, 3000: 0.8178313970565796, 3100: 0.33875876665115356, 3200: 1.3544265031814575, 3300: 1.3901660442352295, 3400: 1.23399019241333, 3500: 2.14591646194458, 3600: 0.396295428276062, 3700: 0.3870899975299835, 3800: 0.32301202416419983, 3900: 0.35952228307724, 4000: 0.31255462765693665, 4100: 0.5131686925888062, 4200: 0.47426655888557434, 4300: 0.9253572225570679, 4400: 1.0548734664916992, 4500: 0.5150482654571533, 4600: 1.044513463973999, 4700: 1.5269925594329834, 4800: 0.8496265411376953, 4900: 0.5983219146728516, 5000: 0.5183046460151672, 5100: 7.904922962188721, 5200: 0.10023365169763565, 5300: 0.7861002087593079, 5400: 0.726371705532074, 5500: 3.781191825866699, 5600: 0.6666309833526611, 5700: 1.4143671989440918, 5800: 0.7362139821052551, 5900: 1.0032875537872314, 6000: 0.44850942492485046, 6100: 0.7043495774269104, 6200: 1.4664239883422852, 6300: 0.3433164060115814, 6400: 0.9642465710639954, 6500: 0.6101648807525635, 6600: 0.32416731119155884, 6700: 2.4400522708892822, 6800: 2.2165355682373047, 6900: 1.124624490737915, 7000: 0.7212252616882324, 7100: 0.38652241230010986, 7200: 0.7262625694274902, 7300: 9.029679298400879, 7400: 0.7435891032218933, 7500: 1.6388144493103027, 7600: 0.19299839437007904, 7700: 0.8077315092086792, 7800: 0.46039247512817383, 7900: 0.6322153806686401, 8000: 0.20132404565811157, 8100: 0.9480566382408142, 8200: 0.7496411800384521, 8300: 1.2223079204559326, 8400: 0.4955938160419464, 8500: 0.28076279163360596, 8600: 0.20113308727741241, 8700: 1.0990469455718994, 8800: 0.8525422215461731, 8900: 0.2534896433353424, 9000: 0.9652589559555054}, 'F1': {7: 0.6157705734080279}, 'Accuracy': {7: 0.5431472081218274}}\n",
      "Epoch 8\n",
      "\n",
      "Epoch time: 54.755037784576416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.95      0.73       280\n",
      "           1       0.58      0.86      0.69       277\n",
      "           2       0.61      0.68      0.64       293\n",
      "           3       0.60      0.60      0.60       283\n",
      "           4       0.56      0.86      0.68       274\n",
      "           5       0.57      0.71      0.63       275\n",
      "           6       0.57      0.88      0.70       268\n",
      "           7       0.58      0.84      0.69       280\n",
      "           8       0.52      0.79      0.63       272\n",
      "           9       0.54      0.79      0.64       272\n",
      "          10       0.39      0.15      0.21      1757\n",
      "\n",
      "    accuracy                           0.54      4531\n",
      "   macro avg       0.56      0.74      0.62      4531\n",
      "weighted avg       0.50      0.54      0.49      4531\n",
      "\n",
      "Logger {'time': {0: 0.008810997009277344, 100: 0.59012770652771, 200: 1.1908748149871826, 300: 1.7437009811401367, 400: 2.3462398052215576, 500: 3.04998779296875, 600: 3.6463518142700195, 700: 4.205997943878174, 800: 4.744079828262329, 900: 5.239866733551025, 1000: 5.807212829589844, 1100: 6.314154863357544, 1200: 6.857332944869995, 1300: 7.444444894790649, 1400: 8.02184796333313, 1500: 8.52416181564331, 1600: 9.081232786178589, 1700: 9.610253810882568, 1800: 10.124079704284668, 1900: 10.623352766036987, 2000: 11.280545949935913, 2100: 12.090205907821655, 2200: 12.879491806030273, 2300: 13.615819931030273, 2400: 14.19150161743164, 2500: 14.776648759841919, 2600: 15.34882664680481, 2700: 15.945114850997925, 2800: 16.509053945541382, 2900: 17.0606210231781, 3000: 17.59858775138855, 3100: 18.105692863464355, 3200: 18.621233701705933, 3300: 19.163963794708252, 3400: 19.677283763885498, 3500: 20.16724181175232, 3600: 20.6720130443573, 3700: 21.15719985961914, 3800: 21.686726808547974, 3900: 22.174739837646484, 4000: 22.672249794006348, 4100: 23.181204795837402, 4200: 23.694398880004883, 4300: 24.383556842803955, 4400: 25.049574851989746, 4500: 25.797744750976562, 4600: 26.39573073387146, 4700: 27.01013970375061, 4800: 27.621501922607422, 4900: 28.246872663497925, 5000: 28.838867902755737, 5100: 29.44521689414978, 5200: 30.639633893966675, 5300: 31.368891716003418, 5400: 31.90771985054016, 5500: 32.59524488449097, 5600: 33.12001085281372, 5700: 33.65416598320007, 5800: 34.23535084724426, 5900: 34.76725482940674, 6000: 35.29233193397522, 6100: 35.84013891220093, 6200: 36.337984800338745, 6300: 36.97833585739136, 6400: 37.61027765274048, 6500: 38.17993378639221, 6600: 39.062495946884155, 6700: 39.87899684906006, 6800: 40.44913387298584, 6900: 40.992915868759155, 7000: 41.49166989326477, 7100: 42.028361797332764, 7200: 42.77119588851929, 7300: 43.3954758644104, 7400: 44.08958888053894, 7500: 44.727609634399414, 7600: 45.31311273574829, 7700: 45.98456597328186, 7800: 46.57694363594055, 7900: 47.1530077457428, 8000: 47.811614751815796, 8100: 48.467689752578735, 8200: 49.078392028808594, 8300: 49.63715577125549, 8400: 50.16910791397095, 8500: 50.72489070892334, 8600: 51.38044285774231, 8700: 52.387823820114136, 8800: 53.07936382293701, 8900: 53.6935088634491, 9000: 54.28112196922302}, 'loss': {0: 3.144970417022705, 100: 0.5942169427871704, 200: 1.6147516965866089, 300: 0.7045115232467651, 400: 1.040536880493164, 500: 1.5051037073135376, 600: 2.3584837913513184, 700: 0.17048737406730652, 800: 0.9493921399116516, 900: 0.3273027837276459, 1000: 0.607588529586792, 1100: 1.5077013969421387, 1200: 0.7256975769996643, 1300: 0.3549821674823761, 1400: 1.4332873821258545, 1500: 0.4722130596637726, 1600: 1.4100486040115356, 1700: 0.8145842552185059, 1800: 5.670523166656494, 1900: 1.6517155170440674, 2000: 1.0630426406860352, 2100: 0.6568171381950378, 2200: 1.512117862701416, 2300: 0.4874457120895386, 2400: 0.7061749696731567, 2500: 1.4576433897018433, 2600: 1.407069444656372, 2700: 3.668276071548462, 2800: 1.0925241708755493, 2900: 1.403842806816101, 3000: 0.7342692613601685, 3100: 0.37091001868247986, 3200: 0.7932760119438171, 3300: 0.5380837321281433, 3400: 0.7815276384353638, 3500: 1.6019573211669922, 3600: 0.3823595643043518, 3700: 0.5244230628013611, 3800: 0.4671187102794647, 3900: 0.8701238036155701, 4000: 0.3359803557395935, 4100: 0.4836590588092804, 4200: 0.4554920494556427, 4300: 1.2730451822280884, 4400: 0.9769159555435181, 4500: 0.343360960483551, 4600: 0.49517345428466797, 4700: 4.473050117492676, 4800: 0.9198214411735535, 4900: 0.49891728162765503, 5000: 0.6143200397491455, 5100: 7.8815107345581055, 5200: 0.1473575234413147, 5300: 0.139632448554039, 5400: 0.6333329677581787, 5500: 2.5126230716705322, 5600: 0.5872262716293335, 5700: 0.42128944396972656, 5800: 0.8747033476829529, 5900: 1.5602433681488037, 6000: 0.41096583008766174, 6100: 1.0550010204315186, 6200: 0.7787542939186096, 6300: 0.3987809121608734, 6400: 1.2461103200912476, 6500: 0.351936936378479, 6600: 0.4896886348724365, 6700: 2.6842775344848633, 6800: 2.333975315093994, 6900: 1.0088417530059814, 7000: 0.6277551651000977, 7100: 0.4302409291267395, 7200: 0.5965410470962524, 7300: 8.314824104309082, 7400: 0.6137357354164124, 7500: 2.348050594329834, 7600: 0.261726438999176, 7700: 2.3052616119384766, 7800: 0.511972188949585, 7900: 1.1647849082946777, 8000: 0.2376691997051239, 8100: 0.7507641911506653, 8200: 0.6397880911827087, 8300: 1.9217442274093628, 8400: 0.17658062279224396, 8500: 0.763573944568634, 8600: 0.22768758237361908, 8700: 0.922491192817688, 8800: 0.8436802625656128, 8900: 0.47836220264434814, 9000: 0.6745040416717529}, 'F1': {8: 0.6219905102072905}, 'Accuracy': {8: 0.5442507172809534}}\n",
      "Epoch 9\n",
      "\n",
      "Epoch time: 51.58788204193115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       280\n",
      "           1       0.61      0.77      0.68       277\n",
      "           2       0.61      0.69      0.65       293\n",
      "           3       0.59      0.65      0.62       283\n",
      "           4       0.56      0.89      0.69       274\n",
      "           5       0.55      0.64      0.59       275\n",
      "           6       0.57      0.86      0.68       268\n",
      "           7       0.57      0.84      0.68       280\n",
      "           8       0.54      0.58      0.56       272\n",
      "           9       0.52      0.87      0.65       272\n",
      "          10       0.39      0.17      0.24      1757\n",
      "\n",
      "    accuracy                           0.54      4531\n",
      "   macro avg       0.55      0.72      0.61      4531\n",
      "weighted avg       0.50      0.54      0.49      4531\n",
      "\n",
      "Logger {'time': {0: 0.01658010482788086, 100: 0.8128688335418701, 200: 1.5089590549468994, 300: 2.063570976257324, 400: 2.644021987915039, 500: 3.2924909591674805, 600: 3.9242141246795654, 700: 4.5957350730896, 800: 5.387077808380127, 900: 6.114541053771973, 1000: 6.811717987060547, 1100: 7.405280113220215, 1200: 7.964635848999023, 1300: 8.708763837814331, 1400: 9.35336184501648, 1500: 9.899674892425537, 1600: 10.48551082611084, 1700: 11.18836784362793, 1800: 11.845814943313599, 1900: 12.381139993667603, 2000: 13.264986038208008, 2100: 14.079994916915894, 2200: 14.66905403137207, 2300: 15.48292088508606, 2400: 16.09849715232849, 2500: 16.72655200958252, 2600: 17.282109022140503, 2700: 17.78217911720276, 2800: 18.303706884384155, 2900: 18.804535150527954, 3000: 19.327775955200195, 3100: 19.82097887992859, 3200: 20.34805703163147, 3300: 20.857994079589844, 3400: 21.407514810562134, 3500: 21.92588996887207, 3600: 22.45980215072632, 3700: 22.96111488342285, 3800: 23.516672134399414, 3900: 24.073877096176147, 4000: 24.61023497581482, 4100: 25.105528116226196, 4200: 25.620101928710938, 4300: 26.125473976135254, 4400: 26.686342000961304, 4500: 27.196948051452637, 4600: 27.79781198501587, 4700: 28.324417114257812, 4800: 28.86419105529785, 4900: 29.412183046340942, 5000: 29.93374013900757, 5100: 30.452270030975342, 5200: 30.9723699092865, 5300: 31.474507093429565, 5400: 32.000571966171265, 5500: 32.60066103935242, 5600: 33.122666120529175, 5700: 33.63029885292053, 5800: 34.191970109939575, 5900: 34.71055006980896, 6000: 35.26080012321472, 6100: 35.784960985183716, 6200: 36.34087920188904, 6300: 36.85843515396118, 6400: 37.422996044158936, 6500: 37.95719814300537, 6600: 38.54232597351074, 6700: 39.10026812553406, 6800: 39.61563301086426, 6900: 40.111021995544434, 7000: 40.631819009780884, 7100: 41.12404799461365, 7200: 41.633492946624756, 7300: 42.12018895149231, 7400: 42.64212703704834, 7500: 43.20279002189636, 7600: 43.75334882736206, 7700: 44.25236511230469, 7800: 44.766170024871826, 7900: 45.37149381637573, 8000: 46.032463788986206, 8100: 46.58812689781189, 8200: 47.113142013549805, 8300: 47.63123607635498, 8400: 48.14520978927612, 8500: 48.651390075683594, 8600: 49.17251801490784, 8700: 49.66484880447388, 8800: 50.172836780548096, 8900: 50.67192506790161, 9000: 51.192057847976685}, 'loss': {0: 2.6943461894989014, 100: 0.8948658108711243, 200: 1.451744794845581, 300: 0.569860577583313, 400: 1.6822090148925781, 500: 1.0432031154632568, 600: 2.9427013397216797, 700: 0.30128541588783264, 800: 1.058072566986084, 900: 0.43390563130378723, 1000: 0.6332215070724487, 1100: 0.9337216019630432, 1200: 0.9307013154029846, 1300: 0.5135267376899719, 1400: 1.2693489789962769, 1500: 0.268608421087265, 1600: 1.5549237728118896, 1700: 0.8957468271255493, 1800: 6.955782890319824, 1900: 1.401436686515808, 2000: 1.9439680576324463, 2100: 0.7288362383842468, 2200: 1.4733684062957764, 2300: 0.3821753263473511, 2400: 0.5884513258934021, 2500: 1.2566938400268555, 2600: 1.3412950038909912, 2700: 3.786356210708618, 2800: 0.6370075345039368, 2900: 1.4975025653839111, 3000: 0.4579119384288788, 3100: 1.1561319828033447, 3200: 1.2099560499191284, 3300: 0.5262107849121094, 3400: 1.879294514656067, 3500: 1.6049177646636963, 3600: 0.45397961139678955, 3700: 0.5231677293777466, 3800: 0.37371206283569336, 3900: 0.43166953325271606, 4000: 0.40604397654533386, 4100: 0.4070683717727661, 4200: 1.2361583709716797, 4300: 1.4193916320800781, 4400: 0.7485406398773193, 4500: 0.5496716499328613, 4600: 1.2023820877075195, 4700: 1.0113027095794678, 4800: 1.108607292175293, 4900: 0.6923068165779114, 5000: 0.6917351484298706, 5100: 7.732967376708984, 5200: 0.19794145226478577, 5300: 0.5858740210533142, 5400: 0.7592386603355408, 5500: 3.3228964805603027, 5600: 0.6842178702354431, 5700: 0.4789466857910156, 5800: 0.7428253889083862, 5900: 0.27404236793518066, 6000: 0.8514947891235352, 6100: 1.1726419925689697, 6200: 0.499701589345932, 6300: 0.3582463562488556, 6400: 1.461500644683838, 6500: 0.2918911874294281, 6600: 0.19264981150627136, 6700: 1.9476275444030762, 6800: 1.7785063982009888, 6900: 0.5067505836486816, 7000: 0.7991702556610107, 7100: 0.3769674003124237, 7200: 0.6461532115936279, 7300: 9.261605262756348, 7400: 0.45480993390083313, 7500: 1.826228380203247, 7600: 0.20178420841693878, 7700: 0.8952330350875854, 7800: 0.6973782777786255, 7900: 1.482184886932373, 8000: 0.21963196992874146, 8100: 0.7904120087623596, 8200: 0.9185866117477417, 8300: 0.5693360567092896, 8400: 0.3087293207645416, 8500: 0.6049534678459167, 8600: 0.15615329146385193, 8700: 1.1600723266601562, 8800: 1.1499935388565063, 8900: 0.30156373977661133, 9000: 0.8811194896697998}, 'F1': {9: 0.6122838965981813}, 'Accuracy': {9: 0.5374089604943721}}\n",
      "Epoch 10\n",
      "\n",
      "Epoch time: 48.06500577926636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.68       280\n",
      "           1       0.61      0.84      0.71       277\n",
      "           2       0.61      0.76      0.67       293\n",
      "           3       0.61      0.59      0.60       283\n",
      "           4       0.54      0.88      0.67       274\n",
      "           5       0.55      0.72      0.62       275\n",
      "           6       0.58      0.84      0.68       268\n",
      "           7       0.57      0.84      0.68       280\n",
      "           8       0.54      0.67      0.60       272\n",
      "           9       0.55      0.79      0.65       272\n",
      "          10       0.36      0.14      0.20      1757\n",
      "\n",
      "    accuracy                           0.54      4531\n",
      "   macro avg       0.55      0.73      0.62      4531\n",
      "weighted avg       0.49      0.54      0.48      4531\n",
      "\n",
      "Logger {'time': {0: 0.009369850158691406, 100: 0.5149860382080078, 200: 1.0955820083618164, 300: 1.585448980331421, 400: 2.1057920455932617, 500: 2.6089649200439453, 600: 3.1616389751434326, 700: 3.671207904815674, 800: 4.183732032775879, 900: 4.7040557861328125, 1000: 5.337612867355347, 1100: 5.960004806518555, 1200: 6.491380929946899, 1300: 7.05093789100647, 1400: 7.669742822647095, 1500: 8.189970970153809, 1600: 8.709699869155884, 1700: 9.214920997619629, 1800: 9.723500728607178, 1900: 10.310570001602173, 2000: 10.886005878448486, 2100: 11.42572808265686, 2200: 11.980518817901611, 2300: 12.466619968414307, 2400: 13.0174400806427, 2500: 13.572169065475464, 2600: 14.124491691589355, 2700: 14.623976945877075, 2800: 15.160861015319824, 2900: 15.702448844909668, 3000: 16.29594588279724, 3100: 16.931748867034912, 3200: 17.50473976135254, 3300: 18.068267822265625, 3400: 18.614134788513184, 3500: 19.16931676864624, 3600: 19.673075914382935, 3700: 20.168352842330933, 3800: 20.69687581062317, 3900: 21.207690954208374, 4000: 21.75242590904236, 4100: 22.27442479133606, 4200: 22.794777870178223, 4300: 23.306203842163086, 4400: 23.82884192466736, 4500: 24.371368885040283, 4600: 24.903528928756714, 4700: 25.400311708450317, 4800: 25.919787883758545, 4900: 26.424375772476196, 5000: 26.952473878860474, 5100: 27.485427856445312, 5200: 27.996120929718018, 5300: 28.503833770751953, 5400: 29.025893926620483, 5500: 29.51656985282898, 5600: 30.029313802719116, 5700: 30.536431789398193, 5800: 31.06907606124878, 5900: 31.574377059936523, 6000: 32.09824895858765, 6100: 32.59728384017944, 6200: 33.15491271018982, 6300: 33.65303874015808, 6400: 34.18620705604553, 6500: 34.6956627368927, 6600: 35.229074001312256, 6700: 35.749281883239746, 6800: 36.28820204734802, 6900: 36.80993175506592, 7000: 37.354689836502075, 7100: 37.8527398109436, 7200: 38.36271691322327, 7300: 38.88280391693115, 7400: 39.383479833602905, 7500: 39.92157602310181, 7600: 40.43090581893921, 7700: 40.94507193565369, 7800: 41.44732880592346, 7900: 41.97059988975525, 8000: 42.469167947769165, 8100: 42.97360277175903, 8200: 43.477184772491455, 8300: 44.009347915649414, 8400: 44.510643005371094, 8500: 45.02880001068115, 8600: 45.52429175376892, 8700: 46.03438186645508, 8800: 46.53976583480835, 8900: 47.134543895721436, 9000: 47.64012384414673}, 'loss': {0: 3.2028393745422363, 100: 0.7217994928359985, 200: 1.4521549940109253, 300: 0.3451690077781677, 400: 1.5707286596298218, 500: 1.5842523574829102, 600: 1.4832087755203247, 700: 0.6301001310348511, 800: 0.7223032116889954, 900: 0.12523780763149261, 1000: 0.7501068115234375, 1100: 0.8548370599746704, 1200: 0.7502166628837585, 1300: 0.6146420836448669, 1400: 1.3001766204833984, 1500: 0.5050501227378845, 1600: 1.1794469356536865, 1700: 0.7329875826835632, 1800: 7.078109264373779, 1900: 1.547078251838684, 2000: 1.6448112726211548, 2100: 0.9585279226303101, 2200: 1.523051381111145, 2300: 0.3660372495651245, 2400: 0.8200027942657471, 2500: 1.124302864074707, 2600: 1.4926226139068604, 2700: 3.6738662719726562, 2800: 0.9329261779785156, 2900: 1.166329264640808, 3000: 0.6023262739181519, 3100: 0.3472147583961487, 3200: 1.2250165939331055, 3300: 0.5722290277481079, 3400: 1.7308300733566284, 3500: 2.1925039291381836, 3600: 0.6254881024360657, 3700: 0.4834064245223999, 3800: 0.385015606880188, 3900: 0.4236147999763489, 4000: 0.27983760833740234, 4100: 0.34011906385421753, 4200: 1.0897390842437744, 4300: 1.123214840888977, 4400: 0.8887362480163574, 4500: 0.5529153943061829, 4600: 0.7439352869987488, 4700: 4.327406883239746, 4800: 0.9042831063270569, 4900: 0.6500515341758728, 5000: 0.7602205872535706, 5100: 6.776537895202637, 5200: 0.2076590657234192, 5300: 0.3804749846458435, 5400: 0.509708821773529, 5500: 3.774528980255127, 5600: 0.35772499442100525, 5700: 0.5759115815162659, 5800: 0.8144082427024841, 5900: 1.0401341915130615, 6000: 0.3459772765636444, 6100: 1.0839025974273682, 6200: 1.1935853958129883, 6300: 0.576020359992981, 6400: 1.3083720207214355, 6500: 0.30188092589378357, 6600: 0.4385123550891876, 6700: 2.5598299503326416, 6800: 1.7951678037643433, 6900: 0.8382243514060974, 7000: 0.6350196003913879, 7100: 0.2757189869880676, 7200: 0.8311530351638794, 7300: 9.174939155578613, 7400: 0.47620463371276855, 7500: 2.5014162063598633, 7600: 0.5493001341819763, 7700: 0.44818273186683655, 7800: 0.6990787982940674, 7900: 1.4195289611816406, 8000: 0.19939753413200378, 8100: 0.31844618916511536, 8200: 0.5120623707771301, 8300: 1.2536165714263916, 8400: 0.17407916486263275, 8500: 0.8076863884925842, 8600: 0.2397354543209076, 8700: 1.5478577613830566, 8800: 1.6723018884658813, 8900: 0.25768303871154785, 9000: 0.9562627077102661}, 'F1': {10: 0.6155688665418161}, 'Accuracy': {10: 0.5354226440079453}}\n",
      "Training with dataset size: 20000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Epoch 1\n",
      "\n",
      "Epoch time: 94.52627515792847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       563\n",
      "           1       0.62      0.83      0.71       561\n",
      "           2       0.56      0.73      0.63       564\n",
      "           3       0.64      0.45      0.53       573\n",
      "           4       0.57      0.88      0.69       575\n",
      "           5       0.58      0.71      0.64       556\n",
      "           6       0.62      0.64      0.63       564\n",
      "           7       0.59      0.34      0.43       555\n",
      "           8       0.60      0.71      0.65       567\n",
      "           9       0.57      0.71      0.63       542\n",
      "          10       0.37      0.30      0.33      3461\n",
      "\n",
      "    accuracy                           0.52      9081\n",
      "   macro avg       0.57      0.63      0.59      9081\n",
      "weighted avg       0.51      0.52      0.51      9081\n",
      "\n",
      "Logger {'time': {0: 0.021533966064453125, 100: 0.6163430213928223, 200: 1.1722362041473389, 300: 1.7040410041809082, 400: 2.228564977645874, 500: 2.718268871307373, 600: 3.227155923843384, 700: 3.742960214614868, 800: 4.250384092330933, 900: 4.74835991859436, 1000: 5.283780097961426, 1100: 5.903045892715454, 1200: 6.4307520389556885, 1300: 6.923058986663818, 1400: 7.435853004455566, 1500: 7.941326141357422, 1600: 8.528685092926025, 1700: 9.02174997329712, 1800: 9.539050102233887, 1900: 10.04167103767395, 2000: 10.568508863449097, 2100: 11.07662320137024, 2200: 11.583148002624512, 2300: 12.10145616531372, 2400: 12.59188199043274, 2500: 13.102632999420166, 2600: 13.605982065200806, 2700: 14.137396097183228, 2800: 14.641149997711182, 2900: 15.15732192993164, 3000: 15.653164148330688, 3100: 16.168215036392212, 3200: 16.672794103622437, 3300: 17.24921703338623, 3400: 17.818697929382324, 3500: 18.360903024673462, 3600: 18.875542163848877, 3700: 19.391289234161377, 3800: 19.88956904411316, 3900: 20.405156135559082, 4000: 20.897675037384033, 4100: 21.472043991088867, 4200: 21.987491130828857, 4300: 22.51051902770996, 4400: 23.008361101150513, 4500: 23.5207622051239, 4600: 24.01781725883484, 4700: 24.535794019699097, 4800: 25.026906967163086, 4900: 25.570853233337402, 5000: 26.135013103485107, 5100: 26.683440923690796, 5200: 27.212125062942505, 5300: 27.717514991760254, 5400: 28.210095167160034, 5500: 28.710613012313843, 5600: 29.223352193832397, 5700: 29.725452184677124, 5800: 30.239586114883423, 5900: 30.72461223602295, 6000: 31.259165048599243, 6100: 31.765995025634766, 6200: 32.283259868621826, 6300: 32.78911113739014, 6400: 33.307050943374634, 6500: 33.80231308937073, 6600: 34.34139394760132, 6700: 34.887277126312256, 6800: 35.55905103683472, 6900: 36.07524108886719, 7000: 36.62967824935913, 7100: 37.16816806793213, 7200: 37.69721817970276, 7300: 38.19695210456848, 7400: 38.70232009887695, 7500: 39.2159628868103, 7600: 39.7199010848999, 7700: 40.23916697502136, 7800: 40.747791051864624, 7900: 41.60918617248535, 8000: 42.407432079315186, 8100: 42.93961811065674, 8200: 43.443527936935425, 8300: 43.9556770324707, 8400: 44.469977140426636, 8500: 44.986407995224, 8600: 45.515718936920166, 8700: 46.06108117103577, 8800: 46.57033920288086, 8900: 47.083348989486694, 9000: 47.58156108856201, 9100: 48.09248995780945, 9200: 48.585789918899536, 9300: 49.09417009353638, 9400: 49.60227990150452, 9500: 50.12006998062134, 9600: 50.6354820728302, 9700: 51.18923497200012, 9800: 51.77706813812256, 9900: 52.303091049194336, 10000: 52.811034202575684, 10100: 53.333731174468994, 10200: 53.83173990249634, 10300: 54.34001111984253, 10400: 54.84826612472534, 10500: 55.34541320800781, 10600: 55.852477073669434, 10700: 56.356396198272705, 10800: 56.871849060058594, 10900: 57.374842166900635, 11000: 57.884499073028564, 11100: 58.38523817062378, 11200: 58.9018759727478, 11300: 59.41139006614685, 11400: 59.92108917236328, 11500: 60.42969799041748, 11600: 60.93753504753113, 11700: 61.447190046310425, 11800: 61.966042280197144, 11900: 62.47734713554382, 12000: 62.98786211013794, 12100: 63.487330198287964, 12200: 63.989604234695435, 12300: 64.49681615829468, 12400: 65.02415704727173, 12500: 65.53017020225525, 12600: 66.04650115966797, 12700: 66.65076208114624, 12800: 67.16496586799622, 12900: 67.64737010002136, 13000: 68.14831018447876, 13100: 68.65380311012268, 13200: 69.16160202026367, 13300: 69.68453192710876, 13400: 70.19471216201782, 13500: 70.74955296516418, 13600: 71.2844250202179, 13700: 71.81681799888611, 13800: 72.32581210136414, 13900: 72.821613073349, 14000: 73.33145904541016, 14100: 73.84040093421936, 14200: 74.33491802215576, 14300: 74.84572005271912, 14400: 75.34187126159668, 14500: 75.86684012413025, 14600: 76.39290499687195, 14700: 76.9014060497284, 14800: 77.40971112251282, 14900: 77.9166522026062, 15000: 78.42944002151489, 15100: 78.93820285797119, 15200: 79.46385216712952, 15300: 79.96772193908691, 15400: 80.47770500183105, 15500: 80.97141098976135, 15600: 81.49954104423523, 15700: 82.05883407592773, 15800: 82.57920598983765, 15900: 83.07087898254395, 16000: 83.57779097557068, 16100: 84.07194113731384, 16200: 84.58634305000305, 16300: 85.06859803199768, 16400: 85.58659887313843, 16500: 86.08840203285217, 16600: 86.59937405586243, 16700: 87.08234405517578, 16800: 87.60958790779114, 16900: 88.11079597473145, 17000: 88.6255271434784, 17100: 89.12118291854858, 17200: 89.63391900062561, 17300: 90.12633204460144, 17400: 90.63107991218567, 17500: 91.13088583946228, 17600: 91.6312210559845, 17700: 92.1567611694336, 17800: 92.66253709793091, 17900: 93.17749500274658, 18000: 93.66920924186707, 18100: 94.17953896522522}, 'loss': {0: 0.20651096105575562, 100: 0.5711467266082764, 200: 0.3950749933719635, 300: 1.9494566917419434, 400: 0.9354805946350098, 500: 0.25457999110221863, 600: 0.1248956173658371, 700: 1.7611503601074219, 800: 0.7153387069702148, 900: 0.7348484396934509, 1000: 2.0494322776794434, 1100: 1.7233370542526245, 1200: 0.5662564039230347, 1300: 0.632602870464325, 1400: 0.4846588969230652, 1500: 1.5722618103027344, 1600: 0.14548146724700928, 1700: 1.1731677055358887, 1800: 0.6915903091430664, 1900: 0.45194733142852783, 2000: 1.2773946523666382, 2100: 0.49445778131484985, 2200: 1.0495058298110962, 2300: 1.3271489143371582, 2400: 1.7918808460235596, 2500: 1.4365887641906738, 2600: 1.4505350589752197, 2700: 0.26056861877441406, 2800: 4.223142147064209, 2900: 0.8434751033782959, 3000: 0.5460407137870789, 3100: 1.5595321655273438, 3200: 0.3593614995479584, 3300: 0.6865453720092773, 3400: 0.751336395740509, 3500: 0.5950156450271606, 3600: 0.33794355392456055, 3700: 0.7222084999084473, 3800: 0.14410021901130676, 3900: 2.4264161586761475, 4000: 0.7663614153862, 4100: 1.5571510791778564, 4200: 0.9963863492012024, 4300: 0.5907496213912964, 4400: 0.8361501693725586, 4500: 0.7438158392906189, 4600: 1.7810992002487183, 4700: 1.5403163433074951, 4800: 0.5790107846260071, 4900: 0.42669665813446045, 5000: 1.0573506355285645, 5100: 0.6253320574760437, 5200: 0.6699389815330505, 5300: 1.5646107196807861, 5400: 0.7469335198402405, 5500: 0.47292760014533997, 5600: 1.793319582939148, 5700: 0.6274311542510986, 5800: 0.6994569897651672, 5900: 1.7937345504760742, 6000: 0.37106895446777344, 6100: 0.5511555671691895, 6200: 0.5621396899223328, 6300: 3.245270013809204, 6400: 0.3462717533111572, 6500: 1.625706672668457, 6600: 1.363749384880066, 6700: 1.5940606594085693, 6800: 0.26990461349487305, 6900: 0.45537054538726807, 7000: 0.8714734315872192, 7100: 0.3403536379337311, 7200: 1.0204062461853027, 7300: 0.16184693574905396, 7400: 0.23932959139347076, 7500: 0.351362943649292, 7600: 0.47587183117866516, 7700: 2.8068103790283203, 7800: 1.8069905042648315, 7900: 1.0710039138793945, 8000: 0.7042117714881897, 8100: 0.5466516017913818, 8200: 0.8865833282470703, 8300: 0.4603525996208191, 8400: 0.5371213555335999, 8500: 0.5136510133743286, 8600: 1.0668504238128662, 8700: 0.8706150054931641, 8800: 0.8061241507530212, 8900: 1.0090997219085693, 9000: 0.8806192278862, 9100: 0.2740473747253418, 9200: 0.40946656465530396, 9300: 0.26783397793769836, 9400: 2.968968391418457, 9500: 1.0180253982543945, 9600: 1.9270108938217163, 9700: 1.397953987121582, 9800: 3.7142386436462402, 9900: 0.3660988509654999, 10000: 1.9361047744750977, 10100: 1.024895191192627, 10200: 1.011637568473816, 10300: 2.0587122440338135, 10400: 0.4628664255142212, 10500: 0.6151939034461975, 10600: 0.6321329474449158, 10700: 1.6047990322113037, 10800: 0.15200042724609375, 10900: 0.3258320689201355, 11000: 1.6374421119689941, 11100: 1.5661163330078125, 11200: 0.35901540517807007, 11300: 0.4531925320625305, 11400: 1.4386800527572632, 11500: 0.5823414325714111, 11600: 0.6344362497329712, 11700: 0.7125269174575806, 11800: 1.3935104608535767, 11900: 0.5227215886116028, 12000: 1.757676362991333, 12100: 0.7619937062263489, 12200: 0.466387540102005, 12300: 0.6482782363891602, 12400: 0.603108823299408, 12500: 1.051418662071228, 12600: 0.4321242570877075, 12700: 0.4442812204360962, 12800: 0.6415926218032837, 12900: 1.284631609916687, 13000: 2.585810899734497, 13100: 2.8205652236938477, 13200: 0.8435799479484558, 13300: 2.0099167823791504, 13400: 0.5124024152755737, 13500: 1.2121868133544922, 13600: 1.435078501701355, 13700: 0.9914498329162598, 13800: 1.0098800659179688, 13900: 0.5936916470527649, 14000: 0.3735261559486389, 14100: 0.80594801902771, 14200: 1.0327668190002441, 14300: 1.2462918758392334, 14400: 0.6958798766136169, 14500: 2.149888515472412, 14600: 0.7823861837387085, 14700: 2.4276483058929443, 14800: 0.5023261308670044, 14900: 0.5608379244804382, 15000: 1.0316133499145508, 15100: 0.4404437243938446, 15200: 0.4811058044433594, 15300: 0.43041256070137024, 15400: 2.5046229362487793, 15500: 0.4801858067512512, 15600: 0.7531221508979797, 15700: 0.9675306677818298, 15800: 1.451573133468628, 15900: 0.7797315716743469, 16000: 1.2775475978851318, 16100: 0.8990800976753235, 16200: 0.4924733340740204, 16300: 1.4134595394134521, 16400: 0.5478847026824951, 16500: 1.8212894201278687, 16600: 0.3156430423259735, 16700: 0.4004010260105133, 16800: 0.6768494248390198, 16900: 0.3468700647354126, 17000: 1.3226768970489502, 17100: 0.49800434708595276, 17200: 4.288643836975098, 17300: 1.1576058864593506, 17400: 0.8015682697296143, 17500: 3.35421085357666, 17600: 0.6583523750305176, 17700: 0.5497828125953674, 17800: 0.2158292680978775, 17900: 0.8710851669311523, 18000: 0.39132335782051086, 18100: 0.2740460932254791}, 'F1': {1: 0.5896482075043358}, 'Accuracy': {1: 0.5243915868296443}}\n",
      "Epoch 2\n",
      "\n",
      "Epoch time: 93.61545825004578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.42      0.49       563\n",
      "           1       0.62      0.83      0.71       561\n",
      "           2       0.58      0.68      0.63       564\n",
      "           3       0.62      0.47      0.53       573\n",
      "           4       0.58      0.83      0.68       575\n",
      "           5       0.57      0.71      0.63       556\n",
      "           6       0.62      0.45      0.52       564\n",
      "           7       0.57      0.39      0.46       555\n",
      "           8       0.59      0.50      0.54       567\n",
      "           9       0.55      0.65      0.60       542\n",
      "          10       0.37      0.37      0.37      3461\n",
      "\n",
      "    accuracy                           0.51      9081\n",
      "   macro avg       0.57      0.57      0.56      9081\n",
      "weighted avg       0.51      0.51      0.50      9081\n",
      "\n",
      "Logger {'time': {0: 0.01560211181640625, 100: 0.579254150390625, 200: 1.1086490154266357, 300: 1.6079270839691162, 400: 2.136763095855713, 500: 2.6378509998321533, 600: 3.149334192276001, 700: 3.64827823638916, 800: 4.161570072174072, 900: 4.690189838409424, 1000: 5.1796650886535645, 1100: 5.692227840423584, 1200: 6.1926610469818115, 1300: 6.715204954147339, 1400: 7.269567012786865, 1500: 7.819048166275024, 1600: 8.315380096435547, 1700: 8.8353271484375, 1800: 9.338289022445679, 1900: 9.864889860153198, 2000: 10.358838081359863, 2100: 10.877515077590942, 2200: 11.357361078262329, 2300: 11.88470196723938, 2400: 12.384958982467651, 2500: 12.911899089813232, 2600: 13.414138078689575, 2700: 13.930563926696777, 2800: 14.462338924407959, 2900: 15.042736053466797, 3000: 15.609086990356445, 3100: 16.168519020080566, 3200: 16.690178155899048, 3300: 17.20719599723816, 3400: 17.71534299850464, 3500: 18.219057083129883, 3600: 18.703130960464478, 3700: 19.215058088302612, 3800: 19.718732118606567, 3900: 20.233592987060547, 4000: 20.730740070343018, 4100: 21.238807201385498, 4200: 21.74277901649475, 4300: 22.289788007736206, 4400: 22.81926989555359, 4500: 23.316434144973755, 4600: 23.845109224319458, 4700: 24.347312927246094, 4800: 24.865926027297974, 4900: 25.363367080688477, 5000: 25.887786149978638, 5100: 26.385338068008423, 5200: 26.924511194229126, 5300: 27.436361074447632, 5400: 27.960938215255737, 5500: 28.454555988311768, 5600: 28.975684881210327, 5700: 29.541311025619507, 5800: 30.074115991592407, 5900: 30.57117199897766, 6000: 31.074491024017334, 6100: 31.56812310218811, 6200: 32.10201811790466, 6300: 32.603201150894165, 6400: 33.112115144729614, 6500: 33.607654094696045, 6600: 34.11632800102234, 6700: 34.59939217567444, 6800: 35.090025186538696, 6900: 35.59068703651428, 7000: 36.08400917053223, 7100: 36.593530893325806, 7200: 37.12737703323364, 7300: 37.686213970184326, 7400: 38.18287491798401, 7500: 38.70662999153137, 7600: 39.216996908187866, 7700: 39.74286508560181, 7800: 40.23774003982544, 7900: 40.75277018547058, 8000: 41.25760102272034, 8100: 41.77703523635864, 8200: 42.26835894584656, 8300: 42.78462100028992, 8400: 43.28155517578125, 8500: 43.79955697059631, 8600: 44.29026699066162, 8700: 44.81890392303467, 8800: 45.314372062683105, 8900: 45.83166003227234, 9000: 46.33454608917236, 9100: 46.842702865600586, 9200: 47.352522134780884, 9300: 47.86543297767639, 9400: 48.381906032562256, 9500: 48.90194010734558, 9600: 49.40755796432495, 9700: 49.96759796142578, 9800: 50.47997188568115, 9900: 51.03796100616455, 10000: 51.56393098831177, 10100: 52.10414123535156, 10200: 52.66242790222168, 10300: 53.22631311416626, 10400: 53.762736082077026, 10500: 54.25980496406555, 10600: 54.78014397621155, 10700: 55.283775091171265, 10800: 55.81421613693237, 10900: 56.32036304473877, 11000: 56.83489394187927, 11100: 57.45815300941467, 11200: 57.987205028533936, 11300: 58.47835397720337, 11400: 58.99967122077942, 11500: 59.51640725135803, 11600: 60.03819394111633, 11700: 60.54310894012451, 11800: 61.06448793411255, 11900: 61.56362700462341, 12000: 62.08927607536316, 12100: 62.59852409362793, 12200: 63.12735390663147, 12300: 63.635119915008545, 12400: 64.14466500282288, 12500: 64.64143013954163, 12600: 65.14163994789124, 12700: 65.63317012786865, 12800: 66.14546489715576, 12900: 66.66493010520935, 13000: 67.17772912979126, 13100: 67.7564959526062, 13200: 68.26583099365234, 13300: 68.77705717086792, 13400: 69.30613303184509, 13500: 69.82030701637268, 13600: 70.33560419082642, 13700: 70.83798694610596, 13800: 71.33380699157715, 13900: 71.85789012908936, 14000: 72.36495184898376, 14100: 72.901211977005, 14200: 73.41073489189148, 14300: 73.92048001289368, 14400: 74.42058205604553, 14500: 74.9492039680481, 14600: 75.44186615943909, 14700: 75.95024800300598, 14800: 76.43768215179443, 14900: 76.98758006095886, 15000: 77.49351096153259, 15100: 78.0172529220581, 15200: 78.50647401809692, 15300: 79.01213026046753, 15400: 79.50894117355347, 15500: 80.03374814987183, 15600: 80.53227806091309, 15700: 81.06552720069885, 15800: 81.56446695327759, 15900: 82.06244587898254, 16000: 82.58289217948914, 16100: 83.0841429233551, 16200: 83.60180306434631, 16300: 84.09363317489624, 16400: 84.60291695594788, 16500: 85.11871290206909, 16600: 85.6549289226532, 16700: 86.15117716789246, 16800: 86.66033005714417, 16900: 87.15668797492981, 17000: 87.68607115745544, 17100: 88.18179416656494, 17200: 88.68756890296936, 17300: 89.19239091873169, 17400: 89.70444917678833, 17500: 90.20920991897583, 17600: 90.71991991996765, 17700: 91.22073292732239, 17800: 91.75516200065613, 17900: 92.25621318817139, 18000: 92.77400517463684, 18100: 93.26966905593872}, 'loss': {0: 0.5830358266830444, 100: 0.47576218843460083, 200: 0.3499809801578522, 300: 1.5875617265701294, 400: 0.9945048689842224, 500: 0.3268900513648987, 600: 0.3884609341621399, 700: 1.0545661449432373, 800: 1.0785415172576904, 900: 1.074173092842102, 1000: 1.9055501222610474, 1100: 1.6671550273895264, 1200: 0.3723192512989044, 1300: 0.44852352142333984, 1400: 0.34400707483291626, 1500: 0.3738871216773987, 1600: 0.19107279181480408, 1700: 1.289023756980896, 1800: 0.8137001395225525, 1900: 0.7233321070671082, 2000: 1.380365014076233, 2100: 0.6920239329338074, 2200: 1.213649034500122, 2300: 0.8294391632080078, 2400: 1.3413569927215576, 2500: 1.319521427154541, 2600: 1.5496987104415894, 2700: 0.42518505454063416, 2800: 1.9099488258361816, 2900: 0.7614796757698059, 3000: 0.3960057497024536, 3100: 0.6730829477310181, 3200: 0.39292892813682556, 3300: 0.9233822822570801, 3400: 0.9122870564460754, 3500: 0.6634944677352905, 3600: 1.017808198928833, 3700: 0.4407142102718353, 3800: 0.5316959619522095, 3900: 3.436323642730713, 4000: 0.4494813084602356, 4100: 1.9595125913619995, 4200: 0.5090519785881042, 4300: 0.6764136552810669, 4400: 0.8871229290962219, 4500: 1.0789625644683838, 4600: 1.02499520778656, 4700: 0.5232831835746765, 4800: 0.3386266529560089, 4900: 0.4584042429924011, 5000: 0.8967260122299194, 5100: 0.5522928237915039, 5200: 0.5890709161758423, 5300: 1.1513502597808838, 5400: 0.5806373953819275, 5500: 0.4716184437274933, 5600: 1.373178482055664, 5700: 0.8322034478187561, 5800: 0.5192708373069763, 5900: 1.7415368556976318, 6000: 0.4701506197452545, 6100: 0.3717002868652344, 6200: 0.6267561316490173, 6300: 3.3699636459350586, 6400: 0.4154830276966095, 6500: 1.6889429092407227, 6600: 0.5515397787094116, 6700: 0.9487762451171875, 6800: 0.5697120428085327, 6900: 0.3461524248123169, 7000: 0.41081637144088745, 7100: 1.1254456043243408, 7200: 1.0820691585540771, 7300: 0.2903086543083191, 7400: 0.29562389850616455, 7500: 0.25027042627334595, 7600: 0.5711959004402161, 7700: 0.7985886335372925, 7800: 2.1002817153930664, 7900: 1.085348129272461, 8000: 1.0235908031463623, 8100: 0.4380069077014923, 8200: 0.8045785427093506, 8300: 0.6560125946998596, 8400: 0.37899234890937805, 8500: 0.5375227928161621, 8600: 1.047724962234497, 8700: 0.38172000646591187, 8800: 1.2831040620803833, 8900: 0.5151970982551575, 9000: 0.6799408197402954, 9100: 0.545244574546814, 9200: 0.3342205584049225, 9300: 0.1182902604341507, 9400: 2.5392394065856934, 9500: 0.866399884223938, 9600: 0.8461405634880066, 9700: 1.4773600101470947, 9800: 4.048797607421875, 9900: 0.3169296383857727, 10000: 3.060755968093872, 10100: 0.4611603021621704, 10200: 0.5832222700119019, 10300: 0.23318852484226227, 10400: 1.2500033378601074, 10500: 0.589336097240448, 10600: 0.32840052247047424, 10700: 1.8131780624389648, 10800: 0.2008691430091858, 10900: 0.2340572327375412, 11000: 1.6378045082092285, 11100: 1.5996209383010864, 11200: 1.4450623989105225, 11300: 0.5970967411994934, 11400: 3.9076685905456543, 11500: 0.7240500450134277, 11600: 0.9118754863739014, 11700: 0.9751285314559937, 11800: 1.4914672374725342, 11900: 0.39410799741744995, 12000: 0.7720667719841003, 12100: 0.5637862682342529, 12200: 0.3934112787246704, 12300: 1.0796763896942139, 12400: 0.45386770367622375, 12500: 1.3809123039245605, 12600: 0.35168981552124023, 12700: 0.9499284029006958, 12800: 0.939376175403595, 12900: 1.3939752578735352, 13000: 1.5419676303863525, 13100: 0.9655153751373291, 13200: 1.167651653289795, 13300: 1.0510978698730469, 13400: 0.5659921765327454, 13500: 1.1212080717086792, 13600: 1.530766487121582, 13700: 1.239675760269165, 13800: 1.0538127422332764, 13900: 0.4757714569568634, 14000: 0.47222599387168884, 14100: 0.6515358090400696, 14200: 0.6876311302185059, 14300: 1.3860095739364624, 14400: 0.8714913129806519, 14500: 1.0523436069488525, 14600: 1.0349071025848389, 14700: 1.937727451324463, 14800: 0.5497026443481445, 14900: 0.8535277247428894, 15000: 0.7839351892471313, 15100: 1.0444809198379517, 15200: 0.9079657793045044, 15300: 0.6542157530784607, 15400: 1.7333905696868896, 15500: 1.1556810140609741, 15600: 0.9922189712524414, 15700: 0.7418608665466309, 15800: 1.398781418800354, 15900: 0.5364907383918762, 16000: 1.4127748012542725, 16100: 0.550523579120636, 16200: 0.6354143619537354, 16300: 0.42600342631340027, 16400: 0.572472870349884, 16500: 1.4780631065368652, 16600: 0.3773750960826874, 16700: 0.3470039665699005, 16800: 0.4645214080810547, 16900: 0.320701539516449, 17000: 0.8605836629867554, 17100: 0.4993058145046234, 17200: 3.918787956237793, 17300: 1.0954495668411255, 17400: 0.9642413854598999, 17500: 1.4164130687713623, 17600: 0.576447069644928, 17700: 1.5197710990905762, 17800: 0.3538568615913391, 17900: 0.7916910648345947, 18000: 0.22456970810890198, 18100: 0.3311401903629303}, 'F1': {2: 0.559986260430463}, 'Accuracy': {2: 0.5063319017729325}}\n",
      "Epoch 3\n",
      "\n",
      "Epoch time: 95.65631008148193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59       563\n",
      "           1       0.61      0.88      0.72       561\n",
      "           2       0.57      0.72      0.64       564\n",
      "           3       0.60      0.51      0.55       573\n",
      "           4       0.58      0.79      0.67       575\n",
      "           5       0.57      0.62      0.60       556\n",
      "           6       0.60      0.11      0.19       564\n",
      "           7       0.60      0.62      0.61       555\n",
      "           8       0.59      0.25      0.35       567\n",
      "           9       0.57      0.46      0.51       542\n",
      "          10       0.37      0.41      0.39      3461\n",
      "\n",
      "    accuracy                           0.50      9081\n",
      "   macro avg       0.57      0.54      0.53      9081\n",
      "weighted avg       0.51      0.50      0.48      9081\n",
      "\n",
      "Logger {'time': {0: 0.01110982894897461, 100: 0.5173170566558838, 200: 1.0397169589996338, 300: 1.5491399765014648, 400: 2.034482955932617, 500: 2.5474419593811035, 600: 3.0208089351654053, 700: 3.531592845916748, 800: 4.042130947113037, 900: 4.557988166809082, 1000: 5.053562879562378, 1100: 5.563355207443237, 1200: 6.055675745010376, 1300: 6.560267925262451, 1400: 7.059452772140503, 1500: 7.750732898712158, 1600: 8.363887071609497, 1700: 8.87910509109497, 1800: 9.420300960540771, 1900: 9.939925909042358, 2000: 10.439234972000122, 2100: 10.956934928894043, 2200: 11.468708038330078, 2300: 11.982693195343018, 2400: 12.503825902938843, 2500: 13.019237041473389, 2600: 13.522141933441162, 2700: 14.09506893157959, 2800: 14.600492000579834, 2900: 15.125399112701416, 3000: 15.629364967346191, 3100: 16.14772391319275, 3200: 16.63846182823181, 3300: 17.15235185623169, 3400: 17.658065795898438, 3500: 18.179705142974854, 3600: 18.69198989868164, 3700: 19.21368384361267, 3800: 19.715070962905884, 3900: 20.26293706893921, 4000: 20.824676990509033, 4100: 21.575330018997192, 4200: 22.583235025405884, 4300: 23.195284843444824, 4400: 23.83009099960327, 4500: 24.49077796936035, 4600: 25.033050060272217, 4700: 25.566127061843872, 4800: 26.10822081565857, 4900: 26.61453890800476, 5000: 27.122822761535645, 5100: 27.62069797515869, 5200: 28.140342950820923, 5300: 28.63553786277771, 5400: 29.15809392929077, 5500: 29.657290935516357, 5600: 30.173221826553345, 5700: 30.665324926376343, 5800: 31.178213119506836, 5900: 31.694241046905518, 6000: 32.19757318496704, 6100: 32.81709885597229, 6200: 33.510716915130615, 6300: 34.21545481681824, 6400: 34.83926296234131, 6500: 35.35599994659424, 6600: 35.84524989128113, 6700: 36.35896182060242, 6800: 36.86351299285889, 6900: 37.38717007637024, 7000: 37.88344383239746, 7100: 38.44590210914612, 7200: 38.94550704956055, 7300: 39.468777894973755, 7400: 39.958709955215454, 7500: 40.45623707771301, 7600: 40.95195293426514, 7700: 41.446211099624634, 7800: 41.96489191055298, 7900: 42.45692205429077, 8000: 42.966813802719116, 8100: 43.48973989486694, 8200: 44.0182409286499, 8300: 44.51901578903198, 8400: 45.029232025146484, 8500: 45.53310585021973, 8600: 46.03638505935669, 8700: 46.54110789299011, 8800: 47.06108999252319, 8900: 47.56712794303894, 9000: 48.07513904571533, 9100: 48.597641944885254, 9200: 49.11362886428833, 9300: 49.615520000457764, 9400: 50.161303997039795, 9500: 50.67202877998352, 9600: 51.30552911758423, 9700: 51.81361794471741, 9800: 52.39374303817749, 9900: 52.888181924819946, 10000: 53.417328119277954, 10100: 53.92429995536804, 10200: 54.4635488986969, 10300: 55.01337385177612, 10400: 55.53558897972107, 10500: 56.02980613708496, 10600: 56.560100078582764, 10700: 57.0585777759552, 10800: 57.56101083755493, 10900: 58.06605100631714, 11000: 58.61131501197815, 11100: 59.156699895858765, 11200: 59.67321181297302, 11300: 60.181880950927734, 11400: 60.68147611618042, 11500: 61.188271045684814, 11600: 61.6767258644104, 11700: 62.19369196891785, 11800: 62.682559967041016, 11900: 63.18999195098877, 12000: 63.690791845321655, 12100: 64.21030187606812, 12200: 64.70968079566956, 12300: 65.23860192298889, 12400: 65.74782991409302, 12500: 66.26484704017639, 12600: 66.88618278503418, 12700: 67.46814894676208, 12800: 67.98802495002747, 12900: 68.54567813873291, 13000: 69.05572605133057, 13100: 69.60039186477661, 13200: 70.09511590003967, 13300: 70.62179493904114, 13400: 71.11647582054138, 13500: 71.63517475128174, 13600: 72.14340996742249, 13700: 72.67703294754028, 13800: 73.20513606071472, 13900: 73.78469610214233, 14000: 74.2955870628357, 14100: 74.824697971344, 14200: 75.32574105262756, 14300: 75.83555793762207, 14400: 76.37084698677063, 14500: 76.8860399723053, 14600: 77.39209604263306, 14700: 77.90998697280884, 14800: 78.42180395126343, 14900: 78.91683888435364, 15000: 79.42705297470093, 15100: 79.92390489578247, 15200: 80.44568395614624, 15300: 80.9347231388092, 15400: 81.44210886955261, 15500: 81.93081188201904, 15600: 82.43620705604553, 15700: 82.93401193618774, 15800: 83.45856094360352, 15900: 83.95885682106018, 16000: 84.47803497314453, 16100: 85.05736494064331, 16200: 85.58566284179688, 16300: 86.08982610702515, 16400: 86.62129616737366, 16500: 87.15726494789124, 16600: 87.66619491577148, 16700: 88.17957496643066, 16800: 88.70553803443909, 16900: 89.20694184303284, 17000: 89.71724581718445, 17100: 90.21537899971008, 17200: 90.72462487220764, 17300: 91.2160587310791, 17400: 91.7158579826355, 17500: 92.2140998840332, 17600: 92.71052598953247, 17700: 93.22570896148682, 17800: 93.7749650478363, 17900: 94.29656910896301, 18000: 94.79339003562927, 18100: 95.30619788169861}, 'loss': {0: 0.4376446008682251, 100: 0.49134212732315063, 200: 0.31600213050842285, 300: 1.570303201675415, 400: 0.5340446829795837, 500: 0.27193236351013184, 600: 0.4953598082065582, 700: 1.6273868083953857, 800: 0.6089612245559692, 900: 3.1505863666534424, 1000: 1.8528742790222168, 1100: 1.5211312770843506, 1200: 0.31953322887420654, 1300: 1.0256690979003906, 1400: 0.3454294800758362, 1500: 0.3897973895072937, 1600: 0.21969637274742126, 1700: 1.2374025583267212, 1800: 0.839188277721405, 1900: 0.5613127946853638, 2000: 1.2779639959335327, 2100: 0.7927056550979614, 2200: 2.353668689727783, 2300: 2.743245840072632, 2400: 1.5301061868667603, 2500: 1.7322996854782104, 2600: 1.411543846130371, 2700: 0.5917097926139832, 2800: 2.4057888984680176, 2900: 0.9563788175582886, 3000: 0.44004958868026733, 3100: 1.582085132598877, 3200: 0.29883161187171936, 3300: 1.104315996170044, 3400: 0.7361559867858887, 3500: 0.49428001046180725, 3600: 0.431102991104126, 3700: 0.42788851261138916, 3800: 0.38363441824913025, 3900: 2.366253614425659, 4000: 0.4131653904914856, 4100: 1.8163766860961914, 4200: 0.6184184551239014, 4300: 0.7104626893997192, 4400: 1.0351688861846924, 4500: 1.1867032051086426, 4600: 3.115293264389038, 4700: 0.8382351994514465, 4800: 0.18623413145542145, 4900: 0.6549540758132935, 5000: 1.116581916809082, 5100: 0.7386509776115417, 5200: 0.5211476683616638, 5300: 0.670054018497467, 5400: 0.5511637926101685, 5500: 0.9895774126052856, 5600: 1.54305100440979, 5700: 0.6864598393440247, 5800: 0.5641334652900696, 5900: 0.6850232481956482, 6000: 0.40524885058403015, 6100: 0.3292652368545532, 6200: 0.6438760757446289, 6300: 3.1133928298950195, 6400: 0.4366278052330017, 6500: 1.6112134456634521, 6600: 1.3612242937088013, 6700: 1.1565228700637817, 6800: 0.6465515494346619, 6900: 0.46481361985206604, 7000: 0.835472822189331, 7100: 0.968961238861084, 7200: 1.1281222105026245, 7300: 0.28636059165000916, 7400: 0.2826234698295593, 7500: 0.2512804865837097, 7600: 0.739710807800293, 7700: 0.8099311590194702, 7800: 1.816541075706482, 7900: 0.889949381351471, 8000: 0.761537492275238, 8100: 0.4001663029193878, 8200: 1.0539848804473877, 8300: 0.8857531547546387, 8400: 0.49268582463264465, 8500: 0.7775357365608215, 8600: 0.6488338112831116, 8700: 1.1473443508148193, 8800: 1.2359304428100586, 8900: 0.6112697720527649, 9000: 0.621866762638092, 9100: 0.4271111786365509, 9200: 0.3893432915210724, 9300: 0.10872172564268112, 9400: 3.0398762226104736, 9500: 1.0451112985610962, 9600: 0.5872745513916016, 9700: 1.3740060329437256, 9800: 5.316903591156006, 9900: 0.6888514757156372, 10000: 4.442962169647217, 10100: 0.5959888100624084, 10200: 0.6730685234069824, 10300: 2.152961492538452, 10400: 0.5041677951812744, 10500: 0.5278490781784058, 10600: 0.4193747639656067, 10700: 1.0442992448806763, 10800: 0.40879330039024353, 10900: 0.4592724144458771, 11000: 0.6070863604545593, 11100: 1.3068151473999023, 11200: 2.2545387744903564, 11300: 0.5997740626335144, 11400: 3.674555778503418, 11500: 0.4601655602455139, 11600: 0.9995576739311218, 11700: 1.1768251657485962, 11800: 1.4589269161224365, 11900: 0.6074212789535522, 12000: 0.817002534866333, 12100: 0.9412479996681213, 12200: 0.5026262402534485, 12300: 1.0416536331176758, 12400: 0.31569111347198486, 12500: 1.8449594974517822, 12600: 0.31138408184051514, 12700: 0.29613110423088074, 12800: 0.49219828844070435, 12900: 1.413398027420044, 13000: 1.264749526977539, 13100: 1.5068904161453247, 13200: 1.834536075592041, 13300: 1.9568629264831543, 13400: 0.5002005100250244, 13500: 1.0683833360671997, 13600: 1.0951939821243286, 13700: 1.0477887392044067, 13800: 0.9396024942398071, 13900: 0.6255695223808289, 14000: 0.4077088236808777, 14100: 0.45958903431892395, 14200: 0.7194935083389282, 14300: 1.591487169265747, 14400: 1.603200912475586, 14500: 3.1652419567108154, 14600: 1.647740364074707, 14700: 0.9791848063468933, 14800: 0.5767410397529602, 14900: 0.33309313654899597, 15000: 1.1648714542388916, 15100: 0.7121233940124512, 15200: 0.6833761930465698, 15300: 0.6941912770271301, 15400: 3.5491600036621094, 15500: 0.8825695514678955, 15600: 0.756544291973114, 15700: 1.0220680236816406, 15800: 1.3252618312835693, 15900: 0.8716861009597778, 16000: 1.398612141609192, 16100: 0.9233031272888184, 16200: 0.5164312124252319, 16300: 0.7432718873023987, 16400: 0.3406982719898224, 16500: 1.4104621410369873, 16600: 0.24508552253246307, 16700: 1.1119298934936523, 16800: 0.5139635801315308, 16900: 0.4604923725128174, 17000: 1.1921745538711548, 17100: 0.07470216602087021, 17200: 2.371433973312378, 17300: 0.9519707560539246, 17400: 0.7549272179603577, 17500: 1.3807324171066284, 17600: 0.5524302124977112, 17700: 1.008789300918579, 17800: 0.30018362402915955, 17900: 0.7024087905883789, 18000: 0.31394606828689575, 18100: 0.3735062777996063}, 'F1': {3: 0.5286477789966801}, 'Accuracy': {3: 0.49939433983041515}}\n",
      "Epoch 4\n",
      "\n",
      "Epoch time: 116.56786108016968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64       563\n",
      "           1       0.61      0.86      0.71       561\n",
      "           2       0.57      0.66      0.61       564\n",
      "           3       0.64      0.45      0.53       573\n",
      "           4       0.56      0.81      0.66       575\n",
      "           5       0.58      0.70      0.64       556\n",
      "           6       0.62      0.46      0.53       564\n",
      "           7       0.61      0.64      0.63       555\n",
      "           8       0.60      0.60      0.60       567\n",
      "           9       0.54      0.62      0.57       542\n",
      "          10       0.38      0.31      0.34      3461\n",
      "\n",
      "    accuracy                           0.52      9081\n",
      "   macro avg       0.57      0.62      0.59      9081\n",
      "weighted avg       0.51      0.52      0.51      9081\n",
      "\n",
      "Logger {'time': {0: 0.017364025115966797, 100: 0.577049970626831, 200: 1.0929510593414307, 300: 1.6033308506011963, 400: 2.103811025619507, 500: 2.6118369102478027, 600: 3.142732858657837, 700: 3.651304006576538, 800: 4.15869402885437, 900: 4.677434921264648, 1000: 5.174628973007202, 1100: 5.698544025421143, 1200: 6.217361927032471, 1300: 6.726059198379517, 1400: 7.251585006713867, 1500: 7.759926080703735, 1600: 8.276805877685547, 1700: 8.797484159469604, 1800: 9.298724889755249, 1900: 9.882121086120605, 2000: 10.381599187850952, 2100: 10.899311065673828, 2200: 11.397017002105713, 2300: 11.9100661277771, 2400: 12.42061710357666, 2500: 12.922876119613647, 2600: 13.429528951644897, 2700: 13.945029973983765, 2800: 14.443287134170532, 2900: 14.939698934555054, 3000: 15.448307991027832, 3100: 15.964193105697632, 3200: 16.482903957366943, 3300: 16.9980571269989, 3400: 17.507711172103882, 3500: 18.013707160949707, 3600: 18.5283842086792, 3700: 19.041239976882935, 3800: 19.563579082489014, 3900: 20.07000708580017, 4000: 20.571730136871338, 4100: 21.08200716972351, 4200: 21.603488206863403, 4300: 22.119345903396606, 4400: 22.623597860336304, 4500: 23.134688138961792, 4600: 23.620426177978516, 4700: 24.175692796707153, 4800: 24.667407989501953, 4900: 25.17417001724243, 5000: 25.670592069625854, 5100: 26.182734966278076, 5200: 26.680373191833496, 5300: 27.226914167404175, 5400: 27.72398591041565, 5500: 28.265668869018555, 5600: 28.77914309501648, 5700: 29.29497003555298, 5800: 29.78552508354187, 5900: 30.297502994537354, 6000: 30.809329986572266, 6100: 31.317716121673584, 6200: 31.81545615196228, 6300: 32.324337005615234, 6400: 32.81729602813721, 6500: 33.42223501205444, 6600: 33.99465823173523, 6700: 34.54869198799133, 6800: 35.05604004859924, 6900: 35.56851100921631, 7000: 36.05951404571533, 7100: 36.57662081718445, 7200: 37.31925415992737, 7300: 38.01550912857056, 7400: 38.55759406089783, 7500: 39.237870931625366, 7600: 39.908074140548706, 7700: 40.98861598968506, 7800: 41.589690923690796, 7900: 43.00999212265015, 8000: 43.751587867736816, 8100: 44.497068881988525, 8200: 45.2523980140686, 8300: 46.21795415878296, 8400: 46.812386989593506, 8500: 47.41955900192261, 8600: 48.25370812416077, 8700: 49.28981900215149, 8800: 50.29440116882324, 8900: 51.40613579750061, 9000: 52.341166973114014, 9100: 53.34106802940369, 9200: 53.978955030441284, 9300: 54.64972901344299, 9400: 55.17333507537842, 9500: 55.66423201560974, 9600: 56.17662024497986, 9700: 56.67859220504761, 9800: 57.1964750289917, 9900: 57.67817711830139, 10000: 58.210920095443726, 10100: 58.69818615913391, 10200: 59.22718286514282, 10300: 59.78483200073242, 10400: 60.29409384727478, 10500: 61.10606098175049, 10600: 61.65020704269409, 10700: 62.19363808631897, 10800: 62.7083899974823, 10900: 63.41041398048401, 11000: 64.11014199256897, 11100: 64.66197299957275, 11200: 65.16541290283203, 11300: 65.66802597045898, 11400: 66.17231798171997, 11500: 66.66903519630432, 11600: 67.16898488998413, 11700: 67.67734694480896, 11800: 68.18322396278381, 11900: 68.7510290145874, 12000: 69.28997683525085, 12100: 69.84423995018005, 12200: 70.41491198539734, 12300: 70.92826890945435, 12400: 71.42215514183044, 12500: 71.94102311134338, 12600: 72.59589695930481, 12700: 73.4754068851471, 12800: 74.5571129322052, 12900: 75.4934401512146, 13000: 76.47185015678406, 13100: 77.4593391418457, 13200: 78.05559802055359, 13300: 78.58809208869934, 13400: 79.09411311149597, 13500: 79.60258913040161, 13600: 80.10457611083984, 13700: 80.60115694999695, 13800: 81.17624092102051, 13900: 81.75901293754578, 14000: 82.34994792938232, 14100: 82.89168119430542, 14200: 83.41632795333862, 14300: 83.98426604270935, 14400: 84.4910659790039, 14500: 85.06372690200806, 14600: 86.05668807029724, 14700: 86.98669695854187, 14800: 87.99917602539062, 14900: 88.59862303733826, 15000: 89.14595603942871, 15100: 89.62275910377502, 15200: 90.2110869884491, 15300: 91.25283098220825, 15400: 91.96133208274841, 15500: 92.66988396644592, 15600: 93.26175713539124, 15700: 93.85860109329224, 15800: 94.87550711631775, 15900: 95.84202980995178, 16000: 96.98481607437134, 16100: 97.71859908103943, 16200: 98.70964479446411, 16300: 99.41722512245178, 16400: 100.39920711517334, 16500: 101.46491503715515, 16600: 102.47122311592102, 16700: 103.4772219657898, 16800: 104.03981399536133, 16900: 105.07316493988037, 17000: 106.11385798454285, 17100: 107.14296412467957, 17200: 108.26215100288391, 17300: 109.31694388389587, 17400: 110.16983294487, 17500: 111.09830403327942, 17600: 111.97736096382141, 17700: 113.0311930179596, 17800: 114.04368996620178, 17900: 114.59289717674255, 18000: 115.11734414100647, 18100: 115.91353106498718}, 'loss': {0: 0.5312244892120361, 100: 0.5119563937187195, 200: 0.40896302461624146, 300: 1.1927772760391235, 400: 1.0004119873046875, 500: 0.25860556960105896, 600: 0.2657877504825592, 700: 1.4600286483764648, 800: 0.6016188859939575, 900: 3.1038527488708496, 1000: 1.2492380142211914, 1100: 1.8623756170272827, 1200: 0.27064743638038635, 1300: 1.2409353256225586, 1400: 0.22642670571804047, 1500: 0.6497810482978821, 1600: 0.2239627093076706, 1700: 1.328037977218628, 1800: 0.813891589641571, 1900: 0.5993128418922424, 2000: 1.5033742189407349, 2100: 0.4753050208091736, 2200: 2.1984803676605225, 2300: 0.32894501090049744, 2400: 2.106855869293213, 2500: 0.4557224214076996, 2600: 1.9006184339523315, 2700: 0.20484396815299988, 2800: 0.9496560096740723, 2900: 0.9255990386009216, 3000: 0.5354849696159363, 3100: 1.1349372863769531, 3200: 0.38544657826423645, 3300: 0.6989568471908569, 3400: 1.229750633239746, 3500: 0.8549533486366272, 3600: 0.9090747237205505, 3700: 0.4926888942718506, 3800: 0.46890175342559814, 3900: 2.302577018737793, 4000: 0.7190983891487122, 4100: 1.444104790687561, 4200: 0.8025938272476196, 4300: 0.752909779548645, 4400: 1.1971064805984497, 4500: 0.9260149002075195, 4600: 1.30088210105896, 4700: 1.239047646522522, 4800: 0.11840993165969849, 4900: 0.5367781519889832, 5000: 0.7822928428649902, 5100: 0.6035234332084656, 5200: 0.6463468074798584, 5300: 1.191030740737915, 5400: 0.5384782552719116, 5500: 0.6755303740501404, 5600: 1.4877160787582397, 5700: 0.828148365020752, 5800: 0.4710208773612976, 5900: 0.9230921864509583, 6000: 0.4114115834236145, 6100: 0.38261881470680237, 6200: 0.47347813844680786, 6300: 3.1734845638275146, 6400: 0.42288756370544434, 6500: 1.286744236946106, 6600: 1.0416293144226074, 6700: 1.0747859477996826, 6800: 0.7496559619903564, 6900: 0.8790455460548401, 7000: 0.9069629907608032, 7100: 0.39550676941871643, 7200: 0.7035417556762695, 7300: 0.468516081571579, 7400: 0.16892553865909576, 7500: 1.2924481630325317, 7600: 0.8069865107536316, 7700: 0.798893392086029, 7800: 1.0734959840774536, 7900: 0.7886528968811035, 8000: 0.4731505215167999, 8100: 0.48343855142593384, 8200: 0.9199000000953674, 8300: 0.47301560640335083, 8400: 0.7040479183197021, 8500: 0.6804916858673096, 8600: 0.6080037355422974, 8700: 0.6873155236244202, 8800: 1.1941540241241455, 8900: 0.6372169256210327, 9000: 0.906261682510376, 9100: 0.34800732135772705, 9200: 0.5694229602813721, 9300: 0.22563335299491882, 9400: 6.0440802574157715, 9500: 0.7947785258293152, 9600: 1.4553499221801758, 9700: 1.167799711227417, 9800: 4.058145046234131, 9900: 1.0768449306488037, 10000: 5.1240057945251465, 10100: 0.07684186100959778, 10200: 1.131211757659912, 10300: 0.46870192885398865, 10400: 0.4998888373374939, 10500: 0.5664201378822327, 10600: 0.38054588437080383, 10700: 1.2469521760940552, 10800: 0.25748538970947266, 10900: 0.6045985817909241, 11000: 0.8181493282318115, 11100: 1.0665223598480225, 11200: 0.45610886812210083, 11300: 0.2916047275066376, 11400: 0.9838537573814392, 11500: 0.6884695291519165, 11600: 0.7118586897850037, 11700: 0.5951501727104187, 11800: 1.7325252294540405, 11900: 0.5366881489753723, 12000: 0.6622611284255981, 12100: 0.8757179379463196, 12200: 0.3403901755809784, 12300: 0.8007482290267944, 12400: 0.4217556416988373, 12500: 1.1385126113891602, 12600: 0.43594032526016235, 12700: 0.5586094856262207, 12800: 0.49467188119888306, 12900: 1.0627107620239258, 13000: 0.9014214873313904, 13100: 0.6972824335098267, 13200: 1.0758721828460693, 13300: 2.099478006362915, 13400: 0.7195761799812317, 13500: 1.371950626373291, 13600: 1.5139663219451904, 13700: 1.2034071683883667, 13800: 0.788342297077179, 13900: 0.6313304901123047, 14000: 0.39092156291007996, 14100: 0.7851587533950806, 14200: 0.876689612865448, 14300: 1.2827068567276, 14400: 0.767385721206665, 14500: 1.8794550895690918, 14600: 1.197596788406372, 14700: 1.414232611656189, 14800: 0.5892335772514343, 14900: 0.771804690361023, 15000: 0.8728184103965759, 15100: 1.2964314222335815, 15200: 0.6773584485054016, 15300: 0.6155491471290588, 15400: 3.470742702484131, 15500: 0.8841658234596252, 15600: 0.8242307305335999, 15700: 1.073141098022461, 15800: 1.6399681568145752, 15900: 0.9375468492507935, 16000: 1.275752067565918, 16100: 0.7860880494117737, 16200: 0.5796124935150146, 16300: 3.389486312866211, 16400: 0.3188122510910034, 16500: 1.3771919012069702, 16600: 0.4229928255081177, 16700: 0.49904778599739075, 16800: 0.43951281905174255, 16900: 0.5292412638664246, 17000: 0.9483733773231506, 17100: 0.43813246488571167, 17200: 1.7737805843353271, 17300: 1.1062206029891968, 17400: 0.9264066815376282, 17500: 3.1470205783843994, 17600: 1.0271835327148438, 17700: 1.9613008499145508, 17800: 0.326938271522522, 17900: 0.8361755609512329, 18000: 0.17368824779987335, 18100: 0.40631726384162903}, 'F1': {4: 0.5876305822368135}, 'Accuracy': {4: 0.5220790661821385}}\n",
      "Epoch 5\n",
      "\n",
      "Epoch time: 102.93317365646362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       563\n",
      "           1       0.62      0.86      0.72       561\n",
      "           2       0.57      0.72      0.64       564\n",
      "           3       0.60      0.54      0.57       573\n",
      "           4       0.59      0.85      0.70       575\n",
      "           5       0.54      0.64      0.59       556\n",
      "           6       0.60      0.40      0.48       564\n",
      "           7       0.62      0.50      0.55       555\n",
      "           8       0.61      0.65      0.63       567\n",
      "           9       0.57      0.49      0.53       542\n",
      "          10       0.38      0.35      0.37      3461\n",
      "\n",
      "    accuracy                           0.52      9081\n",
      "   macro avg       0.57      0.59      0.58      9081\n",
      "weighted avg       0.51      0.52      0.51      9081\n",
      "\n",
      "Logger {'time': {0: 0.01760268211364746, 100: 0.9131326675415039, 200: 1.4654719829559326, 300: 1.9907658100128174, 400: 3.1012117862701416, 500: 3.6671879291534424, 600: 4.202247858047485, 700: 4.694310903549194, 800: 5.201761722564697, 900: 5.685345649719238, 1000: 6.181451797485352, 1100: 6.676548719406128, 1200: 7.182585716247559, 1300: 7.672310829162598, 1400: 8.452234029769897, 1500: 9.03512978553772, 1600: 9.560874700546265, 1700: 10.04410982131958, 1800: 10.560464859008789, 1900: 11.049904823303223, 2000: 11.563969850540161, 2100: 12.066873788833618, 2200: 12.594275712966919, 2300: 13.115409851074219, 2400: 13.636940717697144, 2500: 14.137954711914062, 2600: 14.641835689544678, 2700: 15.461463689804077, 2800: 16.474267959594727, 2900: 17.492496967315674, 3000: 18.423301935195923, 3100: 19.12939763069153, 3200: 19.656012773513794, 3300: 20.291350841522217, 3400: 20.80996584892273, 3500: 21.319236755371094, 3600: 22.196810960769653, 3700: 22.709105968475342, 3800: 23.264927864074707, 3900: 23.765808820724487, 4000: 24.31408166885376, 4100: 24.886530876159668, 4200: 25.48934292793274, 4300: 26.02766489982605, 4400: 26.635342836380005, 4500: 27.223597764968872, 4600: 27.90388584136963, 4700: 28.459438800811768, 4800: 28.98332190513611, 4900: 29.511700868606567, 5000: 30.014325618743896, 5100: 30.52816677093506, 5200: 31.032548904418945, 5300: 31.535895824432373, 5400: 32.04408097267151, 5500: 32.551050901412964, 5600: 33.13652682304382, 5700: 33.65079092979431, 5800: 34.16323471069336, 5900: 34.65953779220581, 6000: 35.20803093910217, 6100: 35.748103857040405, 6200: 36.345865964889526, 6300: 36.86662292480469, 6400: 37.445212841033936, 6500: 38.0565767288208, 6600: 38.64041781425476, 6700: 39.2756826877594, 6800: 39.923900842666626, 6900: 41.37600374221802, 7000: 42.22592067718506, 7100: 42.93101978302002, 7200: 43.52437472343445, 7300: 44.054468870162964, 7400: 44.575132846832275, 7500: 45.07364082336426, 7600: 45.58889389038086, 7700: 46.14180898666382, 7800: 46.66343879699707, 7900: 47.156898736953735, 8000: 47.698856830596924, 8100: 48.203558921813965, 8200: 48.697595834732056, 8300: 49.208690881729126, 8400: 49.701472759246826, 8500: 50.24976181983948, 8600: 50.81830286979675, 8700: 51.41608285903931, 8800: 52.04046273231506, 8900: 52.604032039642334, 9000: 53.145914793014526, 9100: 53.65451765060425, 9200: 54.168375730514526, 9300: 54.666138887405396, 9400: 55.19706869125366, 9500: 55.70123767852783, 9600: 56.2171630859375, 9700: 56.730875968933105, 9800: 57.25194501876831, 9900: 57.756112813949585, 10000: 58.26075482368469, 10100: 58.81705093383789, 10200: 59.335097789764404, 10300: 59.85429382324219, 10400: 60.34146785736084, 10500: 60.84935784339905, 10600: 61.355517864227295, 10700: 61.86018180847168, 10800: 62.36455988883972, 10900: 62.874021768569946, 11000: 63.389222860336304, 11100: 63.90295672416687, 11200: 64.41088700294495, 11300: 64.92066097259521, 11400: 65.44732284545898, 11500: 65.96412968635559, 11600: 66.50976371765137, 11700: 67.069091796875, 11800: 67.66360783576965, 11900: 68.25492978096008, 12000: 68.76001691818237, 12100: 69.27495980262756, 12200: 69.7703607082367, 12300: 70.28760075569153, 12400: 70.79025793075562, 12500: 71.34601664543152, 12600: 71.97589373588562, 12700: 72.675363779068, 12800: 73.37505173683167, 12900: 74.05730271339417, 13000: 74.71385669708252, 13100: 75.28517985343933, 13200: 75.81323385238647, 13300: 76.32670497894287, 13400: 76.84236598014832, 13500: 77.35441279411316, 13600: 77.87261176109314, 13700: 78.37545394897461, 13800: 78.88018798828125, 13900: 79.37407183647156, 14000: 79.87885594367981, 14100: 80.37827277183533, 14200: 80.88904571533203, 14300: 81.39954471588135, 14400: 81.90592694282532, 14500: 82.41464686393738, 14600: 82.92150783538818, 14700: 83.43127083778381, 14800: 83.9247670173645, 14900: 84.43576979637146, 15000: 84.92216873168945, 15100: 85.45616173744202, 15200: 86.07068490982056, 15300: 86.67890286445618, 15400: 87.25564074516296, 15500: 87.83639287948608, 15600: 88.47753500938416, 15700: 89.03850078582764, 15800: 89.56385684013367, 15900: 90.0511839389801, 16000: 90.5903570652008, 16100: 91.16350388526917, 16200: 91.68444180488586, 16300: 92.30150890350342, 16400: 92.84755086898804, 16500: 93.41482877731323, 16600: 93.98562574386597, 16700: 94.57197904586792, 16800: 95.26051092147827, 16900: 95.8297438621521, 17000: 96.33106684684753, 17100: 96.85005378723145, 17200: 97.44202089309692, 17300: 98.03805088996887, 17400: 98.68484878540039, 17500: 99.2562837600708, 17600: 99.75844383239746, 17700: 100.28213286399841, 17800: 100.91373801231384, 17900: 101.50001573562622, 18000: 102.04333090782166, 18100: 102.58913373947144}, 'loss': {0: 0.30330294370651245, 100: 0.5498080253601074, 200: 0.3202301561832428, 300: 1.3104290962219238, 400: 0.7946544289588928, 500: 0.7235535979270935, 600: 0.38625550270080566, 700: 1.31714928150177, 800: 0.26201578974723816, 900: 2.0772547721862793, 1000: 1.2754038572311401, 1100: 2.569411039352417, 1200: 0.34824422001838684, 1300: 0.8711538910865784, 1400: 0.32519400119781494, 1500: 0.7448399662971497, 1600: 0.33122363686561584, 1700: 1.3294880390167236, 1800: 3.229804039001465, 1900: 0.6943885684013367, 2000: 1.041390299797058, 2100: 1.1766366958618164, 2200: 2.0186753273010254, 2300: 0.5109660029411316, 2400: 1.0424041748046875, 2500: 0.47605884075164795, 2600: 1.870566725730896, 2700: 0.11516304314136505, 2800: 1.3279547691345215, 2900: 0.8361050486564636, 3000: 0.5935598015785217, 3100: 0.9762182235717773, 3200: 0.35068219900131226, 3300: 0.9015578627586365, 3400: 0.9202430844306946, 3500: 0.7691895961761475, 3600: 0.8494372963905334, 3700: 0.549699604511261, 3800: 0.4525202214717865, 3900: 1.6420291662216187, 4000: 0.45519527792930603, 4100: 1.9842448234558105, 4200: 0.7401408553123474, 4300: 0.6242889761924744, 4400: 0.911777675151825, 4500: 0.43642425537109375, 4600: 0.982516348361969, 4700: 0.2747929096221924, 4800: 0.4706788957118988, 4900: 0.4997997283935547, 5000: 0.8560408353805542, 5100: 0.8678337335586548, 5200: 0.5065152049064636, 5300: 1.2842820882797241, 5400: 0.6268529295921326, 5500: 0.7686823606491089, 5600: 1.416689157485962, 5700: 0.6346887350082397, 5800: 0.3859867453575134, 5900: 1.6140568256378174, 6000: 0.38482561707496643, 6100: 0.28707581758499146, 6200: 0.36893004179000854, 6300: 3.545196771621704, 6400: 0.3794108033180237, 6500: 1.7826591730117798, 6600: 1.0621724128723145, 6700: 1.2130001783370972, 6800: 0.7652158141136169, 6900: 1.0286130905151367, 7000: 0.6036948561668396, 7100: 0.44621509313583374, 7200: 1.1019837856292725, 7300: 0.4207955002784729, 7400: 0.25668865442276, 7500: 0.2673785090446472, 7600: 0.48626708984375, 7700: 0.27551719546318054, 7800: 1.8057878017425537, 7900: 0.8381117582321167, 8000: 0.5451096296310425, 8100: 0.506375789642334, 8200: 0.9509295225143433, 8300: 0.4175018072128296, 8400: 0.9296827912330627, 8500: 1.0444891452789307, 8600: 0.8654050230979919, 8700: 0.3720366954803467, 8800: 0.44825980067253113, 8900: 0.9520293474197388, 9000: 0.885933518409729, 9100: 0.6947392821311951, 9200: 0.5176917910575867, 9300: 0.46579962968826294, 9400: 4.715569972991943, 9500: 1.1412557363510132, 9600: 1.2645703554153442, 9700: 1.1241254806518555, 9800: 2.8397064208984375, 9900: 0.6129559278488159, 10000: 4.701437950134277, 10100: 0.52970951795578, 10200: 0.6284037828445435, 10300: 0.5225687623023987, 10400: 0.3957621455192566, 10500: 0.3868371844291687, 10600: 0.5414109230041504, 10700: 0.9611456990242004, 10800: 0.3388132154941559, 10900: 0.22848926484584808, 11000: 0.5818788409233093, 11100: 1.6170337200164795, 11200: 0.37327396869659424, 11300: 0.44144415855407715, 11400: 2.5088748931884766, 11500: 0.48163485527038574, 11600: 0.9887957572937012, 11700: 0.9048604965209961, 11800: 1.6015970706939697, 11900: 0.28175315260887146, 12000: 0.8164566159248352, 12100: 0.5685021281242371, 12200: 0.26750898361206055, 12300: 0.6655463576316833, 12400: 0.41120877861976624, 12500: 0.6207478046417236, 12600: 2.1579930782318115, 12700: 0.81215500831604, 12800: 0.7224109172821045, 12900: 1.42567777633667, 13000: 1.1195366382598877, 13100: 2.785214424133301, 13200: 1.0605454444885254, 13300: 1.4354991912841797, 13400: 0.3688471019268036, 13500: 1.1813206672668457, 13600: 1.3941574096679688, 13700: 1.0239211320877075, 13800: 0.8780134320259094, 13900: 0.6769641637802124, 14000: 0.34706220030784607, 14100: 0.9082255959510803, 14200: 1.3571264743804932, 14300: 1.345933437347412, 14400: 0.6092349290847778, 14500: 2.339869976043701, 14600: 2.1742031574249268, 14700: 0.8549003005027771, 14800: 0.6582959890365601, 14900: 0.5781948566436768, 15000: 1.1742750406265259, 15100: 0.440121054649353, 15200: 0.6399236917495728, 15300: 0.700417697429657, 15400: 2.898099184036255, 15500: 0.6718276143074036, 15600: 0.9394868612289429, 15700: 0.9385238289833069, 15800: 1.4307787418365479, 15900: 0.8291481137275696, 16000: 1.942022442817688, 16100: 0.8489848375320435, 16200: 0.46616220474243164, 16300: 2.40852427482605, 16400: 0.3643420338630676, 16500: 1.3866655826568604, 16600: 0.333466112613678, 16700: 0.4398510158061981, 16800: 0.5427455306053162, 16900: 0.21915487945079803, 17000: 0.9257312417030334, 17100: 0.7605307698249817, 17200: 1.807152509689331, 17300: 0.8375735878944397, 17400: 0.8564587235450745, 17500: 4.184256076812744, 17600: 0.6781775951385498, 17700: 0.9019290208816528, 17800: 0.32771381735801697, 17900: 0.8231803774833679, 18000: 0.3923392593860626, 18100: 0.19578240811824799}, 'F1': {5: 0.5757094058589444}, 'Accuracy': {5: 0.5178945050104614}}\n",
      "Epoch 6\n",
      "\n",
      "Epoch time: 105.27547526359558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.36      0.46       563\n",
      "           1       0.61      0.56      0.59       561\n",
      "           2       0.59      0.57      0.58       564\n",
      "           3       0.61      0.50      0.55       573\n",
      "           4       0.56      0.60      0.58       575\n",
      "           5       0.55      0.67      0.61       556\n",
      "           6       0.63      0.35      0.46       564\n",
      "           7       0.60      0.65      0.63       555\n",
      "           8       0.55      0.65      0.60       567\n",
      "           9       0.57      0.64      0.60       542\n",
      "          10       0.37      0.41      0.39      3461\n",
      "\n",
      "    accuracy                           0.50      9081\n",
      "   macro avg       0.57      0.54      0.55      9081\n",
      "weighted avg       0.51      0.50      0.50      9081\n",
      "\n",
      "Logger {'time': {0: 0.01607036590576172, 100: 0.5560550689697266, 200: 1.091874122619629, 300: 1.590515375137329, 400: 2.13661527633667, 500: 2.633113145828247, 600: 3.1574814319610596, 700: 3.662391185760498, 800: 4.178069353103638, 900: 4.685213327407837, 1000: 5.192194223403931, 1100: 5.687098264694214, 1200: 6.252627372741699, 1300: 6.793060302734375, 1400: 7.386345386505127, 1500: 7.956039190292358, 1600: 8.54269528388977, 1700: 9.106945037841797, 1800: 9.677370309829712, 1900: 10.204321146011353, 2000: 10.721992254257202, 2100: 11.279520034790039, 2200: 11.799612283706665, 2300: 12.31153416633606, 2400: 12.82016110420227, 2500: 13.423932313919067, 2600: 14.085216045379639, 2700: 14.626244306564331, 2800: 15.23293423652649, 2900: 15.785131216049194, 3000: 16.28473424911499, 3100: 16.855895042419434, 3200: 17.410327196121216, 3300: 17.976264238357544, 3400: 18.59375834465027, 3500: 19.122214317321777, 3600: 19.682968139648438, 3700: 20.213096380233765, 3800: 20.772855043411255, 3900: 21.288324117660522, 4000: 21.80364227294922, 4100: 22.336790084838867, 4200: 22.830236196517944, 4300: 23.343868255615234, 4400: 23.838305234909058, 4500: 24.370561122894287, 4600: 24.88139009475708, 4700: 25.40012812614441, 4800: 25.900298357009888, 4900: 26.44693422317505, 5000: 27.00752830505371, 5100: 27.556275367736816, 5200: 28.05385112762451, 5300: 28.555066108703613, 5400: 29.07570219039917, 5500: 29.596150159835815, 5600: 30.092400312423706, 5700: 30.656413316726685, 5800: 31.195014238357544, 5900: 31.810559272766113, 6000: 32.450857400894165, 6100: 33.068297386169434, 6200: 33.66877222061157, 6300: 34.28137826919556, 6400: 34.848700284957886, 6500: 35.37489724159241, 6600: 35.91786217689514, 6700: 36.50220012664795, 6800: 37.08747434616089, 6900: 37.65251612663269, 7000: 38.30714702606201, 7100: 38.82366323471069, 7200: 39.35861825942993, 7300: 39.879178285598755, 7400: 40.51297116279602, 7500: 41.01757740974426, 7600: 41.53851628303528, 7700: 42.049660205841064, 7800: 42.61409115791321, 7900: 43.162941217422485, 8000: 43.70126533508301, 8100: 44.23282527923584, 8200: 44.74632430076599, 8300: 45.246676445007324, 8400: 45.78945326805115, 8500: 46.3112051486969, 8600: 46.81705713272095, 8700: 47.325318336486816, 8800: 47.864524126052856, 8900: 48.41167426109314, 9000: 48.92260932922363, 9100: 49.4698212146759, 9200: 50.022953271865845, 9300: 50.603360176086426, 9400: 51.12672734260559, 9500: 51.623780250549316, 9600: 52.16162323951721, 9700: 52.69104218482971, 9800: 53.40679430961609, 9900: 54.02451038360596, 10000: 54.68907022476196, 10100: 55.6376051902771, 10200: 56.42902612686157, 10300: 56.95584321022034, 10400: 57.501376152038574, 10500: 58.1101713180542, 10600: 58.68366312980652, 10700: 59.34729814529419, 10800: 60.041542291641235, 10900: 60.851017236709595, 11000: 61.53170323371887, 11100: 62.29998326301575, 11200: 62.97553038597107, 11300: 63.77309226989746, 11400: 64.5147693157196, 11500: 65.2331292629242, 11600: 65.78047108650208, 11700: 66.43336725234985, 11800: 67.0542562007904, 11900: 67.59070014953613, 12000: 68.21003818511963, 12100: 68.77608442306519, 12200: 69.39361429214478, 12300: 69.99899911880493, 12400: 70.65849423408508, 12500: 71.24907326698303, 12600: 71.86289715766907, 12700: 72.5504744052887, 12800: 73.16128921508789, 12900: 73.8409411907196, 13000: 74.49768018722534, 13100: 75.18915033340454, 13200: 75.84742140769958, 13300: 76.51022934913635, 13400: 77.06640625, 13500: 77.56683802604675, 13600: 78.4001841545105, 13700: 79.18076419830322, 13800: 79.85376214981079, 13900: 80.43663620948792, 14000: 81.03236627578735, 14100: 81.68421125411987, 14200: 82.27588033676147, 14300: 82.8165671825409, 14400: 83.34902334213257, 14500: 83.85257720947266, 14600: 84.39869117736816, 14700: 85.0448751449585, 14800: 85.631343126297, 14900: 86.1568672657013, 15000: 86.73979640007019, 15100: 87.28700423240662, 15200: 87.85817527770996, 15300: 88.45381927490234, 15400: 89.01291704177856, 15500: 89.77901911735535, 15600: 90.41467118263245, 15700: 91.04040431976318, 15800: 91.65547013282776, 15900: 92.29169511795044, 16000: 92.9173092842102, 16100: 93.55773425102234, 16200: 94.29384422302246, 16300: 94.86804914474487, 16400: 95.38600826263428, 16500: 95.93026423454285, 16600: 96.4791784286499, 16700: 97.0951144695282, 16800: 97.691091299057, 16900: 98.28941631317139, 17000: 98.86486029624939, 17100: 99.54520320892334, 17200: 100.0621862411499, 17300: 100.58309626579285, 17400: 101.09239339828491, 17500: 101.60564517974854, 17600: 102.16660237312317, 17700: 102.68032932281494, 17800: 103.20172810554504, 17900: 103.72384524345398, 18000: 104.31007719039917, 18100: 104.8696403503418}, 'loss': {0: 0.6027597784996033, 100: 0.33935803174972534, 200: 0.4075593948364258, 300: 1.2846765518188477, 400: 0.3585362732410431, 500: 0.3095785081386566, 600: 0.300998717546463, 700: 0.7621036767959595, 800: 1.1747360229492188, 900: 1.5581223964691162, 1000: 1.1398004293441772, 1100: 1.512941598892212, 1200: 0.3045131266117096, 1300: 0.7429310083389282, 1400: 0.48775896430015564, 1500: 0.9462507963180542, 1600: 0.193966343998909, 1700: 1.112718939781189, 1800: 0.8282355070114136, 1900: 0.7088133096694946, 2000: 1.2295329570770264, 2100: 0.8389285206794739, 2200: 1.0855164527893066, 2300: 0.6204010248184204, 2400: 1.1377074718475342, 2500: 1.2095285654067993, 2600: 1.5585399866104126, 2700: 0.5522406697273254, 2800: 4.4599103927612305, 2900: 0.9144203066825867, 3000: 0.6466895937919617, 3100: 1.0144619941711426, 3200: 0.2832510471343994, 3300: 0.8247621059417725, 3400: 0.8887835741043091, 3500: 0.7332345247268677, 3600: 0.7597280740737915, 3700: 0.5972447395324707, 3800: 0.1312588006258011, 3900: 1.5043072700500488, 4000: 0.2546965181827545, 4100: 2.005068063735962, 4200: 0.9089820384979248, 4300: 0.6455384492874146, 4400: 0.8507729172706604, 4500: 1.254528522491455, 4600: 2.2227067947387695, 4700: 0.24358566105365753, 4800: 0.2925967872142792, 4900: 1.0011792182922363, 5000: 0.7857522368431091, 5100: 0.7691598534584045, 5200: 0.6530230641365051, 5300: 0.9521414637565613, 5400: 0.8522321581840515, 5500: 0.664674699306488, 5600: 1.3825931549072266, 5700: 0.9608172178268433, 5800: 0.3332381248474121, 5900: 0.7078820466995239, 6000: 0.4200376868247986, 6100: 0.6051570177078247, 6200: 0.2585414946079254, 6300: 3.465801239013672, 6400: 0.39128509163856506, 6500: 1.5120279788970947, 6600: 1.1661499738693237, 6700: 1.2863084077835083, 6800: 0.6843507289886475, 6900: 0.7809132933616638, 7000: 0.41497886180877686, 7100: 0.4681150019168854, 7200: 1.0727996826171875, 7300: 0.2273869663476944, 7400: 0.2880934774875641, 7500: 0.863559365272522, 7600: 1.8909987211227417, 7700: 0.6886773109436035, 7800: 1.0861706733703613, 7900: 0.7587054967880249, 8000: 0.6492563486099243, 8100: 0.5016366243362427, 8200: 0.9980419278144836, 8300: 0.35890910029411316, 8400: 0.2978348433971405, 8500: 0.711293637752533, 8600: 0.5381718873977661, 8700: 0.33963119983673096, 8800: 0.6765625476837158, 8900: 0.7582398056983948, 9000: 0.5358298420906067, 9100: 0.3280256688594818, 9200: 0.3564748466014862, 9300: 0.23112042248249054, 9400: 2.586723566055298, 9500: 1.3490831851959229, 9600: 1.5229543447494507, 9700: 1.3338391780853271, 9800: 4.128702163696289, 9900: 1.085217833518982, 10000: 4.562106132507324, 10100: 0.7616407871246338, 10200: 0.11017894744873047, 10300: 0.30038952827453613, 10400: 0.3198390603065491, 10500: 0.2944641709327698, 10600: 0.38462352752685547, 10700: 0.8449131846427917, 10800: 0.32762378454208374, 10900: 0.40475404262542725, 11000: 0.5484234690666199, 11100: 1.226174235343933, 11200: 0.4501458406448364, 11300: 0.6739834547042847, 11400: 1.2840383052825928, 11500: 0.7037627100944519, 11600: 0.9578194618225098, 11700: 1.081955909729004, 11800: 1.370517373085022, 11900: 0.3723655939102173, 12000: 0.8021121621131897, 12100: 0.5615971684455872, 12200: 0.38646140694618225, 12300: 0.495548278093338, 12400: 0.3857269883155823, 12500: 0.9480935335159302, 12600: 0.29496142268180847, 12700: 0.19951647520065308, 12800: 0.5985588431358337, 12900: 1.3357539176940918, 13000: 1.2912194728851318, 13100: 2.443399667739868, 13200: 2.333578109741211, 13300: 1.223372220993042, 13400: 0.7388063073158264, 13500: 1.5442079305648804, 13600: 1.3832448720932007, 13700: 1.2857364416122437, 13800: 1.0133328437805176, 13900: 0.5037718415260315, 14000: 0.35230469703674316, 14100: 0.8500582575798035, 14200: 0.5682640075683594, 14300: 1.3894767761230469, 14400: 0.8920143842697144, 14500: 2.928163766860962, 14600: 1.3177990913391113, 14700: 1.0132226943969727, 14800: 0.4063965678215027, 14900: 0.856208324432373, 15000: 0.6002932190895081, 15100: 0.4964539110660553, 15200: 0.7873891592025757, 15300: 0.6299656629562378, 15400: 2.8457090854644775, 15500: 1.1662216186523438, 15600: 0.46228185296058655, 15700: 0.940939724445343, 15800: 1.2760344743728638, 15900: 0.5355414748191833, 16000: 1.971306562423706, 16100: 0.6561678647994995, 16200: 0.7049047946929932, 16300: 0.4361521601676941, 16400: 0.5150676965713501, 16500: 1.3660967350006104, 16600: 0.6192441582679749, 16700: 0.4060332477092743, 16800: 0.45549476146698, 16900: 0.17512162029743195, 17000: 1.3964364528656006, 17100: 0.6730807423591614, 17200: 1.9800786972045898, 17300: 1.0395493507385254, 17400: 0.8569793105125427, 17500: 0.6380326747894287, 17600: 0.7882748246192932, 17700: 0.9752159118652344, 17800: 0.49386322498321533, 17900: 0.8370829820632935, 18000: 0.4849173128604889, 18100: 0.29210716485977173}, 'F1': {6: 0.5479638424194846}, 'Accuracy': {6: 0.497742539367911}}\n",
      "Epoch 7\n",
      "\n",
      "Epoch time: 114.89088201522827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66       563\n",
      "           1       0.62      0.88      0.73       561\n",
      "           2       0.58      0.72      0.64       564\n",
      "           3       0.63      0.50      0.56       573\n",
      "           4       0.59      0.74      0.66       575\n",
      "           5       0.57      0.76      0.65       556\n",
      "           6       0.61      0.24      0.34       564\n",
      "           7       0.59      0.62      0.61       555\n",
      "           8       0.62      0.63      0.62       567\n",
      "           9       0.53      0.72      0.61       542\n",
      "          10       0.37      0.31      0.34      3461\n",
      "\n",
      "    accuracy                           0.52      9081\n",
      "   macro avg       0.57      0.62      0.58      9081\n",
      "weighted avg       0.51      0.52      0.51      9081\n",
      "\n",
      "Logger {'time': {0: 0.010478734970092773, 100: 0.529836893081665, 200: 1.0426287651062012, 300: 1.605266809463501, 400: 2.154984951019287, 500: 2.7036447525024414, 600: 3.28334379196167, 700: 3.899103879928589, 800: 4.486938714981079, 900: 5.085887908935547, 1000: 5.631052017211914, 1100: 6.181896924972534, 1200: 6.763063907623291, 1300: 7.338806867599487, 1400: 8.003246784210205, 1500: 8.666255712509155, 1600: 9.24729585647583, 1700: 9.843973875045776, 1800: 10.466341733932495, 1900: 11.042878866195679, 2000: 11.64613389968872, 2100: 12.247682094573975, 2200: 12.860769033432007, 2300: 13.455919742584229, 2400: 14.162660121917725, 2500: 14.783973932266235, 2600: 15.358617782592773, 2700: 15.903296947479248, 2800: 16.477248907089233, 2900: 17.06228995323181, 3000: 17.624762773513794, 3100: 18.198211908340454, 3200: 18.800355911254883, 3300: 19.325525999069214, 3400: 19.9370059967041, 3500: 20.442898988723755, 3600: 20.937164068222046, 3700: 21.536219835281372, 3800: 22.05552577972412, 3900: 22.602062940597534, 4000: 23.100926876068115, 4100: 23.622391939163208, 4200: 24.15823483467102, 4300: 24.679476976394653, 4400: 25.18078589439392, 4500: 25.698071002960205, 4600: 26.19923496246338, 4700: 26.74271583557129, 4800: 27.271440744400024, 4900: 27.857906818389893, 5000: 28.3628249168396, 5100: 28.899040937423706, 5200: 29.402490854263306, 5300: 29.93873691558838, 5400: 30.44986581802368, 5500: 30.975814819335938, 5600: 31.551556825637817, 5700: 32.14988589286804, 5800: 32.75179171562195, 5900: 33.36182498931885, 6000: 34.015657901763916, 6100: 34.61525869369507, 6200: 35.215494871139526, 6300: 35.82263398170471, 6400: 36.43006205558777, 6500: 37.03372383117676, 6600: 37.62133193016052, 6700: 38.2112398147583, 6800: 38.86641478538513, 6900: 39.4485068321228, 7000: 40.10403084754944, 7100: 40.687938928604126, 7200: 41.236526012420654, 7300: 42.23997378349304, 7400: 42.9397509098053, 7500: 43.64273476600647, 7600: 44.2753529548645, 7700: 44.9600088596344, 7800: 45.69641995429993, 7900: 46.46483874320984, 8000: 47.07153677940369, 8100: 47.68021607398987, 8200: 48.40078377723694, 8300: 49.780834913253784, 8400: 50.46300482749939, 8500: 51.153361797332764, 8600: 51.88919687271118, 8700: 52.508877992630005, 8800: 53.04708385467529, 8900: 53.67702603340149, 9000: 54.314799785614014, 9100: 54.89449191093445, 9200: 55.500792026519775, 9300: 56.053072929382324, 9400: 56.619892835617065, 9500: 57.20000100135803, 9600: 57.90812373161316, 9700: 58.55033588409424, 9800: 59.09885287284851, 9900: 59.71761679649353, 10000: 60.256386041641235, 10100: 61.13789486885071, 10200: 61.83479690551758, 10300: 62.41127586364746, 10400: 63.08871793746948, 10500: 63.6748731136322, 10600: 64.24669194221497, 10700: 64.91480278968811, 10800: 65.5078330039978, 10900: 66.11980891227722, 11000: 66.82991886138916, 11100: 67.54782485961914, 11200: 68.27565574645996, 11300: 69.03971672058105, 11400: 69.70795583724976, 11500: 70.43934893608093, 11600: 71.05435180664062, 11700: 71.60392594337463, 11800: 72.22596287727356, 11900: 73.01561379432678, 12000: 73.91329097747803, 12100: 74.7564868927002, 12200: 75.26299285888672, 12300: 75.86364269256592, 12400: 76.4359700679779, 12500: 77.04268789291382, 12600: 77.84395170211792, 12700: 78.52453184127808, 12800: 79.78550982475281, 12900: 80.59302186965942, 13000: 81.26445198059082, 13100: 82.07130289077759, 13200: 82.67112803459167, 13300: 83.28371667861938, 13400: 83.84246301651001, 13500: 84.40537595748901, 13600: 84.98333787918091, 13700: 85.59961175918579, 13800: 86.51186299324036, 13900: 87.23407673835754, 14000: 87.9276659488678, 14100: 88.5617778301239, 14200: 89.19042992591858, 14300: 89.7485728263855, 14400: 90.35767078399658, 14500: 90.95428776741028, 14600: 91.50751376152039, 14700: 92.06730484962463, 14800: 92.56849694252014, 14900: 93.15328192710876, 15000: 93.65995788574219, 15100: 94.32049584388733, 15200: 94.91258072853088, 15300: 95.44343185424805, 15400: 96.18752098083496, 15500: 96.84858894348145, 15600: 97.72659683227539, 15700: 98.44976782798767, 15800: 99.23060774803162, 15900: 99.86893486976624, 16000: 100.42690682411194, 16100: 101.14036202430725, 16200: 101.81529593467712, 16300: 102.37240481376648, 16400: 102.99502372741699, 16500: 103.61853098869324, 16600: 104.39171600341797, 16700: 105.15085101127625, 16800: 105.81322908401489, 16900: 106.58364009857178, 17000: 107.2401967048645, 17100: 107.96362376213074, 17200: 108.60918498039246, 17300: 109.22688889503479, 17400: 109.8115668296814, 17500: 110.4790198802948, 17600: 111.15129280090332, 17700: 111.81613993644714, 17800: 112.58480310440063, 17900: 113.207927942276, 18000: 113.7578558921814, 18100: 114.40727090835571}, 'loss': {0: 0.43613550066947937, 100: 0.1535225510597229, 200: 0.5353856086730957, 300: 0.9001864194869995, 400: 1.0122443437576294, 500: 0.2551848590373993, 600: 0.19766482710838318, 700: 0.7744813561439514, 800: 0.1705581545829773, 900: 3.6119372844696045, 1000: 1.6393966674804688, 1100: 1.9072339534759521, 1200: 0.32556024193763733, 1300: 1.0145319700241089, 1400: 0.3758554458618164, 1500: 0.38323527574539185, 1600: 0.21041853725910187, 1700: 1.3088889122009277, 1800: 0.6855821013450623, 1900: 0.6599595546722412, 2000: 1.1732120513916016, 2100: 0.95737624168396, 2200: 1.4408526420593262, 2300: 0.6250439286231995, 2400: 1.2017312049865723, 2500: 1.461745262145996, 2600: 1.928422451019287, 2700: 0.335553377866745, 2800: 1.2654249668121338, 2900: 0.8387187719345093, 3000: 0.39879947900772095, 3100: 0.8622567653656006, 3200: 0.3517112135887146, 3300: 0.6507421135902405, 3400: 1.1620197296142578, 3500: 0.8571906685829163, 3600: 1.0053479671478271, 3700: 0.5275428295135498, 3800: 0.37593212723731995, 3900: 1.844913363456726, 4000: 0.4443761706352234, 4100: 1.7407519817352295, 4200: 1.225813388824463, 4300: 0.8519161939620972, 4400: 1.5734827518463135, 4500: 1.034193515777588, 4600: 1.1272761821746826, 4700: 0.5117166042327881, 4800: 0.534801721572876, 4900: 0.39604130387306213, 5000: 0.8690422177314758, 5100: 0.6295883655548096, 5200: 0.6866495013237, 5300: 0.9517453908920288, 5400: 0.5812894701957703, 5500: 0.7327744960784912, 5600: 1.3930846452713013, 5700: 0.9342947006225586, 5800: 0.35811713337898254, 5900: 1.5148630142211914, 6000: 0.4384799003601074, 6100: 0.33076491951942444, 6200: 0.4344111382961273, 6300: 3.1657748222351074, 6400: 0.4385334253311157, 6500: 1.3772764205932617, 6600: 1.57267427444458, 6700: 1.101743459701538, 6800: 0.6134916543960571, 6900: 0.5095230340957642, 7000: 0.35377466678619385, 7100: 0.44244030117988586, 7200: 1.1045011281967163, 7300: 0.27095577120780945, 7400: 0.20842954516410828, 7500: 1.0216861963272095, 7600: 1.424386978149414, 7700: 0.6683346033096313, 7800: 2.0645639896392822, 7900: 0.6731680035591125, 8000: 0.4643526077270508, 8100: 0.21331462264060974, 8200: 1.0533114671707153, 8300: 0.42307788133621216, 8400: 0.6771350502967834, 8500: 0.7203181385993958, 8600: 0.6526569724082947, 8700: 0.3883942663669586, 8800: 1.139253854751587, 8900: 0.9152888655662537, 9000: 0.5506315231323242, 9100: 0.46433356404304504, 9200: 0.4037405848503113, 9300: 0.3629034161567688, 9400: 3.5983505249023438, 9500: 1.2471338510513306, 9600: 0.6392326951026917, 9700: 1.2534253597259521, 9800: 6.656830787658691, 9900: 0.4725922644138336, 10000: 4.057227611541748, 10100: 0.6077658534049988, 10200: 0.5487998723983765, 10300: 2.3871262073516846, 10400: 0.4852081835269928, 10500: 0.6944417953491211, 10600: 0.4243432283401489, 10700: 0.9424823522567749, 10800: 0.4207723140716553, 10900: 0.4236871302127838, 11000: 0.6155937314033508, 11100: 1.2576959133148193, 11200: 0.37176793813705444, 11300: 0.3477148413658142, 11400: 1.478525161743164, 11500: 0.46719464659690857, 11600: 0.9558543562889099, 11700: 0.7998670935630798, 11800: 0.8636127710342407, 11900: 0.9695796370506287, 12000: 0.8397666811943054, 12100: 0.396332710981369, 12200: 0.2764427661895752, 12300: 1.1533339023590088, 12400: 0.4885316789150238, 12500: 0.5147044062614441, 12600: 0.2557671070098877, 12700: 1.0119224786758423, 12800: 0.8027361035346985, 12900: 1.8743782043457031, 13000: 2.592778205871582, 13100: 0.30869361758232117, 13200: 0.6977005004882812, 13300: 1.6257699728012085, 13400: 0.5234371423721313, 13500: 0.9499921202659607, 13600: 1.5368907451629639, 13700: 1.2062426805496216, 13800: 1.073616623878479, 13900: 0.5380669236183167, 14000: 0.41440483927726746, 14100: 0.6883428692817688, 14200: 0.4193406105041504, 14300: 1.3876055479049683, 14400: 0.5589242577552795, 14500: 1.391242265701294, 14600: 0.8996164798736572, 14700: 1.2905679941177368, 14800: 0.5206938982009888, 14900: 0.6603769063949585, 15000: 1.0419740676879883, 15100: 0.4327397048473358, 15200: 0.47994786500930786, 15300: 0.6381165981292725, 15400: 3.2458767890930176, 15500: 1.083017349243164, 15600: 1.0061919689178467, 15700: 0.6965955495834351, 15800: 1.7073581218719482, 15900: 0.8117544651031494, 16000: 1.5777945518493652, 16100: 0.7397162914276123, 16200: 0.666215181350708, 16300: 0.14041642844676971, 16400: 0.41440749168395996, 16500: 1.2267348766326904, 16600: 1.1063705682754517, 16700: 0.3995817005634308, 16800: 0.4040559232234955, 16900: 0.44328033924102783, 17000: 0.7946195006370544, 17100: 0.5496901273727417, 17200: 1.3380253314971924, 17300: 1.1758326292037964, 17400: 0.9545279145240784, 17500: 1.2515220642089844, 17600: 0.9991680979728699, 17700: 0.5237623453140259, 17800: 0.3214552104473114, 17900: 0.7517172694206238, 18000: 0.16794532537460327, 18100: 0.3267206847667694}, 'F1': {7: 0.5836739917255944}, 'Accuracy': {7: 0.5226296663363066}}\n",
      "Epoch 8\n",
      "\n",
      "Epoch time: 113.80014085769653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       563\n",
      "           1       0.62      0.80      0.70       561\n",
      "           2       0.58      0.64      0.61       564\n",
      "           3       0.64      0.50      0.56       573\n",
      "           4       0.58      0.83      0.68       575\n",
      "           5       0.54      0.75      0.63       556\n",
      "           6       0.58      0.38      0.46       564\n",
      "           7       0.58      0.64      0.61       555\n",
      "           8       0.61      0.56      0.58       567\n",
      "           9       0.56      0.63      0.59       542\n",
      "          10       0.38      0.31      0.34      3461\n",
      "\n",
      "    accuracy                           0.52      9081\n",
      "   macro avg       0.57      0.62      0.59      9081\n",
      "weighted avg       0.51      0.52      0.51      9081\n",
      "\n",
      "Logger {'time': {0: 0.00803685188293457, 100: 0.6546738147735596, 200: 1.2671167850494385, 300: 1.8745298385620117, 400: 2.4551949501037598, 500: 3.256053924560547, 600: 4.055832862854004, 700: 4.6005539894104, 800: 5.693182945251465, 900: 6.3583738803863525, 1000: 6.892429828643799, 1100: 7.5367209911346436, 1200: 8.307575702667236, 1300: 8.826444864273071, 1400: 9.392149925231934, 1500: 9.983510732650757, 1600: 10.925854921340942, 1700: 11.577838897705078, 1800: 12.074508905410767, 1900: 12.725450038909912, 2000: 13.270533800125122, 2100: 13.79953384399414, 2200: 14.373173952102661, 2300: 15.056269884109497, 2400: 15.725340843200684, 2500: 16.382308959960938, 2600: 16.927425861358643, 2700: 17.4821298122406, 2800: 18.054558038711548, 2900: 18.62579369544983, 3000: 19.167954921722412, 3100: 19.682124853134155, 3200: 20.235163927078247, 3300: 20.785496950149536, 3400: 21.336829900741577, 3500: 21.859532833099365, 3600: 22.458181858062744, 3700: 22.961003065109253, 3800: 23.48880100250244, 3900: 24.292541980743408, 4000: 24.899013996124268, 4100: 25.498239994049072, 4200: 26.19997787475586, 4300: 26.88313603401184, 4400: 27.53568387031555, 4500: 28.15688681602478, 4600: 28.786512851715088, 4700: 29.422799825668335, 4800: 30.097244024276733, 4900: 30.731170892715454, 5000: 31.403291940689087, 5100: 32.19332194328308, 5200: 32.90419387817383, 5300: 33.577006816864014, 5400: 34.258137941360474, 5500: 34.932506799697876, 5600: 35.637197732925415, 5700: 36.35330271720886, 5800: 37.04559278488159, 5900: 37.77865982055664, 6000: 38.534021854400635, 6100: 39.209550857543945, 6200: 39.758853912353516, 6300: 40.26320171356201, 6400: 40.79556679725647, 6500: 41.456018924713135, 6600: 42.14451885223389, 6700: 42.69317102432251, 6800: 43.20892691612244, 6900: 43.810070753097534, 7000: 44.54501986503601, 7100: 45.19837808609009, 7200: 45.863924980163574, 7300: 46.575801849365234, 7400: 47.19312596321106, 7500: 47.73254084587097, 7600: 48.37271976470947, 7700: 49.02521085739136, 7800: 49.72197985649109, 7900: 50.42031908035278, 8000: 51.157612800598145, 8100: 51.74415683746338, 8200: 52.45729112625122, 8300: 53.10685086250305, 8400: 53.63941287994385, 8500: 54.1746129989624, 8600: 54.69376802444458, 8700: 55.200236797332764, 8800: 55.71092987060547, 8900: 56.234821796417236, 9000: 56.787734031677246, 9100: 57.47063684463501, 9200: 58.145285844802856, 9300: 58.78246188163757, 9400: 59.31339502334595, 9500: 59.847728967666626, 9600: 60.37114596366882, 9700: 60.88890504837036, 9800: 61.415618896484375, 9900: 61.91743993759155, 10000: 62.413739919662476, 10100: 63.099867820739746, 10200: 63.641671895980835, 10300: 64.33771586418152, 10400: 64.98026609420776, 10500: 65.68249893188477, 10600: 66.40730500221252, 10700: 67.06290292739868, 10800: 68.13379693031311, 10900: 68.86644101142883, 11000: 69.60088181495667, 11100: 70.39178991317749, 11200: 70.98192286491394, 11300: 71.6001627445221, 11400: 72.22020292282104, 11500: 72.94757509231567, 11600: 73.57605195045471, 11700: 74.319650888443, 11800: 74.91121578216553, 11900: 75.43610191345215, 12000: 76.01644802093506, 12100: 76.57375001907349, 12200: 77.169686794281, 12300: 77.7081401348114, 12400: 78.28189086914062, 12500: 78.84787368774414, 12600: 79.35579800605774, 12700: 79.90291380882263, 12800: 80.4252381324768, 12900: 80.95885276794434, 13000: 81.5419409275055, 13100: 82.15724086761475, 13200: 82.69366693496704, 13300: 83.22861385345459, 13400: 83.83462977409363, 13500: 84.37940692901611, 13600: 84.91248106956482, 13700: 85.51344394683838, 13800: 86.29261684417725, 13900: 86.97724390029907, 14000: 87.56443190574646, 14100: 88.13145399093628, 14200: 88.69926309585571, 14300: 89.26491189002991, 14400: 89.84500694274902, 14500: 90.5127809047699, 14600: 91.09551906585693, 14700: 91.68355894088745, 14800: 92.22574090957642, 14900: 92.75235486030579, 15000: 93.34599089622498, 15100: 93.89949178695679, 15200: 94.43011593818665, 15300: 94.95919394493103, 15400: 95.48614287376404, 15500: 96.03387880325317, 15600: 96.55199480056763, 15700: 97.07719683647156, 15800: 97.655033826828, 15900: 98.1905517578125, 16000: 98.73120999336243, 16100: 99.3266670703888, 16200: 100.03719186782837, 16300: 100.70430183410645, 16400: 101.5118248462677, 16500: 102.1945788860321, 16600: 102.8773398399353, 16700: 103.62320113182068, 16800: 104.32392883300781, 16900: 105.05384087562561, 17000: 105.75964379310608, 17100: 106.45209288597107, 17200: 107.17596793174744, 17300: 107.90470790863037, 17400: 108.4976258277893, 17500: 109.00172591209412, 17600: 109.66676473617554, 17700: 110.39737200737, 17800: 111.08832383155823, 17900: 111.79444980621338, 18000: 112.48798274993896, 18100: 113.30287480354309}, 'loss': {0: 0.5231492519378662, 100: 0.31377142667770386, 200: 0.3455103933811188, 300: 2.8538951873779297, 400: 0.8807982802391052, 500: 0.5182190537452698, 600: 0.1782299280166626, 700: 0.889330267906189, 800: 0.37469086050987244, 900: 0.5461023449897766, 1000: 1.7720718383789062, 1100: 1.7105063199996948, 1200: 0.2538478970527649, 1300: 0.49531760811805725, 1400: 1.0877490043640137, 1500: 0.29956290125846863, 1600: 0.21568650007247925, 1700: 1.4603092670440674, 1800: 1.0195002555847168, 1900: 0.517257571220398, 2000: 1.1715763807296753, 2100: 0.40296947956085205, 2200: 1.2052128314971924, 2300: 0.61892169713974, 2400: 1.2067680358886719, 2500: 1.6763814687728882, 2600: 1.521897315979004, 2700: 0.4751831889152527, 2800: 4.433258056640625, 2900: 0.9354299902915955, 3000: 0.7242963314056396, 3100: 0.6890150308609009, 3200: 0.3184247612953186, 3300: 0.8805612325668335, 3400: 0.9295023083686829, 3500: 0.8331850171089172, 3600: 1.0886751413345337, 3700: 0.5917189717292786, 3800: 0.44293898344039917, 3900: 2.9151763916015625, 4000: 0.7745476365089417, 4100: 1.0337176322937012, 4200: 1.2330026626586914, 4300: 0.9655320048332214, 4400: 1.1754344701766968, 4500: 1.1559405326843262, 4600: 0.794967532157898, 4700: 0.2731764316558838, 4800: 0.475471168756485, 4900: 0.5071737170219421, 5000: 0.7167807221412659, 5100: 0.639549970626831, 5200: 0.566791296005249, 5300: 0.9394687414169312, 5400: 0.5618985891342163, 5500: 0.564195990562439, 5600: 1.689573049545288, 5700: 0.9405588507652283, 5800: 0.4106144607067108, 5900: 1.0360091924667358, 6000: 0.5647035241127014, 6100: 1.700734257698059, 6200: 0.757785439491272, 6300: 3.163463830947876, 6400: 0.2760516405105591, 6500: 1.454343318939209, 6600: 1.272742748260498, 6700: 1.1753170490264893, 6800: 0.6685782074928284, 6900: 0.5237477421760559, 7000: 0.43425092101097107, 7100: 0.3859700560569763, 7200: 1.0383939743041992, 7300: 0.19921088218688965, 7400: 0.24686601758003235, 7500: 0.31218644976615906, 7600: 0.4826691150665283, 7700: 0.9334607124328613, 7800: 1.415381908416748, 7900: 0.9786491394042969, 8000: 0.620760977268219, 8100: 0.34922119975090027, 8200: 1.1794195175170898, 8300: 0.4370426833629608, 8400: 0.5336557030677795, 8500: 0.9536092281341553, 8600: 0.7490550875663757, 8700: 0.31638288497924805, 8800: 1.0356305837631226, 8900: 1.1469141244888306, 9000: 2.7754104137420654, 9100: 0.4489882290363312, 9200: 0.3720514178276062, 9300: 0.2728143334388733, 9400: 3.0523290634155273, 9500: 1.3695136308670044, 9600: 1.7593321800231934, 9700: 1.5287137031555176, 9800: 4.624798774719238, 9900: 0.460022896528244, 10000: 4.164710521697998, 10100: 0.548786997795105, 10200: 0.4985610842704773, 10300: 0.38144969940185547, 10400: 0.6191041469573975, 10500: 0.37198352813720703, 10600: 0.3092896342277527, 10700: 0.9417791366577148, 10800: 0.2799396812915802, 10900: 0.30791088938713074, 11000: 0.7665701508522034, 11100: 1.3385237455368042, 11200: 0.40850919485092163, 11300: 0.31470492482185364, 11400: 2.9002485275268555, 11500: 0.6000639796257019, 11600: 1.4585986137390137, 11700: 0.863224983215332, 11800: 1.4284946918487549, 11900: 0.7218185663223267, 12000: 0.7262344360351562, 12100: 0.734373927116394, 12200: 0.22070269286632538, 12300: 0.5260623693466187, 12400: 0.4360247254371643, 12500: 0.39917007088661194, 12600: 0.15206114947795868, 12700: 0.5339077711105347, 12800: 0.7246253490447998, 12900: 1.4680696725845337, 13000: 1.0013991594314575, 13100: 0.27297940850257874, 13200: 0.9944941401481628, 13300: 2.832911968231201, 13400: 0.6671788096427917, 13500: 0.9814904928207397, 13600: 1.497711420059204, 13700: 1.2033770084381104, 13800: 1.1072547435760498, 13900: 0.5410172939300537, 14000: 0.3715687692165375, 14100: 0.8432174324989319, 14200: 0.2694878578186035, 14300: 1.4213796854019165, 14400: 1.2137644290924072, 14500: 1.7679551839828491, 14600: 1.2714248895645142, 14700: 0.5861911773681641, 14800: 0.37360432744026184, 14900: 0.5932347178459167, 15000: 0.9967027902603149, 15100: 0.49761781096458435, 15200: 0.5568247437477112, 15300: 0.4136107861995697, 15400: 3.6859707832336426, 15500: 1.2917990684509277, 15600: 0.4868139326572418, 15700: 1.182814121246338, 15800: 1.6076560020446777, 15900: 0.9216964840888977, 16000: 1.5082979202270508, 16100: 0.8210505843162537, 16200: 0.5404971837997437, 16300: 1.2665082216262817, 16400: 0.33475685119628906, 16500: 1.4816819429397583, 16600: 0.4686394929885864, 16700: 0.3586766719818115, 16800: 0.4604807198047638, 16900: 0.32865437865257263, 17000: 0.6745138764381409, 17100: 0.3981465995311737, 17200: 3.918400526046753, 17300: 1.1873862743377686, 17400: 1.0382075309753418, 17500: 2.683666229248047, 17600: 0.8410500884056091, 17700: 0.5181560516357422, 17800: 0.23427191376686096, 17900: 0.5962499976158142, 18000: 0.2989887297153473, 18100: 0.33210790157318115}, 'F1': {8: 0.5859406236282826}, 'Accuracy': {8: 0.5209778658738025}}\n",
      "Epoch 9\n",
      "\n",
      "Epoch time: 106.48630619049072\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.66       563\n",
      "           1       0.62      0.81      0.71       561\n",
      "           2       0.58      0.67      0.62       564\n",
      "           3       0.64      0.59      0.61       573\n",
      "           4       0.57      0.84      0.68       575\n",
      "           5       0.54      0.75      0.63       556\n",
      "           6       0.60      0.43      0.50       564\n",
      "           7       0.59      0.68      0.63       555\n",
      "           8       0.60      0.33      0.42       567\n",
      "           9       0.57      0.72      0.64       542\n",
      "          10       0.37      0.31      0.34      3461\n",
      "\n",
      "    accuracy                           0.52      9081\n",
      "   macro avg       0.57      0.62      0.59      9081\n",
      "weighted avg       0.51      0.52      0.51      9081\n",
      "\n",
      "Logger {'time': {0: 0.01695418357849121, 100: 0.7480740547180176, 200: 1.469109058380127, 300: 2.1541991233825684, 400: 2.921617269515991, 500: 3.724443197250366, 600: 4.442073106765747, 700: 5.098692178726196, 800: 5.621745347976685, 900: 6.178995132446289, 1000: 6.790162086486816, 1100: 7.4630820751190186, 1200: 7.98841118812561, 1300: 8.519911050796509, 1400: 9.048389196395874, 1500: 9.587299108505249, 1600: 10.121869087219238, 1700: 10.762824058532715, 1800: 11.423156023025513, 1900: 11.99876618385315, 2000: 12.765233278274536, 2100: 13.355505228042603, 2200: 14.009421110153198, 2300: 14.602352142333984, 2400: 15.18806505203247, 2500: 15.769228219985962, 2600: 16.487017154693604, 2700: 17.24323010444641, 2800: 17.867767095565796, 2900: 18.423068284988403, 3000: 18.952978134155273, 3100: 19.49184799194336, 3200: 19.992870330810547, 3300: 20.55406904220581, 3400: 21.049344062805176, 3500: 21.55758810043335, 3600: 22.11036229133606, 3700: 22.64136028289795, 3800: 23.28196096420288, 3900: 23.879008054733276, 4000: 24.499845266342163, 4100: 25.07034134864807, 4200: 25.705219268798828, 4300: 26.350529193878174, 4400: 27.244392156600952, 4500: 27.9019672870636, 4600: 28.577011108398438, 4700: 29.16529631614685, 4800: 29.754465103149414, 4900: 30.41284418106079, 5000: 31.078766107559204, 5100: 31.799684286117554, 5200: 32.609769105911255, 5300: 33.33808708190918, 5400: 34.07404804229736, 5500: 34.6491961479187, 5600: 35.35160708427429, 5700: 35.94992518424988, 5800: 36.509045124053955, 5900: 37.20653414726257, 6000: 37.857755184173584, 6100: 38.473060131073, 6200: 39.060500144958496, 6300: 39.62026619911194, 6400: 40.166971921920776, 6500: 40.92410922050476, 6600: 41.46699500083923, 6700: 42.0292181968689, 6800: 42.610634088516235, 6900: 43.199281215667725, 7000: 43.78204703330994, 7100: 44.36143517494202, 7200: 44.96921706199646, 7300: 45.562512159347534, 7400: 46.12290620803833, 7500: 46.61091732978821, 7600: 47.136887073516846, 7700: 47.6808021068573, 7800: 48.211143016815186, 7900: 48.70030331611633, 8000: 49.20434808731079, 8100: 49.69073510169983, 8200: 50.242128133773804, 8300: 50.8062059879303, 8400: 51.391366958618164, 8500: 51.9036340713501, 8600: 52.467297077178955, 8700: 52.97222304344177, 8800: 53.52424931526184, 8900: 54.086756229400635, 9000: 54.66568613052368, 9100: 55.22556495666504, 9200: 55.828479051589966, 9300: 56.47579336166382, 9400: 57.06750226020813, 9500: 57.65839433670044, 9600: 58.27525520324707, 9700: 58.87595820426941, 9800: 59.45880317687988, 9900: 60.0576069355011, 10000: 60.66815519332886, 10100: 61.273388147354126, 10200: 61.87890410423279, 10300: 62.44713807106018, 10400: 63.04186511039734, 10500: 63.669448137283325, 10600: 64.35494613647461, 10700: 64.94206595420837, 10800: 65.57631421089172, 10900: 66.22959327697754, 11000: 66.81622099876404, 11100: 67.43665313720703, 11200: 68.02534818649292, 11300: 68.62882208824158, 11400: 69.19025802612305, 11500: 69.79500007629395, 11600: 70.39873909950256, 11700: 71.0096230506897, 11800: 71.61895108222961, 11900: 72.20119404792786, 12000: 72.80495715141296, 12100: 73.38232016563416, 12200: 73.97414112091064, 12300: 74.54042291641235, 12400: 75.14562106132507, 12500: 75.70219612121582, 12600: 76.2633421421051, 12700: 76.79606032371521, 12800: 77.36069107055664, 12900: 77.88464426994324, 13000: 78.42896318435669, 13100: 78.9932451248169, 13200: 79.63246607780457, 13300: 80.2489652633667, 13400: 80.87588405609131, 13500: 81.51742911338806, 13600: 82.12574219703674, 13700: 82.70011234283447, 13800: 83.26355910301208, 13900: 83.82545328140259, 14000: 84.34461331367493, 14100: 84.91681218147278, 14200: 85.4728672504425, 14300: 86.01593017578125, 14400: 86.6135721206665, 14500: 87.11423015594482, 14600: 87.70472931861877, 14700: 88.24842810630798, 14800: 88.76366710662842, 14900: 89.26925015449524, 15000: 89.7775981426239, 15100: 90.28313612937927, 15200: 90.80632400512695, 15300: 91.31834506988525, 15400: 91.83464908599854, 15500: 92.34447526931763, 15600: 92.85024428367615, 15700: 93.35779309272766, 15800: 93.86413216590881, 15900: 94.38362312316895, 16000: 94.88582301139832, 16100: 95.41608119010925, 16200: 95.97272205352783, 16300: 96.53763222694397, 16400: 97.04624700546265, 16500: 97.63018298149109, 16600: 98.2326591014862, 16700: 98.82148003578186, 16800: 99.35229802131653, 16900: 99.84416103363037, 17000: 100.37328004837036, 17100: 100.89863014221191, 17200: 101.41776919364929, 17300: 101.92579627037048, 17400: 102.42908120155334, 17500: 102.95084118843079, 17600: 103.48321008682251, 17700: 104.01845526695251, 17800: 104.5799810886383, 17900: 105.09255504608154, 18000: 105.60522294044495, 18100: 106.13402128219604}, 'loss': {0: 0.5051982998847961, 100: 0.38330376148223877, 200: 0.3604212701320648, 300: 1.0342657566070557, 400: 0.7776010632514954, 500: 0.36707472801208496, 600: 0.13778212666511536, 700: 1.1054630279541016, 800: 0.31954240798950195, 900: 2.419417142868042, 1000: 1.6870653629302979, 1100: 1.6572513580322266, 1200: 0.5880650281906128, 1300: 0.7276011109352112, 1400: 0.7049285769462585, 1500: 0.3240874707698822, 1600: 0.2891680896282196, 1700: 1.3068429231643677, 1800: 0.6584482192993164, 1900: 0.736167311668396, 2000: 1.3449379205703735, 2100: 0.38976964354515076, 2200: 0.9808847308158875, 2300: 0.5863386988639832, 2400: 1.643955945968628, 2500: 2.0154824256896973, 2600: 1.6313817501068115, 2700: 0.19596263766288757, 2800: 1.5669312477111816, 2900: 0.8811827301979065, 3000: 0.3250200152397156, 3100: 0.9147680997848511, 3200: 0.31355878710746765, 3300: 0.8361387252807617, 3400: 1.231673240661621, 3500: 0.8732829093933105, 3600: 1.156510591506958, 3700: 0.6353051662445068, 3800: 0.3925184905529022, 3900: 2.654083490371704, 4000: 0.3904989957809448, 4100: 1.7112013101577759, 4200: 1.225276231765747, 4300: 1.0394753217697144, 4400: 1.1800671815872192, 4500: 0.8825753331184387, 4600: 2.3081612586975098, 4700: 0.22074198722839355, 4800: 0.388301283121109, 4900: 0.38463374972343445, 5000: 0.8531099557876587, 5100: 0.5935532450675964, 5200: 0.609478771686554, 5300: 1.0263354778289795, 5400: 0.6782852411270142, 5500: 0.519527792930603, 5600: 1.4267981052398682, 5700: 0.8531026840209961, 5800: 0.36492764949798584, 5900: 1.0003330707550049, 6000: 0.5667940974235535, 6100: 1.0341180562973022, 6200: 0.35446369647979736, 6300: 3.352071523666382, 6400: 0.32120874524116516, 6500: 1.3697116374969482, 6600: 1.4187064170837402, 6700: 1.3278785943984985, 6800: 0.6562435626983643, 6900: 0.5392776131629944, 7000: 0.43772822618484497, 7100: 0.36394694447517395, 7200: 1.0552496910095215, 7300: 0.24081167578697205, 7400: 0.22634287178516388, 7500: 0.27833911776542664, 7600: 0.5989249348640442, 7700: 0.8048262596130371, 7800: 1.2831273078918457, 7900: 0.8470429182052612, 8000: 0.5372857451438904, 8100: 0.23643487691879272, 8200: 1.0083775520324707, 8300: 0.569668710231781, 8400: 0.5890761017799377, 8500: 0.7741042375564575, 8600: 0.6649110913276672, 8700: 0.862356960773468, 8800: 1.4263789653778076, 8900: 0.5306546688079834, 9000: 0.7321230173110962, 9100: 0.4957500994205475, 9200: 0.5352166891098022, 9300: 0.2533666789531708, 9400: 1.643257737159729, 9500: 1.2483607530593872, 9600: 1.4354884624481201, 9700: 1.9292207956314087, 9800: 4.593723297119141, 9900: 0.8804340958595276, 10000: 4.202297210693359, 10100: 0.6085761785507202, 10200: 0.5422523021697998, 10300: 0.3519655168056488, 10400: 0.20770400762557983, 10500: 0.3131808638572693, 10600: 0.38925161957740784, 10700: 0.7603634595870972, 10800: 0.3711516261100769, 10900: 0.39970096945762634, 11000: 0.6190273761749268, 11100: 1.405379295349121, 11200: 0.4155007302761078, 11300: 0.661868691444397, 11400: 2.1089906692504883, 11500: 0.5197776556015015, 11600: 1.547370433807373, 11700: 0.8818866610527039, 11800: 1.2678768634796143, 11900: 0.39990365505218506, 12000: 0.8349714875221252, 12100: 0.3056587874889374, 12200: 0.27215731143951416, 12300: 0.9302588701248169, 12400: 0.5020529627799988, 12500: 0.9215784072875977, 12600: 0.23928943276405334, 12700: 0.4873766601085663, 12800: 0.6399765014648438, 12900: 1.3746179342269897, 13000: 1.3974132537841797, 13100: 0.44178518652915955, 13200: 1.5928620100021362, 13300: 2.52117657661438, 13400: 0.6268316507339478, 13500: 0.9214050769805908, 13600: 2.0253467559814453, 13700: 1.7228400707244873, 13800: 0.8583254814147949, 13900: 0.5603151321411133, 14000: 0.4598081111907959, 14100: 0.8920272588729858, 14200: 0.7482735514640808, 14300: 1.7159067392349243, 14400: 0.6533024311065674, 14500: 1.3743923902511597, 14600: 0.8435381650924683, 14700: 1.006976842880249, 14800: 0.432038277387619, 14900: 0.5830491185188293, 15000: 0.3910565972328186, 15100: 0.48560795187950134, 15200: 0.4331968128681183, 15300: 0.5315759181976318, 15400: 3.361485004425049, 15500: 0.6354703903198242, 15600: 0.5629443526268005, 15700: 0.984782874584198, 15800: 1.5174939632415771, 15900: 0.6515779495239258, 16000: 1.1641731262207031, 16100: 0.829727292060852, 16200: 0.5948953032493591, 16300: 1.6361470222473145, 16400: 0.47974905371665955, 16500: 1.394781231880188, 16600: 0.32679471373558044, 16700: 0.4231948256492615, 16800: 0.3431161046028137, 16900: 0.28339847922325134, 17000: 1.8535475730895996, 17100: 0.4630219042301178, 17200: 3.6657443046569824, 17300: 0.7514606714248657, 17400: 1.0286493301391602, 17500: 2.8017001152038574, 17600: 0.6180598139762878, 17700: 0.5656311511993408, 17800: 0.284676194190979, 17900: 0.4657164216041565, 18000: 0.32002875208854675, 18100: 0.2434167116880417}, 'F1': {9: 0.585423304634852}, 'Accuracy': {9: 0.5216385860588041}}\n",
      "Epoch 10\n",
      "\n",
      "Epoch time: 95.16306495666504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77       563\n",
      "           1       0.62      0.83      0.71       561\n",
      "           2       0.57      0.71      0.63       564\n",
      "           3       0.64      0.51      0.57       573\n",
      "           4       0.57      0.78      0.66       575\n",
      "           5       0.52      0.79      0.62       556\n",
      "           6       0.62      0.58      0.60       564\n",
      "           7       0.60      0.66      0.63       555\n",
      "           8       0.61      0.51      0.56       567\n",
      "           9       0.56      0.61      0.59       542\n",
      "          10       0.41      0.32      0.36      3461\n",
      "\n",
      "    accuracy                           0.54      9081\n",
      "   macro avg       0.59      0.65      0.61      9081\n",
      "weighted avg       0.53      0.54      0.53      9081\n",
      "\n",
      "Logger {'time': {0: 0.01734304428100586, 100: 0.6555631160736084, 200: 1.1991050243377686, 300: 1.764003038406372, 400: 2.3664300441741943, 500: 2.949291229248047, 600: 3.5021989345550537, 700: 4.134244918823242, 800: 4.7382190227508545, 900: 5.376893043518066, 1000: 5.939482927322388, 1100: 6.503911018371582, 1200: 7.053275108337402, 1300: 7.620940923690796, 1400: 8.122742176055908, 1500: 8.647106885910034, 1600: 9.145142078399658, 1700: 9.686438083648682, 1800: 10.182904958724976, 1900: 10.705620050430298, 2000: 11.205046892166138, 2100: 11.736491918563843, 2200: 12.238898992538452, 2300: 12.754684925079346, 2400: 13.26448917388916, 2500: 13.807681798934937, 2600: 14.363319873809814, 2700: 14.90423583984375, 2800: 15.406423807144165, 2900: 15.913806915283203, 3000: 16.43547511100769, 3100: 16.95505118370056, 3200: 17.450993061065674, 3300: 17.960871934890747, 3400: 18.467393159866333, 3500: 18.989223957061768, 3600: 19.486413955688477, 3700: 20.00259494781494, 3800: 20.522844076156616, 3900: 21.015933990478516, 4000: 21.526422023773193, 4100: 22.023702144622803, 4200: 22.543742179870605, 4300: 23.040199041366577, 4400: 23.545194149017334, 4500: 24.034123182296753, 4600: 24.548224210739136, 4700: 25.064062118530273, 4800: 25.57724094390869, 4900: 26.068745136260986, 5000: 26.582403898239136, 5100: 27.081069946289062, 5200: 27.60613489151001, 5300: 28.098037004470825, 5400: 28.62233304977417, 5500: 29.117146968841553, 5600: 29.630486011505127, 5700: 30.197911977767944, 5800: 30.726686000823975, 5900: 31.250002145767212, 6000: 31.787497997283936, 6100: 32.27292513847351, 6200: 32.784993171691895, 6300: 33.29211616516113, 6400: 33.85231304168701, 6500: 34.35846519470215, 6600: 34.85856294631958, 6700: 35.36729717254639, 6800: 35.85824394226074, 6900: 36.37224793434143, 7000: 36.87542414665222, 7100: 37.38151693344116, 7200: 37.88016700744629, 7300: 38.40089201927185, 7400: 38.91305208206177, 7500: 39.4275119304657, 7600: 39.92699885368347, 7700: 40.44569802284241, 7800: 40.970715045928955, 7900: 41.508639097213745, 8000: 42.03633689880371, 8100: 42.554579973220825, 8200: 43.04942083358765, 8300: 43.55823612213135, 8400: 44.08828902244568, 8500: 44.60564303398132, 8600: 45.091294050216675, 8700: 45.605576038360596, 8800: 46.10617208480835, 8900: 46.610981941223145, 9000: 47.135169982910156, 9100: 47.6445038318634, 9200: 48.1544668674469, 9300: 48.66577506065369, 9400: 49.17144417762756, 9500: 49.67741394042969, 9600: 50.18804311752319, 9700: 50.687841176986694, 9800: 51.19445586204529, 9900: 51.76650094985962, 10000: 52.28401708602905, 10100: 52.78466010093689, 10200: 53.28135299682617, 10300: 53.79239797592163, 10400: 54.301316022872925, 10500: 54.80629801750183, 10600: 55.306458950042725, 10700: 55.80060410499573, 10800: 56.34192490577698, 10900: 56.84138894081116, 11000: 57.349870920181274, 11100: 57.86163115501404, 11200: 58.35594606399536, 11300: 58.88346719741821, 11400: 59.388346910476685, 11500: 59.896541118621826, 11600: 60.43805909156799, 11700: 60.93811106681824, 11800: 61.433993101119995, 11900: 61.94627904891968, 12000: 62.44949698448181, 12100: 62.973334074020386, 12200: 63.48074412345886, 12300: 63.99295401573181, 12400: 64.48913812637329, 12500: 65.00221610069275, 12600: 65.50344681739807, 12700: 66.02273225784302, 12800: 66.54154086112976, 12900: 67.122722864151, 13000: 67.71260905265808, 13100: 68.26849007606506, 13200: 68.80515384674072, 13300: 69.36732816696167, 13400: 69.86580491065979, 13500: 70.41945791244507, 13600: 70.94376111030579, 13700: 71.46558284759521, 13800: 71.95900297164917, 13900: 72.47502899169922, 14000: 72.98718905448914, 14100: 73.50102400779724, 14200: 74.05003881454468, 14300: 74.59435415267944, 14400: 75.16062712669373, 14500: 75.8076639175415, 14600: 76.34420108795166, 14700: 76.9661111831665, 14800: 77.56373500823975, 14900: 78.1659779548645, 15000: 78.74528503417969, 15100: 79.40281200408936, 15200: 79.92734694480896, 15300: 80.44555807113647, 15400: 80.95912504196167, 15500: 81.46212220191956, 15600: 81.97745180130005, 15700: 82.47789096832275, 15800: 82.98087000846863, 15900: 83.48055696487427, 16000: 84.01661205291748, 16100: 84.52091407775879, 16200: 85.02105498313904, 16300: 85.54343795776367, 16400: 86.03574109077454, 16500: 86.57257795333862, 16600: 87.06944108009338, 16700: 87.59159517288208, 16800: 88.08210897445679, 16900: 88.58969306945801, 17000: 89.09626889228821, 17100: 89.62215209007263, 17200: 90.12587189674377, 17300: 90.70321488380432, 17400: 91.19849705696106, 17500: 91.74504899978638, 17600: 92.23638415336609, 17700: 92.74673390388489, 17800: 93.25223994255066, 17900: 93.77862095832825, 18000: 94.27598285675049, 18100: 94.81056904792786}, 'loss': {0: 0.5708509087562561, 100: 1.033144474029541, 200: 0.38018250465393066, 300: 0.7626068592071533, 400: 0.2803589403629303, 500: 0.3965628743171692, 600: 0.3669939339160919, 700: 0.8191918730735779, 800: 0.3077934682369232, 900: 0.6099541783332825, 1000: 1.524391531944275, 1100: 1.5901765823364258, 1200: 0.627282977104187, 1300: 0.7278223037719727, 1400: 0.2735963463783264, 1500: 0.6686701774597168, 1600: 0.2321370542049408, 1700: 1.3255826234817505, 1800: 4.174983978271484, 1900: 0.6505124568939209, 2000: 1.267350673675537, 2100: 0.37538740038871765, 2200: 0.8749505281448364, 2300: 0.5860460996627808, 2400: 1.3544893264770508, 2500: 2.4770898818969727, 2600: 1.4881495237350464, 2700: 0.17990100383758545, 2800: 0.8668131232261658, 2900: 0.7334624528884888, 3000: 0.32691559195518494, 3100: 0.6095895171165466, 3200: 0.2348756045103073, 3300: 0.7708456516265869, 3400: 1.0858402252197266, 3500: 0.8448050022125244, 3600: 1.1095585823059082, 3700: 0.6642342209815979, 3800: 0.41861769556999207, 3900: 4.3537278175354, 4000: 0.5800542235374451, 4100: 1.6663095951080322, 4200: 1.0183305740356445, 4300: 0.6620082855224609, 4400: 0.7717439532279968, 4500: 1.508807897567749, 4600: 0.976082980632782, 4700: 0.3873112201690674, 4800: 0.33887532353401184, 4900: 0.44296494126319885, 5000: 0.7817286849021912, 5100: 0.9709950089454651, 5200: 0.43970781564712524, 5300: 1.2755602598190308, 5400: 0.8842504620552063, 5500: 0.6040740013122559, 5600: 1.7917460203170776, 5700: 1.6744279861450195, 5800: 0.46090471744537354, 5900: 1.2193036079406738, 6000: 0.776975154876709, 6100: 0.29878804087638855, 6200: 0.4230556786060333, 6300: 2.9457716941833496, 6400: 0.28662046790122986, 6500: 2.3207991123199463, 6600: 1.3913094997406006, 6700: 1.1356096267700195, 6800: 0.7639873027801514, 6900: 0.5983051061630249, 7000: 0.4378739595413208, 7100: 0.3977479934692383, 7200: 1.0509506464004517, 7300: 0.2866261899471283, 7400: 0.05163607373833656, 7500: 1.2997853755950928, 7600: 2.540595054626465, 7700: 1.2121764421463013, 7800: 1.137028694152832, 7900: 0.8754851818084717, 8000: 0.44373273849487305, 8100: 0.2203025221824646, 8200: 1.1524933576583862, 8300: 0.5987920761108398, 8400: 0.36758288741111755, 8500: 0.7075134515762329, 8600: 0.9174638986587524, 8700: 0.24070467054843903, 8800: 0.5316855907440186, 8900: 0.6114648580551147, 9000: 0.20712272822856903, 9100: 0.2497643530368805, 9200: 0.6058869957923889, 9300: 0.14385680854320526, 9400: 3.4877405166625977, 9500: 1.2993054389953613, 9600: 1.128722906112671, 9700: 1.4979063272476196, 9800: 4.828116416931152, 9900: 0.18489915132522583, 10000: 5.794341087341309, 10100: 0.40998396277427673, 10200: 0.36940446496009827, 10300: 1.0820280313491821, 10400: 0.513433575630188, 10500: 0.4043382704257965, 10600: 0.3401268720626831, 10700: 0.8009388446807861, 10800: 0.3183199465274811, 10900: 0.4643878936767578, 11000: 0.7027342319488525, 11100: 1.345499873161316, 11200: 0.5025853514671326, 11300: 0.5916236639022827, 11400: 3.6976752281188965, 11500: 0.513862669467926, 11600: 0.890009880065918, 11700: 0.9071897268295288, 11800: 1.5577502250671387, 11900: 0.32638588547706604, 12000: 1.1288670301437378, 12100: 0.7153011560440063, 12200: 0.41361016035079956, 12300: 0.5647354125976562, 12400: 0.36074885725975037, 12500: 0.9730957746505737, 12600: 0.2030886709690094, 12700: 0.5620585083961487, 12800: 0.8747236132621765, 12900: 1.231414556503296, 13000: 1.262794852256775, 13100: 0.2708275616168976, 13200: 0.9761975407600403, 13300: 1.5591503381729126, 13400: 0.815597414970398, 13500: 1.6478638648986816, 13600: 1.4798328876495361, 13700: 1.1562113761901855, 13800: 0.780869722366333, 13900: 0.42448562383651733, 14000: 0.2864883542060852, 14100: 0.2811915874481201, 14200: 0.1873534619808197, 14300: 1.3478621244430542, 14400: 0.7757092714309692, 14500: 1.605345606803894, 14600: 0.5121780633926392, 14700: 0.7277671694755554, 14800: 0.47369900345802307, 14900: 0.8975933790206909, 15000: 0.2722713351249695, 15100: 1.402726650238037, 15200: 0.7069295048713684, 15300: 2.3724143505096436, 15400: 2.8615236282348633, 15500: 1.2619420289993286, 15600: 0.6788387298583984, 15700: 0.8045408725738525, 15800: 1.3668944835662842, 15900: 0.6805511116981506, 16000: 1.3401607275009155, 16100: 0.8050380349159241, 16200: 0.566744327545166, 16300: 1.968205451965332, 16400: 0.29668480157852173, 16500: 1.2353122234344482, 16600: 0.3636510670185089, 16700: 0.20855186879634857, 16800: 0.6583894491195679, 16900: 0.2865353226661682, 17000: 0.7054620385169983, 17100: 0.5653719902038574, 17200: 2.811464548110962, 17300: 1.0600934028625488, 17400: 0.663171112537384, 17500: 0.763825535774231, 17600: 1.1974252462387085, 17700: 0.5356927514076233, 17800: 0.22468635439872742, 17900: 0.8165820240974426, 18000: 0.3040958046913147, 18100: 0.4543604254722595}, 'F1': {10: 0.6085565780952988}, 'Accuracy': {10: 0.5430018720405242}}\n",
      "Training with dataset size: 30000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Epoch 1\n",
      "\n",
      "Epoch time: 139.58571481704712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74       837\n",
      "           1       0.60      0.93      0.73       832\n",
      "           2       0.63      0.39      0.49       858\n",
      "           3       0.62      0.65      0.63       850\n",
      "           4       0.56      0.83      0.67       829\n",
      "           5       0.56      0.74      0.64       846\n",
      "           6       0.61      0.82      0.70       851\n",
      "           7       0.59      0.85      0.70       851\n",
      "           8       0.58      0.76      0.66       845\n",
      "           9       0.60      0.43      0.50       851\n",
      "          10       0.39      0.25      0.31      5171\n",
      "\n",
      "    accuracy                           0.55     13621\n",
      "   macro avg       0.58      0.68      0.61     13621\n",
      "weighted avg       0.52      0.55      0.52     13621\n",
      "\n",
      "Logger {'time': {0: 0.03645586967468262, 100: 0.6095030307769775, 200: 1.1236400604248047, 300: 1.667846918106079, 400: 2.167135000228882, 500: 2.699843168258667, 600: 3.2074499130249023, 700: 3.726322889328003, 800: 4.231039047241211, 900: 4.753210783004761, 1000: 5.24821400642395, 1100: 5.745003938674927, 1200: 6.250231027603149, 1300: 6.769871950149536, 1400: 7.291063070297241, 1500: 7.793305158615112, 1600: 8.306226968765259, 1700: 8.813985109329224, 1800: 9.351072072982788, 1900: 9.842565774917603, 2000: 10.363616943359375, 2100: 10.85724687576294, 2200: 11.372976779937744, 2300: 11.862275123596191, 2400: 12.37207818031311, 2500: 12.859650135040283, 2600: 13.447403907775879, 2700: 13.94683289527893, 2800: 14.469883918762207, 2900: 14.95178484916687, 3000: 15.48060393333435, 3100: 15.978605031967163, 3200: 16.496331930160522, 3300: 16.992665767669678, 3400: 17.49263906478882, 3500: 18.004177808761597, 3600: 18.500927925109863, 3700: 19.017220735549927, 3800: 19.539639949798584, 3900: 20.06015110015869, 4000: 20.585237979888916, 4100: 21.103349924087524, 4200: 21.59780979156494, 4300: 22.104495763778687, 4400: 22.650831937789917, 4500: 23.15591812133789, 4600: 23.66209316253662, 4700: 24.15704917907715, 4800: 24.68005394935608, 4900: 25.20694875717163, 5000: 25.713924169540405, 5100: 26.26204800605774, 5200: 26.81479501724243, 5300: 27.31593894958496, 5400: 27.81560492515564, 5500: 28.321295022964478, 5600: 28.812147855758667, 5700: 29.338841915130615, 5800: 29.833034992218018, 5900: 30.33188509941101, 6000: 30.828521966934204, 6100: 31.334662914276123, 6200: 32.0909948348999, 6300: 32.79731512069702, 6400: 33.306856870651245, 6500: 33.82325291633606, 6600: 34.32848596572876, 6700: 34.838069915771484, 6800: 35.34100413322449, 6900: 35.85268497467041, 7000: 36.34694695472717, 7100: 36.87135314941406, 7200: 37.372793197631836, 7300: 37.87857007980347, 7400: 38.38087797164917, 7500: 38.88638997077942, 7600: 39.39803385734558, 7700: 39.89423394203186, 7800: 40.40847682952881, 7900: 40.90374493598938, 8000: 41.42916774749756, 8100: 41.92442178726196, 8200: 42.439486026763916, 8300: 42.93137884140015, 8400: 43.525803089141846, 8500: 44.02194619178772, 8600: 44.53664803504944, 8700: 45.03054094314575, 8800: 45.5545117855072, 8900: 46.0426230430603, 9000: 46.55997586250305, 9100: 47.061208963394165, 9200: 47.570111989974976, 9300: 48.064181089401245, 9400: 48.56938290596008, 9500: 49.0530948638916, 9600: 49.582452058792114, 9700: 50.09742498397827, 9800: 50.62776303291321, 9900: 51.11208200454712, 10000: 51.61768913269043, 10100: 52.13280892372131, 10200: 52.64762091636658, 10300: 53.15566110610962, 10400: 53.65615701675415, 10500: 54.15552306175232, 10600: 54.654659032821655, 10700: 55.165480852127075, 10800: 55.67039680480957, 10900: 56.192357778549194, 11000: 56.708943128585815, 11100: 57.22750377655029, 11200: 57.72875690460205, 11300: 58.246898889541626, 11400: 58.73667597770691, 11500: 59.24362015724182, 11600: 59.80007982254028, 11700: 60.310916900634766, 11800: 60.81261992454529, 11900: 61.3391809463501, 12000: 61.82930898666382, 12100: 62.32537913322449, 12200: 62.82265901565552, 12300: 63.32206201553345, 12400: 63.81871581077576, 12500: 64.31690812110901, 12600: 64.82530999183655, 12700: 65.32584595680237, 12800: 65.84182405471802, 12900: 66.33591985702515, 13000: 66.84192204475403, 13100: 67.33790993690491, 13200: 67.85109877586365, 13300: 68.34775590896606, 13400: 68.85762691497803, 13500: 69.3570339679718, 13600: 69.8657898902893, 13700: 70.37083101272583, 13800: 70.88679099082947, 13900: 71.38893795013428, 14000: 71.90826892852783, 14100: 72.42637395858765, 14200: 72.92279195785522, 14300: 73.43538308143616, 14400: 73.98147201538086, 14500: 74.50152611732483, 14600: 75.00276708602905, 14700: 75.51382493972778, 14800: 76.00756311416626, 14900: 76.5315887928009, 15000: 77.0271008014679, 15100: 77.53941297531128, 15200: 78.02934718132019, 15300: 78.55358695983887, 15400: 79.0598521232605, 15500: 79.64310097694397, 15600: 80.233078956604, 15700: 80.78632807731628, 15800: 81.29512405395508, 15900: 81.83885383605957, 16000: 82.36921191215515, 16100: 82.90216898918152, 16200: 83.39184212684631, 16300: 83.93258094787598, 16400: 84.43131899833679, 16500: 84.94392395019531, 16600: 85.45118689537048, 16700: 85.98171281814575, 16800: 86.47769808769226, 16900: 87.0109498500824, 17000: 87.51532793045044, 17100: 88.01899099349976, 17200: 88.52630615234375, 17300: 89.0317029953003, 17400: 89.53976392745972, 17500: 90.04144215583801, 17600: 90.5610249042511, 17700: 91.06222009658813, 17800: 91.5861189365387, 17900: 92.07710099220276, 18000: 92.59259605407715, 18100: 93.0913999080658, 18200: 93.61340808868408, 18300: 94.10290098190308, 18400: 94.61379289627075, 18500: 95.10168695449829, 18600: 95.61315608024597, 18700: 96.11585998535156, 18800: 96.63798403739929, 18900: 97.12127304077148, 19000: 97.63166093826294, 19100: 98.12675094604492, 19200: 98.63966012001038, 19300: 99.13324999809265, 19400: 99.64705300331116, 19500: 100.16661977767944, 19600: 100.67771100997925, 19700: 101.19798493385315, 19800: 101.70346999168396, 19900: 102.21661376953125, 20000: 102.71869206428528, 20100: 103.22826600074768, 20200: 103.78361296653748, 20300: 104.31503200531006, 20400: 104.79914903640747, 20500: 105.31129503250122, 20600: 105.80575299263, 20700: 106.33295392990112, 20800: 106.83531999588013, 20900: 107.35496282577515, 21000: 107.83801078796387, 21100: 108.36279511451721, 21200: 108.85495591163635, 21300: 109.37202787399292, 21400: 109.85587191581726, 21500: 110.3676438331604, 21600: 110.84954595565796, 21700: 111.41845393180847, 21800: 111.92303681373596, 21900: 112.5008180141449, 22000: 112.99013710021973, 22100: 113.49679899215698, 22200: 113.98949193954468, 22300: 114.48804879188538, 22400: 115.02848410606384, 22500: 115.53857398033142, 22600: 116.05247497558594, 22700: 116.55608296394348, 22800: 117.06305003166199, 22900: 117.56317377090454, 23000: 118.06393909454346, 23100: 118.56801199913025, 23200: 119.07841396331787, 23300: 119.57088112831116, 23400: 120.07924294471741, 23500: 120.57068705558777, 23600: 121.0738959312439, 23700: 121.57743096351624, 23800: 122.07571196556091, 23900: 122.58033299446106, 24000: 123.07764291763306, 24100: 123.59322595596313, 24200: 124.09419012069702, 24300: 124.58832788467407, 24400: 125.08086705207825, 24500: 125.60563778877258, 24600: 126.10766792297363, 24700: 126.62699007987976, 24800: 127.11888194084167, 24900: 127.64090490341187, 25000: 128.1381471157074, 25100: 128.65261006355286, 25200: 129.1378309726715, 25300: 129.6532769203186, 25400: 130.15123414993286, 25500: 130.65809988975525, 25600: 131.15033602714539, 25700: 131.66764497756958, 25800: 132.1700520515442, 25900: 132.67464399337769, 26000: 133.1864697933197, 26100: 133.68330907821655, 26200: 134.2474820613861, 26300: 134.74787497520447, 26400: 135.25871992111206, 26500: 135.7582550048828, 26600: 136.26800203323364, 26700: 136.76181507110596, 26800: 137.25756788253784, 26900: 137.75855898857117, 27000: 138.28673791885376, 27100: 138.77756190299988, 27200: 139.2918930053711}, 'loss': {0: 0.3007597029209137, 100: 0.600787878036499, 200: 0.8929435014724731, 300: 0.612231433391571, 400: 0.506996750831604, 500: 0.5796663761138916, 600: 0.48059019446372986, 700: 1.8495309352874756, 800: 0.573223888874054, 900: 0.7317283153533936, 1000: 0.28696051239967346, 1100: 0.625139594078064, 1200: 0.33186089992523193, 1300: 0.8833296895027161, 1400: 0.6383138298988342, 1500: 1.1069642305374146, 1600: 0.3130929172039032, 1700: 0.724857747554779, 1800: 1.5911805629730225, 1900: 0.41020625829696655, 2000: 1.1472694873809814, 2100: 0.8952183723449707, 2200: 0.36447882652282715, 2300: 6.981485366821289, 2400: 2.0246119499206543, 2500: 0.35751593112945557, 2600: 0.797968327999115, 2700: 0.9546340107917786, 2800: 0.37123310565948486, 2900: 0.9854359030723572, 3000: 0.25331881642341614, 3100: 1.222038745880127, 3200: 2.78653621673584, 3300: 0.10726462304592133, 3400: 0.583848237991333, 3500: 1.1202160120010376, 3600: 5.182580947875977, 3700: 0.15994669497013092, 3800: 1.501916766166687, 3900: 0.6161721348762512, 4000: 1.2119451761245728, 4100: 1.313746452331543, 4200: 0.6588067412376404, 4300: 0.7287406325340271, 4400: 7.356076240539551, 4500: 1.0254510641098022, 4600: 0.9562366008758545, 4700: 1.5681602954864502, 4800: 0.6639881730079651, 4900: 1.416644811630249, 5000: 0.6184263229370117, 5100: 2.1923022270202637, 5200: 0.0653594359755516, 5300: 0.1187848448753357, 5400: 2.203537940979004, 5500: 0.6371736526489258, 5600: 1.7316157817840576, 5700: 2.230109930038452, 5800: 1.744398593902588, 5900: 0.837607741355896, 6000: 1.261369228363037, 6100: 0.5116191506385803, 6200: 1.1494908332824707, 6300: 0.31241872906684875, 6400: 0.40671974420547485, 6500: 0.18295638263225555, 6600: 0.4675915837287903, 6700: 0.33428728580474854, 6800: 1.2761576175689697, 6900: 0.4823528528213501, 7000: 0.25674158334732056, 7100: 0.4350852966308594, 7200: 0.6004270315170288, 7300: 1.2227530479431152, 7400: 1.0818591117858887, 7500: 0.42820173501968384, 7600: 0.5507805347442627, 7700: 0.13122440874576569, 7800: 1.3810069561004639, 7900: 0.25912806391716003, 8000: 0.7373545169830322, 8100: 0.25042885541915894, 8200: 0.5868373513221741, 8300: 0.8030619025230408, 8400: 0.3395591378211975, 8500: 0.5777793526649475, 8600: 0.27058711647987366, 8700: 0.9429309964179993, 8800: 1.5851202011108398, 8900: 0.45439252257347107, 9000: 1.1514761447906494, 9100: 0.31646081805229187, 9200: 0.3260805010795593, 9300: 0.2724462151527405, 9400: 1.4220694303512573, 9500: 1.7456203699111938, 9600: 0.7886502146720886, 9700: 8.481428146362305, 9800: 0.5144725441932678, 9900: 0.8109397888183594, 10000: 1.1419336795806885, 10100: 0.18224678933620453, 10200: 2.746195077896118, 10300: 0.5290616154670715, 10400: 0.9773401618003845, 10500: 0.4856939911842346, 10600: 1.482175350189209, 10700: 0.3116217255592346, 10800: 0.4411452114582062, 10900: 0.7524584531784058, 11000: 0.49008697271347046, 11100: 0.34816470742225647, 11200: 0.3991639316082001, 11300: 0.22512751817703247, 11400: 1.5048952102661133, 11500: 0.8812633752822876, 11600: 2.1482529640197754, 11700: 0.6041038632392883, 11800: 1.0604366064071655, 11900: 0.5349081158638, 12000: 1.024773359298706, 12100: 0.7132649421691895, 12200: 0.3433185815811157, 12300: 0.5095431804656982, 12400: 1.302921175956726, 12500: 0.4950169622898102, 12600: 0.2814079821109772, 12700: 0.7059822082519531, 12800: 0.5781078338623047, 12900: 0.3429690897464752, 13000: 1.379092812538147, 13100: 1.3799716234207153, 13200: 0.5798544883728027, 13300: 0.8758954405784607, 13400: 0.28126195073127747, 13500: 1.030783772468567, 13600: 0.3753091096878052, 13700: 0.7303779721260071, 13800: 0.31401312351226807, 13900: 0.5673272013664246, 14000: 1.1250511407852173, 14100: 0.5933954119682312, 14200: 0.5018479228019714, 14300: 0.7704327702522278, 14400: 0.842529833316803, 14500: 0.3889288902282715, 14600: 0.5350910425186157, 14700: 1.3113701343536377, 14800: 0.11040635406970978, 14900: 0.5137388706207275, 15000: 0.7005975842475891, 15100: 0.7411874532699585, 15200: 1.1795088052749634, 15300: 0.8229482769966125, 15400: 0.4331936240196228, 15500: 0.9292783737182617, 15600: 0.7235020399093628, 15700: 4.031679153442383, 15800: 1.8383997678756714, 15900: 0.48165732622146606, 16000: 2.0067543983459473, 16100: 0.4809650778770447, 16200: 0.40075790882110596, 16300: 0.40636831521987915, 16400: 1.3812801837921143, 16500: 0.6715701818466187, 16600: 1.5314016342163086, 16700: 0.24592773616313934, 16800: 0.6323010325431824, 16900: 0.8105592727661133, 17000: 0.8378653526306152, 17100: 0.8173075914382935, 17200: 0.7244530916213989, 17300: 0.494174987077713, 17400: 0.712972104549408, 17500: 0.4716588258743286, 17600: 0.38730570673942566, 17700: 1.1412032842636108, 17800: 1.0956614017486572, 17900: 0.6105333566665649, 18000: 1.1250994205474854, 18100: 0.7075705528259277, 18200: 0.24367591738700867, 18300: 1.3867318630218506, 18400: 0.8822875618934631, 18500: 0.430355966091156, 18600: 0.5846371650695801, 18700: 1.1644880771636963, 18800: 0.7411671280860901, 18900: 0.2923152446746826, 19000: 0.4084000289440155, 19100: 4.985691070556641, 19200: 1.4246995449066162, 19300: 1.5250674486160278, 19400: 0.4458940327167511, 19500: 0.18934838473796844, 19600: 1.1498394012451172, 19700: 0.6247883439064026, 19800: 0.19954274594783783, 19900: 1.1143627166748047, 20000: 1.113072395324707, 20100: 0.7982977032661438, 20200: 0.45632702112197876, 20300: 1.0129070281982422, 20400: 0.945864737033844, 20500: 0.7444821000099182, 20600: 0.3069128692150116, 20700: 0.4666704535484314, 20800: 0.2903778553009033, 20900: 5.279003620147705, 21000: 1.178473949432373, 21100: 0.3463899791240692, 21200: 0.17858217656612396, 21300: 0.4172206521034241, 21400: 1.3012064695358276, 21500: 5.447087287902832, 21600: 0.2584214508533478, 21700: 0.6232949495315552, 21800: 1.1635637283325195, 21900: 1.2369625568389893, 22000: 1.6887285709381104, 22100: 0.35356518626213074, 22200: 0.5238210558891296, 22300: 0.24855753779411316, 22400: 0.3230125606060028, 22500: 0.22916993498802185, 22600: 0.76214200258255, 22700: 0.5125774145126343, 22800: 0.29681238532066345, 22900: 6.236455917358398, 23000: 0.19155490398406982, 23100: 0.5555165410041809, 23200: 0.36926349997520447, 23300: 1.4009015560150146, 23400: 2.0441417694091797, 23500: 0.2383892983198166, 23600: 1.5199189186096191, 23700: 2.2104029655456543, 23800: 1.2610480785369873, 23900: 0.9942059516906738, 24000: 0.7558403611183167, 24100: 0.21408383548259735, 24200: 0.9756414294242859, 24300: 0.5253040790557861, 24400: 0.9994910955429077, 24500: 1.1811261177062988, 24600: 1.3969578742980957, 24700: 0.3926370143890381, 24800: 1.3081474304199219, 24900: 1.7893147468566895, 25000: 0.5598694086074829, 25100: 0.38000747561454773, 25200: 1.3077360391616821, 25300: 0.42573797702789307, 25400: 0.7403042912483215, 25500: 0.49155113101005554, 25600: 0.7744541764259338, 25700: 1.1295031309127808, 25800: 0.7552487254142761, 25900: 1.6208299398422241, 26000: 3.19230055809021, 26100: 2.066838026046753, 26200: 0.07738716155290604, 26300: 1.085316777229309, 26400: 0.873435378074646, 26500: 1.248001217842102, 26600: 0.46116316318511963, 26700: 0.4310699701309204, 26800: 1.3963196277618408, 26900: 0.44760504364967346, 27000: 0.6785053014755249, 27100: 0.9607836604118347, 27200: 0.8457084894180298}, 'F1': {1: 0.614846759148152}, 'Accuracy': {1: 0.5473900594669995}}\n",
      "Epoch 2\n",
      "\n",
      "Epoch time: 152.9026129245758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.74       837\n",
      "           1       0.60      0.96      0.74       832\n",
      "           2       0.66      0.29      0.41       858\n",
      "           3       0.61      0.64      0.63       850\n",
      "           4       0.54      0.75      0.63       829\n",
      "           5       0.58      0.73      0.65       846\n",
      "           6       0.60      0.84      0.70       851\n",
      "           7       0.61      0.78      0.69       851\n",
      "           8       0.57      0.75      0.65       845\n",
      "           9       0.60      0.68      0.64       851\n",
      "          10       0.39      0.26      0.31      5171\n",
      "\n",
      "    accuracy                           0.55     13621\n",
      "   macro avg       0.58      0.68      0.62     13621\n",
      "weighted avg       0.52      0.55      0.52     13621\n",
      "\n",
      "Logger {'time': {0: 0.018871784210205078, 100: 0.5794298648834229, 200: 1.1072578430175781, 300: 1.599158763885498, 400: 2.1397528648376465, 500: 2.643258810043335, 600: 3.1622517108917236, 700: 3.6636879444122314, 800: 4.175579786300659, 900: 4.674412727355957, 1000: 5.211658000946045, 1100: 5.718538045883179, 1200: 6.234328746795654, 1300: 6.730456829071045, 1400: 7.250079870223999, 1500: 7.748312711715698, 1600: 8.249234914779663, 1700: 8.76372480392456, 1800: 9.255559921264648, 1900: 9.85467791557312, 2000: 10.36196780204773, 2100: 10.864259719848633, 2200: 11.36143183708191, 2300: 11.87145185470581, 2400: 12.372332096099854, 2500: 12.881367683410645, 2600: 13.37365198135376, 2700: 13.888972759246826, 2800: 14.38984990119934, 2900: 14.901119947433472, 3000: 15.395384788513184, 3100: 15.913121700286865, 3200: 16.399460792541504, 3300: 16.91791081428528, 3400: 17.42445182800293, 3500: 17.936890840530396, 3600: 18.423141956329346, 3700: 18.925601720809937, 3800: 19.43633270263672, 3900: 19.928139686584473, 4000: 20.460112810134888, 4100: 20.96971583366394, 4200: 21.499695777893066, 4300: 21.998779773712158, 4400: 22.520211935043335, 4500: 23.067341804504395, 4600: 23.584261894226074, 4700: 24.102262020111084, 4800: 24.60309672355652, 4900: 25.121447801589966, 5000: 25.63253092765808, 5100: 26.130582809448242, 5200: 26.634482860565186, 5300: 27.13274598121643, 5400: 27.6361186504364, 5500: 28.150686979293823, 5600: 28.65115189552307, 5700: 29.162879943847656, 5800: 29.6735680103302, 5900: 30.16574478149414, 6000: 30.652587890625, 6100: 31.179706811904907, 6200: 31.672024726867676, 6300: 32.19050979614258, 6400: 32.694655895233154, 6500: 33.21153473854065, 6600: 33.70396590232849, 6700: 34.23048782348633, 6800: 34.72939586639404, 6900: 35.24619483947754, 7000: 35.72990798950195, 7100: 36.241931676864624, 7200: 36.74094891548157, 7300: 37.25242781639099, 7400: 37.747206926345825, 7500: 38.279751777648926, 7600: 38.77759385108948, 7700: 39.293805837631226, 7800: 39.83765196800232, 7900: 40.362025022506714, 8000: 40.85050702095032, 8100: 41.369494676589966, 8200: 41.87225294113159, 8300: 42.37107300758362, 8400: 42.88385987281799, 8500: 43.38524079322815, 8600: 43.895100831985474, 8700: 44.38561177253723, 8800: 44.893908977508545, 8900: 45.45974397659302, 9000: 45.99128484725952, 9100: 46.56546998023987, 9200: 47.102942943573, 9300: 47.626524925231934, 9400: 48.29342269897461, 9500: 48.91359066963196, 9600: 49.50578188896179, 9700: 50.12692975997925, 9800: 50.702284812927246, 9900: 51.29139304161072, 10000: 51.89777994155884, 10100: 52.565889835357666, 10200: 53.137961864471436, 10300: 53.71662783622742, 10400: 54.265448808670044, 10500: 54.80555582046509, 10600: 55.354559898376465, 10700: 55.907758712768555, 10800: 56.424694776535034, 10900: 56.9243597984314, 11000: 57.49158573150635, 11100: 57.99945092201233, 11200: 58.52765083312988, 11300: 59.05855083465576, 11400: 59.636815786361694, 11500: 60.14868187904358, 11600: 60.68234395980835, 11700: 61.21557879447937, 11800: 61.732171058654785, 11900: 62.24662399291992, 12000: 62.770838022232056, 12100: 63.271501779556274, 12200: 63.758484840393066, 12300: 64.27049589157104, 12400: 64.76209473609924, 12500: 65.289479970932, 12600: 65.8582079410553, 12700: 66.45696592330933, 12800: 67.08406567573547, 12900: 67.66984176635742, 13000: 68.26081371307373, 13100: 68.82662892341614, 13200: 69.4702217578888, 13300: 70.05580973625183, 13400: 70.6157157421112, 13500: 71.15774273872375, 13600: 71.81768774986267, 13700: 72.50319266319275, 13800: 73.21030569076538, 13900: 73.84497284889221, 14000: 74.50165390968323, 14100: 75.11531972885132, 14200: 75.75473999977112, 14300: 76.42859983444214, 14400: 77.23562979698181, 14500: 78.02824091911316, 14600: 78.7365026473999, 14700: 79.41545605659485, 14800: 80.06663084030151, 14900: 80.72719383239746, 15000: 81.41978192329407, 15100: 82.0903959274292, 15200: 82.77037978172302, 15300: 83.419921875, 15400: 84.03719878196716, 15500: 84.78550291061401, 15600: 85.47189092636108, 15700: 86.12771368026733, 15800: 86.77386689186096, 15900: 87.40774989128113, 16000: 88.07683992385864, 16100: 88.71259689331055, 16200: 89.37551379203796, 16300: 90.0268669128418, 16400: 90.68475079536438, 16500: 91.37600994110107, 16600: 92.00995874404907, 16700: 92.66104674339294, 16800: 93.30002188682556, 16900: 93.96530199050903, 17000: 94.59609174728394, 17100: 95.355712890625, 17200: 96.01415491104126, 17300: 96.62334680557251, 17400: 97.26238894462585, 17500: 97.90443086624146, 17600: 98.54176902770996, 17700: 99.17344999313354, 17800: 99.79753875732422, 17900: 100.50090599060059, 18000: 101.1283688545227, 18100: 101.77763485908508, 18200: 102.43159198760986, 18300: 103.0677559375763, 18400: 103.70929384231567, 18500: 104.33828401565552, 18600: 104.99245071411133, 18700: 105.65197682380676, 18800: 106.29267001152039, 18900: 106.94041395187378, 19000: 107.58287596702576, 19100: 108.24823880195618, 19200: 108.85364365577698, 19300: 109.46801590919495, 19400: 110.09178972244263, 19500: 110.72529983520508, 19600: 111.37873888015747, 19700: 112.02183198928833, 19800: 112.71121788024902, 19900: 113.3647689819336, 20000: 114.00335693359375, 20100: 114.63189768791199, 20200: 115.28345990180969, 20300: 115.91585278511047, 20400: 116.57084894180298, 20500: 117.2219169139862, 20600: 117.84086680412292, 20700: 118.4880108833313, 20800: 119.10935091972351, 20900: 119.6949508190155, 21000: 120.25024485588074, 21100: 120.8900887966156, 21200: 121.52281379699707, 21300: 122.12053394317627, 21400: 122.65602207183838, 21500: 123.1785478591919, 21600: 123.71463561058044, 21700: 124.22935390472412, 21800: 124.7486469745636, 21900: 125.26273989677429, 22000: 125.77006268501282, 22100: 126.28148579597473, 22200: 126.78793287277222, 22300: 127.30365681648254, 22400: 127.79737186431885, 22500: 128.31262278556824, 22600: 128.84870505332947, 22700: 129.3580837249756, 22800: 129.8493776321411, 22900: 130.46328592300415, 23000: 131.00984978675842, 23100: 131.52506399154663, 23200: 132.01809191703796, 23300: 132.53649377822876, 23400: 133.0487208366394, 23500: 133.56960892677307, 23600: 134.06289982795715, 23700: 134.59098386764526, 23800: 135.0986487865448, 23900: 135.60211086273193, 24000: 136.1348967552185, 24100: 136.64622592926025, 24200: 137.14315795898438, 24300: 137.64868783950806, 24400: 138.15096187591553, 24500: 138.66099977493286, 24600: 139.17936182022095, 24700: 139.69097685813904, 24800: 140.20007491111755, 24900: 140.71652579307556, 25000: 141.30065274238586, 25100: 141.81576991081238, 25200: 142.33736085891724, 25300: 142.8805787563324, 25400: 143.3874156475067, 25500: 143.89677476882935, 25600: 144.40357565879822, 25700: 144.90794587135315, 25800: 145.42337489128113, 25900: 145.92847180366516, 26000: 146.45086884498596, 26100: 146.95450687408447, 26200: 147.49305295944214, 26300: 147.98591589927673, 26400: 148.50035572052002, 26500: 149.00832796096802, 26600: 149.51960587501526, 26700: 150.02297282218933, 26800: 150.53308391571045, 26900: 151.04197883605957, 27000: 151.56048488616943, 27100: 152.07554984092712, 27200: 152.59993767738342}, 'loss': {0: 0.9198943376541138, 100: 0.9009120464324951, 200: 0.6112802624702454, 300: 0.6807736158370972, 400: 0.42749157547950745, 500: 0.5256545543670654, 600: 0.45880916714668274, 700: 1.1975529193878174, 800: 0.7083137631416321, 900: 0.5580302476882935, 1000: 0.5603100657463074, 1100: 0.43933820724487305, 1200: 0.3949030637741089, 1300: 0.8493030071258545, 1400: 0.4119541049003601, 1500: 0.7646423578262329, 1600: 0.3007822036743164, 1700: 1.0092651844024658, 1800: 1.3925763368606567, 1900: 0.4387359321117401, 2000: 0.8041728734970093, 2100: 1.2392313480377197, 2200: 0.38412758708000183, 2300: 4.627334117889404, 2400: 3.202897310256958, 2500: 0.6979452967643738, 2600: 1.1010205745697021, 2700: 0.9276056885719299, 2800: 0.5833498239517212, 2900: 0.3207448720932007, 3000: 0.3464832901954651, 3100: 0.4705479145050049, 3200: 0.5810642838478088, 3300: 0.15270037949085236, 3400: 0.3821295201778412, 3500: 0.9658777117729187, 3600: 1.7533223628997803, 3700: 0.14508704841136932, 3800: 1.3796513080596924, 3900: 0.7183923721313477, 4000: 1.146069049835205, 4100: 1.684842824935913, 4200: 0.4620875120162964, 4300: 0.9960488677024841, 4400: 3.6203033924102783, 4500: 1.1109027862548828, 4600: 0.7812970280647278, 4700: 1.1837804317474365, 4800: 0.505366325378418, 4900: 1.2996608018875122, 5000: 0.6727951765060425, 5100: 2.2073044776916504, 5200: 0.3170054256916046, 5300: 0.19837716221809387, 5400: 1.3393163681030273, 5500: 0.5441297292709351, 5600: 1.5406501293182373, 5700: 3.2496910095214844, 5800: 1.4402332305908203, 5900: 0.868021547794342, 6000: 1.4217112064361572, 6100: 0.47932949662208557, 6200: 1.1806292533874512, 6300: 0.3061554431915283, 6400: 0.2435188591480255, 6500: 1.2672935724258423, 6600: 0.6770074367523193, 6700: 0.3440193235874176, 6800: 1.0490443706512451, 6900: 0.7050648927688599, 7000: 0.2731897830963135, 7100: 1.1666040420532227, 7200: 0.37493908405303955, 7300: 1.170858383178711, 7400: 1.0221577882766724, 7500: 0.24767611920833588, 7600: 0.2640821933746338, 7700: 0.1932222694158554, 7800: 1.3333251476287842, 7900: 0.2665506899356842, 8000: 0.6252925395965576, 8100: 0.5052686929702759, 8200: 0.6293311715126038, 8300: 0.8303937315940857, 8400: 0.18444305658340454, 8500: 0.506524920463562, 8600: 0.41970765590667725, 8700: 0.5594503879547119, 8800: 1.7711783647537231, 8900: 0.2693033814430237, 9000: 0.9122315049171448, 9100: 0.30574801564216614, 9200: 0.25994282960891724, 9300: 0.36020153760910034, 9400: 0.698205292224884, 9500: 1.140477180480957, 9600: 0.9552785158157349, 9700: 8.259828567504883, 9800: 0.5481767058372498, 9900: 2.325483798980713, 10000: 0.961361825466156, 10100: 0.5602906942367554, 10200: 3.175750255584717, 10300: 0.4030393660068512, 10400: 0.2758432924747467, 10500: 0.40677887201309204, 10600: 1.4069139957427979, 10700: 0.44979527592658997, 10800: 0.21166598796844482, 10900: 0.6146066784858704, 11000: 0.3644644021987915, 11100: 0.4409625828266144, 11200: 0.3915294408798218, 11300: 0.24207250773906708, 11400: 0.8786781430244446, 11500: 0.8242303729057312, 11600: 2.190558910369873, 11700: 0.5929848551750183, 11800: 1.1314488649368286, 11900: 0.6663053035736084, 12000: 0.2884756326675415, 12100: 0.36571231484413147, 12200: 0.37734633684158325, 12300: 0.5356869101524353, 12400: 0.5312235355377197, 12500: 0.5697890520095825, 12600: 1.7044849395751953, 12700: 0.8623749613761902, 12800: 0.5009569525718689, 12900: 0.3034670948982239, 13000: 1.8409614562988281, 13100: 1.3071869611740112, 13200: 0.519515872001648, 13300: 0.2325964719057083, 13400: 0.5041155815124512, 13500: 0.8205884099006653, 13600: 0.43449127674102783, 13700: 0.49292251467704773, 13800: 0.6129952073097229, 13900: 0.41503041982650757, 14000: 0.5426491498947144, 14100: 0.5831117033958435, 14200: 0.5801534652709961, 14300: 0.6208780407905579, 14400: 0.46572840213775635, 14500: 0.6616603136062622, 14600: 0.7208534479141235, 14700: 1.0220284461975098, 14800: 0.09597765654325485, 14900: 0.37666815519332886, 15000: 0.8223307132720947, 15100: 0.8710036873817444, 15200: 0.8526704907417297, 15300: 0.47870534658432007, 15400: 0.45250204205513, 15500: 0.9383613467216492, 15600: 0.39800503849983215, 15700: 4.268337249755859, 15800: 1.457019329071045, 15900: 0.23861552774906158, 16000: 2.1182994842529297, 16100: 1.530029296875, 16200: 0.3567868769168854, 16300: 0.7975743412971497, 16400: 1.062251091003418, 16500: 0.6099108457565308, 16600: 1.6245296001434326, 16700: 0.29902195930480957, 16800: 1.6921050548553467, 16900: 0.7707597017288208, 17000: 0.5695359706878662, 17100: 0.9576045870780945, 17200: 1.0202008485794067, 17300: 0.3118271827697754, 17400: 0.4993658661842346, 17500: 0.5238224864006042, 17600: 0.21912606060504913, 17700: 0.8546891212463379, 17800: 1.0496467351913452, 17900: 0.4985399544239044, 18000: 0.6694706678390503, 18100: 0.8548923134803772, 18200: 0.28223636746406555, 18300: 1.2437504529953003, 18400: 0.9382111430168152, 18500: 0.3776049315929413, 18600: 0.6468861103057861, 18700: 1.1469708681106567, 18800: 0.47617006301879883, 18900: 0.300703227519989, 19000: 0.34102535247802734, 19100: 4.978752136230469, 19200: 1.7871793508529663, 19300: 1.7793841361999512, 19400: 0.37075552344322205, 19500: 0.30739688873291016, 19600: 0.9693536758422852, 19700: 0.7108703255653381, 19800: 0.26141825318336487, 19900: 1.48451828956604, 20000: 1.2677100896835327, 20100: 0.6612032651901245, 20200: 0.3873370885848999, 20300: 0.987811803817749, 20400: 0.8345780372619629, 20500: 0.6970955729484558, 20600: 0.4333689510822296, 20700: 0.47518378496170044, 20800: 0.9573918581008911, 20900: 1.2663965225219727, 21000: 0.5122615694999695, 21100: 0.8322384357452393, 21200: 0.22754506766796112, 21300: 0.43641138076782227, 21400: 0.5721441507339478, 21500: 5.243951320648193, 21600: 0.33225011825561523, 21700: 0.5832563638687134, 21800: 1.3458466529846191, 21900: 1.2348313331604004, 22000: 1.384832739830017, 22100: 0.37811920046806335, 22200: 0.47017744183540344, 22300: 0.2576569616794586, 22400: 0.8763293027877808, 22500: 0.2787260115146637, 22600: 0.2977878451347351, 22700: 0.7358962893486023, 22800: 0.41934192180633545, 22900: 4.408019065856934, 23000: 0.11908025294542313, 23100: 0.4678822159767151, 23200: 0.30053913593292236, 23300: 1.3353830575942993, 23400: 1.2794698476791382, 23500: 0.3154647946357727, 23600: 1.5696868896484375, 23700: 1.1493141651153564, 23800: 1.143506646156311, 23900: 0.805809497833252, 24000: 0.37775927782058716, 24100: 0.2394578605890274, 24200: 0.5304766893386841, 24300: 0.4766642153263092, 24400: 1.41996431350708, 24500: 3.198596477508545, 24600: 1.6705464124679565, 24700: 0.5272042751312256, 24800: 0.821567714214325, 24900: 0.2856156527996063, 25000: 0.34209126234054565, 25100: 0.34227946400642395, 25200: 1.1313544511795044, 25300: 0.38470426201820374, 25400: 3.3346755504608154, 25500: 0.4732702970504761, 25600: 0.6965050101280212, 25700: 1.1131086349487305, 25800: 0.6824043393135071, 25900: 0.9863476157188416, 26000: 4.093920707702637, 26100: 2.207658529281616, 26200: 0.07701781392097473, 26300: 1.0761991739273071, 26400: 0.8824814558029175, 26500: 1.0427308082580566, 26600: 0.5239643454551697, 26700: 0.5165687203407288, 26800: 1.5332379341125488, 26900: 0.3868463337421417, 27000: 2.409259796142578, 27100: 0.738553524017334, 27200: 0.831425666809082}, 'F1': {2: 0.6155370573070258}, 'Accuracy': {2: 0.5482710520519786}}\n",
      "Epoch 3\n",
      "\n",
      "Epoch time: 141.73448085784912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77       837\n",
      "           1       0.58      0.95      0.72       832\n",
      "           2       0.65      0.06      0.11       858\n",
      "           3       0.62      0.62      0.62       850\n",
      "           4       0.56      0.90      0.69       829\n",
      "           5       0.58      0.65      0.62       846\n",
      "           6       0.59      0.90      0.71       851\n",
      "           7       0.60      0.78      0.68       851\n",
      "           8       0.57      0.72      0.63       845\n",
      "           9       0.62      0.34      0.44       851\n",
      "          10       0.41      0.33      0.37      5171\n",
      "\n",
      "    accuracy                           0.54     13621\n",
      "   macro avg       0.59      0.64      0.58     13621\n",
      "weighted avg       0.53      0.54      0.51     13621\n",
      "\n",
      "Logger {'time': {0: 0.010820865631103516, 100: 0.5740799903869629, 200: 1.0996387004852295, 300: 1.6187269687652588, 400: 2.131584882736206, 500: 2.639050006866455, 600: 3.171290874481201, 700: 3.6999030113220215, 800: 4.250885725021362, 900: 4.788034677505493, 1000: 5.301621913909912, 1100: 5.805614709854126, 1200: 6.31245493888855, 1300: 6.812946796417236, 1400: 7.322876930236816, 1500: 7.809755802154541, 1600: 8.334744691848755, 1700: 8.832840919494629, 1800: 9.352125883102417, 1900: 9.850265741348267, 2000: 10.3782479763031, 2100: 10.880324840545654, 2200: 11.383159637451172, 2300: 11.895525932312012, 2400: 12.40257477760315, 2500: 12.908346891403198, 2600: 13.404858827590942, 2700: 13.902618885040283, 2800: 14.410874843597412, 2900: 14.925276756286621, 3000: 15.444945812225342, 3100: 15.952138900756836, 3200: 16.455476999282837, 3300: 17.029923677444458, 3400: 17.537102699279785, 3500: 18.05691170692444, 3600: 18.56331181526184, 3700: 19.080323696136475, 3800: 19.57529592514038, 3900: 20.089990854263306, 4000: 20.588275909423828, 4100: 21.095634937286377, 4200: 21.59327268600464, 4300: 22.096515893936157, 4400: 22.605396032333374, 4500: 23.18808078765869, 4600: 23.694973945617676, 4700: 24.204309940338135, 4800: 24.707270860671997, 4900: 25.21441388130188, 5000: 25.706719875335693, 5100: 26.2010760307312, 5200: 26.714743852615356, 5300: 27.218564748764038, 5400: 27.729789972305298, 5500: 28.22705578804016, 5600: 28.738003969192505, 5700: 29.245956897735596, 5800: 29.786537885665894, 5900: 30.291777849197388, 6000: 30.802506923675537, 6100: 31.308879852294922, 6200: 31.816174745559692, 6300: 32.326934814453125, 6400: 32.85201096534729, 6500: 33.35732674598694, 6600: 33.86754274368286, 6700: 34.37256669998169, 6800: 34.88245677947998, 6900: 35.401453733444214, 7000: 35.90835690498352, 7100: 36.40447282791138, 7200: 36.904650926589966, 7300: 37.47820806503296, 7400: 38.016684770584106, 7500: 38.580713987350464, 7600: 39.091744899749756, 7700: 39.63613176345825, 7800: 40.13658881187439, 7900: 40.650781869888306, 8000: 41.15131688117981, 8100: 41.663514852523804, 8200: 42.23612189292908, 8300: 42.74214291572571, 8400: 43.276371002197266, 8500: 43.79794383049011, 8600: 44.3963668346405, 8700: 44.97258496284485, 8800: 45.474525928497314, 8900: 45.99519062042236, 9000: 46.49310803413391, 9100: 47.003315925598145, 9200: 47.51115965843201, 9300: 48.026285886764526, 9400: 48.53407001495361, 9500: 49.0495867729187, 9600: 49.54627585411072, 9700: 50.06159782409668, 9800: 50.56575679779053, 9900: 51.07647180557251, 10000: 51.57955479621887, 10100: 52.100183725357056, 10200: 52.599963903427124, 10300: 53.132375717163086, 10400: 53.668869733810425, 10500: 54.190077781677246, 10600: 54.70204186439514, 10700: 55.229777812957764, 10800: 55.73170781135559, 10900: 56.240049839019775, 11000: 56.74793767929077, 11100: 57.25784969329834, 11200: 57.75778365135193, 11300: 58.26927995681763, 11400: 58.78181576728821, 11500: 59.30220174789429, 11600: 59.83190178871155, 11700: 60.36249279975891, 11800: 60.88107490539551, 11900: 61.38506078720093, 12000: 61.89668679237366, 12100: 62.403310775756836, 12200: 62.912773847579956, 12300: 63.44403791427612, 12400: 63.97639989852905, 12500: 64.49349975585938, 12600: 65.04664587974548, 12700: 65.5537428855896, 12800: 66.06627202033997, 12900: 66.56766986846924, 13000: 67.09779787063599, 13100: 67.60183882713318, 13200: 68.11709189414978, 13300: 68.62434482574463, 13400: 69.14839506149292, 13500: 69.66343975067139, 13600: 70.17527675628662, 13700: 70.68712592124939, 13800: 71.21880602836609, 13900: 71.71539092063904, 14000: 72.22511792182922, 14100: 72.75187468528748, 14200: 73.28028392791748, 14300: 73.7845687866211, 14400: 74.31581783294678, 14500: 74.85804796218872, 14600: 75.36105990409851, 14700: 75.8768219947815, 14800: 76.39126992225647, 14900: 76.91312885284424, 15000: 77.42552495002747, 15100: 77.94505286216736, 15200: 78.47099494934082, 15300: 78.980055809021, 15400: 79.47715377807617, 15500: 79.97649478912354, 15600: 80.4853036403656, 15700: 80.99162602424622, 15800: 81.48846578598022, 15900: 82.00304985046387, 16000: 82.49955081939697, 16100: 83.00028967857361, 16200: 83.55671501159668, 16300: 84.06374287605286, 16400: 84.59578585624695, 16500: 85.10687780380249, 16600: 85.62362694740295, 16700: 86.23755884170532, 16800: 86.87412571907043, 16900: 87.52002000808716, 17000: 88.15879082679749, 17100: 88.78988075256348, 17200: 89.3400650024414, 17300: 89.84488081932068, 17400: 90.35821795463562, 17500: 90.84731793403625, 17600: 91.35865688323975, 17700: 91.85649085044861, 17800: 92.37966275215149, 17900: 92.8921549320221, 18000: 93.40361595153809, 18100: 93.90807390213013, 18200: 94.41663694381714, 18300: 94.93267369270325, 18400: 95.54879593849182, 18500: 96.05456900596619, 18600: 96.5672299861908, 18700: 97.07893085479736, 18800: 97.5953438282013, 18900: 98.10191679000854, 19000: 98.60457181930542, 19100: 99.11290764808655, 19200: 99.62508392333984, 19300: 100.14012694358826, 19400: 100.64534783363342, 19500: 101.16572070121765, 19600: 101.68031072616577, 19700: 102.19051384925842, 19800: 102.69319987297058, 19900: 103.21424174308777, 20000: 103.70148873329163, 20100: 104.22180485725403, 20200: 104.72243690490723, 20300: 105.22997975349426, 20400: 105.7298629283905, 20500: 106.23083806037903, 20600: 106.76050996780396, 20700: 107.2660927772522, 20800: 107.78051686286926, 20900: 108.28710770606995, 21000: 108.79903268814087, 21100: 109.4072687625885, 21200: 109.91871380805969, 21300: 110.42379069328308, 21400: 110.9404706954956, 21500: 111.49898195266724, 21600: 112.01612067222595, 21700: 112.51538896560669, 21800: 113.02912878990173, 21900: 113.59168577194214, 22000: 114.09859681129456, 22100: 114.68368887901306, 22200: 115.21517372131348, 22300: 115.71442985534668, 22400: 116.2183427810669, 22500: 116.72294974327087, 22600: 117.23888182640076, 22700: 117.82128882408142, 22800: 118.3949499130249, 22900: 118.95023274421692, 23000: 119.48918294906616, 23100: 120.02430582046509, 23200: 120.5680639743805, 23300: 121.12407183647156, 23400: 121.6423728466034, 23500: 122.13800597190857, 23600: 122.66086077690125, 23700: 123.16709470748901, 23800: 123.68158078193665, 23900: 124.18331789970398, 24000: 124.74762296676636, 24100: 125.25162982940674, 24200: 125.76780271530151, 24300: 126.26996374130249, 24400: 126.78863286972046, 24500: 127.29798674583435, 24600: 127.8083848953247, 24700: 128.3133409023285, 24800: 128.84375882148743, 24900: 129.35563969612122, 25000: 129.87166380882263, 25100: 130.37363982200623, 25200: 130.88266706466675, 25300: 131.38643980026245, 25400: 131.89981889724731, 25500: 132.40713596343994, 25600: 132.90576696395874, 25700: 133.4728877544403, 25800: 134.02899193763733, 25900: 134.66385984420776, 26000: 135.29477882385254, 26100: 135.7883448600769, 26200: 136.36731386184692, 26300: 136.85733199119568, 26400: 137.3771789073944, 26500: 137.883526802063, 26600: 138.405987739563, 26700: 138.89855003356934, 26800: 139.4170639514923, 26900: 139.91309785842896, 27000: 140.41375184059143, 27100: 140.91302394866943, 27200: 141.41086173057556}, 'loss': {0: 0.6575804948806763, 100: 0.550217866897583, 200: 0.5525457262992859, 300: 0.23159544169902802, 400: 0.28052860498428345, 500: 0.42511141300201416, 600: 0.25691086053848267, 700: 1.6263277530670166, 800: 0.31203052401542664, 900: 0.6096866130828857, 1000: 0.759369969367981, 1100: 0.28181466460227966, 1200: 0.5288202166557312, 1300: 0.8062682151794434, 1400: 0.5058727860450745, 1500: 0.6110259294509888, 1600: 0.34507396817207336, 1700: 0.7970975041389465, 1800: 1.5087456703186035, 1900: 0.68687903881073, 2000: 1.2544816732406616, 2100: 0.6930202841758728, 2200: 0.2823200523853302, 2300: 5.795348644256592, 2400: 2.397062063217163, 2500: 0.3674841523170471, 2600: 0.6229634284973145, 2700: 1.2579638957977295, 2800: 0.4811117649078369, 2900: 0.2367265671491623, 3000: 0.09148994833230972, 3100: 0.4192295968532562, 3200: 0.4011964201927185, 3300: 0.18217018246650696, 3400: 0.38979294896125793, 3500: 1.3336267471313477, 3600: 1.128043532371521, 3700: 0.2640060484409332, 3800: 1.861008644104004, 3900: 1.1150346994400024, 4000: 1.1488057374954224, 4100: 1.3106498718261719, 4200: 0.619250476360321, 4300: 0.7548344731330872, 4400: 3.471653461456299, 4500: 1.0795724391937256, 4600: 1.1008579730987549, 4700: 1.1438899040222168, 4800: 0.46700528264045715, 4900: 1.3373596668243408, 5000: 0.7132114171981812, 5100: 3.3934128284454346, 5200: 0.2070884257555008, 5300: 0.10060250014066696, 5400: 0.7153871059417725, 5500: 0.8084852695465088, 5600: 2.296961545944214, 5700: 7.204107761383057, 5800: 1.3210327625274658, 5900: 0.9857468008995056, 6000: 1.2097480297088623, 6100: 0.7968164086341858, 6200: 0.9836795330047607, 6300: 0.36351126432418823, 6400: 0.5844930410385132, 6500: 1.4520448446273804, 6600: 0.4820193648338318, 6700: 0.5849652886390686, 6800: 1.18404221534729, 6900: 0.40027695894241333, 7000: 0.18927547335624695, 7100: 1.1296308040618896, 7200: 0.5013564825057983, 7300: 1.1070905923843384, 7400: 1.038551688194275, 7500: 1.0691611766815186, 7600: 0.42717838287353516, 7700: 0.12137162685394287, 7800: 1.1184276342391968, 7900: 0.2520167827606201, 8000: 1.0921630859375, 8100: 0.25220346450805664, 8200: 0.6562963724136353, 8300: 1.2448043823242188, 8400: 0.28421273827552795, 8500: 0.48399195075035095, 8600: 1.5453987121582031, 8700: 0.7391800880432129, 8800: 1.8211439847946167, 8900: 1.6324111223220825, 9000: 1.1443514823913574, 9100: 0.40544119477272034, 9200: 0.23305973410606384, 9300: 0.3718666732311249, 9400: 2.059291362762451, 9500: 2.051723003387451, 9600: 0.9973022937774658, 9700: 9.395813941955566, 9800: 0.6413529515266418, 9900: 1.4755032062530518, 10000: 2.3635921478271484, 10100: 0.30880260467529297, 10200: 1.6574982404708862, 10300: 0.49543020129203796, 10400: 0.13221316039562225, 10500: 0.37412765622138977, 10600: 1.5295324325561523, 10700: 0.3204251229763031, 10800: 1.1274018287658691, 10900: 0.7729843258857727, 11000: 0.8407381176948547, 11100: 0.4873862564563751, 11200: 3.4452145099639893, 11300: 0.11984159052371979, 11400: 0.4775598645210266, 11500: 0.6791670322418213, 11600: 1.8097773790359497, 11700: 0.6047142148017883, 11800: 2.5434563159942627, 11900: 0.9615901708602905, 12000: 0.38496020436286926, 12100: 0.48105525970458984, 12200: 1.025425910949707, 12300: 0.4405595064163208, 12400: 1.432477593421936, 12500: 8.092700004577637, 12600: 0.27676495909690857, 12700: 0.6255508065223694, 12800: 0.5583756566047668, 12900: 0.3821147382259369, 13000: 2.2548134326934814, 13100: 0.8812164664268494, 13200: 0.6961051225662231, 13300: 1.1285183429718018, 13400: 0.26449891924858093, 13500: 1.0457158088684082, 13600: 0.3196241557598114, 13700: 0.36536312103271484, 13800: 1.054880142211914, 13900: 0.14305754005908966, 14000: 0.8560773730278015, 14100: 0.39050552248954773, 14200: 0.6189403533935547, 14300: 0.9030134081840515, 14400: 1.1560852527618408, 14500: 1.4305930137634277, 14600: 0.34979456663131714, 14700: 1.2620419263839722, 14800: 0.24264374375343323, 14900: 0.8391409516334534, 15000: 0.6127433776855469, 15100: 0.8093517422676086, 15200: 1.0498203039169312, 15300: 0.8469511866569519, 15400: 0.7381189465522766, 15500: 2.731713056564331, 15600: 0.6184595823287964, 15700: 2.567373752593994, 15800: 1.1678663492202759, 15900: 0.20196053385734558, 16000: 3.1776888370513916, 16100: 0.4474211037158966, 16200: 0.4119027853012085, 16300: 0.5469908714294434, 16400: 0.9590610861778259, 16500: 0.586839497089386, 16600: 2.360750675201416, 16700: 0.35277315974235535, 16800: 1.3078794479370117, 16900: 0.9195141196250916, 17000: 0.46266207098960876, 17100: 1.2958487272262573, 17200: 1.149593472480774, 17300: 0.3177197277545929, 17400: 0.892928421497345, 17500: 0.42958590388298035, 17600: 0.2946396470069885, 17700: 1.1932032108306885, 17800: 0.8819484710693359, 17900: 0.4685525596141815, 18000: 0.5948824882507324, 18100: 0.5575146079063416, 18200: 0.31456393003463745, 18300: 0.7750369906425476, 18400: 0.9837381839752197, 18500: 0.5670715570449829, 18600: 0.28297898173332214, 18700: 1.3490046262741089, 18800: 0.5568801164627075, 18900: 0.3562770187854767, 19000: 0.40740063786506653, 19100: 3.2246437072753906, 19200: 1.685289978981018, 19300: 1.3717474937438965, 19400: 0.4831964373588562, 19500: 0.2106969654560089, 19600: 1.0324510335922241, 19700: 0.9205500483512878, 19800: 0.26425227522850037, 19900: 1.4077941179275513, 20000: 1.2076635360717773, 20100: 0.24819551408290863, 20200: 0.643592894077301, 20300: 1.5601402521133423, 20400: 0.7276846766471863, 20500: 0.6708463430404663, 20600: 0.37206020951271057, 20700: 0.1906948685646057, 20800: 0.9554247260093689, 20900: 1.6467633247375488, 21000: 0.8014828562736511, 21100: 0.7981659770011902, 21200: 0.20308254659175873, 21300: 0.4496413767337799, 21400: 0.5980544090270996, 21500: 3.56269907951355, 21600: 0.683276355266571, 21700: 0.38950029015541077, 21800: 0.9393033981323242, 21900: 0.6682852506637573, 22000: 1.4644819498062134, 22100: 0.35456621646881104, 22200: 0.6782212257385254, 22300: 0.522851288318634, 22400: 0.36664989590644836, 22500: 1.3056257963180542, 22600: 0.4194287657737732, 22700: 0.4866234362125397, 22800: 0.45410504937171936, 22900: 2.3874950408935547, 23000: 0.1915062814950943, 23100: 0.49356353282928467, 23200: 0.3206598460674286, 23300: 1.5093573331832886, 23400: 2.880554437637329, 23500: 0.21541956067085266, 23600: 1.4485323429107666, 23700: 1.8439651727676392, 23800: 1.2130746841430664, 23900: 0.9614934325218201, 24000: 0.6822828054428101, 24100: 0.18175886571407318, 24200: 0.5482956767082214, 24300: 0.5691604018211365, 24400: 1.3421305418014526, 24500: 2.2132959365844727, 24600: 1.253745675086975, 24700: 0.3943847119808197, 24800: 0.9777015447616577, 24900: 0.23971256613731384, 25000: 0.739983856678009, 25100: 0.2688567042350769, 25200: 1.3104019165039062, 25300: 0.4905935823917389, 25400: 3.7251639366149902, 25500: 0.5670067667961121, 25600: 0.6579635739326477, 25700: 1.3189778327941895, 25800: 0.7759951949119568, 25900: 1.7605969905853271, 26000: 4.845986366271973, 26100: 2.113947629928589, 26200: 0.08868671953678131, 26300: 1.3506407737731934, 26400: 0.8300289511680603, 26500: 1.111833095550537, 26600: 0.3086748719215393, 26700: 0.4928229749202728, 26800: 1.380042314529419, 26900: 0.48794588446617126, 27000: 4.300537109375, 27100: 0.9438787698745728, 27200: 1.0494859218597412}, 'F1': {3: 0.5783816763455468}, 'Accuracy': {3: 0.5425446002496146}}\n",
      "Epoch 4\n",
      "\n",
      "Epoch time: 152.39539313316345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73       837\n",
      "           1       0.59      0.96      0.73       832\n",
      "           2       0.63      0.58      0.60       858\n",
      "           3       0.62      0.64      0.63       850\n",
      "           4       0.54      0.81      0.65       829\n",
      "           5       0.57      0.72      0.64       846\n",
      "           6       0.59      0.89      0.71       851\n",
      "           7       0.58      0.83      0.68       851\n",
      "           8       0.55      0.70      0.62       845\n",
      "           9       0.61      0.70      0.65       851\n",
      "          10       0.41      0.22      0.28      5171\n",
      "\n",
      "    accuracy                           0.55     13621\n",
      "   macro avg       0.58      0.71      0.63     13621\n",
      "weighted avg       0.52      0.55      0.52     13621\n",
      "\n",
      "Logger {'time': {0: 0.015064239501953125, 100: 0.5854451656341553, 200: 1.1131882667541504, 300: 1.6332180500030518, 400: 2.163950204849243, 500: 2.6777470111846924, 600: 3.1937270164489746, 700: 3.700467109680176, 800: 4.216891288757324, 900: 4.730203151702881, 1000: 5.242905139923096, 1100: 5.752746105194092, 1200: 6.2641332149505615, 1300: 6.7770020961761475, 1400: 7.287745237350464, 1500: 7.792349338531494, 1600: 8.317826271057129, 1700: 8.81031608581543, 1800: 9.306008100509644, 1900: 9.82278823852539, 2000: 10.32573127746582, 2100: 10.852518320083618, 2200: 11.347018003463745, 2300: 11.860971212387085, 2400: 12.350805044174194, 2500: 12.867496252059937, 2600: 13.361865043640137, 2700: 13.872661113739014, 2800: 14.372003078460693, 2900: 14.897745370864868, 3000: 15.400161027908325, 3100: 15.901853322982788, 3200: 16.39875817298889, 3300: 16.921911239624023, 3400: 17.509295225143433, 3500: 18.036745071411133, 3600: 18.55791211128235, 3700: 19.06163215637207, 3800: 19.806474208831787, 3900: 20.560530185699463, 4000: 21.273845195770264, 4100: 21.80180311203003, 4200: 22.35150909423828, 4300: 22.854740142822266, 4400: 23.38137125968933, 4500: 23.922476053237915, 4600: 24.468852043151855, 4700: 24.961762189865112, 4800: 25.52943205833435, 4900: 26.044260263442993, 5000: 26.770413160324097, 5100: 27.33197808265686, 5200: 27.91151738166809, 5300: 28.45782709121704, 5400: 28.991029024124146, 5500: 29.49686312675476, 5600: 30.01768398284912, 5700: 30.563494205474854, 5800: 31.09711527824402, 5900: 31.614076375961304, 6000: 32.12452507019043, 6100: 32.62155222892761, 6200: 33.136263370513916, 6300: 33.6517071723938, 6400: 34.16780233383179, 6500: 34.67003417015076, 6600: 35.18430209159851, 6700: 35.684091329574585, 6800: 36.19596314430237, 6900: 36.695555210113525, 7000: 37.21338438987732, 7100: 37.728047132492065, 7200: 38.277637243270874, 7300: 38.787684202194214, 7400: 39.29523015022278, 7500: 39.8104293346405, 7600: 40.31974506378174, 7700: 40.823989152908325, 7800: 41.33496618270874, 7900: 41.845635175704956, 8000: 42.33155632019043, 8100: 42.84238314628601, 8200: 43.34416222572327, 8300: 43.87928032875061, 8400: 44.383204221725464, 8500: 44.90802216529846, 8600: 45.41659331321716, 8700: 45.94168019294739, 8800: 46.47083806991577, 8900: 47.002119302749634, 9000: 47.5854389667511, 9100: 48.094858169555664, 9200: 48.59469699859619, 9300: 49.12176322937012, 9400: 49.62280511856079, 9500: 50.13533639907837, 9600: 50.70386624336243, 9700: 51.22994923591614, 9800: 51.743911266326904, 9900: 52.249977111816406, 10000: 52.75646901130676, 10100: 53.26588416099548, 10200: 53.794023275375366, 10300: 54.299580335617065, 10400: 54.80774927139282, 10500: 55.31681823730469, 10600: 55.822490215301514, 10700: 56.34687900543213, 10800: 56.86823296546936, 10900: 57.383684158325195, 11000: 57.90483832359314, 11100: 58.54425024986267, 11200: 59.06215238571167, 11300: 59.60104417800903, 11400: 60.099762201309204, 11500: 60.630786180496216, 11600: 61.13205409049988, 11700: 61.65802216529846, 11800: 62.16073131561279, 11900: 62.682998180389404, 12000: 63.18797516822815, 12100: 63.74137020111084, 12200: 64.2498881816864, 12300: 64.75374007225037, 12400: 65.28405141830444, 12500: 65.86770629882812, 12600: 66.38415312767029, 12700: 66.88711714744568, 12800: 67.40654802322388, 12900: 67.91602110862732, 13000: 68.44030809402466, 13100: 68.93164801597595, 13200: 69.45413708686829, 13300: 69.95377612113953, 13400: 70.50066828727722, 13500: 71.00389814376831, 13600: 71.55684614181519, 13700: 72.0678551197052, 13800: 72.60123419761658, 13900: 73.10304832458496, 14000: 73.80199813842773, 14100: 74.37979531288147, 14200: 74.89880514144897, 14300: 75.38977527618408, 14400: 75.92352628707886, 14500: 76.4192042350769, 14600: 76.94008708000183, 14700: 77.53693413734436, 14800: 78.05216836929321, 14900: 78.56859016418457, 15000: 79.08468723297119, 15100: 79.57957196235657, 15200: 80.18187618255615, 15300: 80.95691227912903, 15400: 81.5871832370758, 15500: 82.23925614356995, 15600: 82.78571701049805, 15700: 83.32030534744263, 15800: 83.87393522262573, 15900: 84.39796924591064, 16000: 84.92739820480347, 16100: 85.53043627738953, 16200: 86.08836627006531, 16300: 86.66045427322388, 16400: 87.15899109840393, 16500: 87.71295428276062, 16600: 88.26894211769104, 16700: 88.79087209701538, 16800: 89.31435132026672, 16900: 89.86018824577332, 17000: 90.56908416748047, 17100: 91.29890012741089, 17200: 91.85679817199707, 17300: 92.40104913711548, 17400: 92.97393202781677, 17500: 93.49161028862, 17600: 94.01396608352661, 17700: 94.53817319869995, 17800: 95.06220316886902, 17900: 95.58332705497742, 18000: 96.15640020370483, 18100: 96.66485118865967, 18200: 97.18141913414001, 18300: 97.70758724212646, 18400: 98.2369601726532, 18500: 98.76385521888733, 18600: 99.27688121795654, 18700: 99.79328107833862, 18800: 100.31822729110718, 18900: 100.84650111198425, 19000: 101.77280521392822, 19100: 102.48098421096802, 19200: 102.98380708694458, 19300: 103.52236604690552, 19400: 104.01578712463379, 19500: 104.60553908348083, 19600: 105.36360716819763, 19700: 105.93549633026123, 19800: 106.46799206733704, 19900: 106.98973107337952, 20000: 107.57818818092346, 20100: 108.10092425346375, 20200: 108.5982620716095, 20300: 109.10730814933777, 20400: 109.62549304962158, 20500: 110.13315510749817, 20600: 110.66750621795654, 20700: 111.1926622390747, 20800: 111.70610523223877, 20900: 112.35616517066956, 21000: 112.8665452003479, 21100: 113.37493515014648, 21200: 113.88610219955444, 21300: 114.38977527618408, 21400: 114.90084505081177, 21500: 115.47296118736267, 21600: 115.97870898246765, 21700: 116.51033926010132, 21800: 117.010409116745, 21900: 117.59133625030518, 22000: 118.12763333320618, 22100: 118.66545104980469, 22200: 119.1666362285614, 22300: 119.70033311843872, 22400: 120.20709109306335, 22500: 120.74174904823303, 22600: 121.30808234214783, 22700: 123.06084322929382, 22800: 126.74219703674316, 22900: 127.60934019088745, 23000: 128.75237917900085, 23100: 129.60887622833252, 23200: 130.3245632648468, 23300: 130.93193912506104, 23400: 131.512145280838, 23500: 132.0513951778412, 23600: 132.604914188385, 23700: 133.1375732421875, 23800: 133.6696813106537, 23900: 134.17385339736938, 24000: 134.71804809570312, 24100: 135.31257605552673, 24200: 135.83920001983643, 24300: 136.35528326034546, 24400: 136.9001202583313, 24500: 137.43072319030762, 24600: 138.11218118667603, 24700: 138.6355230808258, 24800: 139.15934324264526, 24900: 139.70378422737122, 25000: 140.23135328292847, 25100: 140.76189804077148, 25200: 141.29665422439575, 25300: 141.8349530696869, 25400: 142.35051012039185, 25500: 142.85004019737244, 25600: 143.3627951145172, 25700: 143.91470527648926, 25800: 144.48022317886353, 25900: 145.11988830566406, 26000: 145.6727192401886, 26100: 146.16881012916565, 26200: 146.78373622894287, 26300: 147.31914114952087, 26400: 147.84422421455383, 26500: 148.43158721923828, 26600: 148.960675239563, 26700: 149.49477314949036, 26800: 150.0053551197052, 26900: 150.5614001750946, 27000: 151.06006121635437, 27100: 151.58503127098083, 27200: 152.094398021698}, 'loss': {0: 0.7369385957717896, 100: 0.6480506658554077, 200: 0.6535125374794006, 300: 0.7044134736061096, 400: 0.6243503093719482, 500: 0.4478285014629364, 600: 0.8674536347389221, 700: 1.2433643341064453, 800: 0.4540017247200012, 900: 0.5761508941650391, 1000: 0.6258894205093384, 1100: 0.5903740525245667, 1200: 0.3023953139781952, 1300: 0.7450833320617676, 1400: 0.5000446438789368, 1500: 0.7629417181015015, 1600: 0.35807979106903076, 1700: 1.3489470481872559, 1800: 1.3745949268341064, 1900: 0.6556078791618347, 2000: 2.2287938594818115, 2100: 1.0296516418457031, 2200: 0.2841275930404663, 2300: 4.001722812652588, 2400: 1.4761123657226562, 2500: 0.2873018682003021, 2600: 0.9000766277313232, 2700: 1.0711578130722046, 2800: 0.5248600244522095, 2900: 0.1304529458284378, 3000: 0.20353488624095917, 3100: 0.46245887875556946, 3200: 0.5142455101013184, 3300: 0.12024059891700745, 3400: 0.25145626068115234, 3500: 1.03001070022583, 3600: 1.5678985118865967, 3700: 0.12463370710611343, 3800: 1.3181458711624146, 3900: 0.5113524794578552, 4000: 1.2274394035339355, 4100: 1.511188268661499, 4200: 0.5760934352874756, 4300: 0.3998302221298218, 4400: 5.345621109008789, 4500: 1.4890753030776978, 4600: 0.853541910648346, 4700: 1.5305395126342773, 4800: 0.42776191234588623, 4900: 1.3464939594268799, 5000: 0.7918188571929932, 5100: 1.7150096893310547, 5200: 0.2626655101776123, 5300: 0.4011012017726898, 5400: 2.464735507965088, 5500: 0.7407315373420715, 5600: 1.5758447647094727, 5700: 3.5456113815307617, 5800: 1.345935583114624, 5900: 0.9946211576461792, 6000: 0.7992423176765442, 6100: 0.39880526065826416, 6200: 0.9996055960655212, 6300: 0.31144198775291443, 6400: 0.19846659898757935, 6500: 0.19182997941970825, 6600: 0.3442019522190094, 6700: 0.43604448437690735, 6800: 1.1050019264221191, 6900: 0.8406949639320374, 7000: 0.19646620750427246, 7100: 0.5090885758399963, 7200: 0.42633870244026184, 7300: 1.0375244617462158, 7400: 1.2034308910369873, 7500: 0.2925297021865845, 7600: 0.4475206136703491, 7700: 0.13008688390254974, 7800: 1.1333341598510742, 7900: 0.34973329305648804, 8000: 0.6549932360649109, 8100: 0.28509095311164856, 8200: 0.5162402987480164, 8300: 0.32229986786842346, 8400: 0.26966604590415955, 8500: 0.27274155616760254, 8600: 0.3601907193660736, 8700: 0.7405915856361389, 8800: 1.2204262018203735, 8900: 0.2809373438358307, 9000: 1.0389485359191895, 9100: 0.37399858236312866, 9200: 0.270278662443161, 9300: 0.2772659659385681, 9400: 0.8952733874320984, 9500: 1.38100266456604, 9600: 0.8775699734687805, 9700: 8.18995475769043, 9800: 0.7362611889839172, 9900: 1.264204978942871, 10000: 1.3245564699172974, 10100: 0.5422657132148743, 10200: 1.9637452363967896, 10300: 0.5330817699432373, 10400: 0.16581600904464722, 10500: 0.42303094267845154, 10600: 1.1113990545272827, 10700: 0.3393924832344055, 10800: 0.3911944627761841, 10900: 0.6898630857467651, 11000: 0.35828202962875366, 11100: 0.3390738070011139, 11200: 0.8436172008514404, 11300: 0.14712777733802795, 11400: 0.3730504512786865, 11500: 0.8334013819694519, 11600: 2.2178876399993896, 11700: 0.5951673984527588, 11800: 1.5284382104873657, 11900: 0.6419234275817871, 12000: 1.183957815170288, 12100: 1.3881099224090576, 12200: 0.6348698735237122, 12300: 0.45508578419685364, 12400: 1.5406664609909058, 12500: 1.4085257053375244, 12600: 0.8204814791679382, 12700: 1.5107288360595703, 12800: 0.4912331700325012, 12900: 0.3153281807899475, 13000: 1.6751770973205566, 13100: 1.1102298498153687, 13200: 0.5469180345535278, 13300: 0.21896527707576752, 13400: 0.3645191490650177, 13500: 0.7244231700897217, 13600: 0.34672072529792786, 13700: 1.0621899366378784, 13800: 1.0582373142242432, 13900: 0.32677122950553894, 14000: 0.5754638314247131, 14100: 0.596972644329071, 14200: 0.3811316192150116, 14300: 0.7443320751190186, 14400: 0.34673556685447693, 14500: 0.9954270124435425, 14600: 0.6071565747261047, 14700: 0.8385804891586304, 14800: 0.5423044562339783, 14900: 0.5315279960632324, 15000: 0.8457513451576233, 15100: 0.21360649168491364, 15200: 0.8724507689476013, 15300: 0.6003442406654358, 15400: 0.3379531502723694, 15500: 1.034696340560913, 15600: 0.2735307216644287, 15700: 4.222958087921143, 15800: 1.3292312622070312, 15900: 0.9311524629592896, 16000: 2.1500186920166016, 16100: 0.6317075490951538, 16200: 0.2961359918117523, 16300: 0.6330812573432922, 16400: 2.4535975456237793, 16500: 0.753017246723175, 16600: 1.470611333847046, 16700: 0.3089795708656311, 16800: 0.7293227910995483, 16900: 0.6704203486442566, 17000: 0.6341115236282349, 17100: 1.0585012435913086, 17200: 0.11738951504230499, 17300: 0.48923733830451965, 17400: 0.48176050186157227, 17500: 0.3076286315917969, 17600: 1.0960259437561035, 17700: 2.11187744140625, 17800: 1.1844725608825684, 17900: 0.6096819639205933, 18000: 1.3824050426483154, 18100: 2.546830892562866, 18200: 0.397186815738678, 18300: 1.108722448348999, 18400: 0.5910376906394958, 18500: 0.2967376112937927, 18600: 0.6612611413002014, 18700: 1.3015861511230469, 18800: 0.469361275434494, 18900: 0.21816425025463104, 19000: 0.43760889768600464, 19100: 4.5383992195129395, 19200: 1.0803160667419434, 19300: 0.990139365196228, 19400: 0.5560457706451416, 19500: 0.22241048514842987, 19600: 0.9142509698867798, 19700: 0.8588454127311707, 19800: 0.2933189272880554, 19900: 1.4665906429290771, 20000: 1.263688325881958, 20100: 0.5802212357521057, 20200: 0.3073873221874237, 20300: 2.099287748336792, 20400: 0.6386678814888, 20500: 0.681223452091217, 20600: 0.3587004840373993, 20700: 0.31930872797966003, 20800: 0.9145289659500122, 20900: 0.6948338747024536, 21000: 0.8303052186965942, 21100: 0.8508621454238892, 21200: 0.19986335933208466, 21300: 0.3420848250389099, 21400: 0.7896087169647217, 21500: 3.1614105701446533, 21600: 0.19365915656089783, 21700: 0.5487750172615051, 21800: 0.8373182415962219, 21900: 0.713128924369812, 22000: 1.2697727680206299, 22100: 0.8967746496200562, 22200: 0.1533116102218628, 22300: 0.38936758041381836, 22400: 0.8860364556312561, 22500: 1.0674798488616943, 22600: 0.36797329783439636, 22700: 0.46820518374443054, 22800: 0.25432664155960083, 22900: 1.8553059101104736, 23000: 0.18021056056022644, 23100: 0.5304235219955444, 23200: 0.5808054804801941, 23300: 1.2891196012496948, 23400: 1.5685607194900513, 23500: 0.17375598847866058, 23600: 1.6931707859039307, 23700: 2.1159017086029053, 23800: 0.7416800260543823, 23900: 0.8954339027404785, 24000: 0.2968122065067291, 24100: 0.22800110280513763, 24200: 1.0084187984466553, 24300: 0.7178429961204529, 24400: 0.99467933177948, 24500: 2.2766499519348145, 24600: 1.2852997779846191, 24700: 0.40505191683769226, 24800: 1.1290287971496582, 24900: 0.6042754650115967, 25000: 0.3470878005027771, 25100: 0.29244640469551086, 25200: 1.4141712188720703, 25300: 0.5080705285072327, 25400: 3.862370014190674, 25500: 0.5817578434944153, 25600: 0.8075958490371704, 25700: 0.9677723050117493, 25800: 0.24286285042762756, 25900: 1.2791553735733032, 26000: 4.195066928863525, 26100: 2.409747838973999, 26200: 0.029127212241292, 26300: 1.4816362857818604, 26400: 0.739898681640625, 26500: 1.5709106922149658, 26600: 0.31907394528388977, 26700: 0.4775080978870392, 26800: 1.545029878616333, 26900: 0.4497373402118683, 27000: 5.772907733917236, 27100: 0.8134041428565979, 27200: 1.012351155281067}, 'F1': {4: 0.629095281163819}, 'Accuracy': {4: 0.5546582482930769}}\n",
      "Epoch 5\n",
      "\n",
      "Epoch time: 157.9254219532013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73       837\n",
      "           1       0.56      0.95      0.70       832\n",
      "           2       0.64      0.55      0.60       858\n",
      "           3       0.61      0.67      0.64       850\n",
      "           4       0.58      0.83      0.68       829\n",
      "           5       0.58      0.69      0.63       846\n",
      "           6       0.60      0.79      0.68       851\n",
      "           7       0.62      0.80      0.70       851\n",
      "           8       0.53      0.72      0.61       845\n",
      "           9       0.61      0.58      0.59       851\n",
      "          10       0.41      0.25      0.31      5171\n",
      "\n",
      "    accuracy                           0.55     13621\n",
      "   macro avg       0.58      0.70      0.63     13621\n",
      "weighted avg       0.53      0.55      0.53     13621\n",
      "\n",
      "Logger {'time': {0: 0.015330076217651367, 100: 0.7487530708312988, 200: 1.4592039585113525, 300: 2.1102969646453857, 400: 2.8021979331970215, 500: 3.43139910697937, 600: 4.118805885314941, 700: 4.787760019302368, 800: 5.448200225830078, 900: 6.0925071239471436, 1000: 6.742788076400757, 1100: 7.3846518993377686, 1200: 8.046324014663696, 1300: 8.714064121246338, 1400: 9.354291915893555, 1500: 10.006263971328735, 1600: 10.67099404335022, 1700: 11.361223220825195, 1800: 11.998824834823608, 1900: 12.692524909973145, 2000: 13.365696907043457, 2100: 14.022969961166382, 2200: 14.646469116210938, 2300: 15.288280963897705, 2400: 15.951945066452026, 2500: 16.60989785194397, 2600: 17.24256706237793, 2700: 17.890635013580322, 2800: 18.590814113616943, 2900: 19.273226022720337, 3000: 19.941845893859863, 3100: 20.604238033294678, 3200: 21.261090993881226, 3300: 21.919509887695312, 3400: 22.54664897918701, 3500: 23.197967052459717, 3600: 23.824273109436035, 3700: 24.4707932472229, 3800: 25.143763065338135, 3900: 25.79840922355652, 4000: 26.460150003433228, 4100: 27.104137182235718, 4200: 27.758116006851196, 4300: 28.440276861190796, 4400: 29.14392590522766, 4500: 29.807470083236694, 4600: 30.48949694633484, 4700: 31.18552589416504, 4800: 31.962249994277954, 4900: 32.877217054367065, 5000: 33.566333055496216, 5100: 34.242185831069946, 5200: 34.95498323440552, 5300: 35.58666014671326, 5400: 36.265305042266846, 5500: 36.945728063583374, 5600: 37.61872720718384, 5700: 38.329750061035156, 5800: 39.01860189437866, 5900: 39.654792070388794, 6000: 40.2978789806366, 6100: 40.943132162094116, 6200: 41.63129997253418, 6300: 42.282121896743774, 6400: 42.91363286972046, 6500: 43.57874608039856, 6600: 44.23362612724304, 6700: 44.89446806907654, 6800: 45.591660022735596, 6900: 46.25179409980774, 7000: 46.91937494277954, 7100: 47.57649087905884, 7200: 48.20900797843933, 7300: 48.893121004104614, 7400: 49.52313709259033, 7500: 50.19326090812683, 7600: 50.85615825653076, 7700: 51.50164294242859, 7800: 52.14074516296387, 7900: 52.769140005111694, 8000: 53.42015719413757, 8100: 54.06083798408508, 8200: 54.70459508895874, 8300: 55.3628089427948, 8400: 56.016607999801636, 8500: 56.649874210357666, 8600: 57.31653809547424, 8700: 57.96996307373047, 8800: 58.63228511810303, 8900: 59.358652114868164, 9000: 60.01917624473572, 9100: 60.67205595970154, 9200: 61.3533570766449, 9300: 61.98531198501587, 9400: 62.644248962402344, 9500: 63.39523100852966, 9600: 64.04497718811035, 9700: 64.702712059021, 9800: 65.38689708709717, 9900: 66.09730195999146, 10000: 66.77196216583252, 10100: 67.45100784301758, 10200: 68.12600326538086, 10300: 68.83425092697144, 10400: 69.52190709114075, 10500: 70.22666096687317, 10600: 70.92044520378113, 10700: 71.59237694740295, 10800: 72.25321698188782, 10900: 72.91629004478455, 11000: 73.50107216835022, 11100: 73.99688911437988, 11200: 74.5267608165741, 11300: 75.03290009498596, 11400: 75.5555989742279, 11500: 76.0574300289154, 11600: 76.56652522087097, 11700: 77.06930923461914, 11800: 77.59412002563477, 11900: 78.09618711471558, 12000: 78.6193299293518, 12100: 79.12864303588867, 12200: 79.65367603302002, 12300: 80.15288019180298, 12400: 80.66999697685242, 12500: 81.18023490905762, 12600: 81.69414401054382, 12700: 82.21023297309875, 12800: 82.74658298492432, 12900: 83.2542450428009, 13000: 83.75720381736755, 13100: 84.27078223228455, 13200: 84.76789116859436, 13300: 85.27415299415588, 13400: 85.79644298553467, 13500: 86.32540512084961, 13600: 86.8227150440216, 13700: 87.33504986763, 13800: 87.98854494094849, 13900: 88.54968500137329, 14000: 89.11023807525635, 14100: 89.6307282447815, 14200: 90.25998783111572, 14300: 90.7744710445404, 14400: 91.28688097000122, 14500: 91.7862241268158, 14600: 92.27645611763, 14700: 92.78547501564026, 14800: 93.30661392211914, 14900: 93.82387185096741, 15000: 94.38935494422913, 15100: 94.90796303749084, 15200: 95.40666794776917, 15300: 95.93061113357544, 15400: 96.43974804878235, 15500: 96.95842599868774, 15600: 97.48027300834656, 15700: 98.0161759853363, 15800: 98.52845907211304, 15900: 99.07427024841309, 16000: 99.60515904426575, 16100: 100.1261339187622, 16200: 100.61941599845886, 16300: 101.14136791229248, 16400: 101.65483593940735, 16500: 102.18579292297363, 16600: 102.6895751953125, 16700: 103.19640016555786, 16800: 103.69741296768188, 16900: 104.2173638343811, 17000: 104.71784591674805, 17100: 105.23864793777466, 17200: 105.73429489135742, 17300: 106.23907613754272, 17400: 106.73743724822998, 17500: 107.23814296722412, 17600: 107.7698290348053, 17700: 108.27543997764587, 17800: 108.79356217384338, 17900: 109.3085310459137, 18000: 109.81475400924683, 18100: 110.33482098579407, 18200: 110.8524022102356, 18300: 111.36336898803711, 18400: 111.87164402008057, 18500: 112.37581992149353, 18600: 112.8869731426239, 18700: 113.39237594604492, 18800: 113.9015281200409, 18900: 114.42488598823547, 19000: 114.93731808662415, 19100: 115.44281792640686, 19200: 116.00480508804321, 19300: 116.50805020332336, 19400: 117.04359698295593, 19500: 117.56456398963928, 19600: 118.07912802696228, 19700: 118.5964081287384, 19800: 119.1310682296753, 19900: 119.69242310523987, 20000: 120.23712515830994, 20100: 120.75164699554443, 20200: 121.27932214736938, 20300: 121.77274203300476, 20400: 122.29323697090149, 20500: 122.78351998329163, 20600: 123.28762698173523, 20700: 123.79628682136536, 20800: 124.29373788833618, 20900: 124.8127601146698, 21000: 125.32480502128601, 21100: 125.85592603683472, 21200: 126.36651587486267, 21300: 126.89070796966553, 21400: 127.4010751247406, 21500: 127.91181421279907, 21600: 128.42954206466675, 21700: 128.94049191474915, 21800: 129.44766306877136, 21900: 129.9658510684967, 22000: 130.47971081733704, 22100: 130.9946050643921, 22200: 131.51340889930725, 22300: 132.03098106384277, 22400: 132.53333497047424, 22500: 133.05136394500732, 22600: 133.5598850250244, 22700: 134.0794699192047, 22800: 134.59701800346375, 22900: 135.124498128891, 23000: 135.6133770942688, 23100: 136.11525201797485, 23200: 136.63353490829468, 23300: 137.13085317611694, 23400: 137.64480924606323, 23500: 138.15227890014648, 23600: 138.67401909828186, 23700: 139.18188524246216, 23800: 139.71191000938416, 23900: 140.22144985198975, 24000: 140.73400807380676, 24100: 141.2411618232727, 24200: 141.771986246109, 24300: 142.27062487602234, 24400: 142.79240608215332, 24500: 143.30317091941833, 24600: 143.8115839958191, 24700: 144.32128620147705, 24800: 144.82920217514038, 24900: 145.32413411140442, 25000: 145.86310505867004, 25100: 146.37744998931885, 25200: 146.88038611412048, 25300: 147.39261507987976, 25400: 147.8778431415558, 25500: 148.399080991745, 25600: 148.9045090675354, 25700: 149.4771990776062, 25800: 149.97497415542603, 25900: 150.4974172115326, 26000: 150.98581504821777, 26100: 151.5027298927307, 26200: 152.00807905197144, 26300: 152.51791501045227, 26400: 153.0169792175293, 26500: 153.5329360961914, 26600: 154.06201314926147, 26700: 154.5999310016632, 26800: 155.10292196273804, 26900: 155.60217809677124, 27000: 156.1324782371521, 27100: 157.08714485168457, 27200: 157.621511220932}, 'loss': {0: 0.4909495413303375, 100: 0.4842177629470825, 200: 0.6204113364219666, 300: 0.5503272414207458, 400: 0.304535448551178, 500: 0.5334817171096802, 600: 0.6249256730079651, 700: 1.0955156087875366, 800: 0.2833239436149597, 900: 0.5837204456329346, 1000: 0.5418709516525269, 1100: 1.5727434158325195, 1200: 0.17877450585365295, 1300: 0.6334701180458069, 1400: 0.8807712197303772, 1500: 1.3582360744476318, 1600: 0.38495656847953796, 1700: 0.8744882941246033, 1800: 1.5766561031341553, 1900: 0.43333083391189575, 2000: 1.6599664688110352, 2100: 1.4106602668762207, 2200: 0.39864668250083923, 2300: 3.5630874633789062, 2400: 1.394779086112976, 2500: 0.32569703459739685, 2600: 0.8886570334434509, 2700: 0.9143573045730591, 2800: 0.5126280188560486, 2900: 0.18053792417049408, 3000: 0.35131219029426575, 3100: 0.46348246932029724, 3200: 0.5387201905250549, 3300: 0.09865319728851318, 3400: 0.30679649114608765, 3500: 1.124868392944336, 3600: 3.7392091751098633, 3700: 0.14992612600326538, 3800: 1.1436676979064941, 3900: 0.40199318528175354, 4000: 0.9568976759910583, 4100: 1.6440784931182861, 4200: 0.44516196846961975, 4300: 0.6783609986305237, 4400: 2.223242998123169, 4500: 1.1356894969940186, 4600: 0.7207114696502686, 4700: 1.4347879886627197, 4800: 0.7645564675331116, 4900: 1.0724495649337769, 5000: 0.45851415395736694, 5100: 1.8523186445236206, 5200: 0.18902407586574554, 5300: 0.07036320120096207, 5400: 2.5903022289276123, 5500: 2.6451523303985596, 5600: 1.463171124458313, 5700: 4.436810493469238, 5800: 1.4986119270324707, 5900: 0.956074059009552, 6000: 1.343675136566162, 6100: 0.4131637215614319, 6200: 1.120417594909668, 6300: 0.2209276258945465, 6400: 0.9061277508735657, 6500: 1.2727024555206299, 6600: 0.6983611583709717, 6700: 0.46958452463150024, 6800: 1.0878801345825195, 6900: 0.5700533390045166, 7000: 0.3458558917045593, 7100: 0.4422459006309509, 7200: 0.685064435005188, 7300: 0.8443682789802551, 7400: 1.2251784801483154, 7500: 0.06486117094755173, 7600: 0.4165884256362915, 7700: 0.3738164007663727, 7800: 1.27926766872406, 7900: 0.36683130264282227, 8000: 0.6329328417778015, 8100: 0.36655959486961365, 8200: 0.47661927342414856, 8300: 0.6037473082542419, 8400: 0.3142014443874359, 8500: 0.32407283782958984, 8600: 0.4304148852825165, 8700: 0.782906711101532, 8800: 1.758846402168274, 8900: 0.6231425404548645, 9000: 1.013063669204712, 9100: 0.24265159666538239, 9200: 0.27719801664352417, 9300: 0.22230234742164612, 9400: 1.5306944847106934, 9500: 1.688657522201538, 9600: 0.868516743183136, 9700: 7.885610580444336, 9800: 0.6246947646141052, 9900: 0.5388398766517639, 10000: 0.9800369739532471, 10100: 0.5538560152053833, 10200: 1.735222339630127, 10300: 0.5294211506843567, 10400: 0.19545292854309082, 10500: 0.6213225722312927, 10600: 1.126346468925476, 10700: 0.2813347578048706, 10800: 0.41574153304100037, 10900: 0.7130047082901001, 11000: 0.6088226437568665, 11100: 0.28922632336616516, 11200: 2.683849811553955, 11300: 0.36323052644729614, 11400: 1.6591169834136963, 11500: 0.6146429181098938, 11600: 1.7525235414505005, 11700: 0.38204118609428406, 11800: 2.8542745113372803, 11900: 0.9013072848320007, 12000: 0.7808054089546204, 12100: 1.3186678886413574, 12200: 0.4680630564689636, 12300: 0.48023930191993713, 12400: 1.33634352684021, 12500: 0.7113581299781799, 12600: 0.961645781993866, 12700: 1.3635437488555908, 12800: 0.4199863076210022, 12900: 0.6754041910171509, 13000: 2.056694746017456, 13100: 1.203869342803955, 13200: 0.7725670337677002, 13300: 1.037062406539917, 13400: 0.391391783952713, 13500: 0.6037660241127014, 13600: 0.3576725721359253, 13700: 0.484056293964386, 13800: 0.32410749793052673, 13900: 0.38227522373199463, 14000: 0.4148563742637634, 14100: 2.056370735168457, 14200: 0.42799311876296997, 14300: 0.65037602186203, 14400: 0.5810167193412781, 14500: 0.994829535484314, 14600: 0.5140925645828247, 14700: 0.8981226682662964, 14800: 0.3405590355396271, 14900: 0.5631834268569946, 15000: 0.9634636640548706, 15100: 1.0108566284179688, 15200: 1.0184168815612793, 15300: 0.6954895257949829, 15400: 0.354856938123703, 15500: 0.7345533967018127, 15600: 0.26482781767845154, 15700: 4.286989688873291, 15800: 1.2530500888824463, 15900: 0.2385304570198059, 16000: 2.2676310539245605, 16100: 0.4830457866191864, 16200: 0.456779807806015, 16300: 0.4415448009967804, 16400: 1.407045602798462, 16500: 0.5869510173797607, 16600: 1.5907130241394043, 16700: 0.3823854923248291, 16800: 1.4237194061279297, 16900: 0.649492621421814, 17000: 0.40032026171684265, 17100: 1.2232189178466797, 17200: 0.9068279266357422, 17300: 0.3354533910751343, 17400: 0.4512524902820587, 17500: 0.4371139109134674, 17600: 0.24869921803474426, 17700: 1.176712989807129, 17800: 0.8890975713729858, 17900: 0.5122663974761963, 18000: 0.6281273365020752, 18100: 0.5145480036735535, 18200: 0.39324378967285156, 18300: 1.4874788522720337, 18400: 0.6317421793937683, 18500: 0.4070189595222473, 18600: 0.6165342926979065, 18700: 1.0281816720962524, 18800: 0.9378131031990051, 18900: 0.24258071184158325, 19000: 0.4789288341999054, 19100: 2.639340877532959, 19200: 1.2425570487976074, 19300: 1.0879504680633545, 19400: 0.3959367573261261, 19500: 0.2139510214328766, 19600: 0.7562939524650574, 19700: 0.9761199355125427, 19800: 0.32037553191185, 19900: 1.4244635105133057, 20000: 1.702402949333191, 20100: 0.8123915195465088, 20200: 0.2883360683917999, 20300: 0.7106304168701172, 20400: 0.7195351123809814, 20500: 0.6952576041221619, 20600: 0.24746587872505188, 20700: 0.49666503071784973, 20800: 0.42238157987594604, 20900: 5.512706279754639, 21000: 0.4597724974155426, 21100: 0.7933799624443054, 21200: 0.5722929835319519, 21300: 0.7105150818824768, 21400: 0.2612724006175995, 21500: 3.401576280593872, 21600: 0.8652751445770264, 21700: 0.6720033884048462, 21800: 1.3776206970214844, 21900: 0.6276530027389526, 22000: 1.5100820064544678, 22100: 0.40600600838661194, 22200: 0.5287419557571411, 22300: 0.33965548872947693, 22400: 0.28230026364326477, 22500: 0.21271471679210663, 22600: 0.22507640719413757, 22700: 0.5668399930000305, 22800: 0.2420843094587326, 22900: 0.8212016820907593, 23000: 0.32535243034362793, 23100: 0.5450839996337891, 23200: 0.33416473865509033, 23300: 1.0142178535461426, 23400: 1.5589474439620972, 23500: 0.29553377628326416, 23600: 1.3398466110229492, 23700: 2.090913772583008, 23800: 0.9687130451202393, 23900: 0.9151114225387573, 24000: 0.6799769401550293, 24100: 0.2216442972421646, 24200: 0.3509252667427063, 24300: 0.9293453693389893, 24400: 0.9904369711875916, 24500: 1.887036919593811, 24600: 1.1252912282943726, 24700: 0.308464378118515, 24800: 1.6122504472732544, 24900: 0.2193872332572937, 25000: 0.48782292008399963, 25100: 0.20881620049476624, 25200: 2.017791271209717, 25300: 0.2976459562778473, 25400: 0.43522384762763977, 25500: 0.5014163851737976, 25600: 0.6419022679328918, 25700: 0.7219206094741821, 25800: 0.5636824369430542, 25900: 1.3425750732421875, 26000: 4.5345354080200195, 26100: 2.0707039833068848, 26200: 0.06170102208852768, 26300: 0.8081559538841248, 26400: 0.9287275075912476, 26500: 1.2064459323883057, 26600: 0.27254751324653625, 26700: 0.38225552439689636, 26800: 2.4143967628479004, 26900: 0.5152634382247925, 27000: 1.4532374143600464, 27100: 0.8123358488082886, 27200: 1.0956658124923706}, 'F1': {5: 0.6253769163622325}, 'Accuracy': {5: 0.553557007561853}}\n",
      "Epoch 6\n",
      "\n",
      "Epoch time: 1596.8577890396118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       837\n",
      "           1       0.59      0.98      0.74       832\n",
      "           2       0.65      0.35      0.45       858\n",
      "           3       0.60      0.70      0.64       850\n",
      "           4       0.59      0.79      0.67       829\n",
      "           5       0.57      0.72      0.64       846\n",
      "           6       0.59      0.89      0.71       851\n",
      "           7       0.59      0.86      0.70       851\n",
      "           8       0.57      0.71      0.63       845\n",
      "           9       0.60      0.73      0.66       851\n",
      "          10       0.42      0.25      0.31      5171\n",
      "\n",
      "    accuracy                           0.56     13621\n",
      "   macro avg       0.59      0.71      0.63     13621\n",
      "weighted avg       0.54      0.56      0.53     13621\n",
      "\n",
      "Logger {'time': {0: 0.015924930572509766, 100: 0.5704309940338135, 200: 1.1000819206237793, 300: 1.613306999206543, 400: 2.1244800090789795, 500: 2.69484806060791, 600: 3.2006418704986572, 700: 3.8740859031677246, 800: 4.635339736938477, 900: 5.240085124969482, 1000: 5.800256729125977, 1100: 6.421126842498779, 1200: 6.944576025009155, 1300: 7.464423894882202, 1400: 7.992618083953857, 1500: 8.481503963470459, 1600: 9.026546001434326, 1700: 9.521703004837036, 1800: 10.058120965957642, 1900: 10.564092874526978, 2000: 11.08196473121643, 2100: 11.590235948562622, 2200: 12.128090858459473, 2300: 12.642189979553223, 2400: 13.161610126495361, 2500: 13.680434942245483, 2600: 14.214696884155273, 2700: 14.742267847061157, 2800: 15.260026931762695, 2900: 15.76471471786499, 3000: 16.290295839309692, 3100: 16.79060387611389, 3200: 17.27985382080078, 3300: 17.811904907226562, 3400: 18.31671690940857, 3500: 18.842106819152832, 3600: 19.33546495437622, 3700: 19.855947017669678, 3800: 20.354942083358765, 3900: 20.873374938964844, 4000: 21.379326105117798, 4100: 21.907408952713013, 4200: 22.40081787109375, 4300: 23.019157886505127, 4400: 23.53506898880005, 4500: 24.055266857147217, 4600: 24.558405876159668, 4700: 25.087077856063843, 4800: 25.582252740859985, 4900: 26.096051931381226, 5000: 26.59161877632141, 5100: 27.110013008117676, 5200: 27.61940574645996, 5300: 28.13941192626953, 5400: 28.68639588356018, 5500: 29.234976768493652, 5600: 29.768157958984375, 5700: 30.305429697036743, 5800: 30.82120394706726, 5900: 31.353824138641357, 6000: 31.87358283996582, 6100: 32.41962671279907, 6200: 32.97869801521301, 6300: 33.51517868041992, 6400: 34.019715785980225, 6500: 34.5478618144989, 6600: 35.062268018722534, 6700: 35.55884385108948, 6800: 36.08076882362366, 6900: 36.6405987739563, 7000: 37.16061592102051, 7100: 37.66772389411926, 7200: 38.183249950408936, 7300: 38.68575382232666, 7400: 39.39995288848877, 7500: 41.800516843795776, 7600: 42.647541761398315, 7700: 43.1799578666687, 7800: 43.92372488975525, 7900: 44.51232290267944, 8000: 45.30703377723694, 8100: 45.92909812927246, 8200: 46.46731185913086, 8300: 1025.6388139724731, 8400: 1026.5050468444824, 8500: 1027.0266740322113, 8600: 1027.6145370006561, 8700: 1028.4703607559204, 8800: 1029.2128720283508, 8900: 1029.961740732193, 9000: 1030.6807029247284, 9100: 1031.6857409477234, 9200: 1032.2822148799896, 9300: 1032.8947968482971, 9400: 1033.433021068573, 9500: 1033.9250030517578, 9600: 1034.4496018886566, 9700: 1035.1105318069458, 9800: 1035.7063298225403, 9900: 1036.1914808750153, 10000: 1036.6810870170593, 10100: 1037.3287179470062, 10200: 1037.8165209293365, 10300: 1038.3192977905273, 10400: 1038.8111267089844, 10500: 1039.3169009685516, 10600: 1039.828331708908, 10700: 1040.3067290782928, 10800: 1040.8193559646606, 10900: 1041.3014719486237, 11000: 1041.799489736557, 11100: 1042.411468744278, 11200: 1042.9222810268402, 11300: 1043.412398815155, 11400: 1044.0281858444214, 11500: 1044.5513911247253, 11600: 1045.0839829444885, 11700: 1045.5634729862213, 11800: 1046.0671079158783, 11900: 1046.5618119239807, 12000: 1047.0826578140259, 12100: 1047.5997998714447, 12200: 1048.1104867458344, 12300: 1048.6183009147644, 12400: 1049.1336209774017, 12500: 1049.6361079216003, 12600: 1050.367521762848, 12700: 1051.1099128723145, 12800: 1051.762857913971, 12900: 1052.2658870220184, 13000: 1052.7752249240875, 13100: 1053.3121409416199, 13200: 1053.8616888523102, 13300: 1054.3868350982666, 13400: 1054.8821001052856, 13500: 1055.4120609760284, 13600: 1055.9165668487549, 13700: 1056.4071819782257, 13800: 1056.9169309139252, 13900: 1057.4339609146118, 14000: 1057.9296278953552, 14100: 1058.4180068969727, 14200: 1058.9388918876648, 14300: 1059.4495029449463, 14400: 1059.9306659698486, 14500: 1060.4203238487244, 14600: 1060.9181869029999, 14700: 1061.4472961425781, 14800: 1061.9505460262299, 14900: 1062.4485049247742, 15000: 1062.9638087749481, 15100: 1063.4658660888672, 15200: 1063.9573907852173, 15300: 1064.4478719234467, 15400: 1064.9512329101562, 15500: 1065.493272781372, 15600: 1065.9767980575562, 15700: 1066.4857070446014, 15800: 1066.9713819026947, 15900: 1067.4735367298126, 16000: 1067.9510419368744, 16100: 1068.470174074173, 16200: 1069.0696668624878, 16300: 1069.5742979049683, 16400: 1070.068214893341, 16500: 1368.9170031547546, 16600: 1369.5827159881592, 16700: 1370.038880109787, 16800: 1370.6509928703308, 16900: 1371.137598991394, 17000: 1371.659392118454, 17100: 1372.1405100822449, 17200: 1372.7066888809204, 17300: 1373.3300020694733, 17400: 1373.8710360527039, 17500: 1374.4119198322296, 17600: 1374.9252197742462, 17700: 1375.440780878067, 17800: 1375.9538729190826, 17900: 1376.4688987731934, 18000: 1377.0108759403229, 18100: 1377.662978887558, 18200: 1378.1708250045776, 18300: 1378.6922969818115, 18400: 1379.2350528240204, 18500: 1379.727128982544, 18600: 1380.2378408908844, 18700: 1380.745434999466, 18800: 1381.2607350349426, 18900: 1381.7573127746582, 19000: 1382.2982699871063, 19100: 1382.7748560905457, 19200: 1383.3404910564423, 19300: 1383.8308618068695, 19400: 1384.3566579818726, 19500: 1384.8454298973083, 19600: 1385.3558948040009, 19700: 1385.8490488529205, 19800: 1386.3425478935242, 19900: 1386.8728849887848, 20000: 1387.3519759178162, 20100: 1387.8486659526825, 20200: 1388.3303639888763, 20300: 1388.8675019741058, 20400: 1389.36754488945, 20500: 1389.8684759140015, 20600: 1390.364640712738, 20700: 1390.8785269260406, 20800: 1391.3797209262848, 20900: 1391.8928039073944, 21000: 1392.3929297924042, 21100: 1393.0002608299255, 21200: 1393.5122039318085, 21300: 1394.017294883728, 21400: 1394.4996130466461, 21500: 1394.9935200214386, 21600: 1395.4849569797516, 21700: 1395.976721048355, 21800: 1396.4788229465485, 21900: 1396.959392786026, 22000: 1397.4699738025665, 22100: 1397.953449010849, 22200: 1398.4708738327026, 22300: 1398.9896459579468, 22400: 1399.506688117981, 22500: 1399.98548579216, 22600: 1400.5484528541565, 22700: 1401.03067612648, 22800: 1401.5273160934448, 22900: 1402.0131096839905, 23000: 1402.5222659111023, 23100: 1402.9954159259796, 23200: 1403.4974308013916, 23300: 1403.994183063507, 23400: 1404.4848639965057, 23500: 1404.984121799469, 23600: 1405.4745709896088, 23700: 1405.958878993988, 23800: 1406.4460899829865, 23900: 1406.9321208000183, 24000: 1407.4116218090057, 24100: 1407.932345867157, 24200: 1408.432445049286, 24300: 1408.9175188541412, 24400: 1409.4258298873901, 24500: 1409.9065928459167, 24600: 1410.4101068973541, 24700: 1410.8814108371735, 24800: 1411.3852407932281, 24900: 1411.8772218227386, 25000: 1412.4174528121948, 25100: 1412.934427022934, 25200: 1413.4376537799835, 25300: 1414.0116827487946, 25400: 1414.5294229984283, 25500: 1415.0141620635986, 25600: 1582.7006969451904, 25700: 1584.7275338172913, 25800: 1585.7398958206177, 25900: 1586.353388786316, 26000: 1587.0737748146057, 26100: 1587.7165398597717, 26200: 1588.5265839099884, 26300: 1589.3798849582672, 26400: 1589.9966459274292, 26500: 1590.5920629501343, 26600: 1591.2034981250763, 26700: 1591.8793148994446, 26800: 1592.6603798866272, 26900: 1593.4674887657166, 27000: 1594.3162310123444, 27100: 1595.3872468471527, 27200: 1596.1311378479004}, 'loss': {0: 0.6121389865875244, 100: 0.5898967385292053, 200: 0.5964171886444092, 300: 0.47704508900642395, 400: 0.5817031264305115, 500: 0.5223260521888733, 600: 0.5560978651046753, 700: 1.2331864833831787, 800: 0.6056838631629944, 900: 0.6235074996948242, 1000: 0.5542293787002563, 1100: 0.6945329904556274, 1200: 0.519550621509552, 1300: 0.9009478688240051, 1400: 0.5876078009605408, 1500: 0.6914144158363342, 1600: 0.29486939311027527, 1700: 1.1079144477844238, 1800: 1.6320719718933105, 1900: 0.5644398927688599, 2000: 1.3590188026428223, 2100: 1.3413126468658447, 2200: 0.41581571102142334, 2300: 3.592855930328369, 2400: 5.225300312042236, 2500: 0.47376129031181335, 2600: 1.797205924987793, 2700: 0.911709725856781, 2800: 0.5609590411186218, 2900: 0.11521924287080765, 3000: 0.2365051805973053, 3100: 0.5918834209442139, 3200: 0.3591611683368683, 3300: 0.16906797885894775, 3400: 0.2624877393245697, 3500: 1.0945919752120972, 3600: 3.447216272354126, 3700: 0.5230491757392883, 3800: 1.2288720607757568, 3900: 0.4429917335510254, 4000: 1.1917743682861328, 4100: 1.6465024948120117, 4200: 0.8692793846130371, 4300: 0.4962941110134125, 4400: 4.236209392547607, 4500: 1.5083776712417603, 4600: 0.6378816366195679, 4700: 1.4984619617462158, 4800: 0.7284151315689087, 4900: 1.010244369506836, 5000: 0.6688517332077026, 5100: 5.2140374183654785, 5200: 0.3626215159893036, 5300: 0.08434569835662842, 5400: 1.8216654062271118, 5500: 2.8447721004486084, 5600: 1.6504697799682617, 5700: 3.1583471298217773, 5800: 1.0028252601623535, 5900: 0.8312854766845703, 6000: 1.126729130744934, 6100: 0.43201661109924316, 6200: 0.9067567586898804, 6300: 0.166048064827919, 6400: 1.0670969486236572, 6500: 0.2265172004699707, 6600: 0.45477136969566345, 6700: 0.5008093118667603, 6800: 1.2134454250335693, 6900: 0.4665127694606781, 7000: 0.17586418986320496, 7100: 1.1491137742996216, 7200: 0.4041791260242462, 7300: 1.2483255863189697, 7400: 1.086776614189148, 7500: 0.14247745275497437, 7600: 0.5065958499908447, 7700: 0.262651652097702, 7800: 1.2892770767211914, 7900: 0.1587834358215332, 8000: 0.5986284613609314, 8100: 0.36585885286331177, 8200: 0.844118595123291, 8300: 0.5595546364784241, 8400: 0.28477510809898376, 8500: 0.28741955757141113, 8600: 0.40649470686912537, 8700: 0.6986345648765564, 8800: 0.47091159224510193, 8900: 1.343111276626587, 9000: 1.00648832321167, 9100: 0.3271119296550751, 9200: 0.3684278428554535, 9300: 0.5730372667312622, 9400: 1.2350974082946777, 9500: 1.1594525575637817, 9600: 1.3193995952606201, 9700: 7.721653461456299, 9800: 0.6198455691337585, 9900: 1.9460875988006592, 10000: 0.8455784320831299, 10100: 0.64284747838974, 10200: 2.411726474761963, 10300: 0.40626785159111023, 10400: 0.5710641741752625, 10500: 0.5305709838867188, 10600: 0.9721009731292725, 10700: 0.33393436670303345, 10800: 0.3557218015193939, 10900: 0.7420908808708191, 11000: 0.3523096442222595, 11100: 0.26097989082336426, 11200: 2.3947715759277344, 11300: 0.4301120638847351, 11400: 1.467125415802002, 11500: 0.8133346438407898, 11600: 2.3075380325317383, 11700: 1.2367115020751953, 11800: 1.4256172180175781, 11900: 0.9245064854621887, 12000: 0.37400949001312256, 12100: 0.6714417934417725, 12200: 0.45544546842575073, 12300: 0.5723966360092163, 12400: 0.9936915636062622, 12500: 2.170285701751709, 12600: 0.8753718137741089, 12700: 1.7203898429870605, 12800: 0.4026094675064087, 12900: 0.3965374529361725, 13000: 1.9158339500427246, 13100: 0.9505532383918762, 13200: 0.7708026766777039, 13300: 0.8205652236938477, 13400: 0.3377150595188141, 13500: 0.7483447194099426, 13600: 0.24877405166625977, 13700: 0.5902860760688782, 13800: 0.38190409541130066, 13900: 0.39641907811164856, 14000: 1.0262012481689453, 14100: 0.23209252953529358, 14200: 0.41953638195991516, 14300: 0.7025715708732605, 14400: 0.3737698197364807, 14500: 0.8641558885574341, 14600: 0.725464940071106, 14700: 0.922572135925293, 14800: 0.15202531218528748, 14900: 0.4686172604560852, 15000: 0.7822567224502563, 15100: 0.9744609594345093, 15200: 0.8843315839767456, 15300: 0.9088865518569946, 15400: 0.5876396894454956, 15500: 1.2648777961730957, 15600: 0.28662028908729553, 15700: 3.540630340576172, 15800: 1.3399567604064941, 15900: 1.2810595035552979, 16000: 2.5499138832092285, 16100: 0.4803555905818939, 16200: 0.23646950721740723, 16300: 0.5765524506568909, 16400: 1.6089708805084229, 16500: 0.5576146245002747, 16600: 1.9631016254425049, 16700: 0.32435521483421326, 16800: 1.4807788133621216, 16900: 0.7059597373008728, 17000: 0.6084230542182922, 17100: 1.044999122619629, 17200: 0.8391512632369995, 17300: 0.2878759205341339, 17400: 1.0525453090667725, 17500: 0.38337209820747375, 17600: 0.32325124740600586, 17700: 1.1390081644058228, 17800: 1.1088253259658813, 17900: 0.4968647360801697, 18000: 0.3977278172969818, 18100: 0.5202052593231201, 18200: 0.06445396691560745, 18300: 1.0453269481658936, 18400: 0.8254416584968567, 18500: 0.9709845185279846, 18600: 0.4467555284500122, 18700: 3.062462329864502, 18800: 0.699694812297821, 18900: 0.3907516300678253, 19000: 0.43139928579330444, 19100: 6.401629447937012, 19200: 2.2758357524871826, 19300: 0.8685353994369507, 19400: 0.4459002912044525, 19500: 0.17882803082466125, 19600: 1.0086479187011719, 19700: 0.7713763117790222, 19800: 0.26512807607650757, 19900: 1.4448117017745972, 20000: 1.473585844039917, 20100: 0.04077285900712013, 20200: 0.579117476940155, 20300: 1.3408247232437134, 20400: 0.5474555492401123, 20500: 0.7630230784416199, 20600: 0.36415916681289673, 20700: 0.5243170857429504, 20800: 0.31687623262405396, 20900: 3.2132480144500732, 21000: 1.766749620437622, 21100: 0.5991290807723999, 21200: 0.2666870355606079, 21300: 0.451102614402771, 21400: 0.6190435290336609, 21500: 2.1414103507995605, 21600: 0.4389247000217438, 21700: 0.5209189653396606, 21800: 0.8685896396636963, 21900: 0.7798672318458557, 22000: 1.453802227973938, 22100: 0.40405037999153137, 22200: 0.30147069692611694, 22300: 0.19283533096313477, 22400: 0.7011964917182922, 22500: 0.16751782596111298, 22600: 0.22130556404590607, 22700: 0.6736440062522888, 22800: 0.25645676255226135, 22900: 2.2065324783325195, 23000: 0.4532197415828705, 23100: 0.6050117611885071, 23200: 0.35658666491508484, 23300: 1.554358720779419, 23400: 1.7115366458892822, 23500: 0.33554086089134216, 23600: 1.1759791374206543, 23700: 1.9047335386276245, 23800: 0.7313633561134338, 23900: 0.8251450061798096, 24000: 0.5427159070968628, 24100: 0.21239762008190155, 24200: 0.6451226472854614, 24300: 0.6469471454620361, 24400: 0.8311588168144226, 24500: 4.83131742477417, 24600: 1.211607813835144, 24700: 0.3901178538799286, 24800: 0.600739061832428, 24900: 0.18175041675567627, 25000: 0.36019113659858704, 25100: 0.3908548653125763, 25200: 1.4113287925720215, 25300: 0.3996957838535309, 25400: 0.6855449676513672, 25500: 0.4777640104293823, 25600: 0.69551020860672, 25700: 1.0809741020202637, 25800: 0.5680610537528992, 25900: 1.6115167140960693, 26000: 3.9964377880096436, 26100: 0.9488140344619751, 26200: 0.08128321915864944, 26300: 1.5978977680206299, 26400: 0.7938127517700195, 26500: 0.9449891448020935, 26600: 0.31413301825523376, 26700: 0.4848830997943878, 26800: 1.9187841415405273, 26900: 0.4680456519126892, 27000: 1.2503105401992798, 27100: 0.946185827255249, 27200: 0.9857086539268494}, 'F1': {6: 0.6297695585957778}, 'Accuracy': {6: 0.5611922766316717}}\n",
      "Epoch 7\n",
      "\n",
      "Epoch time: 141.76838088035583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75       837\n",
      "           1       0.59      0.96      0.73       832\n",
      "           2       0.64      0.50      0.56       858\n",
      "           3       0.62      0.65      0.63       850\n",
      "           4       0.52      0.79      0.63       829\n",
      "           5       0.55      0.79      0.65       846\n",
      "           6       0.61      0.77      0.68       851\n",
      "           7       0.60      0.82      0.69       851\n",
      "           8       0.58      0.69      0.63       845\n",
      "           9       0.61      0.64      0.62       851\n",
      "          10       0.40      0.23      0.29      5171\n",
      "\n",
      "    accuracy                           0.55     13621\n",
      "   macro avg       0.58      0.70      0.62     13621\n",
      "weighted avg       0.52      0.55      0.52     13621\n",
      "\n",
      "Logger {'time': {0: 0.014246940612792969, 100: 0.5790410041809082, 200: 1.1149139404296875, 300: 1.6357309818267822, 400: 2.1579599380493164, 500: 2.690725803375244, 600: 3.217233896255493, 700: 3.7330009937286377, 800: 4.224169015884399, 900: 4.746019124984741, 1000: 5.240797996520996, 1100: 5.739109039306641, 1200: 6.240423917770386, 1300: 6.773236036300659, 1400: 7.278969049453735, 1500: 7.878142833709717, 1600: 8.580831050872803, 1700: 9.219290733337402, 1800: 9.88354206085205, 1900: 10.632474899291992, 2000: 11.416800022125244, 2100: 12.051653861999512, 2200: 12.679931879043579, 2300: 13.190917015075684, 2400: 13.677337169647217, 2500: 14.190454959869385, 2600: 14.680206060409546, 2700: 15.195803880691528, 2800: 15.709552764892578, 2900: 16.213731050491333, 3000: 16.73871898651123, 3100: 17.244417905807495, 3200: 17.764698028564453, 3300: 18.2605938911438, 3400: 18.76861310005188, 3500: 19.256793975830078, 3600: 19.755864143371582, 3700: 20.309993028640747, 3800: 20.82509207725525, 3900: 21.328896045684814, 4000: 21.835230827331543, 4100: 22.320992946624756, 4200: 22.832053899765015, 4300: 23.3422110080719, 4400: 23.868698120117188, 4500: 24.36678695678711, 4600: 24.873365879058838, 4700: 25.390542030334473, 4800: 25.89017915725708, 4900: 26.397861003875732, 5000: 26.890440940856934, 5100: 27.42871403694153, 5200: 27.93299102783203, 5300: 28.469794034957886, 5400: 28.960653066635132, 5500: 29.48225498199463, 5600: 29.985295057296753, 5700: 30.510246992111206, 5800: 31.009662866592407, 5900: 31.535730838775635, 6000: 32.0291531085968, 6100: 32.5419487953186, 6200: 33.05583095550537, 6300: 33.55689811706543, 6400: 34.06873798370361, 6500: 34.576558113098145, 6600: 35.08016800880432, 6700: 35.57791090011597, 6800: 36.07479190826416, 6900: 36.58398699760437, 7000: 37.08537793159485, 7100: 37.57506990432739, 7200: 38.10544300079346, 7300: 38.63404703140259, 7400: 39.2154381275177, 7500: 39.78277087211609, 7600: 40.41619515419006, 7700: 40.97826886177063, 7800: 41.54281997680664, 7900: 42.111774921417236, 8000: 42.62784194946289, 8100: 43.15742897987366, 8200: 43.6605749130249, 8300: 44.163511991500854, 8400: 44.64358901977539, 8500: 45.17388892173767, 8600: 45.65944194793701, 8700: 46.16661882400513, 8800: 46.69103693962097, 8900: 47.20761299133301, 9000: 47.69667601585388, 9100: 48.19680881500244, 9200: 48.69653606414795, 9300: 49.20821714401245, 9400: 49.72094202041626, 9500: 50.2535719871521, 9600: 50.76134395599365, 9700: 51.28888916969299, 9800: 51.78598403930664, 9900: 52.3290491104126, 10000: 52.82319784164429, 10100: 53.329272985458374, 10200: 53.83089303970337, 10300: 54.343770027160645, 10400: 54.85314202308655, 10500: 55.358092069625854, 10600: 55.86508893966675, 10700: 56.36848211288452, 10800: 56.85556197166443, 10900: 57.34495782852173, 11000: 57.840951919555664, 11100: 58.35424590110779, 11200: 58.83986783027649, 11300: 59.3756148815155, 11400: 59.862383127212524, 11500: 60.381824016571045, 11600: 60.864038944244385, 11700: 61.36889100074768, 11800: 61.883684158325195, 11900: 62.393024921417236, 12000: 62.87467694282532, 12100: 63.38854503631592, 12200: 63.89547276496887, 12300: 64.40938401222229, 12400: 64.90031313896179, 12500: 65.41570401191711, 12600: 65.9114408493042, 12700: 66.42436408996582, 12800: 66.91983199119568, 12900: 67.4231469631195, 13000: 68.08051705360413, 13100: 68.55331707000732, 13200: 69.14277195930481, 13300: 69.65457606315613, 13400: 70.18982100486755, 13500: 70.70668482780457, 13600: 71.21276903152466, 13700: 71.70645713806152, 13800: 72.23456597328186, 13900: 72.72335481643677, 14000: 73.23846387863159, 14100: 73.72315502166748, 14200: 74.26827216148376, 14300: 74.76076698303223, 14400: 75.26942801475525, 14500: 75.77745413780212, 14600: 76.32771706581116, 14700: 76.84151196479797, 14800: 77.38941311836243, 14900: 77.95087313652039, 15000: 78.48870992660522, 15100: 78.98969912528992, 15200: 79.51409697532654, 15300: 80.05691385269165, 15400: 80.57787895202637, 15500: 81.09266996383667, 15600: 81.65913486480713, 15700: 82.17040205001831, 15800: 82.6869728565216, 15900: 83.20280075073242, 16000: 83.7213499546051, 16100: 84.22354412078857, 16200: 84.7413980960846, 16300: 85.24567294120789, 16400: 85.75770592689514, 16500: 86.25988507270813, 16600: 86.79240083694458, 16700: 87.27819108963013, 16800: 87.77991795539856, 16900: 88.27872109413147, 17000: 88.7745189666748, 17100: 89.32078099250793, 17200: 89.81309390068054, 17300: 90.3226969242096, 17400: 90.8135621547699, 17500: 91.32255697250366, 17600: 91.82311701774597, 17700: 92.34230899810791, 17800: 92.84733486175537, 17900: 93.36804294586182, 18000: 93.85212588310242, 18100: 94.38924908638, 18200: 94.87483286857605, 18300: 95.38276100158691, 18400: 95.87644290924072, 18500: 96.38692593574524, 18600: 96.8817389011383, 18700: 97.39663314819336, 18800: 97.88860392570496, 18900: 98.3873839378357, 19000: 98.96625518798828, 19100: 99.46906900405884, 19200: 99.99997115135193, 19300: 100.50376296043396, 19400: 101.0302300453186, 19500: 101.54387879371643, 19600: 102.07554292678833, 19700: 102.57303595542908, 19800: 103.08371615409851, 19900: 103.58706092834473, 20000: 104.1027729511261, 20100: 104.59153413772583, 20200: 105.12081098556519, 20300: 105.61436486244202, 20400: 106.13636302947998, 20500: 106.63994097709656, 20600: 107.18268394470215, 20700: 107.68217587471008, 20800: 108.20393490791321, 20900: 108.72538018226624, 21000: 109.2484290599823, 21100: 109.7638430595398, 21200: 110.2963969707489, 21300: 110.81260585784912, 21400: 111.3336169719696, 21500: 111.82675790786743, 21600: 112.38113689422607, 21700: 112.86886096000671, 21800: 113.40024185180664, 21900: 113.89578795433044, 22000: 114.42585396766663, 22100: 114.9328818321228, 22200: 115.42538595199585, 22300: 115.93356013298035, 22400: 116.45083212852478, 22500: 116.96109318733215, 22600: 117.45809006690979, 22700: 117.97272896766663, 22800: 118.46325087547302, 22900: 119.00058007240295, 23000: 119.4949381351471, 23100: 120.00409197807312, 23200: 120.50220584869385, 23300: 121.01169991493225, 23400: 121.50339603424072, 23500: 122.03800916671753, 23600: 122.51642894744873, 23700: 123.02773714065552, 23800: 123.52607202529907, 23900: 124.02099990844727, 24000: 124.5449960231781, 24100: 125.03279900550842, 24200: 125.52440094947815, 24300: 126.01028394699097, 24400: 126.52542996406555, 24500: 127.01985597610474, 24600: 127.52522897720337, 24700: 128.05040407180786, 24800: 128.57091617584229, 24900: 129.1427140235901, 25000: 129.6570508480072, 25100: 130.20146775245667, 25200: 130.73696780204773, 25300: 131.2364320755005, 25400: 131.7458839416504, 25500: 132.23942589759827, 25600: 132.74488282203674, 25700: 133.24878787994385, 25800: 133.76054096221924, 25900: 134.26285314559937, 26000: 134.78177881240845, 26100: 135.28022289276123, 26200: 135.7659990787506, 26300: 136.42169284820557, 26400: 137.00832509994507, 26500: 137.5747950077057, 26600: 138.11493492126465, 26700: 138.7034637928009, 26800: 139.27359414100647, 26900: 139.83940982818604, 27000: 140.41446185112, 27100: 140.95060205459595, 27200: 141.45956897735596}, 'loss': {0: 0.5732500553131104, 100: 0.605799674987793, 200: 0.6813098192214966, 300: 0.6471021771430969, 400: 0.30433499813079834, 500: 0.41012683510780334, 600: 0.7292816638946533, 700: 1.1858702898025513, 800: 0.8914936780929565, 900: 0.6329646110534668, 1000: 2.0819501876831055, 1100: 0.973487138748169, 1200: 0.1632900834083557, 1300: 0.8331677317619324, 1400: 0.6715635657310486, 1500: 0.7303726673126221, 1600: 0.46802765130996704, 1700: 1.1145273447036743, 1800: 1.4471285343170166, 1900: 0.4839065670967102, 2000: 1.1221978664398193, 2100: 1.4050155878067017, 2200: 0.45149219036102295, 2300: 3.4601125717163086, 2400: 1.1590538024902344, 2500: 0.43760427832603455, 2600: 0.44832825660705566, 2700: 0.806836724281311, 2800: 0.4018295407295227, 2900: 0.46624043583869934, 3000: 0.3887767195701599, 3100: 0.5731098055839539, 3200: 0.3777616322040558, 3300: 0.25724393129348755, 3400: 0.38837945461273193, 3500: 1.071109414100647, 3600: 2.6122617721557617, 3700: 0.13075989484786987, 3800: 1.226198673248291, 3900: 0.48018544912338257, 4000: 1.0298330783843994, 4100: 1.3091638088226318, 4200: 0.6742810606956482, 4300: 0.5750748515129089, 4400: 4.382813453674316, 4500: 1.2639944553375244, 4600: 0.7247740626335144, 4700: 1.403934121131897, 4800: 0.43046581745147705, 4900: 1.150299072265625, 5000: 0.7348063588142395, 5100: 1.9794995784759521, 5200: 0.30536332726478577, 5300: 0.04896914213895798, 5400: 2.4053618907928467, 5500: 1.0285422801971436, 5600: 1.5253186225891113, 5700: 4.626996994018555, 5800: 1.1565022468566895, 5900: 0.9446847438812256, 6000: 1.2022583484649658, 6100: 0.44036099314689636, 6200: 0.9203446507453918, 6300: 0.15445254743099213, 6400: 0.8722416758537292, 6500: 0.26110854744911194, 6600: 0.5144232511520386, 6700: 0.5221668481826782, 6800: 1.1857589483261108, 6900: 0.7936131954193115, 7000: 0.46045008301734924, 7100: 1.0142855644226074, 7200: 0.48030057549476624, 7300: 1.676301121711731, 7400: 1.2762047052383423, 7500: 0.2936159372329712, 7600: 0.21707986295223236, 7700: 0.1434144526720047, 7800: 1.0439221858978271, 7900: 0.534981906414032, 8000: 0.6823940277099609, 8100: 0.20218688249588013, 8200: 0.5539126992225647, 8300: 0.7674877643585205, 8400: 0.18277180194854736, 8500: 0.3430817723274231, 8600: 0.3758348226547241, 8700: 0.8350204825401306, 8800: 0.6333667635917664, 8900: 0.7642109990119934, 9000: 1.0045855045318604, 9100: 0.27576956152915955, 9200: 0.4657236635684967, 9300: 0.13158857822418213, 9400: 0.3543408215045929, 9500: 1.4601207971572876, 9600: 0.8916503190994263, 9700: 8.504861831665039, 9800: 0.4006662368774414, 9900: 0.45442232489585876, 10000: 0.8553704619407654, 10100: 0.2886083722114563, 10200: 3.9199862480163574, 10300: 0.43768829107284546, 10400: 0.15815377235412598, 10500: 0.6595668792724609, 10600: 1.2403712272644043, 10700: 0.4384270906448364, 10800: 0.35038548707962036, 10900: 0.9195539951324463, 11000: 0.6022244691848755, 11100: 0.2344929575920105, 11200: 1.2073882818222046, 11300: 0.702166736125946, 11400: 0.274373859167099, 11500: 0.5973595976829529, 11600: 2.0504188537597656, 11700: 0.40051522850990295, 11800: 1.889318823814392, 11900: 0.33901944756507874, 12000: 0.4735589325428009, 12100: 0.7593432068824768, 12200: 0.21680378913879395, 12300: 0.3557281494140625, 12400: 0.465105801820755, 12500: 0.7118493914604187, 12600: 0.3566451072692871, 12700: 1.6708487272262573, 12800: 0.750662624835968, 12900: 0.36924421787261963, 13000: 1.6802778244018555, 13100: 1.2495434284210205, 13200: 0.5416516065597534, 13300: 0.5652894377708435, 13400: 0.29421159625053406, 13500: 1.0176399946212769, 13600: 0.2248838245868683, 13700: 1.179428219795227, 13800: 1.1162911653518677, 13900: 0.26355159282684326, 14000: 0.36790984869003296, 14100: 0.30634719133377075, 14200: 0.3020385205745697, 14300: 0.6016412377357483, 14400: 0.43164336681365967, 14500: 0.7915429472923279, 14600: 0.7258813977241516, 14700: 1.0212098360061646, 14800: 0.25725510716438293, 14900: 0.5304891467094421, 15000: 0.9625948071479797, 15100: 0.7125293016433716, 15200: 0.8389224410057068, 15300: 0.7704730033874512, 15400: 0.5112992525100708, 15500: 0.8170145153999329, 15600: 0.26444748044013977, 15700: 1.4557788372039795, 15800: 1.432621955871582, 15900: 0.13717453181743622, 16000: 0.9663283228874207, 16100: 0.529420793056488, 16200: 0.3397641181945801, 16300: 0.34206661581993103, 16400: 1.1648132801055908, 16500: 0.5195106267929077, 16600: 1.698702096939087, 16700: 0.37760302424430847, 16800: 1.4361671209335327, 16900: 0.7943965792655945, 17000: 0.3183785676956177, 17100: 1.4410693645477295, 17200: 1.048520803451538, 17300: 0.22860555350780487, 17400: 0.40886425971984863, 17500: 0.3942193388938904, 17600: 0.2997695207595825, 17700: 0.8813159465789795, 17800: 1.0106921195983887, 17900: 0.5393937230110168, 18000: 0.27918633818626404, 18100: 0.48111066222190857, 18200: 0.007508864160627127, 18300: 1.1655550003051758, 18400: 0.8826722502708435, 18500: 0.39607876539230347, 18600: 0.4481256306171417, 18700: 1.5006364583969116, 18800: 0.5731648802757263, 18900: 0.31390371918678284, 19000: 0.31560981273651123, 19100: 2.672377109527588, 19200: 2.06805682182312, 19300: 0.9040101170539856, 19400: 1.648697853088379, 19500: 0.14818450808525085, 19600: 1.3398758172988892, 19700: 0.6968061923980713, 19800: 0.2985475957393646, 19900: 1.3468685150146484, 20000: 0.9792919754981995, 20100: 0.06985186040401459, 20200: 0.5225641131401062, 20300: 0.8071902394294739, 20400: 0.7317822575569153, 20500: 0.671244740486145, 20600: 0.3604266941547394, 20700: 0.5367370247840881, 20800: 0.32987380027770996, 20900: 0.5934339761734009, 21000: 1.04084050655365, 21100: 0.559650719165802, 21200: 0.48152416944503784, 21300: 0.41407063603401184, 21400: 0.565952479839325, 21500: 3.041750907897949, 21600: 0.4721953570842743, 21700: 0.49844422936439514, 21800: 0.5949913263320923, 21900: 0.6581951379776001, 22000: 1.4483129978179932, 22100: 0.3592672049999237, 22200: 0.18941161036491394, 22300: 0.23629897832870483, 22400: 0.13020013272762299, 22500: 0.2961548864841461, 22600: 0.23347485065460205, 22700: 0.6157770156860352, 22800: 0.26067259907722473, 22900: 2.6826751232147217, 23000: 0.3512670695781708, 23100: 0.5685145854949951, 23200: 0.4140326678752899, 23300: 1.370670199394226, 23400: 1.728511095046997, 23500: 0.2138025015592575, 23600: 1.082975149154663, 23700: 1.9177871942520142, 23800: 1.001893401145935, 23900: 0.9758124351501465, 24000: 0.47532060742378235, 24100: 0.2160903513431549, 24200: 0.6405669450759888, 24300: 0.6902878880500793, 24400: 1.1066205501556396, 24500: 2.8800482749938965, 24600: 1.602217197418213, 24700: 0.3818598985671997, 24800: 0.7466123700141907, 24900: 0.2662454843521118, 25000: 0.5613881945610046, 25100: 0.40249574184417725, 25200: 1.3111732006072998, 25300: 0.45266321301460266, 25400: 0.7174224853515625, 25500: 0.5267584323883057, 25600: 0.6783456206321716, 25700: 0.8195907473564148, 25800: 0.42744189500808716, 25900: 0.544072151184082, 26000: 3.446220636367798, 26100: 2.0918822288513184, 26200: 0.1577185094356537, 26300: 2.200098991394043, 26400: 0.808394730091095, 26500: 1.0014276504516602, 26600: 0.26691800355911255, 26700: 0.4321633279323578, 26800: 1.5529696941375732, 26900: 0.4233669638633728, 27000: 6.097284317016602, 27100: 1.006427526473999, 27200: 1.1099785566329956}, 'F1': {7: 0.6242047481183234}, 'Accuracy': {7: 0.55157477424565}}\n",
      "Epoch 8\n",
      "\n",
      "Epoch time: 140.1027820110321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       837\n",
      "           1       0.60      0.95      0.74       832\n",
      "           2       0.64      0.41      0.50       858\n",
      "           3       0.62      0.69      0.65       850\n",
      "           4       0.59      0.78      0.67       829\n",
      "           5       0.58      0.73      0.65       846\n",
      "           6       0.61      0.87      0.72       851\n",
      "           7       0.59      0.87      0.70       851\n",
      "           8       0.57      0.73      0.64       845\n",
      "           9       0.58      0.76      0.66       851\n",
      "          10       0.45      0.27      0.34      5171\n",
      "\n",
      "    accuracy                           0.58     13621\n",
      "   macro avg       0.60      0.72      0.65     13621\n",
      "weighted avg       0.55      0.58      0.55     13621\n",
      "\n",
      "Logger {'time': {0: 0.013834953308105469, 100: 0.5514090061187744, 200: 1.0848920345306396, 300: 1.5916359424591064, 400: 2.2246901988983154, 500: 2.7887210845947266, 600: 3.3808810710906982, 700: 3.906141996383667, 800: 4.548789024353027, 900: 5.179415941238403, 1000: 5.7639548778533936, 1100: 6.284472942352295, 1200: 6.82145619392395, 1300: 7.306092977523804, 1400: 7.827627897262573, 1500: 8.31797194480896, 1600: 8.836413145065308, 1700: 9.35111403465271, 1800: 9.86917495727539, 1900: 10.372989177703857, 2000: 10.885113000869751, 2100: 11.496333122253418, 2200: 12.029525995254517, 2300: 12.524045944213867, 2400: 13.09765100479126, 2500: 13.599313020706177, 2600: 14.133238077163696, 2700: 14.6280198097229, 2800: 15.177414178848267, 2900: 15.678401947021484, 3000: 16.205794095993042, 3100: 16.71385097503662, 3200: 17.231252908706665, 3300: 17.723052978515625, 3400: 18.23800015449524, 3500: 18.736222982406616, 3600: 19.25939702987671, 3700: 19.76679491996765, 3800: 20.274642944335938, 3900: 20.771459102630615, 4000: 21.25440001487732, 4100: 21.837030172348022, 4200: 22.34080195426941, 4300: 22.852340936660767, 4400: 23.3608980178833, 4500: 23.869993925094604, 4600: 24.369109869003296, 4700: 24.882012128829956, 4800: 25.374783992767334, 4900: 25.8842830657959, 5000: 26.38876485824585, 5100: 26.89611792564392, 5200: 27.38906502723694, 5300: 27.907986879348755, 5400: 28.399188995361328, 5500: 28.906386137008667, 5600: 29.399533987045288, 5700: 29.90761685371399, 5800: 30.410959005355835, 5900: 30.904969930648804, 6000: 31.40639901161194, 6100: 31.900511026382446, 6200: 32.48961305618286, 6300: 33.036927938461304, 6400: 33.54891800880432, 6500: 34.051239013671875, 6600: 34.55102610588074, 6700: 35.05655288696289, 6800: 35.570226192474365, 6900: 36.06378698348999, 7000: 36.56732988357544, 7100: 37.07653498649597, 7200: 37.614646911621094, 7300: 38.13102197647095, 7400: 38.67397499084473, 7500: 39.201098918914795, 7600: 39.73051404953003, 7700: 40.220125913619995, 7800: 40.844578981399536, 7900: 41.35740685462952, 8000: 41.882105112075806, 8100: 42.3848659992218, 8200: 42.8969509601593, 8300: 43.39471697807312, 8400: 43.93151617050171, 8500: 44.43445706367493, 8600: 44.948249101638794, 8700: 45.45086312294006, 8800: 45.97612524032593, 8900: 46.4849579334259, 9000: 46.99757194519043, 9100: 47.50093412399292, 9200: 48.004749059677124, 9300: 48.517253160476685, 9400: 49.02727699279785, 9500: 49.530776023864746, 9600: 50.041292905807495, 9700: 50.57025194168091, 9800: 51.075597047805786, 9900: 51.57634997367859, 10000: 52.08863091468811, 10100: 52.594507932662964, 10200: 53.09728717803955, 10300: 53.5981879234314, 10400: 54.100937843322754, 10500: 54.60832405090332, 10600: 55.118630170822144, 10700: 55.625738859176636, 10800: 56.11719799041748, 10900: 56.622429847717285, 11000: 57.14529991149902, 11100: 57.68974685668945, 11200: 58.193166971206665, 11300: 58.68566012382507, 11400: 59.20134115219116, 11500: 59.69346308708191, 11600: 60.21542406082153, 11700: 60.7907440662384, 11800: 61.32519292831421, 11900: 61.82074308395386, 12000: 62.41093397140503, 12100: 62.932581186294556, 12200: 63.44659399986267, 12300: 63.95221495628357, 12400: 64.45353603363037, 12500: 64.99204921722412, 12600: 65.50134706497192, 12700: 65.98909592628479, 12800: 66.49244403839111, 12900: 67.00369715690613, 13000: 67.50411009788513, 13100: 68.02629399299622, 13200: 68.53213906288147, 13300: 69.03685021400452, 13400: 69.57626390457153, 13500: 70.07693696022034, 13600: 70.58286905288696, 13700: 71.08402395248413, 13800: 71.61484909057617, 13900: 72.10560393333435, 14000: 72.60679602622986, 14100: 73.12198114395142, 14200: 73.62395405769348, 14300: 74.14990997314453, 14400: 74.65126609802246, 14500: 75.1899881362915, 14600: 75.67857718467712, 14700: 76.20676398277283, 14800: 76.70695900917053, 14900: 77.23706603050232, 15000: 77.73633193969727, 15100: 78.24777221679688, 15200: 78.74371695518494, 15300: 79.250727891922, 15400: 79.74464392662048, 15500: 80.26554107666016, 15600: 80.76593399047852, 15700: 81.2812819480896, 15800: 81.78715109825134, 15900: 82.2936680316925, 16000: 82.78952598571777, 16100: 83.27289605140686, 16200: 83.79593706130981, 16300: 84.28720879554749, 16400: 84.79553818702698, 16500: 85.28657698631287, 16600: 85.80632019042969, 16700: 86.29611682891846, 16800: 86.80738615989685, 16900: 87.32078313827515, 17000: 87.82884407043457, 17100: 88.31972098350525, 17200: 88.8357629776001, 17300: 89.33124899864197, 17400: 89.84616994857788, 17500: 90.33091402053833, 17600: 90.85793900489807, 17700: 91.34757709503174, 17800: 91.86538219451904, 17900: 92.38749885559082, 18000: 92.95641303062439, 18100: 93.45490288734436, 18200: 93.96019196510315, 18300: 94.4638090133667, 18400: 94.95558595657349, 18500: 95.45629405975342, 18600: 95.9572069644928, 18700: 96.46786093711853, 18800: 96.97049593925476, 18900: 97.48198294639587, 19000: 97.98822021484375, 19100: 98.49236392974854, 19200: 98.99541091918945, 19300: 99.4970600605011, 19400: 100.00009298324585, 19500: 100.57181787490845, 19600: 101.07219505310059, 19700: 101.58403396606445, 19800: 102.08524513244629, 19900: 102.59992790222168, 20000: 103.09816288948059, 20100: 103.59794306755066, 20200: 104.11417007446289, 20300: 104.63109493255615, 20400: 105.13113903999329, 20500: 105.62716007232666, 20600: 106.15221500396729, 20700: 106.64649796485901, 20800: 107.16989302635193, 20900: 107.67575907707214, 21000: 108.21827101707458, 21100: 108.7138421535492, 21200: 109.24115490913391, 21300: 109.73457884788513, 21400: 110.24930715560913, 21500: 110.74680399894714, 21600: 111.26641511917114, 21700: 111.76313996315002, 21800: 112.2824170589447, 21900: 112.77485990524292, 22000: 113.28638315200806, 22100: 113.77255392074585, 22200: 114.28683686256409, 22300: 114.78842306137085, 22400: 115.29950904846191, 22500: 115.79893016815186, 22600: 116.28762888908386, 22700: 116.81937980651855, 22800: 117.30089116096497, 22900: 117.82282304763794, 23000: 118.30720710754395, 23100: 118.81807398796082, 23200: 119.31835699081421, 23300: 119.82578611373901, 23400: 120.30740404129028, 23500: 120.81082391738892, 23600: 121.3056218624115, 23700: 121.83407211303711, 23800: 122.32619500160217, 23900: 122.89084696769714, 24000: 123.39586806297302, 24100: 123.91150784492493, 24200: 124.40253591537476, 24300: 124.93456721305847, 24400: 125.41908812522888, 24500: 125.92116093635559, 24600: 126.45072984695435, 24700: 126.96107316017151, 24800: 127.46929717063904, 24900: 127.97292399406433, 25000: 128.5036540031433, 25100: 129.02285408973694, 25200: 129.55709314346313, 25300: 130.05563688278198, 25400: 130.5732080936432, 25500: 131.07931423187256, 25600: 131.5825550556183, 25700: 132.0821418762207, 25800: 132.602530002594, 25900: 133.10310292243958, 26000: 133.61426711082458, 26100: 134.13382697105408, 26200: 134.64608192443848, 26300: 135.19243216514587, 26400: 135.7052459716797, 26500: 136.21343302726746, 26600: 136.7485921382904, 26700: 137.2508249282837, 26800: 137.76433897018433, 26900: 138.26372504234314, 27000: 138.7593560218811, 27100: 139.2867829799652, 27200: 139.78952288627625}, 'loss': {0: 0.6441736221313477, 100: 0.525134801864624, 200: 0.5617040991783142, 300: 0.7351959943771362, 400: 0.41954490542411804, 500: 0.4402455687522888, 600: 0.7235171794891357, 700: 1.3953056335449219, 800: 0.430456280708313, 900: 0.7381945252418518, 1000: 0.5552940964698792, 1100: 0.7631152272224426, 1200: 0.5867795944213867, 1300: 0.8152254223823547, 1400: 0.6372213959693909, 1500: 0.7522804141044617, 1600: 0.3214253783226013, 1700: 0.8585638999938965, 1800: 1.2266221046447754, 1900: 0.5228191614151001, 2000: 0.9552927613258362, 2100: 1.4849590063095093, 2200: 0.24936887621879578, 2300: 3.9598283767700195, 2400: 1.9260962009429932, 2500: 0.49976134300231934, 2600: 1.2051055431365967, 2700: 0.8067077398300171, 2800: 0.47156229615211487, 2900: 0.12041964381933212, 3000: 0.28483644127845764, 3100: 0.255499929189682, 3200: 0.3141772449016571, 3300: 0.13556088507175446, 3400: 0.4143350422382355, 3500: 1.1548930406570435, 3600: 1.3925585746765137, 3700: 0.34889543056488037, 3800: 1.2969281673431396, 3900: 0.44228288531303406, 4000: 0.9075387716293335, 4100: 1.7660624980926514, 4200: 0.6472898721694946, 4300: 0.41329362988471985, 4400: 3.2259678840637207, 4500: 1.5871435403823853, 4600: 1.0437138080596924, 4700: 1.2663792371749878, 4800: 0.5977364778518677, 4900: 0.9988059997558594, 5000: 0.5207119584083557, 5100: 1.6334729194641113, 5200: 0.33625727891921997, 5300: 0.03456861898303032, 5400: 2.2109930515289307, 5500: 0.7317245602607727, 5600: 1.1987663507461548, 5700: 2.9663357734680176, 5800: 1.3113763332366943, 5900: 0.9097155332565308, 6000: 1.0990142822265625, 6100: 0.5112583041191101, 6200: 0.8465810418128967, 6300: 0.2138398438692093, 6400: 0.9835464358329773, 6500: 0.25192728638648987, 6600: 0.40588074922561646, 6700: 0.22899046540260315, 6800: 1.3034816980361938, 6900: 0.7154420018196106, 7000: 0.4668947458267212, 7100: 0.7326865792274475, 7200: 0.3290201723575592, 7300: 1.4445233345031738, 7400: 0.9235721230506897, 7500: 0.25987038016319275, 7600: 0.4075127840042114, 7700: 0.3381507992744446, 7800: 1.022238850593567, 7900: 0.5604154467582703, 8000: 0.7023146748542786, 8100: 0.1573801189661026, 8200: 0.5456153154373169, 8300: 0.7982282042503357, 8400: 0.36670243740081787, 8500: 0.2826537489891052, 8600: 0.40159469842910767, 8700: 0.7614743709564209, 8800: 0.4698397219181061, 8900: 1.5811877250671387, 9000: 0.5284940004348755, 9100: 0.2871013283729553, 9200: 0.30759066343307495, 9300: 0.47314316034317017, 9400: 1.6040376424789429, 9500: 1.2471520900726318, 9600: 1.0345218181610107, 9700: 8.010594367980957, 9800: 0.558132529258728, 9900: 1.479327917098999, 10000: 1.01066255569458, 10100: 0.5791053175926208, 10200: 1.8471248149871826, 10300: 0.5255997776985168, 10400: 0.4143710434436798, 10500: 0.5954264998435974, 10600: 1.1338558197021484, 10700: 0.2977544963359833, 10800: 0.4005213677883148, 10900: 0.788004994392395, 11000: 0.6980298757553101, 11100: 0.2818601727485657, 11200: 2.6379852294921875, 11300: 0.28162965178489685, 11400: 1.4979865550994873, 11500: 1.2857325077056885, 11600: 2.714653968811035, 11700: 0.5477784872055054, 11800: 2.0886895656585693, 11900: 0.721295177936554, 12000: 1.7358241081237793, 12100: 0.3693690598011017, 12200: 0.6137447953224182, 12300: 0.34163782000541687, 12400: 0.944163978099823, 12500: 0.4196229577064514, 12600: 0.7499914765357971, 12700: 0.4153072237968445, 12800: 0.6466889381408691, 12900: 0.3756905496120453, 13000: 1.4163508415222168, 13100: 0.935653805732727, 13200: 0.852356493473053, 13300: 0.6719512343406677, 13400: 0.2048642635345459, 13500: 0.5970093011856079, 13600: 0.33476966619491577, 13700: 1.16341233253479, 13800: 0.8269290924072266, 13900: 0.2652994394302368, 14000: 0.22190749645233154, 14100: 2.1405088901519775, 14200: 0.4093623161315918, 14300: 0.7031919360160828, 14400: 0.5441790223121643, 14500: 1.0093622207641602, 14600: 0.3043496906757355, 14700: 0.9276977777481079, 14800: 0.2896212339401245, 14900: 0.5293994545936584, 15000: 0.7920910120010376, 15100: 1.0380973815917969, 15200: 1.2246054410934448, 15300: 0.6251971125602722, 15400: 0.8744014501571655, 15500: 0.7503448128700256, 15600: 0.6381709575653076, 15700: 2.205892324447632, 15800: 1.6360594034194946, 15900: 0.09248778969049454, 16000: 1.1547727584838867, 16100: 1.0632878541946411, 16200: 0.41962334513664246, 16300: 0.5555760264396667, 16400: 1.1933660507202148, 16500: 0.733610987663269, 16600: 1.7052618265151978, 16700: 0.3614843487739563, 16800: 1.6584231853485107, 16900: 0.5148522257804871, 17000: 0.3950329124927521, 17100: 1.2113521099090576, 17200: 0.5038618445396423, 17300: 0.30845755338668823, 17400: 1.0754839181900024, 17500: 0.45326852798461914, 17600: 0.2957405149936676, 17700: 1.535226583480835, 17800: 1.125054121017456, 17900: 0.3618341386318207, 18000: 0.38065701723098755, 18100: 0.3030690550804138, 18200: 0.0031869832891970873, 18300: 1.172994613647461, 18400: 0.6525811553001404, 18500: 0.33593136072158813, 18600: 3.067502498626709, 18700: 3.6119041442871094, 18800: 0.33752214908599854, 18900: 0.407297819852829, 19000: 0.6626420617103577, 19100: 3.0714595317840576, 19200: 2.5220839977264404, 19300: 0.6663300395011902, 19400: 0.2855573296546936, 19500: 0.11811729520559311, 19600: 1.3648953437805176, 19700: 0.2582699954509735, 19800: 0.18882907927036285, 19900: 1.6972757577896118, 20000: 1.1416802406311035, 20100: 1.7025132179260254, 20200: 0.4068030118942261, 20300: 0.8605663180351257, 20400: 1.3577172756195068, 20500: 0.756004810333252, 20600: 0.336777001619339, 20700: 0.6307343244552612, 20800: 0.3349207043647766, 20900: 1.065124750137329, 21000: 0.8000183701515198, 21100: 0.47752827405929565, 21200: 0.32603248953819275, 21300: 0.516311764717102, 21400: 0.5183141231536865, 21500: 1.828395962715149, 21600: 0.273088276386261, 21700: 0.5839595794677734, 21800: 1.005312442779541, 21900: 0.6447590589523315, 22000: 1.624448537826538, 22100: 0.3619188964366913, 22200: 0.16652534902095795, 22300: 0.5201083421707153, 22400: 0.8798582553863525, 22500: 0.8275843262672424, 22600: 0.25675901770591736, 22700: 0.7138343453407288, 22800: 0.2107812613248825, 22900: 0.9004306197166443, 23000: 0.10022890567779541, 23100: 0.6010132431983948, 23200: 0.35901108384132385, 23300: 1.3521645069122314, 23400: 1.3168301582336426, 23500: 0.2768639326095581, 23600: 1.6658084392547607, 23700: 1.8132476806640625, 23800: 0.90840083360672, 23900: 0.8804977536201477, 24000: 0.6988735198974609, 24100: 0.21572954952716827, 24200: 0.5791944265365601, 24300: 0.9247092008590698, 24400: 0.8477126955986023, 24500: 1.284340500831604, 24600: 1.2599527835845947, 24700: 0.3271152675151825, 24800: 1.063645839691162, 24900: 0.21980442106723785, 25000: 0.27037209272384644, 25100: 0.44284307956695557, 25200: 1.1288151741027832, 25300: 0.5629763603210449, 25400: 0.4935319423675537, 25500: 0.33583468198776245, 25600: 0.5811240673065186, 25700: 0.9148634076118469, 25800: 0.5599542856216431, 25900: 0.5502104759216309, 26000: 2.8899269104003906, 26100: 1.2200446128845215, 26200: 0.08651605248451233, 26300: 0.7515265941619873, 26400: 0.9718316197395325, 26500: 0.9597612023353577, 26600: 0.17900945246219635, 26700: 0.45126423239707947, 26800: 1.3338253498077393, 26900: 0.5106789469718933, 27000: 2.0010883808135986, 27100: 0.8209953904151917, 27200: 1.1870274543762207}, 'F1': {8: 0.6451115336516093}, 'Accuracy': {8: 0.5756552382350781}}\n",
      "Epoch 9\n",
      "\n",
      "Epoch time: 139.90683794021606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80       837\n",
      "           1       0.59      0.96      0.73       832\n",
      "           2       0.63      0.41      0.49       858\n",
      "           3       0.61      0.66      0.64       850\n",
      "           4       0.56      0.79      0.65       829\n",
      "           5       0.53      0.61      0.57       846\n",
      "           6       0.59      0.92      0.72       851\n",
      "           7       0.60      0.88      0.71       851\n",
      "           8       0.57      0.72      0.64       845\n",
      "           9       0.62      0.71      0.66       851\n",
      "          10       0.41      0.24      0.30      5171\n",
      "\n",
      "    accuracy                           0.56     13621\n",
      "   macro avg       0.58      0.71      0.63     13621\n",
      "weighted avg       0.53      0.56      0.52     13621\n",
      "\n",
      "Logger {'time': {0: 0.015016794204711914, 100: 0.5879659652709961, 200: 1.1041440963745117, 300: 1.6049349308013916, 400: 2.1052238941192627, 500: 2.6123738288879395, 600: 3.1106879711151123, 700: 3.692478895187378, 800: 4.208967924118042, 900: 4.766363143920898, 1000: 5.302717924118042, 1100: 5.89413595199585, 1200: 6.454679012298584, 1300: 6.973985910415649, 1400: 7.471765995025635, 1500: 7.994440793991089, 1600: 8.507007837295532, 1700: 9.102828979492188, 1800: 9.71660590171814, 1900: 10.28134799003601, 2000: 10.801347017288208, 2100: 11.33577275276184, 2200: 11.84964895248413, 2300: 12.346245050430298, 2400: 12.851845979690552, 2500: 13.364408016204834, 2600: 13.855262994766235, 2700: 14.380467891693115, 2800: 14.89306092262268, 2900: 15.400735855102539, 3000: 15.90411376953125, 3100: 16.424222946166992, 3200: 16.911707162857056, 3300: 17.4307758808136, 3400: 17.931089878082275, 3500: 18.464807748794556, 3600: 18.95670795440674, 3700: 19.470287084579468, 3800: 19.969074964523315, 3900: 20.472071886062622, 4000: 20.978558778762817, 4100: 21.49098801612854, 4200: 21.99650502204895, 4300: 22.50575304031372, 4400: 23.00623893737793, 4500: 23.510376930236816, 4600: 24.01297879219055, 4700: 24.512232780456543, 4800: 25.041368007659912, 4900: 25.534974813461304, 5000: 26.048447847366333, 5100: 26.54656672477722, 5200: 27.05721378326416, 5300: 27.55169701576233, 5400: 28.136101961135864, 5500: 28.64301109313965, 5600: 29.152320861816406, 5700: 29.65074872970581, 5800: 30.202913999557495, 5900: 30.741863012313843, 6000: 31.25085997581482, 6100: 31.750624895095825, 6200: 32.265941858291626, 6300: 32.75951099395752, 6400: 33.29090094566345, 6500: 33.79004788398743, 6600: 34.29444980621338, 6700: 34.79552674293518, 6800: 35.31987690925598, 6900: 35.80972480773926, 7000: 36.324532985687256, 7100: 36.84559607505798, 7200: 37.36497092247009, 7300: 37.887168884277344, 7400: 38.38687086105347, 7500: 38.908952951431274, 7600: 39.41954183578491, 7700: 39.93148899078369, 7800: 40.490580797195435, 7900: 41.00007390975952, 8000: 41.5070698261261, 8100: 42.02536702156067, 8200: 42.5236337184906, 8300: 43.03439402580261, 8400: 43.526849031448364, 8500: 44.04094195365906, 8600: 44.545517921447754, 8700: 45.04896879196167, 8800: 45.54204487800598, 8900: 46.06525778770447, 9000: 46.56928300857544, 9100: 47.08856010437012, 9200: 47.58705401420593, 9300: 48.10953211784363, 9400: 48.60684299468994, 9500: 49.10110306739807, 9600: 49.62383413314819, 9700: 50.13872981071472, 9800: 50.63953495025635, 9900: 51.13609790802002, 10000: 51.649049043655396, 10100: 52.14144682884216, 10200: 52.65319800376892, 10300: 53.148764848709106, 10400: 53.66401505470276, 10500: 54.15859603881836, 10600: 54.66813516616821, 10700: 55.17736887931824, 10800: 55.683921813964844, 10900: 56.1888108253479, 11000: 56.705909967422485, 11100: 57.21390199661255, 11200: 57.72904706001282, 11300: 58.30419301986694, 11400: 58.8128879070282, 11500: 59.32524585723877, 11600: 59.8131890296936, 11700: 60.319140911102295, 11800: 60.80059790611267, 11900: 61.31480598449707, 12000: 61.8250789642334, 12100: 62.35941195487976, 12200: 62.843127965927124, 12300: 63.35431385040283, 12400: 63.850685834884644, 12500: 64.36237692832947, 12600: 64.85114216804504, 12700: 65.36674189567566, 12800: 65.85613584518433, 12900: 66.37492084503174, 13000: 66.8825798034668, 13100: 67.4009850025177, 13200: 67.90002799034119, 13300: 68.42692804336548, 13400: 68.91864705085754, 13500: 69.45398902893066, 13600: 69.94418406486511, 13700: 70.4376699924469, 13800: 70.95274996757507, 13900: 71.46763205528259, 14000: 71.98080492019653, 14100: 72.49053001403809, 14200: 73.00914287567139, 14300: 73.5022361278534, 14400: 74.02321100234985, 14500: 74.52330899238586, 14600: 75.03469395637512, 14700: 75.53077793121338, 14800: 76.05412292480469, 14900: 76.55572986602783, 15000: 77.07121706008911, 15100: 77.56907486915588, 15200: 78.08458805084229, 15300: 78.58466601371765, 15400: 79.10154795646667, 15500: 79.59778714179993, 15600: 80.11775994300842, 15700: 80.61848378181458, 15800: 81.12924790382385, 15900: 81.63345289230347, 16000: 82.13471412658691, 16100: 82.63590288162231, 16200: 83.12350797653198, 16300: 83.63090872764587, 16400: 84.12415981292725, 16500: 84.63870096206665, 16600: 85.128005027771, 16700: 85.63772106170654, 16800: 86.1404321193695, 16900: 86.67006206512451, 17000: 87.18267488479614, 17100: 87.7919328212738, 17200: 88.42405390739441, 17300: 88.96018815040588, 17400: 89.50216484069824, 17500: 90.04937481880188, 17600: 90.55170607566833, 17700: 91.0829689502716, 17800: 91.59138607978821, 17900: 92.11363697052002, 18000: 92.60066795349121, 18100: 93.13078093528748, 18200: 93.63724994659424, 18300: 94.15771317481995, 18400: 94.68422794342041, 18500: 95.2101628780365, 18600: 95.71972298622131, 18700: 96.22630906105042, 18800: 96.71100401878357, 18900: 97.23272013664246, 19000: 97.74946975708008, 19100: 98.26480889320374, 19200: 98.74871802330017, 19300: 99.27762293815613, 19400: 99.7808780670166, 19500: 100.31580090522766, 19600: 100.83978199958801, 19700: 101.34549283981323, 19800: 101.85408306121826, 19900: 102.39081907272339, 20000: 102.89728498458862, 20100: 103.39487791061401, 20200: 103.92376279830933, 20300: 104.46711897850037, 20400: 104.96920394897461, 20500: 105.47407293319702, 20600: 105.98431992530823, 20700: 106.48982501029968, 20800: 107.00089383125305, 20900: 107.50382590293884, 21000: 108.00744700431824, 21100: 108.49462008476257, 21200: 109.00216603279114, 21300: 109.4909770488739, 21400: 109.9985740184784, 21500: 110.48800683021545, 21600: 110.98891687393188, 21700: 111.55319118499756, 21800: 112.05736899375916, 21900: 112.55869197845459, 22000: 113.06845092773438, 22100: 113.58884906768799, 22200: 114.08697891235352, 22300: 114.60267090797424, 22400: 115.09641909599304, 22500: 115.5991599559784, 22600: 116.11853313446045, 22700: 116.61726999282837, 22800: 117.10996913909912, 22900: 117.61735010147095, 23000: 118.12041807174683, 23100: 118.68876194953918, 23200: 119.19241213798523, 23300: 119.70330095291138, 23400: 120.20519185066223, 23500: 120.72236895561218, 23600: 121.22082591056824, 23700: 121.73242211341858, 23800: 122.23922300338745, 23900: 122.74221205711365, 24000: 123.23115301132202, 24100: 123.72811198234558, 24200: 124.24310994148254, 24300: 124.74873375892639, 24400: 125.2760238647461, 24500: 125.77261900901794, 24600: 126.29750800132751, 24700: 126.81930303573608, 24800: 127.32833099365234, 24900: 127.82342076301575, 25000: 128.33436799049377, 25100: 128.82108902931213, 25200: 129.34100699424744, 25300: 129.8351399898529, 25400: 130.40285682678223, 25500: 130.89368891716003, 25600: 131.41504287719727, 25700: 131.90978598594666, 25800: 132.47202801704407, 25900: 132.99444699287415, 26000: 133.50640988349915, 26100: 134.02518391609192, 26200: 134.55678415298462, 26300: 135.05679297447205, 26400: 135.57297778129578, 26500: 136.07379794120789, 26600: 136.5634150505066, 26700: 137.07219099998474, 26800: 137.56592082977295, 26900: 138.09360790252686, 27000: 138.58313012123108, 27100: 139.10715985298157, 27200: 139.60118913650513}, 'loss': {0: 0.6296842098236084, 100: 0.7238617539405823, 200: 0.6026611328125, 300: 0.7326242327690125, 400: 0.45372965931892395, 500: 0.47498273849487305, 600: 0.7200426459312439, 700: 0.954764723777771, 800: 0.8892138004302979, 900: 0.7537902593612671, 1000: 0.5243520140647888, 1100: 2.7181363105773926, 1200: 0.2757919132709503, 1300: 1.0562618970870972, 1400: 0.7577141523361206, 1500: 0.6377434730529785, 1600: 0.2656795382499695, 1700: 1.2581465244293213, 1800: 1.739895224571228, 1900: 0.5320898294448853, 2000: 1.3949896097183228, 2100: 1.467261791229248, 2200: 0.30445343255996704, 2300: 1.0865488052368164, 2400: 2.6566896438598633, 2500: 0.975443422794342, 2600: 0.8154754042625427, 2700: 0.7773303985595703, 2800: 0.5965033769607544, 2900: 0.41274502873420715, 3000: 0.07690942287445068, 3100: 0.5140220522880554, 3200: 1.6143596172332764, 3300: 0.13592670857906342, 3400: 0.22856837511062622, 3500: 1.1692862510681152, 3600: 1.435583233833313, 3700: 0.13970345258712769, 3800: 1.1151190996170044, 3900: 0.4850422441959381, 4000: 0.692704439163208, 4100: 1.3122478723526, 4200: 0.6476678848266602, 4300: 0.5210731029510498, 4400: 3.117051362991333, 4500: 1.5191065073013306, 4600: 1.154515027999878, 4700: 1.3247554302215576, 4800: 0.4629013240337372, 4900: 1.3400623798370361, 5000: 0.7393234372138977, 5100: 1.5664206743240356, 5200: 0.3552074134349823, 5300: 0.04589254409074783, 5400: 2.583113193511963, 5500: 0.6190918684005737, 5600: 1.9191148281097412, 5700: 2.7272939682006836, 5800: 1.1502180099487305, 5900: 0.7823815941810608, 6000: 1.2132532596588135, 6100: 0.37920212745666504, 6200: 0.898064136505127, 6300: 0.1162441074848175, 6400: 0.8159086108207703, 6500: 0.23191803693771362, 6600: 0.6028284430503845, 6700: 0.39495590329170227, 6800: 1.1208109855651855, 6900: 0.5279622077941895, 7000: 0.2262263149023056, 7100: 0.9614596366882324, 7200: 0.3089428246021271, 7300: 0.9429872632026672, 7400: 0.978455126285553, 7500: 0.3247827887535095, 7600: 0.5176315307617188, 7700: 0.25041744112968445, 7800: 0.7902535796165466, 7900: 0.3246902525424957, 8000: 0.7199589014053345, 8100: 0.19000385701656342, 8200: 0.5026673674583435, 8300: 0.7494852542877197, 8400: 0.46081748604774475, 8500: 0.35679295659065247, 8600: 0.4076189696788788, 8700: 0.6071429252624512, 8800: 0.5777641534805298, 8900: 1.2252672910690308, 9000: 0.91157066822052, 9100: 0.20173442363739014, 9200: 0.3351799249649048, 9300: 0.2686934173107147, 9400: 1.0956945419311523, 9500: 1.3360893726348877, 9600: 0.8652951717376709, 9700: 7.519613265991211, 9800: 0.6592878103256226, 9900: 2.3219399452209473, 10000: 1.9312522411346436, 10100: 0.8790245056152344, 10200: 2.4024391174316406, 10300: 0.5532920956611633, 10400: 0.14528201520442963, 10500: 0.4992913603782654, 10600: 1.0983524322509766, 10700: 0.4467485845088959, 10800: 0.2837093770503998, 10900: 0.8106389045715332, 11000: 0.43833687901496887, 11100: 0.29834672808647156, 11200: 0.5123140215873718, 11300: 0.4871738851070404, 11400: 0.9676111936569214, 11500: 0.7966752648353577, 11600: 2.583728790283203, 11700: 0.46312662959098816, 11800: 2.756166934967041, 11900: 0.496804803609848, 12000: 0.46092402935028076, 12100: 0.733783483505249, 12200: 0.2901875376701355, 12300: 0.379734605550766, 12400: 0.9909920692443848, 12500: 2.302757501602173, 12600: 1.034034013748169, 12700: 1.6732732057571411, 12800: 0.47851935029029846, 12900: 0.3419508635997772, 13000: 2.2498373985290527, 13100: 1.4055930376052856, 13200: 0.7320767045021057, 13300: 0.6754188537597656, 13400: 0.37162911891937256, 13500: 0.5083119869232178, 13600: 0.3422534763813019, 13700: 1.6977665424346924, 13800: 0.9071531295776367, 13900: 0.3115924000740051, 14000: 0.5112698078155518, 14100: 1.3260680437088013, 14200: 0.25370562076568604, 14300: 0.29246795177459717, 14400: 0.7637602090835571, 14500: 1.036452054977417, 14600: 0.6589490175247192, 14700: 0.9556980133056641, 14800: 0.24904869496822357, 14900: 0.4083697497844696, 15000: 0.8121048212051392, 15100: 0.8460365533828735, 15200: 0.8847733736038208, 15300: 0.638784646987915, 15400: 0.41294461488723755, 15500: 0.9433633685112, 15600: 0.29550784826278687, 15700: 3.1759722232818604, 15800: 1.705234408378601, 15900: 1.084000825881958, 16000: 0.769609272480011, 16100: 0.5484231114387512, 16200: 0.415518194437027, 16300: 1.0228817462921143, 16400: 1.1161201000213623, 16500: 0.7488847970962524, 16600: 1.7567929029464722, 16700: 0.3112829923629761, 16800: 1.440180778503418, 16900: 0.5443618893623352, 17000: 0.46025004982948303, 17100: 1.2317109107971191, 17200: 0.7669413089752197, 17300: 0.2977226972579956, 17400: 1.00142240524292, 17500: 0.4268302321434021, 17600: 0.46994656324386597, 17700: 1.1578071117401123, 17800: 0.8119588494300842, 17900: 0.5266823768615723, 18000: 0.4092751741409302, 18100: 2.448225259780884, 18200: 0.1706727296113968, 18300: 1.2067512273788452, 18400: 0.8094781041145325, 18500: 0.34646475315093994, 18600: 0.32513904571533203, 18700: 1.3195724487304688, 18800: 0.7009199261665344, 18900: 0.27826547622680664, 19000: 0.474677175283432, 19100: 3.984687566757202, 19200: 2.1826629638671875, 19300: 1.1956928968429565, 19400: 2.0298430919647217, 19500: 0.11087166517972946, 19600: 1.2815043926239014, 19700: 0.508599042892456, 19800: 0.3242599666118622, 19900: 1.529181718826294, 20000: 1.2107436656951904, 20100: 1.38136887550354, 20200: 0.5152050256729126, 20300: 0.773440957069397, 20400: 0.916487455368042, 20500: 0.8239129781723022, 20600: 0.31612735986709595, 20700: 0.49380743503570557, 20800: 0.7217637300491333, 20900: 0.7115092277526855, 21000: 0.5983851552009583, 21100: 0.41211485862731934, 21200: 0.3200967013835907, 21300: 0.5473855137825012, 21400: 0.505542516708374, 21500: 2.8308160305023193, 21600: 0.38975411653518677, 21700: 0.5285176038742065, 21800: 0.9561124444007874, 21900: 0.7781397700309753, 22000: 1.463040828704834, 22100: 0.450977623462677, 22200: 0.1800825297832489, 22300: 0.3183319866657257, 22400: 0.8720961213111877, 22500: 0.1707194596529007, 22600: 0.2699389159679413, 22700: 0.627949059009552, 22800: 0.29141324758529663, 22900: 4.140583038330078, 23000: 0.24274922907352448, 23100: 0.6131251454353333, 23200: 0.4739452600479126, 23300: 1.2848777770996094, 23400: 1.2265874147415161, 23500: 0.1635725349187851, 23600: 1.4781608581542969, 23700: 1.9996113777160645, 23800: 1.0702718496322632, 23900: 0.9024292230606079, 24000: 0.6138347387313843, 24100: 0.19949685037136078, 24200: 0.6208336353302002, 24300: 0.9539905190467834, 24400: 0.7085264921188354, 24500: 0.8617978692054749, 24600: 1.18966543674469, 24700: 0.3239520490169525, 24800: 1.0887424945831299, 24900: 0.21634674072265625, 25000: 0.5852307081222534, 25100: 0.29292306303977966, 25200: 1.2273445129394531, 25300: 0.5029065012931824, 25400: 0.6306084990501404, 25500: 0.37370967864990234, 25600: 0.6289531588554382, 25700: 1.2103149890899658, 25800: 0.4651472866535187, 25900: 0.8453024625778198, 26000: 0.9261602759361267, 26100: 2.7448039054870605, 26200: 0.13721995055675507, 26300: 1.017314076423645, 26400: 0.8654049634933472, 26500: 1.0181750059127808, 26600: 0.19746963679790497, 26700: 0.44145357608795166, 26800: 1.6953840255737305, 26900: 2.5284934043884277, 27000: 2.0285511016845703, 27100: 0.7857488393783569, 27200: 1.0047314167022705}, 'F1': {9: 0.62793475327556}, 'Accuracy': {9: 0.5571543939505176}}\n",
      "Epoch 10\n",
      "\n",
      "Epoch time: 139.57793998718262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       837\n",
      "           1       0.60      0.91      0.72       832\n",
      "           2       0.66      0.21      0.32       858\n",
      "           3       0.63      0.61      0.62       850\n",
      "           4       0.59      0.81      0.68       829\n",
      "           5       0.56      0.57      0.57       846\n",
      "           6       0.61      0.91      0.73       851\n",
      "           7       0.60      0.81      0.69       851\n",
      "           8       0.57      0.75      0.65       845\n",
      "           9       1.00      0.00      0.00       851\n",
      "          10       0.41      0.39      0.40      5171\n",
      "\n",
      "    accuracy                           0.54     13621\n",
      "   macro avg       0.64      0.62      0.56     13621\n",
      "weighted avg       0.57      0.54      0.51     13621\n",
      "\n",
      "Logger {'time': {0: 0.01529073715209961, 100: 0.6045539379119873, 200: 1.1122159957885742, 300: 1.639915943145752, 400: 2.1606028079986572, 500: 2.68817400932312, 600: 3.1783690452575684, 700: 3.713568925857544, 800: 4.194095134735107, 900: 4.726364850997925, 1000: 5.218440771102905, 1100: 5.7652668952941895, 1200: 6.263699769973755, 1300: 6.79233193397522, 1400: 7.30603289604187, 1500: 7.821713924407959, 1600: 8.310877799987793, 1700: 8.820962905883789, 1800: 9.322802782058716, 1900: 9.8556547164917, 2000: 10.360253810882568, 2100: 10.878703117370605, 2200: 11.377068996429443, 2300: 11.867799997329712, 2400: 12.378114938735962, 2500: 12.862726926803589, 2600: 13.36270785331726, 2700: 13.885233879089355, 2800: 14.395899772644043, 2900: 14.891953945159912, 3000: 15.400864839553833, 3100: 15.908373832702637, 3200: 16.417051792144775, 3300: 16.906615018844604, 3400: 17.436047792434692, 3500: 17.938159704208374, 3600: 18.453050136566162, 3700: 18.945778846740723, 3800: 19.449676036834717, 3900: 19.952534914016724, 4000: 20.453706979751587, 4100: 20.957571983337402, 4200: 21.45106291770935, 4300: 21.95378613471985, 4400: 22.44721508026123, 4500: 22.974266052246094, 4600: 23.472890853881836, 4700: 23.974583864212036, 4800: 24.542919874191284, 4900: 25.069718837738037, 5000: 25.56621789932251, 5100: 26.07516098022461, 5200: 26.574744939804077, 5300: 27.08553385734558, 5400: 27.584333896636963, 5500: 28.091012716293335, 5600: 28.58407187461853, 5700: 29.101882696151733, 5800: 29.601236820220947, 5900: 30.13078284263611, 6000: 30.634015798568726, 6100: 31.1232008934021, 6200: 31.63954186439514, 6300: 32.14910387992859, 6400: 32.71461486816406, 6500: 33.21691584587097, 6600: 33.74931502342224, 6700: 34.2484028339386, 6800: 34.774147033691406, 6900: 35.265254735946655, 7000: 35.8180468082428, 7100: 36.316444873809814, 7200: 36.837639808654785, 7300: 37.33749985694885, 7400: 37.859304904937744, 7500: 38.353590965270996, 7600: 38.86240291595459, 7700: 39.35183310508728, 7800: 39.8677339553833, 7900: 40.3604998588562, 8000: 40.87643790245056, 8100: 41.37572193145752, 8200: 41.89358687400818, 8300: 42.38779377937317, 8400: 42.90845990180969, 8500: 43.41591501235962, 8600: 43.91838788986206, 8700: 44.45433807373047, 8800: 44.96853184700012, 8900: 45.48421812057495, 9000: 45.99388790130615, 9100: 46.50740194320679, 9200: 47.01089000701904, 9300: 47.52235388755798, 9400: 48.05935096740723, 9500: 48.57089400291443, 9600: 49.066311836242676, 9700: 49.59203791618347, 9800: 50.08458685874939, 9900: 50.600547075271606, 10000: 51.09740209579468, 10100: 51.60854983329773, 10200: 52.101343870162964, 10300: 52.64194297790527, 10400: 53.22253370285034, 10500: 53.79897689819336, 10600: 54.38402080535889, 10700: 54.93579292297363, 10800: 55.46504592895508, 10900: 56.000109910964966, 11000: 56.518826961517334, 11100: 57.02252697944641, 11200: 57.52794170379639, 11300: 58.03715491294861, 11400: 58.580909967422485, 11500: 59.09874391555786, 11600: 59.6146240234375, 11700: 60.142327070236206, 11800: 60.67755889892578, 11900: 61.18555474281311, 12000: 61.69230890274048, 12100: 62.2179970741272, 12200: 62.71546292304993, 12300: 63.22132873535156, 12400: 63.74400782585144, 12500: 64.2386679649353, 12600: 64.76412105560303, 12700: 65.2671709060669, 12800: 65.83153080940247, 12900: 66.32880473136902, 13000: 66.83980679512024, 13100: 67.33562994003296, 13200: 67.86904788017273, 13300: 68.35898280143738, 13400: 68.87833189964294, 13500: 69.3800208568573, 13600: 69.90707492828369, 13700: 70.400319814682, 13800: 70.91757583618164, 13900: 71.41907668113708, 14000: 71.92854690551758, 14100: 72.42423892021179, 14200: 72.93204188346863, 14300: 73.43504881858826, 14400: 73.93786072731018, 14500: 74.48658680915833, 14600: 74.97470474243164, 14700: 75.4889976978302, 14800: 75.97721600532532, 14900: 76.49719071388245, 15000: 76.9919068813324, 15100: 77.5144739151001, 15200: 78.00537180900574, 15300: 78.53903889656067, 15400: 79.03794980049133, 15500: 79.54769396781921, 15600: 80.06091594696045, 15700: 80.58365488052368, 15800: 81.0788049697876, 15900: 81.58986902236938, 16000: 82.08606195449829, 16100: 82.59411096572876, 16200: 83.0817928314209, 16300: 83.59717392921448, 16400: 84.09001088142395, 16500: 84.69757270812988, 16600: 85.19779872894287, 16700: 85.69718980789185, 16800: 86.20231294631958, 16900: 86.70186996459961, 17000: 87.22066497802734, 17100: 87.71963787078857, 17200: 88.22820591926575, 17300: 88.7322690486908, 17400: 89.24397897720337, 17500: 89.75743985176086, 17600: 90.2747597694397, 17700: 90.77666568756104, 17800: 91.28706884384155, 17900: 91.79243803024292, 18000: 92.2906768321991, 18100: 92.7846188545227, 18200: 93.30531787872314, 18300: 93.8063108921051, 18400: 94.31817173957825, 18500: 94.8174467086792, 18600: 95.31943798065186, 18700: 95.82376194000244, 18800: 96.32099676132202, 18900: 96.8576807975769, 19000: 97.34771299362183, 19100: 97.86232590675354, 19200: 98.36113977432251, 19300: 98.89008474349976, 19400: 99.40498304367065, 19500: 99.92291975021362, 19600: 100.44174194335938, 19700: 100.97281670570374, 19800: 101.46608686447144, 19900: 101.97418785095215, 20000: 102.47007775306702, 20100: 102.98572587966919, 20200: 103.48937702178955, 20300: 104.01843094825745, 20400: 104.51482391357422, 20500: 105.01422190666199, 20600: 105.51487302780151, 20700: 106.02612709999084, 20800: 106.5383358001709, 20900: 107.03713393211365, 21000: 107.54709386825562, 21100: 108.05011773109436, 21200: 108.56082773208618, 21300: 109.05767798423767, 21400: 109.57172298431396, 21500: 110.07351899147034, 21600: 110.6096818447113, 21700: 111.1094000339508, 21800: 111.63352274894714, 21900: 112.12654209136963, 22000: 112.6402280330658, 22100: 113.13819003105164, 22200: 113.64573574066162, 22300: 114.1669270992279, 22400: 114.73703193664551, 22500: 115.23706483840942, 22600: 115.79201579093933, 22700: 116.29416704177856, 22800: 116.80451488494873, 22900: 117.30622386932373, 23000: 117.8480908870697, 23100: 118.3368558883667, 23200: 118.84887290000916, 23300: 119.35997581481934, 23400: 119.86023283004761, 23500: 120.39319181442261, 23600: 120.89850902557373, 23700: 121.42379593849182, 23800: 121.91908383369446, 23900: 122.4622528553009, 24000: 122.9540388584137, 24100: 123.47022986412048, 24200: 123.97110605239868, 24300: 124.48390698432922, 24400: 124.99902105331421, 24500: 125.53310108184814, 24600: 126.06453394889832, 24700: 126.59050703048706, 24800: 127.08904194831848, 24900: 127.62133193016052, 25000: 128.13214373588562, 25100: 128.64470791816711, 25200: 129.1348488330841, 25300: 129.652410030365, 25400: 130.14579892158508, 25500: 130.67326879501343, 25600: 131.16931080818176, 25700: 131.6863830089569, 25800: 132.1969358921051, 25900: 132.69541883468628, 26000: 133.19933676719666, 26100: 133.70840907096863, 26200: 134.2139618396759, 26300: 134.72270488739014, 26400: 135.23165369033813, 26500: 135.7401828765869, 26600: 136.26906490325928, 26700: 136.77733993530273, 26800: 137.27793788909912, 26900: 137.77187490463257, 27000: 138.27889680862427, 27100: 138.7808449268341, 27200: 139.28392481803894}, 'loss': {0: 0.6158428192138672, 100: 0.5924574136734009, 200: 0.5735377669334412, 300: 1.0117708444595337, 400: 0.32956716418266296, 500: 0.5952080488204956, 600: 0.7640722393989563, 700: 1.0037119388580322, 800: 0.3411584198474884, 900: 0.5667741894721985, 1000: 0.48131048679351807, 1100: 0.4529739022254944, 1200: 0.43751490116119385, 1300: 1.0548592805862427, 1400: 0.683577299118042, 1500: 0.6171748042106628, 1600: 0.29080840945243835, 1700: 1.1587114334106445, 1800: 1.3489141464233398, 1900: 0.42154544591903687, 2000: 1.2172220945358276, 2100: 1.3310474157333374, 2200: 0.3113461136817932, 2300: 3.975329875946045, 2400: 0.9109711050987244, 2500: 1.1443036794662476, 2600: 0.5431193113327026, 2700: 0.7854854464530945, 2800: 0.461425244808197, 2900: 0.3588463068008423, 3000: 0.26709917187690735, 3100: 0.5528262853622437, 3200: 0.9984264969825745, 3300: 0.16697314381599426, 3400: 0.2341267466545105, 3500: 1.0293909311294556, 3600: 1.4415030479431152, 3700: 0.1450631320476532, 3800: 1.3654491901397705, 3900: 0.615900993347168, 4000: 0.6713044047355652, 4100: 1.349899411201477, 4200: 0.4534063935279846, 4300: 0.4789145886898041, 4400: 3.3312625885009766, 4500: 1.3448574542999268, 4600: 0.9160378575325012, 4700: 1.3580416440963745, 4800: 0.45883357524871826, 4900: 1.3262734413146973, 5000: 0.638634204864502, 5100: 1.5440709590911865, 5200: 0.34732484817504883, 5300: 0.02922528050839901, 5400: 2.6899023056030273, 5500: 0.7250670194625854, 5600: 1.618903636932373, 5700: 3.2541768550872803, 5800: 1.449120283126831, 5900: 0.9035171270370483, 6000: 0.8020474314689636, 6100: 0.7749719023704529, 6200: 0.9297855496406555, 6300: 0.18332374095916748, 6400: 0.7582642436027527, 6500: 1.212477445602417, 6600: 0.5828199982643127, 6700: 0.4469740390777588, 6800: 1.161867618560791, 6900: 0.824229896068573, 7000: 0.24992667138576508, 7100: 0.3278166353702545, 7200: 0.13648587465286255, 7300: 0.8364935517311096, 7400: 0.9614059925079346, 7500: 0.3353946805000305, 7600: 0.536323070526123, 7700: 0.542564332485199, 7800: 0.5902794003486633, 7900: 0.2549118101596832, 8000: 0.5185633897781372, 8100: 0.12447130680084229, 8200: 0.5594608187675476, 8300: 0.33537644147872925, 8400: 0.21318285167217255, 8500: 0.30764999985694885, 8600: 0.18239948153495789, 8700: 0.5541248917579651, 8800: 0.7566860914230347, 8900: 0.6333438754081726, 9000: 1.121488094329834, 9100: 0.2113371640443802, 9200: 0.3796587586402893, 9300: 0.3827266991138458, 9400: 1.3567767143249512, 9500: 1.1863794326782227, 9600: 1.0496337413787842, 9700: 7.489087104797363, 9800: 0.6301661133766174, 9900: 1.8957560062408447, 10000: 0.9415633082389832, 10100: 0.3222106397151947, 10200: 2.607424736022949, 10300: 0.4762513041496277, 10400: 0.4502045214176178, 10500: 0.5092801451683044, 10600: 1.0778617858886719, 10700: 0.4564879536628723, 10800: 0.3218225836753845, 10900: 0.6525909900665283, 11000: 0.44128966331481934, 11100: 0.31280967593193054, 11200: 0.49506258964538574, 11300: 0.3239991068840027, 11400: 1.3877284526824951, 11500: 0.6818230152130127, 11600: 1.5950030088424683, 11700: 0.6786642670631409, 11800: 2.6303000450134277, 11900: 0.47390103340148926, 12000: 0.6153623461723328, 12100: 1.0122839212417603, 12200: 0.35267767310142517, 12300: 0.5096358060836792, 12400: 0.31603097915649414, 12500: 0.7191656827926636, 12600: 1.1372039318084717, 12700: 0.7068823575973511, 12800: 0.4376324415206909, 12900: 0.3086596429347992, 13000: 1.3248958587646484, 13100: 1.292284607887268, 13200: 0.7076115012168884, 13300: 0.8199663758277893, 13400: 0.3844468295574188, 13500: 0.5992478728294373, 13600: 0.3440397083759308, 13700: 1.953931450843811, 13800: 1.2009179592132568, 13900: 0.253025084733963, 14000: 0.5412198901176453, 14100: 0.2603299021720886, 14200: 0.30255448818206787, 14300: 0.6179527640342712, 14400: 0.5402141809463501, 14500: 1.108339548110962, 14600: 0.6472428441047668, 14700: 1.1601436138153076, 14800: 0.20450571179389954, 14900: 0.6405335664749146, 15000: 0.7785270810127258, 15100: 0.44878458976745605, 15200: 0.9827150106430054, 15300: 0.7759941816329956, 15400: 0.31234878301620483, 15500: 1.2803163528442383, 15600: 0.3160780966281891, 15700: 1.9363458156585693, 15800: 1.3591487407684326, 15900: 0.08032847940921783, 16000: 2.6203994750976562, 16100: 0.45324161648750305, 16200: 0.2986913025379181, 16300: 0.7563745379447937, 16400: 0.9331134557723999, 16500: 0.611402153968811, 16600: 1.7989157438278198, 16700: 0.30532723665237427, 16800: 1.5452238321304321, 16900: 0.8391844630241394, 17000: 0.46791747212409973, 17100: 1.2240995168685913, 17200: 0.6799929738044739, 17300: 0.34580713510513306, 17400: 0.47721588611602783, 17500: 0.5282940864562988, 17600: 0.38694438338279724, 17700: 1.0308094024658203, 17800: 0.7354058623313904, 17900: 0.4796753227710724, 18000: 0.5348767042160034, 18100: 2.4797909259796143, 18200: 0.4307612478733063, 18300: 1.2281969785690308, 18400: 0.8793401718139648, 18500: 0.2803429961204529, 18600: 0.4118978977203369, 18700: 1.3799020051956177, 18800: 0.5200597047805786, 18900: 0.22813177108764648, 19000: 0.3489046096801758, 19100: 2.430495500564575, 19200: 2.744652032852173, 19300: 1.0779809951782227, 19400: 0.5824655294418335, 19500: 0.1518007218837738, 19600: 0.9538583755493164, 19700: 0.5916388034820557, 19800: 0.3392496109008789, 19900: 1.1629223823547363, 20000: 1.1066443920135498, 20100: 0.25242549180984497, 20200: 0.5230807065963745, 20300: 0.8275146484375, 20400: 0.7911819815635681, 20500: 0.7336541414260864, 20600: 0.33442389965057373, 20700: 0.4998835623264313, 20800: 0.33608198165893555, 20900: 4.303471088409424, 21000: 0.5413161516189575, 21100: 0.5606359243392944, 21200: 0.18480540812015533, 21300: 0.5620421767234802, 21400: 0.5789753794670105, 21500: 2.4066805839538574, 21600: 0.2043878436088562, 21700: 0.5540940165519714, 21800: 0.9351503252983093, 21900: 0.7096385955810547, 22000: 1.3451144695281982, 22100: 0.4036862850189209, 22200: 0.37027299404144287, 22300: 0.10260213166475296, 22400: 0.8163576722145081, 22500: 0.2934902310371399, 22600: 0.2751329243183136, 22700: 0.45490017533302307, 22800: 0.3126419186592102, 22900: 1.3061919212341309, 23000: 0.17330782115459442, 23100: 0.5741035342216492, 23200: 0.39525294303894043, 23300: 1.3746435642242432, 23400: 1.308376669883728, 23500: 0.2044021338224411, 23600: 1.1317561864852905, 23700: 2.0930845737457275, 23800: 0.9920998215675354, 23900: 0.9071871638298035, 24000: 0.5806372761726379, 24100: 0.22065947949886322, 24200: 0.47809484601020813, 24300: 0.7500894069671631, 24400: 0.9266100525856018, 24500: 1.882704734802246, 24600: 1.2090017795562744, 24700: 0.2707614600658417, 24800: 1.4242322444915771, 24900: 0.21612271666526794, 25000: 0.4362918734550476, 25100: 0.5179175734519958, 25200: 1.4014886617660522, 25300: 0.5144782662391663, 25400: 0.8513800501823425, 25500: 0.36935511231422424, 25600: 0.5991594791412354, 25700: 1.0859830379486084, 25800: 0.5818030834197998, 25900: 0.6902074813842773, 26000: 3.4971206188201904, 26100: 1.3420369625091553, 26200: 0.09233465045690536, 26300: 2.209954261779785, 26400: 0.8257576823234558, 26500: 1.715903401374817, 26600: 0.1149957999587059, 26700: 0.4564496874809265, 26800: 1.4806108474731445, 26900: 0.5103763341903687, 27000: 6.3271284103393555, 27100: 0.7512083053588867, 27200: 0.5782549977302551}, 'F1': {10: 0.5616695595162562}, 'Accuracy': {10: 0.5413699434696425}}\n",
      "Training with dataset size: 40000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "Epoch 1\n",
      "\n",
      "Epoch time: 1163.5602581501007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.78      1139\n",
      "           1       0.67      0.24      0.35      1138\n",
      "           2       0.66      0.22      0.33      1125\n",
      "           3       0.59      0.68      0.63      1133\n",
      "           4       0.64      0.13      0.22      1115\n",
      "           5       0.55      0.73      0.62      1111\n",
      "           6       0.61      0.54      0.57      1102\n",
      "           7       0.63      0.60      0.61      1130\n",
      "           8       0.51      0.75      0.61      1127\n",
      "           9       0.51      0.89      0.65      1103\n",
      "          10       0.41      0.43      0.42      6948\n",
      "\n",
      "    accuracy                           0.52     18171\n",
      "   macro avg       0.59      0.56      0.53     18171\n",
      "weighted avg       0.53      0.52      0.49     18171\n",
      "\n",
      "Logger {'time': {0: 0.020174026489257812, 100: 0.5472450256347656, 200: 1.0839459896087646, 300: 1.573518991470337, 400: 2.144892930984497, 500: 2.698989152908325, 600: 3.211035966873169, 700: 3.719576120376587, 800: 4.236546039581299, 900: 4.7402989864349365, 1000: 5.26313591003418, 1100: 5.770053863525391, 1200: 6.27449107170105, 1300: 6.787769079208374, 1400: 7.300997972488403, 1500: 7.8161280155181885, 1600: 8.329966068267822, 1700: 8.851419925689697, 1800: 9.348734855651855, 1900: 9.862228870391846, 2000: 10.365125894546509, 2100: 10.88644003868103, 2200: 11.394075870513916, 2300: 11.904837846755981, 2400: 12.422822952270508, 2500: 12.93268084526062, 2600: 13.433178186416626, 2700: 13.937230110168457, 2800: 14.428236961364746, 2900: 14.946470022201538, 3000: 15.520102977752686, 3100: 16.119499921798706, 3200: 16.639549016952515, 3300: 17.237975120544434, 3400: 17.801898956298828, 3500: 18.334805965423584, 3600: 18.833693981170654, 3700: 19.343817949295044, 3800: 19.85244393348694, 3900: 20.371445894241333, 4000: 20.86681294441223, 4100: 21.373275995254517, 4200: 21.887705087661743, 4300: 22.402701139450073, 4400: 22.908215045928955, 4500: 23.40006184577942, 4600: 23.91711401939392, 4700: 24.41886305809021, 4800: 24.92703890800476, 4900: 25.422823905944824, 5000: 25.958702087402344, 5100: 26.452965021133423, 5200: 26.966413974761963, 5300: 27.477324962615967, 5400: 27.98707413673401, 5500: 28.513723850250244, 5600: 29.026546001434326, 5700: 29.524986028671265, 5800: 30.02908706665039, 5900: 30.521066904067993, 6000: 31.04122281074524, 6100: 31.53174614906311, 6200: 32.05621695518494, 6300: 32.56901979446411, 6400: 33.09515690803528, 6500: 33.593475103378296, 6600: 34.11023211479187, 6700: 34.601075887680054, 6800: 35.1109619140625, 6900: 35.61796712875366, 7000: 36.127788066864014, 7100: 36.70130705833435, 7200: 37.231306076049805, 7300: 37.77662897109985, 7400: 38.27309989929199, 7500: 38.7820680141449, 7600: 39.28191304206848, 7700: 39.789320945739746, 7800: 40.28166198730469, 7900: 40.79304909706116, 8000: 41.294893980026245, 8100: 41.817604064941406, 8200: 42.312402963638306, 8300: 42.830546855926514, 8400: 43.33658504486084, 8500: 43.85545492172241, 8600: 44.351832151412964, 8700: 44.90180706977844, 8800: 45.409822940826416, 8900: 45.92377805709839, 9000: 46.42061114311218, 9100: 46.93213486671448, 9200: 47.48243188858032, 9300: 47.996598958969116, 9400: 48.494487047195435, 9500: 48.98530411720276, 9600: 49.494186878204346, 9700: 49.99881601333618, 9800: 50.57243490219116, 9900: 51.0779550075531, 10000: 51.58869194984436, 10100: 52.08622217178345, 10200: 52.59623408317566, 10300: 53.218820095062256, 10400: 53.71703386306763, 10500: 54.20522904396057, 10600: 54.72326993942261, 10700: 55.21949911117554, 10800: 55.73175096511841, 10900: 56.249659061431885, 11000: 56.75536108016968, 11100: 57.26701378822327, 11200: 57.8261239528656, 11300: 58.31349301338196, 11400: 58.8375301361084, 11500: 59.35430908203125, 11600: 59.88349008560181, 11700: 60.379109144210815, 11800: 60.89509701728821, 11900: 61.39908814430237, 12000: 61.922528982162476, 12100: 62.415756940841675, 12200: 62.91198492050171, 12300: 63.416943073272705, 12400: 63.918352127075195, 12500: 64.4412910938263, 12600: 64.9407410621643, 12700: 65.52220106124878, 12800: 66.13930201530457, 12900: 66.67201900482178, 13000: 67.18575406074524, 13100: 67.7030279636383, 13200: 68.23207712173462, 13300: 68.74184799194336, 13400: 69.25200891494751, 13500: 69.76175785064697, 13600: 70.2635760307312, 13700: 70.77932214736938, 13800: 71.30116510391235, 13900: 71.82787990570068, 14000: 72.33661890029907, 14100: 72.85332894325256, 14200: 73.3509509563446, 14300: 73.86465311050415, 14400: 74.36707997322083, 14500: 74.87788891792297, 14600: 75.37733197212219, 14700: 75.90924382209778, 14800: 76.41896605491638, 14900: 76.93936204910278, 15000: 77.42766094207764, 15100: 78.0481379032135, 15200: 78.54204392433167, 15300: 79.06083703041077, 15400: 79.55333614349365, 15500: 80.07092714309692, 15600: 80.5577380657196, 15700: 81.06685209274292, 15800: 81.56854391098022, 15900: 82.13439011573792, 16000: 82.6441719532013, 16100: 83.14683389663696, 16200: 83.70793604850769, 16300: 84.22206115722656, 16400: 84.73905801773071, 16500: 85.25776624679565, 16600: 85.77409410476685, 16700: 86.28058290481567, 16800: 86.78171491622925, 16900: 87.28587603569031, 17000: 87.79392576217651, 17100: 88.31839299201965, 17200: 88.84045386314392, 17300: 89.33900904655457, 17400: 89.85604405403137, 17500: 90.37526798248291, 17600: 90.8870120048523, 17700: 91.37472987174988, 17800: 91.88856387138367, 17900: 92.39213299751282, 18000: 92.92497205734253, 18100: 93.42854499816895, 18200: 93.93590307235718, 18300: 94.4390959739685, 18400: 94.93892288208008, 18500: 95.45557188987732, 18600: 95.95157814025879, 18700: 96.50707983970642, 18800: 97.01504802703857, 18900: 97.52270412445068, 19000: 98.04238891601562, 19100: 98.55892896652222, 19200: 99.06428694725037, 19300: 99.57370805740356, 19400: 100.07116484642029, 19500: 100.59981393814087, 19600: 101.10612511634827, 19700: 101.61064195632935, 19800: 102.10150599479675, 19900: 102.60883498191833, 20000: 103.11357688903809, 20100: 103.62743020057678, 20200: 104.13770008087158, 20300: 104.65453314781189, 20400: 105.15097904205322, 20500: 105.66400575637817, 20600: 106.18636202812195, 20700: 106.6722629070282, 20800: 107.18479681015015, 20900: 107.72932887077332, 21000: 108.25912499427795, 21100: 108.76285004615784, 21200: 109.27883696556091, 21300: 109.78106594085693, 21400: 110.29055094718933, 21500: 110.7856719493866, 21600: 111.30114412307739, 21700: 111.7933349609375, 21800: 112.32159209251404, 21900: 112.82347702980042, 22000: 113.36133813858032, 22100: 113.85464191436768, 22200: 114.3723680973053, 22300: 114.88099718093872, 22400: 115.39367389678955, 22500: 115.89091205596924, 22600: 116.39336085319519, 22700: 116.89560604095459, 22800: 117.42091393470764, 22900: 117.93985295295715, 23000: 118.44053101539612, 23100: 118.95969200134277, 23200: 119.47984623908997, 23300: 120.03965997695923, 23400: 120.53813195228577, 23500: 121.04874110221863, 23600: 121.55671715736389, 23700: 122.072998046875, 23800: 122.56711506843567, 23900: 123.07829904556274, 24000: 123.57314205169678, 24100: 124.0907130241394, 24200: 124.61792802810669, 24300: 125.1401379108429, 24400: 125.63945007324219, 24500: 126.16873502731323, 24600: 126.66702580451965, 24700: 127.19786810874939, 24800: 127.70581293106079, 24900: 128.21146607398987, 25000: 128.71289014816284, 25100: 129.23255705833435, 25200: 129.7386450767517, 25300: 130.24954295158386, 25400: 130.75406312942505, 25500: 131.2646610736847, 25600: 131.781476020813, 25700: 132.28192782402039, 25800: 132.79534792900085, 25900: 133.29781699180603, 26000: 133.8131799697876, 26100: 134.31307220458984, 26200: 134.8245198726654, 26300: 135.32032299041748, 26400: 135.85332989692688, 26500: 136.34550404548645, 26600: 136.87212300300598, 26700: 137.36512804031372, 26800: 137.97700190544128, 26900: 138.484787940979, 27000: 139.00559997558594, 27100: 139.51996898651123, 27200: 140.05814909934998, 27300: 140.56639409065247, 27400: 141.09748101234436, 27500: 141.59639596939087, 27600: 142.131422996521, 27700: 142.64467883110046, 27800: 143.19964909553528, 27900: 143.71820378303528, 28000: 144.24699997901917, 28100: 144.74870491027832, 28200: 145.25411820411682, 28300: 145.78820204734802, 28400: 146.54957389831543, 28500: 147.187429189682, 28600: 147.8100128173828, 28700: 148.33723402023315, 28800: 148.8550000190735, 28900: 149.34704780578613, 29000: 149.85164380073547, 29100: 151.34495306015015, 29200: 152.51539206504822, 29300: 153.19629311561584, 29400: 153.88948702812195, 29500: 154.41618394851685, 29600: 154.94357085227966, 29700: 155.4732780456543, 29800: 156.17082118988037, 29900: 156.70909690856934, 30000: 157.24111700057983, 30100: 1124.679514169693, 30200: 1125.907291173935, 30300: 1126.5230031013489, 30400: 1127.1083672046661, 30500: 1127.6728320121765, 30600: 1128.2086389064789, 30700: 1128.876806974411, 30800: 1129.5053691864014, 30900: 1130.2568769454956, 31000: 1131.2608890533447, 31100: 1132.0256760120392, 31200: 1132.828621149063, 31300: 1133.370481967926, 31400: 1133.945531129837, 31500: 1134.4354929924011, 31600: 1134.9663741588593, 31700: 1135.486238002777, 31800: 1136.0937330722809, 31900: 1136.7447500228882, 32000: 1137.2711579799652, 32100: 1138.3418810367584, 32200: 1139.2602298259735, 32300: 1139.72793507576, 32400: 1140.3022770881653, 32500: 1140.9949460029602, 32600: 1142.153079032898, 32700: 1142.9282901287079, 32800: 1143.520712852478, 32900: 1144.4401321411133, 33000: 1145.0181789398193, 33100: 1145.9516758918762, 33200: 1146.766513824463, 33300: 1147.3215401172638, 33400: 1147.8688209056854, 33500: 1148.3522019386292, 33600: 1148.8432807922363, 33700: 1149.363273859024, 33800: 1149.9707901477814, 33900: 1150.4669811725616, 34000: 1150.9706330299377, 34100: 1151.4833137989044, 34200: 1152.1654179096222, 34300: 1152.7231848239899, 34400: 1153.2267560958862, 34500: 1153.7732520103455, 34600: 1154.3553919792175, 34700: 1154.9521579742432, 34800: 1155.4759669303894, 34900: 1155.9806809425354, 35000: 1156.503741979599, 35100: 1157.0747320652008, 35200: 1157.7230169773102, 35300: 1158.2452459335327, 35400: 1158.7568850517273, 35500: 1159.243952035904, 35600: 1159.74959897995, 35700: 1160.2322800159454, 35800: 1160.7296040058136, 35900: 1161.2135169506073, 36000: 1161.7360110282898, 36100: 1162.2142670154572, 36200: 1162.7636919021606, 36300: 1163.3162338733673}, 'loss': {0: 2.604130744934082, 100: 0.12412000447511673, 200: 1.4679172039031982, 300: 0.8053011298179626, 400: 0.8254625201225281, 500: 0.30455780029296875, 600: 0.8052245378494263, 700: 0.49405694007873535, 800: 0.5997758507728577, 900: 0.4334922730922699, 1000: 1.2310223579406738, 1100: 1.0729058980941772, 1200: 1.2057477235794067, 1300: 0.42476901412010193, 1400: 0.629834771156311, 1500: 0.18199709057807922, 1600: 0.3598768413066864, 1700: 0.4415747821331024, 1800: 0.08355134725570679, 1900: 0.22315613925457, 2000: 0.8906000256538391, 2100: 0.6352927684783936, 2200: 0.2689196467399597, 2300: 1.070728063583374, 2400: 0.24789515137672424, 2500: 0.15962034463882446, 2600: 1.298948049545288, 2700: 0.42585432529449463, 2800: 0.7271989583969116, 2900: 0.3745063543319702, 3000: 0.1981404572725296, 3100: 0.9268134236335754, 3200: 1.2294425964355469, 3300: 0.696812093257904, 3400: 0.6434785723686218, 3500: 0.6071567535400391, 3600: 0.4256841540336609, 3700: 0.5744410753250122, 3800: 0.3944423198699951, 3900: 0.5540978312492371, 4000: 0.462992787361145, 4100: 1.3132901191711426, 4200: 0.8427889347076416, 4300: 1.3098595142364502, 4400: 0.23981676995754242, 4500: 3.1988039016723633, 4600: 0.28855764865875244, 4700: 0.12487246841192245, 4800: 1.6659740209579468, 4900: 3.4941420555114746, 5000: 0.6486560702323914, 5100: 2.961660385131836, 5200: 0.8174099326133728, 5300: 0.2493254840373993, 5400: 0.7493205070495605, 5500: 1.3525522947311401, 5600: 0.5287047624588013, 5700: 1.2056934833526611, 5800: 1.087871789932251, 5900: 1.3255960941314697, 6000: 0.6780203580856323, 6100: 0.8071544170379639, 6200: 0.5779494643211365, 6300: 0.23904062807559967, 6400: 1.3088722229003906, 6500: 0.22062908113002777, 6600: 0.5961248874664307, 6700: 6.506758213043213, 6800: 0.5851812958717346, 6900: 1.1368317604064941, 7000: 0.6725313067436218, 7100: 0.8906869888305664, 7200: 0.22768206894397736, 7300: 0.4208108186721802, 7400: 0.20557110011577606, 7500: 1.9368871450424194, 7600: 0.647704541683197, 7700: 0.9141724705696106, 7800: 1.0000885725021362, 7900: 0.6438969969749451, 8000: 1.0237261056900024, 8100: 0.35716676712036133, 8200: 0.5937688946723938, 8300: 0.48521652817726135, 8400: 0.7318245768547058, 8500: 1.013203740119934, 8600: 0.7643919587135315, 8700: 0.24946929514408112, 8800: 0.1508922576904297, 8900: 1.8547403812408447, 9000: 0.14733931422233582, 9100: 0.8807960152626038, 9200: 0.37388113141059875, 9300: 1.1435496807098389, 9400: 0.3363482356071472, 9500: 0.7258886694908142, 9600: 1.0642776489257812, 9700: 5.603597640991211, 9800: 0.8776512742042542, 9900: 1.4472386837005615, 10000: 3.6739420890808105, 10100: 0.6112014651298523, 10200: 0.9252157807350159, 10300: 0.4521637260913849, 10400: 0.5230010151863098, 10500: 2.015231132507324, 10600: 0.2548862099647522, 10700: 1.8571196794509888, 10800: 3.7748796939849854, 10900: 0.634367823600769, 11000: 0.8112732172012329, 11100: 0.4679875075817108, 11200: 3.5781307220458984, 11300: 0.5139228701591492, 11400: 0.6979125142097473, 11500: 0.9654063582420349, 11600: 0.8721702098846436, 11700: 6.541639804840088, 11800: 0.40551239252090454, 11900: 1.156368374824524, 12000: 3.591907024383545, 12100: 0.8848845958709717, 12200: 0.3745136559009552, 12300: 1.071575403213501, 12400: 0.8602361083030701, 12500: 1.7519218921661377, 12600: 0.8154768943786621, 12700: 1.300506353378296, 12800: 0.3980896770954132, 12900: 0.7985057234764099, 13000: 0.5520171523094177, 13100: 0.2819785177707672, 13200: 0.8558810949325562, 13300: 0.6296666264533997, 13400: 1.2642227411270142, 13500: 0.9734336137771606, 13600: 0.7836925983428955, 13700: 0.4212619960308075, 13800: 1.8015211820602417, 13900: 1.7620656490325928, 14000: 0.6761001348495483, 14100: 0.6078981757164001, 14200: 0.8815168142318726, 14300: 0.629897952079773, 14400: 0.4871387481689453, 14500: 1.7366669178009033, 14600: 0.5035558938980103, 14700: 0.2736719846725464, 14800: 3.4236865043640137, 14900: 0.6924498677253723, 15000: 0.9369510412216187, 15100: 0.38968583941459656, 15200: 1.522088646888733, 15300: 1.1502361297607422, 15400: 0.4529058635234833, 15500: 0.22830617427825928, 15600: 0.45411139726638794, 15700: 7.939817905426025, 15800: 0.34360000491142273, 15900: 0.768508791923523, 16000: 1.2633202075958252, 16100: 0.6140969395637512, 16200: 3.375589370727539, 16300: 0.05329560115933418, 16400: 0.8494124412536621, 16500: 6.708006858825684, 16600: 5.495448589324951, 16700: 1.2955366373062134, 16800: 1.1036875247955322, 16900: 1.395335078239441, 17000: 0.9035671353340149, 17100: 1.9282472133636475, 17200: 0.3557192087173462, 17300: 1.394307255744934, 17400: 0.3838806748390198, 17500: 0.9063435196876526, 17600: 0.48013418912887573, 17700: 1.2219974994659424, 17800: 1.0990827083587646, 17900: 0.4185117185115814, 18000: 0.7057891488075256, 18100: 0.17201387882232666, 18200: 0.5515248775482178, 18300: 0.4787915349006653, 18400: 0.6876462697982788, 18500: 1.6569544076919556, 18600: 0.8815369606018066, 18700: 0.9128609299659729, 18800: 0.4658665060997009, 18900: 2.4268975257873535, 19000: 0.3075016140937805, 19100: 0.9422316551208496, 19200: 0.9682967066764832, 19300: 1.1799548864364624, 19400: 0.11296290904283524, 19500: 0.6951699256896973, 19600: 1.4409348964691162, 19700: 1.251272201538086, 19800: 0.0911807268857956, 19900: 0.9911222457885742, 20000: 1.5152528285980225, 20100: 0.6227896809577942, 20200: 0.49202418327331543, 20300: 0.4296591281890869, 20400: 0.6701750755310059, 20500: 2.1479339599609375, 20600: 0.5163392424583435, 20700: 0.8313378691673279, 20800: 0.1580253392457962, 20900: 0.7687475681304932, 21000: 0.676470935344696, 21100: 1.6823453903198242, 21200: 1.2228151559829712, 21300: 0.09543926268815994, 21400: 0.33163443207740784, 21500: 1.195997714996338, 21600: 1.0595694780349731, 21700: 0.7024463415145874, 21800: 0.35966238379478455, 21900: 0.48663002252578735, 22000: 0.39460375905036926, 22100: 0.13100597262382507, 22200: 0.2990133762359619, 22300: 0.8944457769393921, 22400: 1.4174840450286865, 22500: 1.2644908428192139, 22600: 0.24066615104675293, 22700: 0.516107439994812, 22800: 1.0571426153182983, 22900: 2.04086971282959, 23000: 0.5863755345344543, 23100: 1.36393141746521, 23200: 1.0637307167053223, 23300: 0.40894725918769836, 23400: 1.0152838230133057, 23500: 2.728245973587036, 23600: 0.9510267972946167, 23700: 0.06384889781475067, 23800: 1.0908300876617432, 23900: 0.7613462805747986, 24000: 2.3538522720336914, 24100: 1.052639126777649, 24200: 0.3021029531955719, 24300: 0.333284854888916, 24400: 0.5286986231803894, 24500: 0.9412091970443726, 24600: 0.48741063475608826, 24700: 0.5462000966072083, 24800: 0.32246583700180054, 24900: 0.6463742852210999, 25000: 0.9442815780639648, 25100: 0.7104020118713379, 25200: 1.1645461320877075, 25300: 0.1403314769268036, 25400: 0.8281904458999634, 25500: 1.6779024600982666, 25600: 0.8617818355560303, 25700: 0.83460932970047, 25800: 0.613136351108551, 25900: 0.6570552587509155, 26000: 1.0494091510772705, 26100: 3.9402081966400146, 26200: 0.45844125747680664, 26300: 0.33511170744895935, 26400: 3.8887500762939453, 26500: 0.4736197292804718, 26600: 0.4565129578113556, 26700: 0.460813045501709, 26800: 1.1259199380874634, 26900: 0.8744531869888306, 27000: 0.6037956476211548, 27100: 1.3449116945266724, 27200: 1.9451961517333984, 27300: 0.6492083072662354, 27400: 0.5542640089988708, 27500: 1.659580945968628, 27600: 1.639858365058899, 27700: 0.34500598907470703, 27800: 0.616146981716156, 27900: 0.971977949142456, 28000: 0.7474163174629211, 28100: 0.9353064894676208, 28200: 0.3122335374355316, 28300: 0.380974680185318, 28400: 0.7483528256416321, 28500: 2.6421079635620117, 28600: 0.3120700418949127, 28700: 1.719740629196167, 28800: 0.13781192898750305, 28900: 0.30681848526000977, 29000: 0.8264285326004028, 29100: 4.292042255401611, 29200: 0.7535768151283264, 29300: 0.6931676864624023, 29400: 0.9950060844421387, 29500: 0.3230311870574951, 29600: 0.7828277349472046, 29700: 0.2592957615852356, 29800: 0.5830118656158447, 29900: 1.0677855014801025, 30000: 0.617065966129303, 30100: 0.42063096165657043, 30200: 1.4724715948104858, 30300: 0.8326199650764465, 30400: 1.6813018321990967, 30500: 0.693498432636261, 30600: 0.2875210642814636, 30700: 1.2198445796966553, 30800: 0.5691039562225342, 30900: 0.8247637748718262, 31000: 0.4686371088027954, 31100: 0.1561240255832672, 31200: 1.4320831298828125, 31300: 0.5690394043922424, 31400: 0.8383313417434692, 31500: 1.8548365831375122, 31600: 1.3974529504776, 31700: 0.17674076557159424, 31800: 0.1899908483028412, 31900: 0.43671783804893494, 32000: 1.47896409034729, 32100: 0.1800837218761444, 32200: 0.5024437308311462, 32300: 0.544690728187561, 32400: 4.667913436889648, 32500: 0.6972277164459229, 32600: 0.5930545330047607, 32700: 0.9284272193908691, 32800: 0.46575331687927246, 32900: 0.3446369171142578, 33000: 0.4848041236400604, 33100: 1.4216898679733276, 33200: 1.0134456157684326, 33300: 0.385330468416214, 33400: 0.7013620138168335, 33500: 0.5233582854270935, 33600: 1.6047083139419556, 33700: 0.8236710429191589, 33800: 0.5189734101295471, 33900: 0.42503097653388977, 34000: 0.048024047166109085, 34100: 0.1867416352033615, 34200: 0.894011378288269, 34300: 1.0464668273925781, 34400: 0.41263553500175476, 34500: 0.5258937478065491, 34600: 1.1742825508117676, 34700: 0.49378693103790283, 34800: 1.70819890499115, 34900: 1.488576889038086, 35000: 7.603526592254639, 35100: 0.12027262896299362, 35200: 0.5847591757774353, 35300: 0.5486003756523132, 35400: 6.071328163146973, 35500: 0.6343334913253784, 35600: 0.7466073632240295, 35700: 0.656413197517395, 35800: 0.15551677346229553, 35900: 0.18415573239326477, 36000: 0.20048105716705322, 36100: 0.4535025358200073, 36200: 1.082871437072754, 36300: 0.9898940324783325}, 'F1': {1: 0.5276671922069999}, 'Accuracy': {1: 0.5158769467833361}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m train_data_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(train_sequences, train_labels))\n\u001b[1;32m    103\u001b[0m test_data_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(test_sequences, test_labels))\n\u001b[0;32m--> 105\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_tuples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_tuples\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, criterion, optimizer, num_epochs, test_data)\u001b[0m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:328\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:808\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 808\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "def train_model(model, train_data, criterion, optimizer, num_epochs, test_data):\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        logger = {'time': {}, 'loss': {}, 'F1': {}, 'Accuracy': {}}\n",
    "\n",
    "        # Iterate over each data point in the training data\n",
    "        for i, (sequence, label) in enumerate(train_data):\n",
    "            # Convert label to tensor if it's not already\n",
    "            if not isinstance(label, torch.Tensor):\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sequence.unsqueeze(0))\n",
    "            loss = criterion(outputs, label.unsqueeze(0))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Logging\n",
    "            if i % 100 == 0:\n",
    "                logger['time'][i] = time.time() - epoch_start_time\n",
    "                logger['loss'][i] = loss.item()\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        print(f\"Epoch {epoch + 1}\\n\")\n",
    "        print(f\"Epoch time: {epoch_end_time - epoch_start_time}\")\n",
    "\n",
    "        # Evaluate at the end of the epoch\n",
    "        f1_score_value, accuracy = evaluate_model(model, test_data)\n",
    "        logger['F1'][epoch + 1] = f1_score_value\n",
    "        logger['Accuracy'][epoch + 1] = accuracy\n",
    "\n",
    "        # Print detailed logger information\n",
    "        print(\"Logger\", logger)\n",
    "\n",
    "def evaluate_model(model, test_data):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence, label in test_data:\n",
    "            # Ensure label is a tensor\n",
    "            if not isinstance(label, torch.Tensor):\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            outputs = model(sequence.unsqueeze(0))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += 1  # Increment total for each label\n",
    "            correct += (predicted == label).sum().item()\n",
    "            all_predictions.append(predicted.item())\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "    f1_score_value = f1_score(all_labels, all_predictions, average='macro')\n",
    "    accuracy = correct / total\n",
    "    return f1_score_value, accuracy\n",
    "\n",
    "# Load and shuffle MNIST dataset\n",
    "train_data, test_data = load_and_shuffle_mnist()\n",
    "\n",
    "# Set LSTM parameters\n",
    "input_size = 784  # 28x28\n",
    "hidden_size = 128\n",
    "num_classes = 11  # Digits 0-9 and 'null'\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "window_size = 10  # Example window size\n",
    "\n",
    "# Create model\n",
    "model = SimpleLSTM(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Example of training with a single data point\n",
    "for size in [1000, 5000, 10000, 20000, 30000, 40000, 50000]:\n",
    "    print(f\"Training with dataset size: {size}\")\n",
    "    sampled_train_data = balanced_sampling(train_data, size)\n",
    "    sampled_test_data = balanced_sampling(test_data, size // 2)\n",
    "\n",
    "    train_sequences, train_labels = create_sequences(sampled_train_data, window_size)\n",
    "    test_sequences, test_labels = create_sequences(sampled_test_data, window_size)\n",
    "\n",
    "    # Convert sequences and labels into a list of tuples for easier iteration\n",
    "    train_data_tuples = list(zip(train_sequences, train_labels))\n",
    "    test_data_tuples = list(zip(test_sequences, test_labels))\n",
    "\n",
    "    train_model(model, train_data_tuples, criterion, optimizer, num_epochs, test_data_tuples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8524b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with dataset size: 32000\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n",
      "balanced_sampling\n",
      "Warning: No data for class 10. Skipping this class.\n",
      "Done sampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      1.00      0.12       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.00      0.00      0.00      5646\n",
      "\n",
      "    accuracy                           0.06     14531\n",
      "   macro avg       0.01      0.09      0.01     14531\n",
      "weighted avg       0.00      0.06      0.01     14531\n",
      "\n",
      "Epoch 1, Step 0, Loss: 2.4203009605407715, F1: 0.01073743325896405, Accuracy: 0.06276237010529213, Time Elapsed: 14.67314100265503 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 100, Loss: 3.5031092166900635, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 30.499523162841797 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 200, Loss: 3.043261766433716, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 46.72759819030762 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 300, Loss: 0.8586784601211548, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 62.06820201873779 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 400, Loss: 2.905369758605957, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 77.43299317359924 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 500, Loss: 2.7015929222106934, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 93.60171604156494 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 600, Loss: 1.099332332611084, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 109.04908633232117 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 700, Loss: 1.6591286659240723, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 123.92569518089294 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.04      0.09      0.05     14531\n",
      "weighted avg       0.15      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 800, Loss: 1.9338128566741943, F1: 0.05087701117834438, Accuracy: 0.38854862019131514, Time Elapsed: 139.0218963623047 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.55      0.01      0.01       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      1.00      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.18      0.09      0.05     14531\n",
      "weighted avg       0.25      0.39      0.22     14531\n",
      "\n",
      "Epoch 1, Step 900, Loss: 0.7233871817588806, F1: 0.053689396127181106, Accuracy: 0.38916798568577526, Time Elapsed: 154.44687914848328 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.95      0.55      5646\n",
      "\n",
      "    accuracy                           0.40     14531\n",
      "   macro avg       0.09      0.13      0.10     14531\n",
      "weighted avg       0.19      0.40      0.25     14531\n",
      "\n",
      "Epoch 1, Step 1000, Loss: 2.9249792098999023, F1: 0.10046694851253948, Accuracy: 0.4007982933039708, Time Elapsed: 169.11343836784363 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.89      0.70       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.91      0.55      5646\n",
      "\n",
      "    accuracy                           0.41     14531\n",
      "   macro avg       0.09      0.16      0.11     14531\n",
      "weighted avg       0.19      0.41      0.26     14531\n",
      "\n",
      "Epoch 1, Step 1100, Loss: 0.7943834662437439, F1: 0.11374757978943505, Accuracy: 0.4091253182850458, Time Elapsed: 185.1915671825409 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.95      0.55      5646\n",
      "\n",
      "    accuracy                           0.40     14531\n",
      "   macro avg       0.09      0.13      0.10     14531\n",
      "weighted avg       0.19      0.40      0.25     14531\n",
      "\n",
      "Epoch 1, Step 1200, Loss: 2.0605263710021973, F1: 0.10098378469390475, Accuracy: 0.40141765879843094, Time Elapsed: 202.35684514045715 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.94      0.55      5646\n",
      "\n",
      "    accuracy                           0.41     14531\n",
      "   macro avg       0.09      0.14      0.11     14531\n",
      "weighted avg       0.19      0.41      0.25     14531\n",
      "\n",
      "Epoch 1, Step 1300, Loss: 1.1146883964538574, F1: 0.1081871567505937, Accuracy: 0.4057532172596518, Time Elapsed: 218.5067000389099 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.08      0.14       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.99      0.56      5646\n",
      "\n",
      "    accuracy                           0.39     14531\n",
      "   macro avg       0.09      0.10      0.06     14531\n",
      "weighted avg       0.19      0.39      0.23     14531\n",
      "\n",
      "Epoch 1, Step 1400, Loss: 0.7597019672393799, F1: 0.06341245656226632, Accuracy: 0.3901314431216021, Time Elapsed: 236.25294733047485 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.59      0.43      0.50       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.88      0.54      5646\n",
      "\n",
      "    accuracy                           0.42     14531\n",
      "   macro avg       0.14      0.19      0.16     14531\n",
      "weighted avg       0.23      0.42      0.28     14531\n",
      "\n",
      "Epoch 1, Step 1500, Loss: 0.7967299818992615, F1: 0.15716553239757722, Accuracy: 0.41724588810130064, Time Elapsed: 252.31317710876465 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.41      0.50       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.96      0.55      5646\n",
      "\n",
      "    accuracy                           0.40     14531\n",
      "   macro avg       0.09      0.12      0.10     14531\n",
      "weighted avg       0.19      0.40      0.25     14531\n",
      "\n",
      "Epoch 1, Step 1600, Loss: 0.9628119468688965, F1: 0.09548003256509206, Accuracy: 0.3987337416557704, Time Elapsed: 268.1903941631317 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.44      0.51       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.90      0.54      5646\n",
      "\n",
      "    accuracy                           0.41     14531\n",
      "   macro avg       0.15      0.17      0.15     14531\n",
      "weighted avg       0.23      0.41      0.28     14531\n",
      "\n",
      "Epoch 1, Step 1700, Loss: 0.9505224823951721, F1: 0.14956410485390034, Accuracy: 0.4125662376987131, Time Elapsed: 285.856192111969 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.91      0.55      5646\n",
      "\n",
      "    accuracy                           0.41     14531\n",
      "   macro avg       0.09      0.16      0.11     14531\n",
      "weighted avg       0.19      0.41      0.26     14531\n",
      "\n",
      "Epoch 1, Step 1800, Loss: 0.7866067290306091, F1: 0.11314308458451389, Accuracy: 0.4077489505195788, Time Elapsed: 302.0912981033325 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.60      0.39      0.47       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.66      0.11      0.18       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.56      0.58       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.74      0.51      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.32      0.31      0.28     14531\n",
      "weighted avg       0.34      0.45      0.36     14531\n",
      "\n",
      "Epoch 1, Step 1900, Loss: 0.933186948299408, F1: 0.28456015981260135, Accuracy: 0.45069162480214714, Time Elapsed: 318.5169322490692 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.69       912\n",
      "           1       0.59      0.47      0.52       885\n",
      "           2       0.57      0.54      0.55       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.50      0.01      0.02       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.47      0.92      0.62       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.70      0.50      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.29      0.31      0.26     14531\n",
      "weighted avg       0.32      0.44      0.34     14531\n",
      "\n",
      "Epoch 1, Step 2000, Loss: 1.0499539375305176, F1: 0.26496300848752996, Accuracy: 0.4384419516894914, Time Elapsed: 334.0909821987152 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.69       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.61      0.27      0.37       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.75      0.00      0.01       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.79      0.52      5646\n",
      "\n",
      "    accuracy                           0.43     14531\n",
      "   macro avg       0.26      0.25      0.21     14531\n",
      "weighted avg       0.31      0.43      0.31     14531\n",
      "\n",
      "Epoch 1, Step 2100, Loss: 0.5745329260826111, F1: 0.20654332408139273, Accuracy: 0.4311472025325167, Time Elapsed: 348.5855281352997 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       912\n",
      "           1       0.60      0.86      0.70       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.63      0.10      0.18       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.85      0.54      5646\n",
      "\n",
      "    accuracy                           0.42     14531\n",
      "   macro avg       0.20      0.21      0.18     14531\n",
      "weighted avg       0.27      0.42      0.30     14531\n",
      "\n",
      "Epoch 1, Step 2200, Loss: 2.961423635482788, F1: 0.17974719645629122, Accuracy: 0.42226963044525495, Time Elapsed: 363.8493010997772 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       912\n",
      "           1       0.63      0.08      0.14       885\n",
      "           2       0.62      0.02      0.04       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.33      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.64      0.08      0.15       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.90      0.55      5646\n",
      "\n",
      "    accuracy                           0.41     14531\n",
      "   macro avg       0.29      0.17      0.14     14531\n",
      "weighted avg       0.33      0.41      0.28     14531\n",
      "\n",
      "Epoch 1, Step 2300, Loss: 2.1002864837646484, F1: 0.1432578237710499, Accuracy: 0.4140114238524534, Time Elapsed: 380.4639811515808 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65       912\n",
      "           1       0.59      0.32      0.42       885\n",
      "           2       0.92      0.01      0.02       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.33      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.91      0.55      5646\n",
      "\n",
      "    accuracy                           0.41     14531\n",
      "   macro avg       0.26      0.17      0.15     14531\n",
      "weighted avg       0.30      0.41      0.28     14531\n",
      "\n",
      "Epoch 1, Step 2400, Loss: 1.7487837076187134, F1: 0.14900490802874666, Accuracy: 0.41380496868763333, Time Elapsed: 395.4858841896057 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.67       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.59      0.10      0.16       862\n",
      "           6       0.40      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.88      0.54      5646\n",
      "\n",
      "    accuracy                           0.41     14531\n",
      "   macro avg       0.17      0.18      0.13     14531\n",
      "weighted avg       0.24      0.41      0.26     14531\n",
      "\n",
      "Epoch 1, Step 2500, Loss: 1.9968363046646118, F1: 0.1256956909108766, Accuracy: 0.4071984034133921, Time Elapsed: 410.6447522640228 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.50      0.96      0.66       885\n",
      "           2       1.00      0.00      0.00       877\n",
      "           3       0.58      0.05      0.10       897\n",
      "           4       0.63      0.31      0.42       892\n",
      "           5       0.22      0.93      0.36       862\n",
      "           6       0.64      0.13      0.22       903\n",
      "           7       0.60      0.20      0.30       889\n",
      "           8       0.45      0.17      0.25       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.40     14531\n",
      "   macro avg       0.51      0.37      0.31     14531\n",
      "weighted avg       0.47      0.40      0.35     14531\n",
      "\n",
      "Epoch 1, Step 2600, Loss: 1.1910966634750366, F1: 0.31100106154575985, Accuracy: 0.39790792099649025, Time Elapsed: 426.4049742221832 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.17      0.28       912\n",
      "           1       0.61      0.67      0.64       885\n",
      "           2       0.74      0.09      0.16       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.62      0.01      0.01       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.49      0.87      0.63       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.40      0.75      0.52      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.38      0.29      0.26     14531\n",
      "weighted avg       0.39      0.44      0.35     14531\n",
      "\n",
      "Epoch 1, Step 2700, Loss: 3.195530891418457, F1: 0.2623441590632922, Accuracy: 0.4436033308099924, Time Elapsed: 442.1592321395874 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.07      0.13       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       1.00      0.00      0.00       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.59      0.42      0.49       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.60      0.21      0.31       889\n",
      "           8       0.50      0.00      0.01       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.86      0.54      5646\n",
      "\n",
      "    accuracy                           0.42     14531\n",
      "   macro avg       0.39      0.21      0.19     14531\n",
      "weighted avg       0.39      0.42      0.31     14531\n",
      "\n",
      "Epoch 1, Step 2800, Loss: 1.3049222230911255, F1: 0.19433381506705255, Accuracy: 0.4230954511045351, Time Elapsed: 457.0471670627594 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.64      0.12      0.20       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.66      0.14      0.23       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.63      0.51      0.56       903\n",
      "           7       0.64      0.03      0.06       889\n",
      "           8       0.49      0.46      0.47       892\n",
      "           9       0.45      0.10      0.17       876\n",
      "          10       0.39      0.71      0.51      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.47      0.33      0.32     14531\n",
      "weighted avg       0.44      0.45      0.38     14531\n",
      "\n",
      "Epoch 1, Step 2900, Loss: 1.1272387504577637, F1: 0.32392191430865097, Accuracy: 0.4524809028972541, Time Elapsed: 471.7495470046997 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.60      0.32      0.42       877\n",
      "           3       0.58      0.39      0.47       897\n",
      "           4       0.55      0.01      0.02       892\n",
      "           5       0.54      0.03      0.05       862\n",
      "           6       0.60      0.72      0.65       903\n",
      "           7       0.62      0.46      0.53       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.47      0.13      0.21       876\n",
      "          10       0.39      0.68      0.50      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.45      0.34      0.32     14531\n",
      "weighted avg       0.43      0.45      0.38     14531\n",
      "\n",
      "Epoch 1, Step 3000, Loss: 2.794877290725708, F1: 0.3235736974056821, Accuracy: 0.4515174454614273, Time Elapsed: 487.08635115623474 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.09      0.16       912\n",
      "           1       0.60      0.80      0.69       885\n",
      "           2       0.73      0.05      0.09       877\n",
      "           3       0.57      0.12      0.20       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.48      0.33      0.39       862\n",
      "           6       0.56      0.84      0.68       903\n",
      "           7       0.55      0.05      0.09       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.56      0.11      0.18       876\n",
      "          10       0.39      0.75      0.51      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.46      0.28      0.27     14531\n",
      "weighted avg       0.44      0.44      0.35     14531\n",
      "\n",
      "Epoch 1, Step 3100, Loss: 1.5894628763198853, F1: 0.27069736196302224, Accuracy: 0.4366526735943844, Time Elapsed: 501.93846225738525 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.67       912\n",
      "           1       0.53      0.96      0.69       885\n",
      "           2       0.65      0.21      0.31       877\n",
      "           3       0.54      0.27      0.36       897\n",
      "           4       0.63      0.08      0.14       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.73      0.67       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.65      0.49      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.35      0.35      0.30     14531\n",
      "weighted avg       0.37      0.45      0.37     14531\n",
      "\n",
      "Epoch 1, Step 3200, Loss: 0.8997759222984314, F1: 0.30320991520498397, Accuracy: 0.4508980799669672, Time Elapsed: 516.7281432151794 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       912\n",
      "           1       0.53      0.96      0.69       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.50      0.66      0.57       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.48      0.02      0.03       862\n",
      "           6       0.46      0.94      0.62       903\n",
      "           7       0.61      0.58      0.60       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.33      0.40      0.33     14531\n",
      "weighted avg       0.35      0.46      0.38     14531\n",
      "\n",
      "Epoch 1, Step 3300, Loss: 1.4486511945724487, F1: 0.33113530989859113, Accuracy: 0.45612827747574153, Time Elapsed: 531.4090790748596 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       912\n",
      "           1       0.62      0.25      0.36       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.67      0.01      0.01       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.33      0.43       903\n",
      "           7       1.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.89      0.54      5646\n",
      "\n",
      "    accuracy                           0.42     14531\n",
      "   macro avg       0.36      0.19      0.18     14531\n",
      "weighted avg       0.37      0.42      0.30     14531\n",
      "\n",
      "Epoch 1, Step 3400, Loss: 1.973649263381958, F1: 0.18034434759346143, Accuracy: 0.4202050787970546, Time Elapsed: 547.0755960941315 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63       912\n",
      "           1       0.61      0.73      0.66       885\n",
      "           2       1.00      0.00      0.00       877\n",
      "           3       0.56      0.33      0.42       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.67      0.00      0.01       862\n",
      "           6       0.61      0.12      0.20       903\n",
      "           7       0.60      0.33      0.42       889\n",
      "           8       0.51      0.42      0.46       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.74      0.51      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.51      0.30      0.30     14531\n",
      "weighted avg       0.47      0.44      0.37     14531\n",
      "\n",
      "Epoch 1, Step 3500, Loss: 0.7031534314155579, F1: 0.300648609417523, Accuracy: 0.4436033308099924, Time Elapsed: 562.7941980361938 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63       912\n",
      "           1       0.61      0.42      0.50       885\n",
      "           2       0.61      0.26      0.37       877\n",
      "           3       0.56      0.18      0.27       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.48      0.41      0.44       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.62      0.33      0.43       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.71      0.51      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.42      0.33      0.35     14531\n",
      "weighted avg       0.41      0.46      0.40     14531\n",
      "\n",
      "Epoch 1, Step 3600, Loss: 1.203021764755249, F1: 0.3487793783153457, Accuracy: 0.457022916523295, Time Elapsed: 578.1462302207947 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70       912\n",
      "           1       0.62      0.32      0.42       885\n",
      "           2       0.61      0.41      0.49       877\n",
      "           3       0.25      0.00      0.00       897\n",
      "           4       0.61      0.10      0.18       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.52      0.84      0.64       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.40      0.67      0.50      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.38      0.36      0.33     14531\n",
      "weighted avg       0.39      0.46      0.39     14531\n",
      "\n",
      "Epoch 1, Step 3700, Loss: 0.6653522849082947, F1: 0.32889518912086635, Accuracy: 0.4620466588672493, Time Elapsed: 592.7558693885803 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.46      0.55       912\n",
      "           1       0.57      0.93      0.70       885\n",
      "           2       0.58      0.49      0.53       877\n",
      "           3       0.54      0.64      0.59       897\n",
      "           4       0.65      0.08      0.15       892\n",
      "           5       0.57      0.10      0.17       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.62      0.61      0.61       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.47      0.42      0.40     14531\n",
      "weighted avg       0.45      0.48      0.43     14531\n",
      "\n",
      "Epoch 1, Step 3800, Loss: 2.761232376098633, F1: 0.40186382145962796, Accuracy: 0.47567269974537196, Time Elapsed: 607.9283080101013 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67       912\n",
      "           1       0.56      0.93      0.70       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.36      0.85      0.50       897\n",
      "           4       0.56      0.63      0.59       892\n",
      "           5       0.55      0.35      0.43       862\n",
      "           6       0.62      0.75      0.68       903\n",
      "           7       0.62      0.53      0.58       889\n",
      "           8       0.60      0.13      0.22       892\n",
      "           9       0.74      0.02      0.03       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.53      0.49     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 3900, Loss: 0.7781776785850525, F1: 0.48669928120760003, Accuracy: 0.48613309476292066, Time Elapsed: 624.0723371505737 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.59      0.49      0.54       877\n",
      "           3       0.60      0.25      0.35       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.54      0.19      0.28       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.59      0.64      0.62       889\n",
      "           8       0.67      0.04      0.08       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.47      0.43      0.40     14531\n",
      "weighted avg       0.45      0.48      0.43     14531\n",
      "\n",
      "Epoch 1, Step 4000, Loss: 1.4311714172363281, F1: 0.40408187283079333, Accuracy: 0.4809028972541463, Time Elapsed: 640.5679471492767 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.58      0.02      0.05       885\n",
      "           2       0.56      0.56      0.56       877\n",
      "           3       0.33      0.00      0.00       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.63      0.77      0.69       903\n",
      "           7       0.60      0.03      0.07       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.75      0.01      0.01       876\n",
      "          10       0.39      0.86      0.53      5646\n",
      "\n",
      "    accuracy                           0.42     14531\n",
      "   macro avg       0.35      0.20      0.17     14531\n",
      "weighted avg       0.36      0.42      0.29     14531\n",
      "\n",
      "Epoch 1, Step 4100, Loss: 1.1060750484466553, F1: 0.17425701939009153, Accuracy: 0.4186222558667676, Time Elapsed: 655.4441223144531 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       912\n",
      "           1       0.62      0.38      0.47       885\n",
      "           2       0.55      0.70      0.62       877\n",
      "           3       0.48      0.03      0.06       897\n",
      "           4       0.38      0.86      0.53       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.63      0.64      0.63       903\n",
      "           7       0.62      0.57      0.59       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.57      0.47      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.39      0.39      0.36     14531\n",
      "weighted avg       0.39      0.45      0.40     14531\n",
      "\n",
      "Epoch 1, Step 4200, Loss: 1.081134557723999, F1: 0.36217924495923676, Accuracy: 0.4546142729337279, Time Elapsed: 670.2130591869354 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.31      0.42       912\n",
      "           1       0.57      0.27      0.37       885\n",
      "           2       0.57      0.61      0.59       877\n",
      "           3       0.34      0.83      0.48       897\n",
      "           4       0.61      0.11      0.19       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.64      0.64      0.64       903\n",
      "           7       0.60      0.47      0.53       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.67      0.08      0.14       876\n",
      "          10       0.39      0.60      0.47      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.45      0.36      0.35     14531\n",
      "weighted avg       0.43      0.44      0.39     14531\n",
      "\n",
      "Epoch 1, Step 4300, Loss: 1.3471254110336304, F1: 0.34756285554125665, Accuracy: 0.4366526735943844, Time Elapsed: 685.2388021945953 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.57       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.63      0.36      0.46       877\n",
      "           3       0.41      0.82      0.55       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.58      0.07      0.12       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.65      0.02      0.05       892\n",
      "           9       0.68      0.02      0.03       876\n",
      "          10       0.39      0.70      0.50      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.42      0.31      0.27     14531\n",
      "weighted avg       0.41      0.44      0.35     14531\n",
      "\n",
      "Epoch 1, Step 4400, Loss: 1.803849458694458, F1: 0.2709955577058917, Accuracy: 0.43534512421719085, Time Elapsed: 700.4208383560181 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01       912\n",
      "           1       0.60      0.44      0.51       885\n",
      "           2       0.71      0.11      0.19       877\n",
      "           3       0.55      0.51      0.53       897\n",
      "           4       0.63      0.35      0.45       892\n",
      "           5       0.46      0.51      0.48       862\n",
      "           6       0.58      0.80      0.67       903\n",
      "           7       0.57      0.82      0.67       889\n",
      "           8       0.58      0.05      0.09       892\n",
      "           9       0.65      0.10      0.18       876\n",
      "          10       0.39      0.61      0.48      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.61      0.39      0.39     14531\n",
      "weighted avg       0.54      0.46      0.42     14531\n",
      "\n",
      "Epoch 1, Step 4500, Loss: 2.3561387062072754, F1: 0.38592493776991116, Accuracy: 0.4612896565962425, Time Elapsed: 942.0934300422668 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.07      0.13       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.51      0.75      0.61       877\n",
      "           3       0.58      0.34      0.43       897\n",
      "           4       0.66      0.10      0.18       892\n",
      "           5       0.41      0.56      0.48       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.58      0.12      0.20       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.60      0.47      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.45      0.37      0.35     14531\n",
      "weighted avg       0.43      0.45      0.39     14531\n",
      "\n",
      "Epoch 1, Step 4600, Loss: 1.1643867492675781, F1: 0.34883354733384847, Accuracy: 0.44835179960085336, Time Elapsed: 958.2118752002716 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.59      0.42      0.49       897\n",
      "           4       1.00      0.00      0.01       892\n",
      "           5       0.52      0.02      0.04       862\n",
      "           6       0.64      0.06      0.11       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.82      0.53      5646\n",
      "\n",
      "    accuracy                           0.43     14531\n",
      "   macro avg       0.39      0.24      0.22     14531\n",
      "weighted avg       0.39      0.43      0.32     14531\n",
      "\n",
      "Epoch 1, Step 4700, Loss: 1.295391321182251, F1: 0.21873348419053984, Accuracy: 0.4265363705182025, Time Elapsed: 974.1141831874847 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.02      0.03       912\n",
      "           1       0.58      0.92      0.71       885\n",
      "           2       0.62      0.35      0.45       877\n",
      "           3       0.58      0.57      0.57       897\n",
      "           4       0.36      0.81      0.50       892\n",
      "           5       0.60      0.00      0.01       862\n",
      "           6       0.63      0.62      0.62       903\n",
      "           7       0.59      0.26      0.36       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.45      0.38      0.34     14531\n",
      "weighted avg       0.43      0.44      0.38     14531\n",
      "\n",
      "Epoch 1, Step 4800, Loss: 0.8206798434257507, F1: 0.3386377344714648, Accuracy: 0.4433968756451724, Time Elapsed: 1016.0183222293854 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.07      0.13       912\n",
      "           1       0.61      0.87      0.71       885\n",
      "           2       0.57      0.65      0.61       877\n",
      "           3       0.48      0.03      0.06       897\n",
      "           4       0.57      0.53      0.55       892\n",
      "           5       0.24      0.01      0.02       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.59      0.21      0.31       889\n",
      "           8       0.54      0.04      0.08       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.68      0.49      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.48      0.34      0.32     14531\n",
      "weighted avg       0.45      0.45      0.38     14531\n",
      "\n",
      "Epoch 1, Step 4900, Loss: 2.093484878540039, F1: 0.3248168831622469, Accuracy: 0.45041635124905377, Time Elapsed: 1031.5849132537842 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.70       912\n",
      "           1       0.60      0.44      0.51       885\n",
      "           2       0.60      0.38      0.47       877\n",
      "           3       0.56      0.58      0.57       897\n",
      "           4       0.62      0.43      0.50       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.44      0.51       903\n",
      "           7       0.58      0.21      0.31       889\n",
      "           8       0.60      0.11      0.19       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.65      0.49      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.47      0.37      0.39     14531\n",
      "weighted avg       0.45      0.46      0.42     14531\n",
      "\n",
      "Epoch 1, Step 5000, Loss: 0.9772859811782837, F1: 0.3862945134671795, Accuracy: 0.46369830018580965, Time Elapsed: 1047.132131099701 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.41      0.50       912\n",
      "           1       0.60      0.51      0.55       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.55      0.62      0.59       897\n",
      "           4       0.45      0.73      0.56       892\n",
      "           5       0.47      0.61      0.53       862\n",
      "           6       0.60      0.17      0.26       903\n",
      "           7       0.57      0.81      0.67       889\n",
      "           8       0.61      0.09      0.16       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.50      0.45      0.44     14531\n",
      "weighted avg       0.46      0.47      0.44     14531\n",
      "\n",
      "Epoch 1, Step 5100, Loss: 0.5452333092689514, F1: 0.43793244430702916, Accuracy: 0.4667263092698369, Time Elapsed: 1129.969954252243 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.63      0.27      0.38       877\n",
      "           3       0.57      0.42      0.48       897\n",
      "           4       0.44      0.83      0.57       892\n",
      "           5       0.55      0.24      0.33       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.58      0.14      0.22       889\n",
      "           8       0.54      0.10      0.17       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.45      0.38      0.36     14531\n",
      "weighted avg       0.43      0.45      0.40     14531\n",
      "\n",
      "Epoch 1, Step 5200, Loss: 2.282413959503174, F1: 0.364482662109112, Accuracy: 0.45165508223797396, Time Elapsed: 1146.57754611969 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67       912\n",
      "           1       0.59      0.91      0.71       885\n",
      "           2       0.59      0.40      0.48       877\n",
      "           3       0.59      0.43      0.50       897\n",
      "           4       0.55      0.45      0.50       892\n",
      "           5       0.46      0.57      0.51       862\n",
      "           6       0.55      0.91      0.68       903\n",
      "           7       0.60      0.47      0.53       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.71      0.07      0.12       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.49      0.47     14531\n",
      "weighted avg       0.47      0.49      0.45     14531\n",
      "\n",
      "Epoch 1, Step 5300, Loss: 1.0806505680084229, F1: 0.4661035457090364, Accuracy: 0.4854449108801872, Time Elapsed: 1162.311819076538 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       912\n",
      "           1       0.61      0.62      0.62       885\n",
      "           2       0.65      0.26      0.37       877\n",
      "           3       0.60      0.41      0.49       897\n",
      "           4       0.53      0.66      0.59       892\n",
      "           5       0.50      0.32      0.39       862\n",
      "           6       0.63      0.64      0.64       903\n",
      "           7       0.62      0.39      0.48       889\n",
      "           8       0.49      0.63      0.55       892\n",
      "           9       0.67      0.03      0.06       876\n",
      "          10       0.40      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.49      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 5400, Loss: 1.6153478622436523, F1: 0.48583824002497916, Accuracy: 0.49060629000068817, Time Elapsed: 1177.3288481235504 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.57      0.53      0.55       897\n",
      "           4       0.64      0.18      0.29       892\n",
      "           5       0.44      0.01      0.02       862\n",
      "           6       0.62      0.65      0.64       903\n",
      "           7       0.62      0.05      0.09       889\n",
      "           8       0.43      0.01      0.01       892\n",
      "           9       0.27      0.91      0.41       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.53      0.45      0.40     14531\n",
      "weighted avg       0.48      0.44      0.40     14531\n",
      "\n",
      "Epoch 1, Step 5500, Loss: 0.9669377207756042, F1: 0.39927784723822257, Accuracy: 0.4434656940334457, Time Elapsed: 1192.5072531700134 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.42      0.50       912\n",
      "           1       0.61      0.69      0.65       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.57      0.56      0.57       897\n",
      "           4       0.40      0.82      0.53       892\n",
      "           5       0.60      0.05      0.10       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.61      0.47      0.53       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.45      0.45      0.42     14531\n",
      "weighted avg       0.43      0.47      0.42     14531\n",
      "\n",
      "Epoch 1, Step 5600, Loss: 2.685230255126953, F1: 0.41679194447261453, Accuracy: 0.4674144931525704, Time Elapsed: 1208.049348115921 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.53      0.02      0.04       885\n",
      "           2       0.59      0.52      0.55       877\n",
      "           3       0.53      0.67      0.59       897\n",
      "           4       0.35      0.96      0.51       892\n",
      "           5       0.54      0.28      0.37       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.57      0.83      0.67       889\n",
      "           8       0.58      0.02      0.04       892\n",
      "           9       0.55      0.12      0.20       876\n",
      "          10       0.38      0.47      0.42      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.47      0.43      0.37     14531\n",
      "weighted avg       0.44      0.44      0.39     14531\n",
      "\n",
      "Epoch 1, Step 5700, Loss: 0.2888947129249573, F1: 0.3723245753777906, Accuracy: 0.4428463285389856, Time Elapsed: 1223.90500831604 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.12      0.20       912\n",
      "           1       0.61      0.60      0.61       885\n",
      "           2       0.58      0.54      0.56       877\n",
      "           3       0.53      0.58      0.56       897\n",
      "           4       0.47      0.73      0.57       892\n",
      "           5       0.57      0.18      0.28       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.60      0.15      0.24       876\n",
      "          10       0.39      0.52      0.44      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.51      0.45      0.44     14531\n",
      "weighted avg       0.47      0.47      0.44     14531\n",
      "\n",
      "Epoch 1, Step 5800, Loss: 1.1996161937713623, F1: 0.437068112897367, Accuracy: 0.47374578487371827, Time Elapsed: 1239.2630791664124 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.49      0.74      0.59       897\n",
      "           4       0.57      0.46      0.51       892\n",
      "           5       0.60      0.01      0.03       862\n",
      "           6       0.63      0.52      0.57       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.62      0.48      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.50      0.39      0.36     14531\n",
      "weighted avg       0.47      0.46      0.40     14531\n",
      "\n",
      "Epoch 1, Step 5900, Loss: 0.6877462267875671, F1: 0.364739203374186, Accuracy: 0.4625972059734361, Time Elapsed: 1255.1398222446442 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.62      0.36      0.46       877\n",
      "           3       0.56      0.55      0.55       897\n",
      "           4       0.61      0.28      0.38       892\n",
      "           5       0.55      0.28      0.37       862\n",
      "           6       0.63      0.54      0.58       903\n",
      "           7       0.60      0.44      0.51       889\n",
      "           8       1.00      0.00      0.00       892\n",
      "           9       0.39      0.82      0.53       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.60      0.48      0.47     14531\n",
      "weighted avg       0.53      0.48      0.46     14531\n",
      "\n",
      "Epoch 1, Step 6000, Loss: 0.5530050992965698, F1: 0.4714805904946729, Accuracy: 0.4769114307342922, Time Elapsed: 1269.5431470870972 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.67      0.07      0.13       877\n",
      "           3       0.57      0.23      0.33       897\n",
      "           4       1.00      0.00      0.00       892\n",
      "           5       0.56      0.14      0.23       862\n",
      "           6       0.62      0.44      0.52       903\n",
      "           7       0.52      0.85      0.65       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.02      0.04       876\n",
      "          10       0.39      0.65      0.49      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.56      0.37      0.34     14531\n",
      "weighted avg       0.50      0.46      0.39     14531\n",
      "\n",
      "Epoch 1, Step 6100, Loss: 0.9552854299545288, F1: 0.34264107768959756, Accuracy: 0.46011974399559563, Time Elapsed: 1284.5611011981964 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.58      0.42      0.49       877\n",
      "           3       0.52      0.75      0.62       897\n",
      "           4       0.68      0.17      0.27       892\n",
      "           5       0.56      0.12      0.20       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.63      0.10      0.17       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.53      0.49      0.45     14531\n",
      "weighted avg       0.48      0.49      0.45     14531\n",
      "\n",
      "Epoch 1, Step 6200, Loss: 2.0667262077331543, F1: 0.4526812297650315, Accuracy: 0.49356548069644207, Time Elapsed: 1299.5762162208557 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       912\n",
      "           1       0.58      0.94      0.71       885\n",
      "           2       0.61      0.41      0.49       877\n",
      "           3       0.56      0.63      0.60       897\n",
      "           4       0.59      0.50      0.54       892\n",
      "           5       0.49      0.69      0.57       862\n",
      "           6       0.63      0.58      0.60       903\n",
      "           7       0.61      0.73      0.66       889\n",
      "           8       0.59      0.20      0.30       892\n",
      "           9       0.68      0.05      0.09       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 6300, Loss: 1.30466628074646, F1: 0.5147464499837507, Accuracy: 0.5031312366664372, Time Elapsed: 1314.439123392105 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.38      0.48       912\n",
      "           1       0.59      0.91      0.71       885\n",
      "           2       0.65      0.16      0.26       877\n",
      "           3       0.52      0.80      0.63       897\n",
      "           4       0.59      0.49      0.54       892\n",
      "           5       0.56      0.15      0.24       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.78      0.01      0.02       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.44      0.42     14531\n",
      "weighted avg       0.49      0.48      0.43     14531\n",
      "\n",
      "Epoch 1, Step 6400, Loss: 0.9176557064056396, F1: 0.4179226389167292, Accuracy: 0.4783566168880325, Time Elapsed: 1329.767415046692 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.62      0.47      0.53       885\n",
      "           2       0.70      0.11      0.18       877\n",
      "           3       0.57      0.66      0.61       897\n",
      "           4       0.56      0.25      0.34       892\n",
      "           5       0.53      0.45      0.49       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.60      0.49      0.54       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.29      0.93      0.44       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.50      0.46      0.44     14531\n",
      "weighted avg       0.47      0.45      0.43     14531\n",
      "\n",
      "Epoch 1, Step 6500, Loss: 0.9666669964790344, F1: 0.43797787755675105, Accuracy: 0.44965934897804694, Time Elapsed: 1345.5906422138214 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65       912\n",
      "           1       0.62      0.62      0.62       885\n",
      "           2       0.63      0.28      0.39       877\n",
      "           3       0.57      0.58      0.57       897\n",
      "           4       0.63      0.33      0.43       892\n",
      "           5       0.54      0.07      0.13       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.55      0.45      0.50       892\n",
      "           9       0.49      0.30      0.37       876\n",
      "          10       0.40      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.48      0.49     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 1, Step 6600, Loss: 0.8372871279716492, F1: 0.4918820715656789, Accuracy: 0.49308375197852866, Time Elapsed: 1360.7257041931152 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64       912\n",
      "           1       0.61      0.76      0.68       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.61      0.41      0.49       897\n",
      "           4       0.47      0.73      0.58       892\n",
      "           5       0.54      0.26      0.35       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.61      0.62      0.62       889\n",
      "           8       0.53      0.65      0.59       892\n",
      "           9       0.62      0.14      0.23       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.56      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 6700, Loss: 4.440350532531738, F1: 0.5353902249489363, Accuracy: 0.5057463354208245, Time Elapsed: 1375.2135531902313 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       912\n",
      "           1       0.61      0.58      0.59       885\n",
      "           2       0.61      0.35      0.44       877\n",
      "           3       0.57      0.21      0.31       897\n",
      "           4       0.45      0.82      0.58       892\n",
      "           5       0.58      0.24      0.34       862\n",
      "           6       0.56      0.01      0.01       903\n",
      "           7       0.61      0.28      0.38       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.63      0.07      0.13       876\n",
      "          10       0.39      0.63      0.48      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.51      0.36      0.36     14531\n",
      "weighted avg       0.47      0.45      0.40     14531\n",
      "\n",
      "Epoch 1, Step 6800, Loss: 1.0890846252441406, F1: 0.3584902181007991, Accuracy: 0.44869589154222006, Time Elapsed: 1390.2712321281433 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.72       912\n",
      "           1       0.60      0.50      0.55       885\n",
      "           2       0.67      0.16      0.26       877\n",
      "           3       0.55      0.16      0.24       897\n",
      "           4       0.56      0.61      0.58       892\n",
      "           5       0.45      0.70      0.55       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.62      0.45      0.52       889\n",
      "           8       0.53      0.57      0.55       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.48      0.46     14531\n",
      "weighted avg       0.47      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 6900, Loss: 0.6775614023208618, F1: 0.4618245747942165, Accuracy: 0.48214162824306656, Time Elapsed: 1405.8001441955566 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.65      0.27      0.38       877\n",
      "           3       0.56      0.59      0.58       897\n",
      "           4       0.47      0.82      0.60       892\n",
      "           5       0.55      0.58      0.56       862\n",
      "           6       0.59      0.89      0.71       903\n",
      "           7       0.62      0.48      0.54       889\n",
      "           8       0.57      0.18      0.28       892\n",
      "           9       0.64      0.11      0.18       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.51     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 7000, Loss: 1.6020631790161133, F1: 0.5116296945090445, Accuracy: 0.5003785011355034, Time Elapsed: 1420.7815370559692 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.32      0.43       912\n",
      "           1       0.61      0.81      0.70       885\n",
      "           2       0.79      0.04      0.07       877\n",
      "           3       0.56      0.66      0.61       897\n",
      "           4       0.60      0.45      0.51       892\n",
      "           5       0.52      0.26      0.35       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.56      0.71      0.62       892\n",
      "           9       0.53      0.62      0.57       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 7100, Loss: 1.0170042514801025, F1: 0.5119806996730124, Accuracy: 0.5023742343954305, Time Elapsed: 1435.1999561786652 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.59      0.41      0.48       877\n",
      "           3       0.60      0.24      0.35       897\n",
      "           4       0.34      0.95      0.50       892\n",
      "           5       0.55      0.02      0.04       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.58      0.10      0.17       892\n",
      "           9       0.66      0.07      0.13       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.55      0.51      0.44     14531\n",
      "weighted avg       0.50      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 7200, Loss: 0.9098405838012695, F1: 0.4417958150277572, Accuracy: 0.470717775789691, Time Elapsed: 1453.8520991802216 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.59      0.50      0.54       897\n",
      "           4       0.50      0.84      0.62       892\n",
      "           5       0.55      0.41      0.47       862\n",
      "           6       0.63      0.48      0.54       903\n",
      "           7       0.62      0.47      0.54       889\n",
      "           8       0.53      0.07      0.13       892\n",
      "           9       0.58      0.59      0.59       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 7300, Loss: 4.885929107666016, F1: 0.5312310412684252, Accuracy: 0.5037506021608974, Time Elapsed: 1475.090205192566 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.73      0.13      0.23       877\n",
      "           3       0.58      0.46      0.51       897\n",
      "           4       0.42      0.90      0.57       892\n",
      "           5       0.58      0.24      0.34       862\n",
      "           6       0.63      0.07      0.13       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.60      0.12      0.20       892\n",
      "           9       0.50      0.00      0.00       876\n",
      "          10       0.39      0.54      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.43      0.40     14531\n",
      "weighted avg       0.51      0.47      0.42     14531\n",
      "\n",
      "Epoch 1, Step 7400, Loss: 1.028014898300171, F1: 0.40447764052539215, Accuracy: 0.46782740348221047, Time Elapsed: 1490.9139730930328 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.39      0.48       912\n",
      "           1       0.60      0.92      0.72       885\n",
      "           2       0.62      0.28      0.38       877\n",
      "           3       0.59      0.27      0.37       897\n",
      "           4       0.60      0.52      0.56       892\n",
      "           5       0.67      0.01      0.02       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.36      0.95      0.52       889\n",
      "           8       0.44      0.01      0.02       892\n",
      "           9       0.52      0.28      0.36       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.54      0.45      0.41     14531\n",
      "weighted avg       0.49      0.46      0.42     14531\n",
      "\n",
      "Epoch 1, Step 7500, Loss: 2.1470322608947754, F1: 0.41465981728489376, Accuracy: 0.4608079278783291, Time Elapsed: 1505.7998111248016 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69       912\n",
      "           1       0.61      0.35      0.44       885\n",
      "           2       0.70      0.04      0.07       877\n",
      "           3       0.59      0.47      0.52       897\n",
      "           4       0.58      0.51      0.54       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.77      0.68       903\n",
      "           7       0.61      0.50      0.55       889\n",
      "           8       0.58      0.40      0.47       892\n",
      "           9       0.63      0.27      0.38       876\n",
      "          10       0.39      0.60      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.42      0.44     14531\n",
      "weighted avg       0.49      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 7600, Loss: 1.1246851682662964, F1: 0.43773412009124013, Accuracy: 0.4817287179134265, Time Elapsed: 1520.5058953762054 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.61      0.37      0.46       877\n",
      "           3       0.31      0.93      0.46       897\n",
      "           4       0.56      0.64      0.60       892\n",
      "           5       0.60      0.00      0.01       862\n",
      "           6       0.58      0.90      0.71       903\n",
      "           7       0.61      0.29      0.39       889\n",
      "           8       0.58      0.37      0.45       892\n",
      "           9       0.57      0.06      0.11       876\n",
      "          10       0.40      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.55      0.51      0.45     14531\n",
      "weighted avg       0.50      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 7700, Loss: 0.15340925753116608, F1: 0.4524532294762334, Accuracy: 0.4672768563760237, Time Elapsed: 1535.164085149765 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.62      0.72      0.66       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.47      0.82      0.60       897\n",
      "           4       0.63      0.07      0.13       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.62      0.81      0.70       903\n",
      "           7       0.49      0.87      0.62       889\n",
      "           8       0.59      0.26      0.36       892\n",
      "           9       0.61      0.17      0.27       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.51     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 7800, Loss: 1.4554651975631714, F1: 0.5056802069527895, Accuracy: 0.49762576560456956, Time Elapsed: 1551.1408712863922 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.52      0.79      0.63       892\n",
      "           5       0.55      0.09      0.16       862\n",
      "           6       0.62      0.40      0.49       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.57      0.16      0.25       892\n",
      "           9       0.63      0.37      0.46       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.51      0.50     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 7900, Loss: 1.4274269342422485, F1: 0.5043780618579695, Accuracy: 0.4968687633335627, Time Elapsed: 1566.1178481578827 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.19      0.29       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.59      0.51      0.54       877\n",
      "           3       0.58      0.61      0.59       897\n",
      "           4       0.63      0.34      0.44       892\n",
      "           5       0.60      0.14      0.22       862\n",
      "           6       0.62      0.57      0.60       903\n",
      "           7       0.61      0.60      0.61       889\n",
      "           8       0.57      0.54      0.56       892\n",
      "           9       0.64      0.27      0.38       876\n",
      "          10       0.39      0.54      0.46      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.46      0.49     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 1, Step 8000, Loss: 0.9207288026809692, F1: 0.4863297326842536, Accuracy: 0.48792237285802764, Time Elapsed: 1581.2745401859283 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       912\n",
      "           1       0.61      0.53      0.57       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.59      0.62      0.60       897\n",
      "           4       0.65      0.24      0.35       892\n",
      "           5       0.59      0.21      0.31       862\n",
      "           6       0.62      0.71      0.67       903\n",
      "           7       0.58      0.18      0.28       889\n",
      "           8       0.54      0.73      0.62       892\n",
      "           9       0.52      0.72      0.60       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 8100, Loss: 1.613781452178955, F1: 0.521801456964202, Accuracy: 0.5005161379120501, Time Elapsed: 1596.3640491962433 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.33      0.43       912\n",
      "           1       0.60      0.54      0.57       885\n",
      "           2       0.61      0.31      0.41       877\n",
      "           3       0.59      0.45      0.51       897\n",
      "           4       0.55      0.64      0.59       892\n",
      "           5       0.54      0.09      0.16       862\n",
      "           6       0.61      0.37      0.46       903\n",
      "           7       0.61      0.37      0.46       889\n",
      "           8       0.46      0.01      0.03       892\n",
      "           9       0.55      0.67      0.60       876\n",
      "          10       0.39      0.60      0.47      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.56      0.40      0.43     14531\n",
      "weighted avg       0.50      0.46      0.44     14531\n",
      "\n",
      "Epoch 1, Step 8200, Loss: 0.7542456388473511, F1: 0.4271500067650232, Accuracy: 0.4648682127864565, Time Elapsed: 1610.9682643413544 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       912\n",
      "           1       0.62      0.25      0.36       885\n",
      "           2       0.60      0.43      0.51       877\n",
      "           3       0.57      0.46      0.51       897\n",
      "           4       0.59      0.31      0.41       892\n",
      "           5       0.55      0.48      0.51       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.62      0.11      0.19       889\n",
      "           8       0.55      0.32      0.40       892\n",
      "           9       1.00      0.00      0.00       876\n",
      "          10       0.39      0.62      0.48      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.61      0.39      0.42     14531\n",
      "weighted avg       0.54      0.47      0.44     14531\n",
      "\n",
      "Epoch 1, Step 8300, Loss: 0.7122849225997925, F1: 0.4207713573090588, Accuracy: 0.4668639460463836, Time Elapsed: 1625.889079093933 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.34      0.44       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.58      0.55      0.57       877\n",
      "           3       0.54      0.03      0.06       897\n",
      "           4       0.57      0.67      0.61       892\n",
      "           5       0.60      0.04      0.07       862\n",
      "           6       0.62      0.72      0.67       903\n",
      "           7       0.63      0.38      0.48       889\n",
      "           8       0.59      0.44      0.50       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.42      0.42     14531\n",
      "weighted avg       0.48      0.48      0.43     14531\n",
      "\n",
      "Epoch 1, Step 8400, Loss: 0.5730993747711182, F1: 0.41776534743355376, Accuracy: 0.4773931594522056, Time Elapsed: 1640.9937252998352 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.59      0.39      0.47       877\n",
      "           3       0.55      0.26      0.35       897\n",
      "           4       0.52      0.76      0.62       892\n",
      "           5       0.39      0.82      0.53       862\n",
      "           6       0.63      0.46      0.54       903\n",
      "           7       0.61      0.38      0.47       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.47      0.42      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.45      0.47      0.43     14531\n",
      "weighted avg       0.43      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 8500, Loss: 1.2633931636810303, F1: 0.43405387967669107, Accuracy: 0.46824031381185055, Time Elapsed: 1656.1059641838074 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.28      0.39       912\n",
      "           1       0.61      0.29      0.40       885\n",
      "           2       0.60      0.43      0.50       877\n",
      "           3       0.49      0.84      0.62       897\n",
      "           4       0.56      0.63      0.59       892\n",
      "           5       0.58      0.19      0.29       862\n",
      "           6       0.62      0.24      0.35       903\n",
      "           7       0.36      0.94      0.52       889\n",
      "           8       0.58      0.19      0.28       892\n",
      "           9       0.72      0.03      0.05       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.56      0.42      0.40     14531\n",
      "weighted avg       0.50      0.44      0.42     14531\n",
      "\n",
      "Epoch 1, Step 8600, Loss: 1.3591738939285278, F1: 0.4035608750269224, Accuracy: 0.44436033308099926, Time Elapsed: 1670.8594131469727 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.69       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.60      0.37      0.46       877\n",
      "           3       0.57      0.17      0.26       897\n",
      "           4       0.45      0.80      0.58       892\n",
      "           5       0.52      0.51      0.52       862\n",
      "           6       0.61      0.83      0.70       903\n",
      "           7       0.61      0.67      0.64       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.61      0.10      0.17       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.51     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 8700, Loss: 0.8766217827796936, F1: 0.5111253202232638, Accuracy: 0.4952859404032758, Time Elapsed: 1686.0128650665283 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.58      0.56      0.57       877\n",
      "           3       0.52      0.81      0.63       897\n",
      "           4       0.58      0.47      0.52       892\n",
      "           5       0.51      0.71      0.59       862\n",
      "           6       0.63      0.55      0.59       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.54      0.69      0.61       892\n",
      "           9       0.61      0.29      0.39       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 8800, Loss: 1.7357361316680908, F1: 0.569416451223823, Accuracy: 0.5149679994494529, Time Elapsed: 1701.9092893600464 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.62      0.23      0.34       877\n",
      "           3       0.54      0.66      0.59       897\n",
      "           4       0.51      0.76      0.61       892\n",
      "           5       0.56      0.32      0.41       862\n",
      "           6       0.63      0.68      0.65       903\n",
      "           7       0.45      0.89      0.60       889\n",
      "           8       0.59      0.29      0.39       892\n",
      "           9       0.65      0.08      0.14       876\n",
      "          10       0.40      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.51     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 8900, Loss: 1.0038273334503174, F1: 0.506820821743137, Accuracy: 0.4966623081687427, Time Elapsed: 1717.44447016716 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.74      0.12      0.20       877\n",
      "           3       0.52      0.80      0.63       897\n",
      "           4       0.49      0.82      0.61       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.63      0.51      0.56       903\n",
      "           7       0.64      0.29      0.39       889\n",
      "           8       0.60      0.15      0.24       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.61      0.48      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.42      0.38      0.35     14531\n",
      "weighted avg       0.41      0.46      0.39     14531\n",
      "\n",
      "Epoch 1, Step 9000, Loss: 0.5216660499572754, F1: 0.3494462042857561, Accuracy: 0.46073910949005575, Time Elapsed: 1732.226879119873 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       912\n",
      "           1       0.61      0.66      0.63       885\n",
      "           2       0.56      0.78      0.65       877\n",
      "           3       0.60      0.53      0.56       897\n",
      "           4       0.52      0.69      0.59       892\n",
      "           5       0.59      0.13      0.22       862\n",
      "           6       0.62      0.63      0.62       903\n",
      "           7       0.59      0.21      0.32       889\n",
      "           8       0.60      0.59      0.60       892\n",
      "           9       0.61      0.43      0.51       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 9100, Loss: 0.8896001577377319, F1: 0.5279021626897927, Accuracy: 0.5040258757139908, Time Elapsed: 1747.4066863059998 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       912\n",
      "           1       0.57      0.98      0.72       885\n",
      "           2       0.58      0.70      0.64       877\n",
      "           3       0.59      0.58      0.58       897\n",
      "           4       0.67      0.09      0.15       892\n",
      "           5       0.58      0.33      0.42       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.63      0.56      0.59       889\n",
      "           8       0.60      0.16      0.26       892\n",
      "           9       0.52      0.57      0.54       876\n",
      "          10       0.39      0.46      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.52      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 9200, Loss: 0.48831507563591003, F1: 0.509220149277091, Accuracy: 0.5007914114651435, Time Elapsed: 2358.184102296829 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.60      0.79      0.68       885\n",
      "           2       0.56      0.75      0.64       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.62      0.37      0.47       892\n",
      "           5       0.56      0.15      0.23       862\n",
      "           6       0.60      0.86      0.71       903\n",
      "           7       0.61      0.58      0.60       889\n",
      "           8       0.59      0.28      0.38       892\n",
      "           9       0.79      0.02      0.03       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.51      0.49     14531\n",
      "weighted avg       0.53      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 9300, Loss: 0.9814693927764893, F1: 0.48868513380765893, Accuracy: 0.49790103915766293, Time Elapsed: 2375.039758205414 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.77      0.01      0.02       885\n",
      "           2       0.59      0.52      0.55       877\n",
      "           3       0.59      0.42      0.49       897\n",
      "           4       0.63      0.28      0.38       892\n",
      "           5       0.80      0.00      0.01       862\n",
      "           6       0.60      0.17      0.26       903\n",
      "           7       0.61      0.52      0.56       889\n",
      "           8       0.37      0.87      0.51       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.54      0.39      0.36     14531\n",
      "weighted avg       0.49      0.45      0.40     14531\n",
      "\n",
      "Epoch 1, Step 9400, Loss: 1.0729398727416992, F1: 0.3622037470499385, Accuracy: 0.4481453444360333, Time Elapsed: 2391.3193600177765 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.00      0.01       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.56      0.13      0.21       897\n",
      "           4       0.61      0.35      0.44       892\n",
      "           5       0.56      0.46      0.50       862\n",
      "           6       0.58      0.90      0.70       903\n",
      "           7       0.60      0.29      0.39       889\n",
      "           8       0.61      0.16      0.26       892\n",
      "           9       0.43      0.84      0.57       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.46      0.44     14531\n",
      "weighted avg       0.51      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 9500, Loss: 0.4815584123134613, F1: 0.4374031388892814, Accuracy: 0.4690661344711307, Time Elapsed: 2407.388388156891 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.72       912\n",
      "           1       0.60      0.46      0.52       885\n",
      "           2       0.57      0.74      0.65       877\n",
      "           3       0.59      0.39      0.47       897\n",
      "           4       0.62      0.41      0.49       892\n",
      "           5       0.54      0.50      0.52       862\n",
      "           6       0.60      0.85      0.71       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.60      0.43      0.50       892\n",
      "           9       0.54      0.51      0.53       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 9600, Loss: 1.2584247589111328, F1: 0.5591614853809996, Accuracy: 0.5120776271419724, Time Elapsed: 2422.930422067642 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.93      0.68       912\n",
      "           1       0.62      0.13      0.22       885\n",
      "           2       0.58      0.53      0.56       877\n",
      "           3       0.60      0.42      0.49       897\n",
      "           4       0.63      0.30      0.40       892\n",
      "           5       0.55      0.11      0.18       862\n",
      "           6       0.62      0.79      0.70       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.57      0.20      0.30       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.48      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 9700, Loss: 0.43576186895370483, F1: 0.4745632026947945, Accuracy: 0.4888858302938545, Time Elapsed: 2437.7657861709595 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.63      0.06      0.10       877\n",
      "           3       0.60      0.57      0.58       897\n",
      "           4       0.55      0.73      0.63       892\n",
      "           5       0.55      0.37      0.44       862\n",
      "           6       0.63      0.58      0.60       903\n",
      "           7       0.61      0.61      0.61       889\n",
      "           8       0.57      0.22      0.31       892\n",
      "           9       0.55      0.73      0.62       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.46      0.46     14531\n",
      "weighted avg       0.48      0.48      0.46     14531\n",
      "\n",
      "Epoch 1, Step 9800, Loss: 0.5210085511207581, F1: 0.45702201818919375, Accuracy: 0.4848943637740004, Time Elapsed: 2452.1358473300934 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.69       912\n",
      "           1       0.61      0.12      0.20       885\n",
      "           2       0.51      0.04      0.08       877\n",
      "           3       0.50      0.82      0.62       897\n",
      "           4       0.61      0.35      0.45       892\n",
      "           5       0.56      0.11      0.18       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.54      0.09      0.16       892\n",
      "           9       0.52      0.70      0.60       876\n",
      "          10       0.39      0.51      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.46      0.43     14531\n",
      "weighted avg       0.50      0.48      0.44     14531\n",
      "\n",
      "Epoch 1, Step 9900, Loss: 1.1683557033538818, F1: 0.4324893134755174, Accuracy: 0.47918243754731266, Time Elapsed: 2467.5429260730743 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.70       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.58      0.58      0.58       877\n",
      "           3       0.56      0.71      0.63       897\n",
      "           4       0.46      0.82      0.59       892\n",
      "           5       0.59      0.13      0.21       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.59      0.62      0.61       892\n",
      "           9       0.60      0.20      0.31       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 10000, Loss: 2.6140737533569336, F1: 0.5469007719569985, Accuracy: 0.5133163581308926, Time Elapsed: 2482.2684581279755 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.44      0.52       912\n",
      "           1       0.60      0.32      0.42       885\n",
      "           2       0.58      0.68      0.63       877\n",
      "           3       0.57      0.57      0.57       897\n",
      "           4       0.56      0.71      0.63       892\n",
      "           5       0.49      0.69      0.57       862\n",
      "           6       0.62      0.44      0.52       903\n",
      "           7       0.60      0.84      0.70       889\n",
      "           8       0.57      0.54      0.56       892\n",
      "           9       0.57      0.66      0.61       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 10100, Loss: 0.9457253813743591, F1: 0.5550741545549168, Accuracy: 0.5060216089739178, Time Elapsed: 2496.638487100601 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       912\n",
      "           1       0.57      0.16      0.25       885\n",
      "           2       0.51      0.83      0.63       877\n",
      "           3       0.57      0.77      0.66       897\n",
      "           4       0.51      0.70      0.59       892\n",
      "           5       0.57      0.09      0.15       862\n",
      "           6       0.53      0.94      0.68       903\n",
      "           7       0.61      0.73      0.66       889\n",
      "           8       0.57      0.26      0.36       892\n",
      "           9       0.59      0.48      0.53       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.55      0.51     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 10200, Loss: 1.8109784126281738, F1: 0.5064913413433628, Accuracy: 0.4952859404032758, Time Elapsed: 2512.044333219528 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.72       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.58      0.70      0.64       877\n",
      "           3       0.50      0.83      0.63       897\n",
      "           4       0.55      0.82      0.66       892\n",
      "           5       0.58      0.27      0.37       862\n",
      "           6       0.60      0.88      0.71       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.55      0.74      0.63       892\n",
      "           9       0.57      0.73      0.64       876\n",
      "          10       0.39      0.17      0.24      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.55      0.71      0.60     14531\n",
      "weighted avg       0.50      0.54      0.49     14531\n",
      "\n",
      "Epoch 1, Step 10300, Loss: 1.3254399299621582, F1: 0.6039147319389001, Accuracy: 0.5377468859679306, Time Elapsed: 2527.856252193451 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.58      0.75      0.65       877\n",
      "           3       0.58      0.69      0.63       897\n",
      "           4       0.48      0.70      0.57       892\n",
      "           5       0.58      0.13      0.21       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.57      0.20      0.30       892\n",
      "           9       0.67      0.00      0.00       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.50     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 10400, Loss: 1.7543001174926758, F1: 0.5003681976524023, Accuracy: 0.503888238937444, Time Elapsed: 2542.7060492038727 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.61      0.47      0.53       897\n",
      "           4       0.56      0.61      0.58       892\n",
      "           5       0.55      0.56      0.56       862\n",
      "           6       0.58      0.91      0.71       903\n",
      "           7       0.61      0.51      0.55       889\n",
      "           8       0.61      0.32      0.42       892\n",
      "           9       0.67      0.04      0.07       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 10500, Loss: 0.5781559944152832, F1: 0.5315491932135579, Accuracy: 0.5101507122703186, Time Elapsed: 2557.078325033188 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       912\n",
      "           1       0.60      0.73      0.66       885\n",
      "           2       0.57      0.72      0.64       877\n",
      "           3       0.58      0.72      0.64       897\n",
      "           4       0.55      0.72      0.62       892\n",
      "           5       0.56      0.43      0.49       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.58      0.26      0.36       892\n",
      "           9       0.59      0.53      0.56       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 10600, Loss: 0.9912089109420776, F1: 0.5730952769651365, Accuracy: 0.5185465556396669, Time Elapsed: 2572.2111752033234 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.52      0.81      0.63       877\n",
      "           3       0.60      0.54      0.56       897\n",
      "           4       0.62      0.31      0.42       892\n",
      "           5       0.57      0.18      0.28       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.59      0.31      0.41       892\n",
      "           9       0.50      0.74      0.59       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.51      0.48     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 10700, Loss: 1.8532965183258057, F1: 0.4829174233423078, Accuracy: 0.48922992223522127, Time Elapsed: 2587.400017261505 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.63      0.35      0.45       877\n",
      "           3       0.61      0.41      0.49       897\n",
      "           4       0.41      0.93      0.57       892\n",
      "           5       0.58      0.22      0.32       862\n",
      "           6       0.62      0.55      0.58       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.56      0.68      0.62       892\n",
      "           9       0.61      0.08      0.14       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.54      0.51     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 10800, Loss: 2.728095054626465, F1: 0.5093178734982322, Accuracy: 0.49452893813226895, Time Elapsed: 2602.8407113552094 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.59      0.60      0.59       877\n",
      "           3       0.59      0.61      0.60       897\n",
      "           4       0.60      0.51      0.55       892\n",
      "           5       0.49      0.68      0.57       862\n",
      "           6       0.63      0.55      0.59       903\n",
      "           7       0.57      0.83      0.68       889\n",
      "           8       0.60      0.26      0.36       892\n",
      "           9       0.61      0.32      0.42       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 10900, Loss: 0.37291252613067627, F1: 0.554779670094324, Accuracy: 0.511595898424059, Time Elapsed: 2617.3961522579193 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.23      0.33       912\n",
      "           1       0.75      0.00      0.01       885\n",
      "           2       0.65      0.24      0.35       877\n",
      "           3       0.57      0.70      0.63       897\n",
      "           4       0.58      0.57      0.58       892\n",
      "           5       0.54      0.40      0.46       862\n",
      "           6       0.66      0.39      0.49       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.54      0.73      0.62       892\n",
      "           9       0.52      0.66      0.58       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.45      0.46     14531\n",
      "weighted avg       0.52      0.48      0.46     14531\n",
      "\n",
      "Epoch 1, Step 11000, Loss: 0.9023125171661377, F1: 0.46083313923401986, Accuracy: 0.47849425366457915, Time Elapsed: 2632.0464823246 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.18      0.28       912\n",
      "           1       0.67      0.24      0.35       885\n",
      "           2       0.63      0.29      0.40       877\n",
      "           3       0.49      0.86      0.62       897\n",
      "           4       0.62      0.36      0.46       892\n",
      "           5       0.55      0.46      0.50       862\n",
      "           6       0.63      0.56      0.59       903\n",
      "           7       0.60      0.40      0.48       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.51      0.62      0.56       876\n",
      "          10       0.40      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.45      0.48     14531\n",
      "weighted avg       0.52      0.48      0.47     14531\n",
      "\n",
      "Epoch 1, Step 11100, Loss: 1.260650873184204, F1: 0.4753356500646351, Accuracy: 0.477461977840479, Time Elapsed: 2648.0013842582703 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.40      0.49       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.69      0.05      0.09       897\n",
      "           4       0.49      0.84      0.62       892\n",
      "           5       0.55      0.27      0.37       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.62      0.33      0.43       889\n",
      "           8       0.56      0.18      0.27       892\n",
      "           9       0.58      0.50      0.54       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.48      0.47     14531\n",
      "weighted avg       0.51      0.48      0.46     14531\n",
      "\n",
      "Epoch 1, Step 11200, Loss: 1.4017447233200073, F1: 0.47053213015888495, Accuracy: 0.48351799600853346, Time Elapsed: 2663.7048943042755 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.46      0.53       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.56      0.24      0.34       897\n",
      "           4       0.60      0.34      0.43       892\n",
      "           5       0.60      0.25      0.36       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.45      0.91      0.60       889\n",
      "           8       0.62      0.01      0.02       892\n",
      "           9       0.43      0.47      0.45       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.55      0.47      0.46     14531\n",
      "weighted avg       0.50      0.47      0.45     14531\n",
      "\n",
      "Epoch 1, Step 11300, Loss: 1.0683178901672363, F1: 0.46148400804052836, Accuracy: 0.47415869520335835, Time Elapsed: 2679.626634120941 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66       912\n",
      "           1       0.58      0.93      0.72       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.56      0.27      0.36       897\n",
      "           4       0.57      0.64      0.60       892\n",
      "           5       0.59      0.25      0.35       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.51      0.04      0.08       892\n",
      "           9       0.51      0.74      0.61       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.53      0.51     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 11400, Loss: 1.3308582305908203, F1: 0.5094029549104735, Accuracy: 0.49838276787557634, Time Elapsed: 2695.0470752716064 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.63      0.08      0.14       885\n",
      "           2       0.55      0.74      0.63       877\n",
      "           3       0.58      0.53      0.56       897\n",
      "           4       0.48      0.70      0.57       892\n",
      "           5       0.51      0.64      0.57       862\n",
      "           6       0.63      0.54      0.58       903\n",
      "           7       0.61      0.07      0.12       889\n",
      "           8       0.59      0.38      0.46       892\n",
      "           9       0.66      0.03      0.06       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.46      0.44     14531\n",
      "weighted avg       0.51      0.47      0.44     14531\n",
      "\n",
      "Epoch 1, Step 11500, Loss: 0.7091379761695862, F1: 0.4392081198085506, Accuracy: 0.47457160553299843, Time Elapsed: 2710.632286310196 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.57      0.60      0.59       877\n",
      "           3       0.58      0.45      0.51       897\n",
      "           4       0.56      0.71      0.63       892\n",
      "           5       0.58      0.10      0.17       862\n",
      "           6       0.57      0.92      0.70       903\n",
      "           7       0.52      0.90      0.66       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.55      0.57       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.57      0.51     14531\n",
      "weighted avg       0.47      0.51      0.47     14531\n",
      "\n",
      "Epoch 1, Step 11600, Loss: 0.9338041543960571, F1: 0.5088874693049139, Accuracy: 0.506847429633198, Time Elapsed: 2726.644517183304 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.62      0.62      0.62       885\n",
      "           2       0.61      0.35      0.44       877\n",
      "           3       0.57      0.29      0.38       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.67      0.01      0.01       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.59      0.71      0.64       889\n",
      "           8       0.51      0.57      0.53       892\n",
      "           9       0.56      0.71      0.62       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.49      0.46     14531\n",
      "weighted avg       0.48      0.49      0.45     14531\n",
      "\n",
      "Epoch 1, Step 11700, Loss: 3.1541056632995605, F1: 0.4602662956860158, Accuracy: 0.4882664647993944, Time Elapsed: 2741.348119020462 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.58       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.57      0.52      0.55       897\n",
      "           4       0.58      0.59      0.59       892\n",
      "           5       0.54      0.32      0.40       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.56      0.58      0.57       892\n",
      "           9       0.45      0.84      0.58       876\n",
      "          10       0.38      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 11800, Loss: 1.350623607635498, F1: 0.5648069775295453, Accuracy: 0.5067097928566513, Time Elapsed: 2756.200513124466 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.58      0.39      0.47       897\n",
      "           4       0.60      0.52      0.56       892\n",
      "           5       0.59      0.10      0.17       862\n",
      "           6       0.62      0.38      0.47       903\n",
      "           7       0.58      0.79      0.67       889\n",
      "           8       0.59      0.45      0.51       892\n",
      "           9       0.62      0.23      0.33       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 11900, Loss: 0.6149489879608154, F1: 0.5014686849555899, Accuracy: 0.4952171220150024, Time Elapsed: 2772.4826323986053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.12      0.21       912\n",
      "           1       0.60      0.73      0.66       885\n",
      "           2       0.62      0.34      0.44       877\n",
      "           3       0.75      0.00      0.01       897\n",
      "           4       0.58      0.47      0.52       892\n",
      "           5       0.55      0.34      0.42       862\n",
      "           6       0.67      0.06      0.12       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.50      0.05      0.09       892\n",
      "           9       0.59      0.37      0.46       876\n",
      "          10       0.39      0.66      0.49      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.59      0.36      0.37     14531\n",
      "weighted avg       0.52      0.45      0.41     14531\n",
      "\n",
      "Epoch 1, Step 12000, Loss: 0.6006646156311035, F1: 0.36902546076812137, Accuracy: 0.4544766361571812, Time Elapsed: 2796.3784000873566 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.57      0.71      0.64       892\n",
      "           5       0.60      0.15      0.23       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.61      0.45      0.52       889\n",
      "           8       0.59      0.04      0.08       892\n",
      "           9       0.62      0.43      0.51       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.53      0.51     14531\n",
      "weighted avg       0.52      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 12100, Loss: 1.1075432300567627, F1: 0.5144867090387706, Accuracy: 0.5069162480214713, Time Elapsed: 2811.65762925148 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.61      0.62      0.61       885\n",
      "           2       0.55      0.73      0.63       877\n",
      "           3       0.52      0.80      0.63       897\n",
      "           4       0.62      0.20      0.31       892\n",
      "           5       0.61      0.08      0.14       862\n",
      "           6       0.60      0.74      0.66       903\n",
      "           7       0.60      0.49      0.54       889\n",
      "           8       0.57      0.27      0.36       892\n",
      "           9       0.59      0.47      0.52       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.52      0.50     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 12200, Loss: 1.3863059282302856, F1: 0.5017786829819296, Accuracy: 0.4953547587915491, Time Elapsed: 2826.9738931655884 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       912\n",
      "           1       0.60      0.43      0.50       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.57      0.11      0.19       897\n",
      "           4       0.59      0.01      0.02       892\n",
      "           5       0.59      0.16      0.25       862\n",
      "           6       0.59      0.10      0.17       903\n",
      "           7       0.58      0.60      0.59       889\n",
      "           8       0.42      0.63      0.50       892\n",
      "           9       0.55      0.25      0.35       876\n",
      "          10       0.39      0.61      0.48      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.56      0.38      0.39     14531\n",
      "weighted avg       0.50      0.45      0.42     14531\n",
      "\n",
      "Epoch 1, Step 12300, Loss: 1.7259376049041748, F1: 0.38691339532826297, Accuracy: 0.4539949074392678, Time Elapsed: 2842.7369441986084 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.69       912\n",
      "           1       0.63      0.24      0.35       885\n",
      "           2       0.56      0.69      0.62       877\n",
      "           3       0.54      0.59      0.56       897\n",
      "           4       0.59      0.29      0.39       892\n",
      "           5       0.57      0.25      0.35       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.59      0.60      0.60       889\n",
      "           8       0.55      0.14      0.23       892\n",
      "           9       0.64      0.19      0.29       876\n",
      "          10       0.39      0.55      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.44      0.46     14531\n",
      "weighted avg       0.51      0.48      0.46     14531\n",
      "\n",
      "Epoch 1, Step 12400, Loss: 0.7083632946014404, F1: 0.4647163512026825, Accuracy: 0.4782189801114858, Time Elapsed: 2858.50248336792 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.71       912\n",
      "           1       0.52      0.97      0.68       885\n",
      "           2       0.53      0.77      0.63       877\n",
      "           3       0.59      0.35      0.44       897\n",
      "           4       0.52      0.77      0.62       892\n",
      "           5       0.54      0.62      0.57       862\n",
      "           6       0.60      0.05      0.10       903\n",
      "           7       0.59      0.53      0.56       889\n",
      "           8       0.56      0.61      0.58       892\n",
      "           9       0.58      0.56      0.57       876\n",
      "          10       0.38      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.59      0.53     14531\n",
      "weighted avg       0.49      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 12500, Loss: 1.9083918333053589, F1: 0.5288757087545333, Accuracy: 0.49790103915766293, Time Elapsed: 2874.649134159088 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.70       912\n",
      "           1       0.61      0.76      0.68       885\n",
      "           2       0.63      0.28      0.38       877\n",
      "           3       0.58      0.31      0.41       897\n",
      "           4       0.60      0.22      0.32       892\n",
      "           5       0.56      0.32      0.40       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.56      0.16      0.25       892\n",
      "           9       0.44      0.80      0.57       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.49     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 12600, Loss: 1.3972173929214478, F1: 0.4943214204946068, Accuracy: 0.4888858302938545, Time Elapsed: 2891.02254319191 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.05      0.09       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.58      0.55      0.56       877\n",
      "           3       0.59      0.44      0.50       897\n",
      "           4       0.57      0.68      0.62       892\n",
      "           5       0.56      0.38      0.45       862\n",
      "           6       0.62      0.43      0.51       903\n",
      "           7       0.60      0.51      0.55       889\n",
      "           8       0.57      0.29      0.39       892\n",
      "           9       0.51      0.82      0.63       876\n",
      "          10       0.38      0.47      0.42      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.49      0.49     14531\n",
      "weighted avg       0.50      0.48      0.47     14531\n",
      "\n",
      "Epoch 1, Step 12700, Loss: 1.0038901567459106, F1: 0.49176514823590034, Accuracy: 0.48303626729062005, Time Elapsed: 2907.3682742118835 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.57       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.56      0.56      0.56       877\n",
      "           3       0.50      0.02      0.03       897\n",
      "           4       0.58      0.61      0.60       892\n",
      "           5       0.60      0.04      0.07       862\n",
      "           6       0.59      0.05      0.10       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.60      0.19      0.28       892\n",
      "           9       0.55      0.70      0.62       876\n",
      "          10       0.39      0.65      0.49      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.51      0.37      0.36     14531\n",
      "weighted avg       0.47      0.46      0.40     14531\n",
      "\n",
      "Epoch 1, Step 12800, Loss: 2.620351552963257, F1: 0.3598005805493027, Accuracy: 0.45826164751221526, Time Elapsed: 2924.0040199756622 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.59      0.17      0.27       885\n",
      "           2       0.60      0.47      0.53       877\n",
      "           3       0.57      0.45      0.51       897\n",
      "           4       0.63      0.12      0.21       892\n",
      "           5       0.58      0.16      0.25       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.60      0.54      0.57       889\n",
      "           8       0.58      0.42      0.49       892\n",
      "           9       1.00      0.00      0.01       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.61      0.42      0.43     14531\n",
      "weighted avg       0.54      0.48      0.44     14531\n",
      "\n",
      "Epoch 1, Step 12900, Loss: 1.1205741167068481, F1: 0.426099893394806, Accuracy: 0.47656733879292545, Time Elapsed: 2940.3690690994263 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.57      0.45      0.50       897\n",
      "           4       0.57      0.62      0.59       892\n",
      "           5       0.50      0.73      0.59       862\n",
      "           6       0.65      0.44      0.53       903\n",
      "           7       0.58      0.73      0.65       889\n",
      "           8       0.56      0.53      0.55       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.46      0.47      0.46     14531\n",
      "weighted avg       0.44      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 13000, Loss: 1.5705983638763428, F1: 0.45698876029619967, Accuracy: 0.480834078865873, Time Elapsed: 2961.5105521678925 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.60      0.37      0.45       897\n",
      "           4       0.59      0.70      0.64       892\n",
      "           5       0.47      0.75      0.58       862\n",
      "           6       0.60      0.06      0.11       903\n",
      "           7       0.59      0.52      0.56       889\n",
      "           8       0.56      0.48      0.51       892\n",
      "           9       0.61      0.42      0.50       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.52      0.51     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 1, Step 13100, Loss: 1.281074047088623, F1: 0.5102540879451541, Accuracy: 0.49101920033032825, Time Elapsed: 2978.479381084442 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61       912\n",
      "           1       0.60      0.76      0.67       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.57      0.63      0.60       897\n",
      "           4       0.59      0.64      0.62       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.63      0.52      0.57       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.59      0.42      0.49       892\n",
      "           9       0.47      0.88      0.61       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 13200, Loss: 0.8102772831916809, F1: 0.5733290605679813, Accuracy: 0.5113206248709655, Time Elapsed: 2994.8611483573914 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       1.00      0.00      0.00       885\n",
      "           2       0.59      0.14      0.22       877\n",
      "           3       0.57      0.53      0.55       897\n",
      "           4       0.59      0.65      0.62       892\n",
      "           5       0.58      0.09      0.15       862\n",
      "           6       0.62      0.33      0.43       903\n",
      "           7       0.59      0.21      0.31       889\n",
      "           8       0.53      0.75      0.62       892\n",
      "           9       0.61      0.36      0.45       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.61      0.41      0.41     14531\n",
      "weighted avg       0.53      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 13300, Loss: 0.3570690155029297, F1: 0.41296394532781466, Accuracy: 0.46920377124767737, Time Elapsed: 3010.7709641456604 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.37      0.47       912\n",
      "           1       0.55      0.95      0.70       885\n",
      "           2       0.56      0.61      0.59       877\n",
      "           3       0.59      0.27      0.37       897\n",
      "           4       0.58      0.67      0.62       892\n",
      "           5       0.55      0.30      0.39       862\n",
      "           6       0.62      0.61      0.61       903\n",
      "           7       0.60      0.24      0.35       889\n",
      "           8       0.59      0.49      0.53       892\n",
      "           9       0.62      0.04      0.08       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.46      0.47     14531\n",
      "weighted avg       0.51      0.48      0.46     14531\n",
      "\n",
      "Epoch 1, Step 13400, Loss: 0.6454511284828186, F1: 0.46858675847139997, Accuracy: 0.4820728098547932, Time Elapsed: 3028.04300904274 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.70       912\n",
      "           1       0.60      0.06      0.11       885\n",
      "           2       0.57      0.69      0.63       877\n",
      "           3       0.49      0.84      0.62       897\n",
      "           4       0.62      0.16      0.26       892\n",
      "           5       0.58      0.27      0.37       862\n",
      "           6       0.59      0.03      0.05       903\n",
      "           7       0.61      0.28      0.38       889\n",
      "           8       0.58      0.48      0.53       892\n",
      "           9       0.56      0.61      0.58       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.56      0.44      0.43     14531\n",
      "weighted avg       0.50      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 13500, Loss: 2.2684953212738037, F1: 0.425603894214369, Accuracy: 0.4692725896359507, Time Elapsed: 3045.6011934280396 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.49      0.82      0.61       877\n",
      "           3       0.55      0.12      0.19       897\n",
      "           4       0.60      0.42      0.49       892\n",
      "           5       0.60      0.06      0.10       862\n",
      "           6       0.62      0.05      0.09       903\n",
      "           7       0.58      0.20      0.30       889\n",
      "           8       0.57      0.01      0.03       892\n",
      "           9       0.62      0.36      0.45       876\n",
      "          10       0.39      0.69      0.50      5646\n",
      "\n",
      "    accuracy                           0.44     14531\n",
      "   macro avg       0.51      0.33      0.32     14531\n",
      "weighted avg       0.47      0.44      0.38     14531\n",
      "\n",
      "Epoch 1, Step 13600, Loss: 1.288863182067871, F1: 0.3166662165052841, Accuracy: 0.44436033308099926, Time Elapsed: 3060.8922250270844 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.57      0.61      0.59       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.56      0.72      0.63       892\n",
      "           5       0.58      0.12      0.20       862\n",
      "           6       0.50      0.00      0.00       903\n",
      "           7       0.60      0.52      0.56       889\n",
      "           8       0.55      0.17      0.26       892\n",
      "           9       0.71      0.08      0.14       876\n",
      "          10       0.38      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.45      0.43     14531\n",
      "weighted avg       0.51      0.48      0.43     14531\n",
      "\n",
      "Epoch 1, Step 13700, Loss: 2.3866589069366455, F1: 0.4275420052064336, Accuracy: 0.47622324685155876, Time Elapsed: 3080.543505191803 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57       912\n",
      "           1       0.61      0.60      0.60       885\n",
      "           2       0.54      0.76      0.63       877\n",
      "           3       0.59      0.32      0.42       897\n",
      "           4       0.60      0.58      0.59       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.53      0.94      0.68       903\n",
      "           7       0.61      0.44      0.51       889\n",
      "           8       0.55      0.03      0.06       892\n",
      "           9       0.62      0.27      0.38       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.45      0.44     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 13800, Loss: 0.24679876863956451, F1: 0.4444813503712869, Accuracy: 0.4798018030417728, Time Elapsed: 3095.2505202293396 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.62      0.53      0.57       885\n",
      "           2       0.63      0.44      0.52       877\n",
      "           3       0.53      0.48      0.51       897\n",
      "           4       0.58      0.68      0.63       892\n",
      "           5       0.58      0.08      0.15       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.64      0.21      0.32       889\n",
      "           8       0.56      0.56      0.56       892\n",
      "           9       0.59      0.54      0.57       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 1, Step 13900, Loss: 1.0715200901031494, F1: 0.5041162162563035, Accuracy: 0.49452893813226895, Time Elapsed: 3109.632843017578 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.56       912\n",
      "           1       0.58      0.02      0.05       885\n",
      "           2       0.62      0.44      0.52       877\n",
      "           3       0.50      0.00      0.01       897\n",
      "           4       0.66      0.26      0.37       892\n",
      "           5       0.58      0.23      0.32       862\n",
      "           6       0.62      0.31      0.42       903\n",
      "           7       0.64      0.19      0.29       889\n",
      "           8       0.54      0.63      0.58       892\n",
      "           9       0.54      0.62      0.58       876\n",
      "          10       0.39      0.67      0.50      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.57      0.35      0.38     14531\n",
      "weighted avg       0.51      0.46      0.42     14531\n",
      "\n",
      "Epoch 1, Step 14000, Loss: 0.4217621982097626, F1: 0.38145117561162467, Accuracy: 0.4578487371825752, Time Elapsed: 3125.174863100052 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.58      0.68      0.63       877\n",
      "           3       0.58      0.46      0.51       897\n",
      "           4       0.50      0.90      0.65       892\n",
      "           5       0.58      0.38      0.46       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.60      0.55      0.57       889\n",
      "           8       0.59      0.37      0.45       892\n",
      "           9       0.58      0.62      0.60       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 14100, Loss: 1.2784910202026367, F1: 0.5767584553106957, Accuracy: 0.5213681095588741, Time Elapsed: 3139.9660453796387 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.58      0.31      0.40       897\n",
      "           4       0.56      0.53      0.54       892\n",
      "           5       0.62      0.03      0.06       862\n",
      "           6       0.63      0.55      0.59       903\n",
      "           7       0.59      0.68      0.63       889\n",
      "           8       0.55      0.66      0.60       892\n",
      "           9       0.63      0.13      0.22       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.52      0.50     14531\n",
      "weighted avg       0.52      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 14200, Loss: 0.44026926159858704, F1: 0.49871647254687107, Accuracy: 0.4987268598169431, Time Elapsed: 3154.2072031497955 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.63      0.23      0.34       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.42      0.01      0.01       897\n",
      "           4       0.59      0.47      0.52       892\n",
      "           5       0.55      0.43      0.48       862\n",
      "           6       0.58      0.86      0.70       903\n",
      "           7       0.59      0.27      0.37       889\n",
      "           8       0.54      0.70      0.61       892\n",
      "           9       0.53      0.78      0.63       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.50      0.48     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 14300, Loss: 1.9062397480010986, F1: 0.48277913188915905, Accuracy: 0.4894363774000413, Time Elapsed: 3168.7054142951965 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.58      0.93      0.71       885\n",
      "           2       0.58      0.61      0.59       877\n",
      "           3       0.56      0.04      0.08       897\n",
      "           4       0.57      0.08      0.14       892\n",
      "           5       0.58      0.42      0.49       862\n",
      "           6       0.63      0.66      0.64       903\n",
      "           7       0.61      0.58      0.60       889\n",
      "           8       0.60      0.17      0.26       892\n",
      "           9       0.57      0.55      0.56       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.49      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 14400, Loss: 3.4785075187683105, F1: 0.47426455676375506, Accuracy: 0.4907439267772349, Time Elapsed: 3183.2941551208496 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.54      0.77      0.64       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.60      0.64      0.62       892\n",
      "           5       0.57      0.00      0.01       862\n",
      "           6       0.63      0.62      0.62       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.58      0.30      0.39       892\n",
      "           9       0.42      0.84      0.56       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.45      0.47      0.42     14531\n",
      "weighted avg       0.43      0.48      0.42     14531\n",
      "\n",
      "Epoch 1, Step 14500, Loss: 0.47712668776512146, F1: 0.4209240533631755, Accuracy: 0.47594797329846533, Time Elapsed: 3198.3051941394806 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.61      0.42      0.50       877\n",
      "           3       0.59      0.46      0.52       897\n",
      "           4       0.62      0.16      0.25       892\n",
      "           5       0.59      0.29      0.39       862\n",
      "           6       0.62      0.67      0.64       903\n",
      "           7       0.62      0.42      0.50       889\n",
      "           8       0.58      0.18      0.27       892\n",
      "           9       0.58      0.67      0.62       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.50      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 14600, Loss: 3.4728546142578125, F1: 0.5051784366032724, Accuracy: 0.4985892230403964, Time Elapsed: 3212.6953921318054 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.93      0.73       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.58      0.40      0.47       897\n",
      "           4       0.51      0.85      0.64       892\n",
      "           5       0.58      0.37      0.45       862\n",
      "           6       0.64      0.22      0.33       903\n",
      "           7       0.59      0.62      0.61       889\n",
      "           8       0.59      0.26      0.36       892\n",
      "           9       0.59      0.67      0.63       876\n",
      "          10       0.38      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 14700, Loss: 1.9462782144546509, F1: 0.5389089323413656, Accuracy: 0.505058151538091, Time Elapsed: 3228.242816209793 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.58      0.35      0.43       897\n",
      "           4       0.61      0.47      0.53       892\n",
      "           5       0.57      0.59      0.58       862\n",
      "           6       0.63      0.50      0.56       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.57      0.65      0.60       892\n",
      "           9       0.60      0.61      0.60       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 1, Step 14800, Loss: 0.8258118629455566, F1: 0.5743269046929679, Accuracy: 0.5192347395224004, Time Elapsed: 3243.6766180992126 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.62      0.60      0.61       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.52      0.81      0.63       897\n",
      "           4       0.62      0.39      0.48       892\n",
      "           5       0.57      0.48      0.52       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.63      0.20      0.31       889\n",
      "           8       0.52      0.62      0.57       892\n",
      "           9       0.39      0.88      0.54       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.57      0.54     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 1, Step 14900, Loss: 1.1899354457855225, F1: 0.5382868641932016, Accuracy: 0.4941848461909022, Time Elapsed: 3260.101065158844 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.08      0.15       912\n",
      "           1       0.62      0.26      0.37       885\n",
      "           2       0.64      0.27      0.38       877\n",
      "           3       0.59      0.36      0.45       897\n",
      "           4       0.61      0.47      0.53       892\n",
      "           5       0.00      0.00      0.00       862\n",
      "           6       0.62      0.17      0.26       903\n",
      "           7       0.59      0.67      0.63       889\n",
      "           8       0.55      0.64      0.59       892\n",
      "           9       0.61      0.14      0.23       876\n",
      "          10       0.39      0.69      0.50      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.53      0.34      0.37     14531\n",
      "weighted avg       0.49      0.45      0.41     14531\n",
      "\n",
      "Epoch 1, Step 15000, Loss: 0.34555545449256897, F1: 0.3709730645488066, Accuracy: 0.45475190971027457, Time Elapsed: 3275.4866151809692 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.24      0.35       912\n",
      "           1       0.57      0.90      0.70       885\n",
      "           2       0.57      0.61      0.59       877\n",
      "           3       0.58      0.34      0.43       897\n",
      "           4       0.57      0.61      0.59       892\n",
      "           5       0.59      0.26      0.36       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.70      0.07      0.12       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 15100, Loss: 0.8817962408065796, F1: 0.4919932160704169, Accuracy: 0.4926708416488886, Time Elapsed: 3289.961297273636 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.23      0.34       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.56      0.69      0.61       877\n",
      "           3       0.61      0.43      0.51       897\n",
      "           4       0.55      0.64      0.59       892\n",
      "           5       0.54      0.09      0.15       862\n",
      "           6       0.61      0.68      0.64       903\n",
      "           7       0.61      0.47      0.53       889\n",
      "           8       0.60      0.41      0.49       892\n",
      "           9       0.43      0.90      0.59       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 15200, Loss: 0.5490255355834961, F1: 0.5055323162215255, Accuracy: 0.4882664647993944, Time Elapsed: 3305.3409621715546 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.61      0.47      0.53       877\n",
      "           3       0.60      0.00      0.01       897\n",
      "           4       0.49      0.87      0.63       892\n",
      "           5       0.58      0.61      0.59       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.63      0.33      0.43       889\n",
      "           8       0.59      0.26      0.36       892\n",
      "           9       0.63      0.29      0.40       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.50      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 15300, Loss: 1.8578310012817383, F1: 0.48731900305617093, Accuracy: 0.49335902553162203, Time Elapsed: 3320.311838388443 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.62      0.01      0.02       885\n",
      "           2       0.62      0.24      0.34       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.52      0.89      0.66       892\n",
      "           5       0.55      0.52      0.54       862\n",
      "           6       0.63      0.59      0.61       903\n",
      "           7       0.61      0.47      0.53       889\n",
      "           8       0.61      0.52      0.56       892\n",
      "           9       0.62      0.33      0.43       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.53      0.44      0.44     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 15400, Loss: 0.8271118402481079, F1: 0.4368777308577307, Accuracy: 0.47959534787695274, Time Elapsed: 3335.872922182083 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62       912\n",
      "           1       0.57      0.23      0.33       885\n",
      "           2       0.61      0.42      0.50       877\n",
      "           3       0.50      0.00      0.00       897\n",
      "           4       0.55      0.73      0.62       892\n",
      "           5       0.56      0.27      0.36       862\n",
      "           6       0.57      0.89      0.69       903\n",
      "           7       0.62      0.47      0.53       889\n",
      "           8       0.58      0.11      0.18       892\n",
      "           9       0.62      0.01      0.03       876\n",
      "          10       0.39      0.61      0.48      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.56      0.40      0.40     14531\n",
      "weighted avg       0.51      0.47      0.42     14531\n",
      "\n",
      "Epoch 1, Step 15500, Loss: 0.9727210998535156, F1: 0.3956602121865469, Accuracy: 0.46665749088156355, Time Elapsed: 3350.829670190811 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.61      0.49      0.54       885\n",
      "           2       0.59      0.52      0.55       877\n",
      "           3       0.58      0.19      0.28       897\n",
      "           4       0.55      0.80      0.65       892\n",
      "           5       0.58      0.36      0.45       862\n",
      "           6       0.57      0.91      0.70       903\n",
      "           7       0.61      0.63      0.62       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.60      0.41      0.48       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.50      0.49     14531\n",
      "weighted avg       0.48      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 15600, Loss: 0.8283507227897644, F1: 0.4887902104948957, Accuracy: 0.4939095726378088, Time Elapsed: 3366.997593164444 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.66       912\n",
      "           1       0.62      0.35      0.45       885\n",
      "           2       0.56      0.69      0.62       877\n",
      "           3       0.55      0.82      0.66       897\n",
      "           4       0.58      0.58      0.58       892\n",
      "           5       0.57      0.42      0.49       862\n",
      "           6       0.64      0.61      0.62       903\n",
      "           7       0.60      0.33      0.42       889\n",
      "           8       0.60      0.47      0.52       892\n",
      "           9       0.51      0.65      0.57       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 1, Step 15700, Loss: 1.4100275039672852, F1: 0.5441788820560993, Accuracy: 0.5015484137361503, Time Elapsed: 3382.6763281822205 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.57      0.25      0.35       897\n",
      "           4       0.56      0.60      0.58       892\n",
      "           5       0.50      0.74      0.60       862\n",
      "           6       0.63      0.71      0.67       903\n",
      "           7       0.60      0.11      0.19       889\n",
      "           8       0.58      0.48      0.52       892\n",
      "           9       0.48      0.71      0.57       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.57      0.53     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 15800, Loss: 0.8498361110687256, F1: 0.5320012724080457, Accuracy: 0.4992774069231299, Time Elapsed: 3397.2405440807343 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67       912\n",
      "           1       0.61      0.44      0.51       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.55      0.76      0.64       892\n",
      "           5       0.58      0.33      0.42       862\n",
      "           6       0.55      0.92      0.69       903\n",
      "           7       0.59      0.56      0.58       889\n",
      "           8       0.55      0.11      0.18       892\n",
      "           9       0.56      0.72      0.63       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 15900, Loss: 0.822632372379303, F1: 0.5346707982477573, Accuracy: 0.5038194205491707, Time Elapsed: 3412.0124962329865 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.61      0.49      0.55       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.60      0.33      0.43       897\n",
      "           4       0.59      0.58      0.58       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.62      0.77      0.69       903\n",
      "           7       0.59      0.65      0.62       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.59      0.29      0.39       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.55      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 16000, Loss: 0.4285499155521393, F1: 0.5492289555848117, Accuracy: 0.506640974468378, Time Elapsed: 3427.712821006775 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.67       912\n",
      "           1       0.59      0.30      0.40       885\n",
      "           2       0.55      0.77      0.64       877\n",
      "           3       0.59      0.60      0.59       897\n",
      "           4       0.51      0.80      0.63       892\n",
      "           5       0.56      0.20      0.30       862\n",
      "           6       0.62      0.42      0.50       903\n",
      "           7       0.61      0.17      0.26       889\n",
      "           8       0.57      0.21      0.31       892\n",
      "           9       0.59      0.54      0.56       876\n",
      "          10       0.38      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.49      0.48     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 1, Step 16100, Loss: 2.3408918380737305, F1: 0.4794082443440507, Accuracy: 0.47656733879292545, Time Elapsed: 3442.8189191818237 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.54      0.77      0.63       877\n",
      "           3       0.57      0.56      0.57       897\n",
      "           4       0.56      0.35      0.43       892\n",
      "           5       0.55      0.58      0.56       862\n",
      "           6       0.62      0.42      0.50       903\n",
      "           7       0.60      0.61      0.60       889\n",
      "           8       0.59      0.37      0.45       892\n",
      "           9       0.61      0.36      0.46       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 16200, Loss: 2.8618195056915283, F1: 0.5469272844159065, Accuracy: 0.5058151538090978, Time Elapsed: 3457.2576682567596 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       912\n",
      "           1       0.59      0.19      0.28       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.56      0.59      0.58       897\n",
      "           4       0.60      0.47      0.53       892\n",
      "           5       0.55      0.03      0.06       862\n",
      "           6       0.63      0.63      0.63       903\n",
      "           7       0.60      0.54      0.57       889\n",
      "           8       0.57      0.47      0.51       892\n",
      "           9       0.49      0.82      0.61       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 16300, Loss: 0.6792012453079224, F1: 0.49850422208182005, Accuracy: 0.49191383937788175, Time Elapsed: 3473.0611951351166 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.59      0.83      0.69       885\n",
      "           2       0.64      0.07      0.13       877\n",
      "           3       0.56      0.65      0.60       897\n",
      "           4       0.61      0.29      0.40       892\n",
      "           5       0.60      0.15      0.23       862\n",
      "           6       0.63      0.52      0.57       903\n",
      "           7       0.57      0.77      0.65       889\n",
      "           8       0.57      0.55      0.56       892\n",
      "           9       0.59      0.37      0.45       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 16400, Loss: 0.4169944226741791, F1: 0.48956677344223004, Accuracy: 0.4937719358612621, Time Elapsed: 3489.035266160965 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.58      0.93      0.72       885\n",
      "           2       0.48      0.01      0.03       877\n",
      "           3       0.57      0.14      0.22       897\n",
      "           4       0.57      0.68      0.62       892\n",
      "           5       0.57      0.15      0.24       862\n",
      "           6       0.62      0.24      0.35       903\n",
      "           7       0.57      0.75      0.65       889\n",
      "           8       0.58      0.44      0.50       892\n",
      "           9       0.61      0.44      0.51       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.47      0.45     14531\n",
      "weighted avg       0.50      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 16500, Loss: 1.013197660446167, F1: 0.45297658221299136, Accuracy: 0.48358681439680684, Time Elapsed: 3504.4478850364685 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.61      0.80      0.70       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.59      0.05      0.09       897\n",
      "           4       0.51      0.90      0.65       892\n",
      "           5       0.58      0.45      0.50       862\n",
      "           6       0.64      0.35      0.46       903\n",
      "           7       0.60      0.56      0.58       889\n",
      "           8       0.59      0.58      0.58       892\n",
      "           9       0.47      0.82      0.60       876\n",
      "          10       0.38      0.33      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.59      0.53     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 16600, Loss: 1.1705729961395264, F1: 0.5333978461335354, Accuracy: 0.5029935998898906, Time Elapsed: 3519.2528591156006 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.61      0.39      0.47       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.55      0.03      0.05       897\n",
      "           4       0.53      0.69      0.60       892\n",
      "           5       0.54      0.63      0.58       862\n",
      "           6       0.64      0.53      0.58       903\n",
      "           7       0.59      0.04      0.07       889\n",
      "           8       0.60      0.40      0.48       892\n",
      "           9       0.63      0.33      0.44       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.46      0.46     14531\n",
      "weighted avg       0.51      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 16700, Loss: 0.8266847133636475, F1: 0.458978630913904, Accuracy: 0.4826921753492533, Time Elapsed: 3533.755356311798 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.59      0.49      0.53       877\n",
      "           3       0.57      0.23      0.33       897\n",
      "           4       0.58      0.74      0.65       892\n",
      "           5       0.57      0.39      0.46       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.65      0.09      0.16       889\n",
      "           8       0.59      0.28      0.38       892\n",
      "           9       0.62      0.39      0.48       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 1, Step 16800, Loss: 0.5464031100273132, F1: 0.4962763293002426, Accuracy: 0.4948042116853623, Time Elapsed: 3548.9265701770782 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.62      0.36      0.46       877\n",
      "           3       0.52      0.12      0.20       897\n",
      "           4       0.55      0.76      0.64       892\n",
      "           5       0.57      0.03      0.06       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.66      0.22      0.33       889\n",
      "           8       0.56      0.61      0.58       892\n",
      "           9       0.51      0.72      0.60       876\n",
      "          10       0.40      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.52      0.49     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 16900, Loss: 1.1497366428375244, F1: 0.4855735426661367, Accuracy: 0.49590530589773585, Time Elapsed: 3564.559671163559 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.66       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.62      0.32      0.42       877\n",
      "           3       0.60      0.45      0.51       897\n",
      "           4       0.62      0.35      0.45       892\n",
      "           5       0.57      0.35      0.44       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.60      0.55      0.58       889\n",
      "           8       0.38      0.91      0.54       892\n",
      "           9       0.47      0.85      0.60       876\n",
      "          10       0.40      0.30      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.59      0.54     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 17000, Loss: 0.716611921787262, F1: 0.5404338600946199, Accuracy: 0.49659348978046935, Time Elapsed: 3579.399730205536 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.58      0.91      0.71       885\n",
      "           2       0.59      0.42      0.49       877\n",
      "           3       0.60      0.53      0.56       897\n",
      "           4       0.61      0.39      0.47       892\n",
      "           5       0.50      0.73      0.60       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.56      0.80      0.66       889\n",
      "           8       0.56      0.66      0.61       892\n",
      "           9       0.44      0.88      0.59       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.49      0.59      0.52     14531\n",
      "weighted avg       0.46      0.50      0.46     14531\n",
      "\n",
      "Epoch 1, Step 17100, Loss: 0.8524736762046814, F1: 0.5210099629364676, Accuracy: 0.4981763127107563, Time Elapsed: 3595.324218273163 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       912\n",
      "           1       0.61      0.09      0.16       885\n",
      "           2       0.58      0.59      0.58       877\n",
      "           3       0.61      0.54      0.57       897\n",
      "           4       0.57      0.68      0.62       892\n",
      "           5       0.54      0.17      0.26       862\n",
      "           6       0.62      0.72      0.66       903\n",
      "           7       0.58      0.31      0.40       889\n",
      "           8       0.57      0.12      0.20       892\n",
      "           9       0.64      0.02      0.04       876\n",
      "          10       0.38      0.66      0.49      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.61      0.35      0.36     14531\n",
      "weighted avg       0.54      0.45      0.40     14531\n",
      "\n",
      "Epoch 1, Step 17200, Loss: 3.3135807514190674, F1: 0.36299301110473237, Accuracy: 0.45378845227444775, Time Elapsed: 3611.18559217453 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.59      0.03      0.05       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.54      0.77      0.64       897\n",
      "           4       0.60      0.37      0.46       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.58      0.86      0.69       903\n",
      "           7       0.56      0.85      0.68       889\n",
      "           8       0.57      0.11      0.18       892\n",
      "           9       0.51      0.75      0.61       876\n",
      "          10       0.38      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.55      0.50     14531\n",
      "weighted avg       0.50      0.50      0.46     14531\n",
      "\n",
      "Epoch 1, Step 17300, Loss: 0.6233159899711609, F1: 0.5007443525730785, Accuracy: 0.49507948523845574, Time Elapsed: 3627.625372171402 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.68       912\n",
      "           1       0.65      0.15      0.24       885\n",
      "           2       0.62      0.46      0.53       877\n",
      "           3       0.61      0.44      0.51       897\n",
      "           4       0.58      0.70      0.63       892\n",
      "           5       0.55      0.29      0.38       862\n",
      "           6       0.61      0.68      0.64       903\n",
      "           7       0.61      0.42      0.50       889\n",
      "           8       0.57      0.56      0.56       892\n",
      "           9       0.47      0.83      0.60       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.52      0.52     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 17400, Loss: 1.6769214868545532, F1: 0.5173124325321579, Accuracy: 0.49542357717982244, Time Elapsed: 3644.714991092682 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69       912\n",
      "           1       0.51      0.99      0.67       885\n",
      "           2       0.61      0.42      0.49       877\n",
      "           3       0.54      0.75      0.63       897\n",
      "           4       0.59      0.63      0.61       892\n",
      "           5       0.56      0.41      0.47       862\n",
      "           6       0.55      0.90      0.68       903\n",
      "           7       0.55      0.85      0.67       889\n",
      "           8       0.52      0.75      0.62       892\n",
      "           9       0.55      0.62      0.59       876\n",
      "          10       0.38      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.58     14531\n",
      "weighted avg       0.49      0.52      0.48     14531\n",
      "\n",
      "Epoch 1, Step 17500, Loss: 0.5362945795059204, F1: 0.5814959228737916, Accuracy: 0.5177895533686601, Time Elapsed: 3661.7752051353455 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.59      0.60      0.59       877\n",
      "           3       0.60      0.62      0.61       897\n",
      "           4       0.59      0.62      0.61       892\n",
      "           5       0.52      0.45      0.48       862\n",
      "           6       0.63      0.69      0.65       903\n",
      "           7       0.63      0.32      0.42       889\n",
      "           8       0.58      0.15      0.24       892\n",
      "           9       0.54      0.68      0.60       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.55      0.54     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 17600, Loss: 0.8157632946968079, F1: 0.5398210790211572, Accuracy: 0.5052646067029111, Time Elapsed: 3677.8139781951904 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.00       912\n",
      "           1       0.59      0.90      0.72       885\n",
      "           2       0.56      0.75      0.64       877\n",
      "           3       0.61      0.51      0.56       897\n",
      "           4       0.58      0.69      0.63       892\n",
      "           5       0.48      0.74      0.58       862\n",
      "           6       0.63      0.58      0.60       903\n",
      "           7       0.61      0.48      0.54       889\n",
      "           8       0.58      0.59      0.59       892\n",
      "           9       0.61      0.53      0.57       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.56      0.53     14531\n",
      "weighted avg       0.49      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 17700, Loss: 2.0572681427001953, F1: 0.5284049887928008, Accuracy: 0.5040946941022642, Time Elapsed: 3695.227246284485 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.57      0.71      0.63       892\n",
      "           5       0.49      0.56      0.53       862\n",
      "           6       0.63      0.68      0.66       903\n",
      "           7       0.59      0.64      0.61       889\n",
      "           8       0.57      0.57      0.57       892\n",
      "           9       0.45      0.88      0.59       876\n",
      "          10       0.38      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.50      0.56      0.52     14531\n",
      "weighted avg       0.46      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 17800, Loss: 1.4420979022979736, F1: 0.5191517240498068, Accuracy: 0.4948042116853623, Time Elapsed: 3711.459631204605 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.60      0.31      0.41       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       1.00      0.00      0.00       897\n",
      "           4       0.61      0.43      0.50       892\n",
      "           5       0.56      0.29      0.38       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.58      0.53      0.55       889\n",
      "           8       0.57      0.46      0.51       892\n",
      "           9       0.60      0.43      0.50       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.61      0.45      0.47     14531\n",
      "weighted avg       0.54      0.48      0.47     14531\n",
      "\n",
      "Epoch 1, Step 17900, Loss: 0.8142619729042053, F1: 0.4718206352181443, Accuracy: 0.48420617989126696, Time Elapsed: 3728.412028312683 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.29      0.40       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.59      0.41      0.48       877\n",
      "           3       0.62      0.28      0.38       897\n",
      "           4       0.58      0.56      0.57       892\n",
      "           5       0.56      0.42      0.48       862\n",
      "           6       0.55      0.91      0.69       903\n",
      "           7       0.64      0.24      0.35       889\n",
      "           8       0.58      0.52      0.55       892\n",
      "           9       0.67      0.22      0.33       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.47      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 18000, Loss: 2.0791544914245605, F1: 0.4875741434120691, Accuracy: 0.48654600509256074, Time Elapsed: 3750.654632329941 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.07      0.13       912\n",
      "           1       0.60      0.64      0.62       885\n",
      "           2       0.48      0.82      0.60       877\n",
      "           3       0.60      0.33      0.43       897\n",
      "           4       0.61      0.37      0.46       892\n",
      "           5       0.56      0.34      0.42       862\n",
      "           6       0.58      0.87      0.70       903\n",
      "           7       0.61      0.36      0.45       889\n",
      "           8       0.58      0.33      0.42       892\n",
      "           9       0.60      0.07      0.13       876\n",
      "          10       0.39      0.54      0.45      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.43      0.44     14531\n",
      "weighted avg       0.51      0.47      0.44     14531\n",
      "\n",
      "Epoch 1, Step 18100, Loss: 0.708750307559967, F1: 0.4385198089131034, Accuracy: 0.4690661344711307, Time Elapsed: 3766.0377111434937 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.56      0.70      0.63       877\n",
      "           3       0.54      0.15      0.24       897\n",
      "           4       0.57      0.71      0.63       892\n",
      "           5       0.52      0.11      0.19       862\n",
      "           6       0.63      0.54      0.58       903\n",
      "           7       0.60      0.68      0.63       889\n",
      "           8       0.59      0.34      0.43       892\n",
      "           9       0.61      0.24      0.35       876\n",
      "          10       0.38      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.52      0.50     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 18200, Loss: 0.9919490218162537, F1: 0.5013809907477751, Accuracy: 0.49514830362672907, Time Elapsed: 3780.797286272049 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.34      0.44       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.62      0.33      0.43       877\n",
      "           3       0.61      0.24      0.34       897\n",
      "           4       0.59      0.54      0.56       892\n",
      "           5       0.55      0.60      0.58       862\n",
      "           6       0.61      0.63      0.62       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.56      0.37      0.45       892\n",
      "           9       0.59      0.45      0.51       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.52      0.42      0.45     14531\n",
      "weighted avg       0.48      0.47      0.46     14531\n",
      "\n",
      "Epoch 1, Step 18300, Loss: 2.251858711242676, F1: 0.45377104656892586, Accuracy: 0.4733328745440782, Time Elapsed: 3796.13626909256 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.61      0.56      0.58       885\n",
      "           2       0.51      0.82      0.63       877\n",
      "           3       0.53      0.07      0.12       897\n",
      "           4       0.56      0.70      0.62       892\n",
      "           5       0.59      0.13      0.22       862\n",
      "           6       0.55      0.88      0.68       903\n",
      "           7       0.65      0.08      0.15       889\n",
      "           8       0.58      0.48      0.53       892\n",
      "           9       0.56      0.65      0.60       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.47     14531\n",
      "weighted avg       0.50      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 18400, Loss: 1.0385940074920654, F1: 0.47443114933026836, Accuracy: 0.48750946252838756, Time Elapsed: 3811.0915350914 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.58      0.66      0.62       897\n",
      "           4       0.59      0.27      0.37       892\n",
      "           5       0.57      0.34      0.43       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.61      0.44      0.51       889\n",
      "           8       0.60      0.36      0.45       892\n",
      "           9       0.49      0.84      0.62       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 18500, Loss: 1.2341718673706055, F1: 0.554353615046214, Accuracy: 0.5135228132957126, Time Elapsed: 3825.7040071487427 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.27      0.00      0.01       885\n",
      "           2       0.64      0.23      0.34       877\n",
      "           3       0.51      0.03      0.06       897\n",
      "           4       0.57      0.82      0.67       892\n",
      "           5       0.58      0.32      0.41       862\n",
      "           6       0.60      0.66      0.63       903\n",
      "           7       0.50      0.95      0.66       889\n",
      "           8       0.56      0.24      0.34       892\n",
      "           9       0.58      0.73      0.65       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.53      0.48      0.45     14531\n",
      "weighted avg       0.48      0.48      0.44     14531\n",
      "\n",
      "Epoch 1, Step 18600, Loss: 1.681744933128357, F1: 0.4453371911839181, Accuracy: 0.48248572018443325, Time Elapsed: 3840.7790582180023 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.72       912\n",
      "           1       0.62      0.37      0.47       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.58      0.53      0.55       897\n",
      "           4       0.55      0.74      0.63       892\n",
      "           5       0.59      0.18      0.27       862\n",
      "           6       0.63      0.67      0.65       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.56      0.26      0.35       892\n",
      "           9       0.59      0.52      0.55       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.53      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 18700, Loss: 1.5835142135620117, F1: 0.5294394260606686, Accuracy: 0.5051269699263643, Time Elapsed: 3855.5484342575073 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.60       912\n",
      "           1       0.62      0.73      0.67       885\n",
      "           2       0.62      0.27      0.37       877\n",
      "           3       0.54      0.75      0.62       897\n",
      "           4       0.49      0.88      0.63       892\n",
      "           5       0.53      0.48      0.50       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.60      0.53      0.56       889\n",
      "           8       0.59      0.46      0.52       892\n",
      "           9       0.58      0.49      0.53       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 18800, Loss: 4.450672149658203, F1: 0.5540413834647151, Accuracy: 0.508430252563485, Time Elapsed: 3870.1714050769806 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.45      0.52       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.57      0.75      0.65       877\n",
      "           3       0.58      0.44      0.50       897\n",
      "           4       0.56      0.69      0.62       892\n",
      "           5       0.57      0.40      0.47       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.56      0.71      0.63       892\n",
      "           9       0.57      0.70      0.63       876\n",
      "          10       0.38      0.35      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 18900, Loss: 0.5967696905136108, F1: 0.5688537254041012, Accuracy: 0.5119399903654256, Time Elapsed: 3884.8724982738495 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.57      0.96      0.71       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.58      0.58      0.58       897\n",
      "           4       0.60      0.29      0.39       892\n",
      "           5       0.54      0.50      0.52       862\n",
      "           6       0.59      0.78      0.67       903\n",
      "           7       0.61      0.57      0.59       889\n",
      "           8       0.57      0.59      0.58       892\n",
      "           9       0.53      0.73      0.61       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 19000, Loss: 0.6148073077201843, F1: 0.5690346749476854, Accuracy: 0.5138669052370793, Time Elapsed: 3899.454092025757 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.59      0.49      0.53       877\n",
      "           3       0.58      0.59      0.58       897\n",
      "           4       0.53      0.83      0.65       892\n",
      "           5       0.54      0.50      0.52       862\n",
      "           6       0.56      0.83      0.67       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.57      0.25      0.35       892\n",
      "           9       0.60      0.45      0.51       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 19100, Loss: 0.7577466368675232, F1: 0.5692468240423757, Accuracy: 0.5184089188631202, Time Elapsed: 3914.7442030906677 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.48      0.54       912\n",
      "           1       0.61      0.51      0.56       885\n",
      "           2       0.50      0.82      0.62       877\n",
      "           3       0.56      0.17      0.27       897\n",
      "           4       0.56      0.75      0.64       892\n",
      "           5       0.70      0.05      0.10       862\n",
      "           6       0.62      0.43      0.51       903\n",
      "           7       0.59      0.76      0.67       889\n",
      "           8       0.57      0.10      0.17       892\n",
      "           9       0.61      0.51      0.56       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.46      0.46     14531\n",
      "weighted avg       0.51      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 19200, Loss: 0.343881756067276, F1: 0.4607596799250176, Accuracy: 0.4797329846534994, Time Elapsed: 3930.4595770835876 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.58      0.93      0.72       885\n",
      "           2       0.56      0.78      0.65       877\n",
      "           3       0.58      0.53      0.56       897\n",
      "           4       0.56      0.75      0.64       892\n",
      "           5       0.57      0.29      0.39       862\n",
      "           6       0.62      0.74      0.68       903\n",
      "           7       0.56      0.86      0.68       889\n",
      "           8       0.56      0.40      0.47       892\n",
      "           9       0.48      0.87      0.62       876\n",
      "          10       0.38      0.24      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 1, Step 19300, Loss: 0.3907598555088043, F1: 0.5805262832807517, Accuracy: 0.5208175624526874, Time Elapsed: 3945.6831312179565 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.58      0.14      0.23       897\n",
      "           4       0.47      0.93      0.63       892\n",
      "           5       0.56      0.43      0.48       862\n",
      "           6       0.63      0.52      0.57       903\n",
      "           7       0.50      0.89      0.64       889\n",
      "           8       0.54      0.17      0.26       892\n",
      "           9       0.63      0.34      0.44       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.55      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 19400, Loss: 0.8509786128997803, F1: 0.5090553132704213, Accuracy: 0.49156974743651505, Time Elapsed: 3960.6308212280273 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.60      0.44      0.51       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.58      0.77      0.66       892\n",
      "           5       0.55      0.58      0.56       862\n",
      "           6       0.60      0.72      0.65       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.56      0.43      0.49       892\n",
      "           9       0.61      0.36      0.46       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 1, Step 19500, Loss: 3.4591336250305176, F1: 0.5661468511891246, Accuracy: 0.518753010804487, Time Elapsed: 3975.961463212967 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.58      0.48      0.52       877\n",
      "           3       0.53      0.81      0.64       897\n",
      "           4       0.56      0.81      0.66       892\n",
      "           5       0.55      0.63      0.58       862\n",
      "           6       0.58      0.81      0.68       903\n",
      "           7       0.58      0.77      0.66       889\n",
      "           8       0.57      0.58      0.58       892\n",
      "           9       0.58      0.55      0.57       876\n",
      "          10       0.38      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 1, Step 19600, Loss: 0.85930335521698, F1: 0.6007995224135357, Accuracy: 0.5294198609868557, Time Elapsed: 3990.4666533470154 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.54      0.82      0.65       877\n",
      "           3       0.55      0.79      0.65       897\n",
      "           4       0.60      0.67      0.64       892\n",
      "           5       0.56      0.61      0.58       862\n",
      "           6       0.57      0.92      0.71       903\n",
      "           7       0.59      0.71      0.65       889\n",
      "           8       0.58      0.53      0.56       892\n",
      "           9       0.58      0.70      0.63       876\n",
      "          10       0.39      0.21      0.27      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 1, Step 19700, Loss: 1.163724422454834, F1: 0.6139778685397108, Accuracy: 0.5395361640630376, Time Elapsed: 4005.7776210308075 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.59      0.56      0.57       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.61      0.44      0.51       892\n",
      "           5       0.56      0.53      0.54       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.59      0.82      0.68       889\n",
      "           8       0.60      0.38      0.46       892\n",
      "           9       0.47      0.84      0.60       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 19800, Loss: 0.6107730865478516, F1: 0.5867599406660058, Accuracy: 0.524533755419448, Time Elapsed: 4021.308351993561 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.56      0.57      0.57       877\n",
      "           3       0.52      0.87      0.65       897\n",
      "           4       0.60      0.62      0.61       892\n",
      "           5       0.56      0.64      0.60       862\n",
      "           6       0.57      0.91      0.70       903\n",
      "           7       0.57      0.82      0.67       889\n",
      "           8       0.59      0.49      0.54       892\n",
      "           9       0.60      0.46      0.52       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 1, Step 19900, Loss: 0.4708186388015747, F1: 0.5987889752256481, Accuracy: 0.5314844126350561, Time Elapsed: 4037.172298192978 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.61      0.86      0.72       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.59      0.64      0.61       897\n",
      "           4       0.60      0.59      0.59       892\n",
      "           5       0.57      0.40      0.47       862\n",
      "           6       0.62      0.74      0.67       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.52      0.79      0.63       892\n",
      "           9       0.64      0.14      0.23       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.57     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 20000, Loss: 0.4979970157146454, F1: 0.5705637320569859, Accuracy: 0.5246025738077215, Time Elapsed: 4053.4200053215027 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.58      0.70      0.64       877\n",
      "           3       0.55      0.78      0.64       897\n",
      "           4       0.61      0.42      0.50       892\n",
      "           5       0.57      0.16      0.25       862\n",
      "           6       0.63      0.43      0.51       903\n",
      "           7       0.63      0.08      0.15       889\n",
      "           8       0.61      0.07      0.12       892\n",
      "           9       0.45      0.79      0.57       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 20100, Loss: 0.6515260934829712, F1: 0.47385699459644715, Accuracy: 0.4888170119055812, Time Elapsed: 4068.1178612709045 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.57      0.75      0.65       877\n",
      "           3       0.52      0.81      0.64       897\n",
      "           4       0.50      0.88      0.64       892\n",
      "           5       0.57      0.16      0.25       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.61      0.43      0.51       889\n",
      "           8       0.52      0.79      0.63       892\n",
      "           9       0.61      0.25      0.36       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.56     14531\n",
      "weighted avg       0.50      0.52      0.48     14531\n",
      "\n",
      "Epoch 1, Step 20200, Loss: 0.7754760980606079, F1: 0.556189008272936, Accuracy: 0.5178583717569335, Time Elapsed: 4084.131897211075 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.16      0.26       912\n",
      "           1       0.53      0.97      0.69       885\n",
      "           2       0.59      0.52      0.55       877\n",
      "           3       0.60      0.57      0.58       897\n",
      "           4       0.46      0.95      0.62       892\n",
      "           5       0.49      0.73      0.59       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.63      0.28      0.39       889\n",
      "           8       0.54      0.69      0.61       892\n",
      "           9       0.57      0.67      0.62       876\n",
      "          10       0.39      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.61      0.54     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 20300, Loss: 1.240021824836731, F1: 0.5384261590052016, Accuracy: 0.49941504369967654, Time Elapsed: 4099.446218013763 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.60      0.62      0.61       877\n",
      "           3       0.58      0.47      0.52       897\n",
      "           4       0.62      0.42      0.50       892\n",
      "           5       0.57      0.41      0.47       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.40      0.90      0.56       892\n",
      "           9       0.66      0.07      0.13       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.46      0.44      0.42     14531\n",
      "weighted avg       0.44      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 20400, Loss: 0.8868150115013123, F1: 0.4163225339854868, Accuracy: 0.4679650402587571, Time Elapsed: 4114.190453052521 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.02      0.04       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.58      0.65      0.62       897\n",
      "           4       0.63      0.35      0.45       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.63      0.61      0.62       903\n",
      "           7       0.63      0.39      0.48       889\n",
      "           8       0.57      0.55      0.56       892\n",
      "           9       0.58      0.57      0.58       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.52      0.52     14531\n",
      "weighted avg       0.53      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 20500, Loss: 2.366136312484741, F1: 0.5169969550375112, Accuracy: 0.5025806895602505, Time Elapsed: 4129.038611412048 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.61      0.51      0.55       877\n",
      "           3       0.59      0.71      0.64       897\n",
      "           4       0.60      0.62      0.61       892\n",
      "           5       0.53      0.59      0.56       862\n",
      "           6       0.63      0.63      0.63       903\n",
      "           7       0.57      0.82      0.67       889\n",
      "           8       0.56      0.73      0.63       892\n",
      "           9       0.59      0.62      0.61       876\n",
      "          10       0.40      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.60     14531\n",
      "weighted avg       0.52      0.53      0.52     14531\n",
      "\n",
      "Epoch 1, Step 20600, Loss: 1.0510544776916504, F1: 0.5975163586309068, Accuracy: 0.5320349597412428, Time Elapsed: 4144.886462211609 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.01      0.02       912\n",
      "           1       0.62      0.75      0.68       885\n",
      "           2       0.59      0.65      0.62       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.58      0.57      0.58       892\n",
      "           5       0.55      0.54      0.54       862\n",
      "           6       0.63      0.34      0.44       903\n",
      "           7       0.58      0.75      0.65       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.58      0.66      0.62       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.54      0.52     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 20700, Loss: 0.9735929369926453, F1: 0.5222844534128567, Accuracy: 0.5010666850182369, Time Elapsed: 4160.814105272293 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.63      0.68      0.65       885\n",
      "           2       0.58      0.29      0.39       877\n",
      "           3       0.53      0.85      0.65       897\n",
      "           4       0.57      0.76      0.65       892\n",
      "           5       0.56      0.11      0.19       862\n",
      "           6       0.61      0.83      0.70       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.61      0.30      0.41       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.52      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.46      0.46      0.43     14531\n",
      "weighted avg       0.44      0.48      0.44     14531\n",
      "\n",
      "Epoch 1, Step 20800, Loss: 1.1997294425964355, F1: 0.43065955619028445, Accuracy: 0.4813846259720597, Time Elapsed: 4176.820930242538 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.70       912\n",
      "           1       0.60      0.04      0.08       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.59      0.68      0.63       897\n",
      "           4       0.58      0.48      0.52       892\n",
      "           5       0.57      0.13      0.21       862\n",
      "           6       0.64      0.45      0.53       903\n",
      "           7       0.61      0.58      0.60       889\n",
      "           8       0.54      0.63      0.58       892\n",
      "           9       0.59      0.59      0.59       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 20900, Loss: 0.7268274426460266, F1: 0.49528128170426594, Accuracy: 0.4952171220150024, Time Elapsed: 4192.528631210327 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.55      0.98      0.71       885\n",
      "           2       0.57      0.73      0.64       877\n",
      "           3       0.59      0.71      0.65       897\n",
      "           4       0.59      0.47      0.52       892\n",
      "           5       0.56      0.15      0.24       862\n",
      "           6       0.61      0.85      0.71       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.57      0.29      0.38       892\n",
      "           9       0.60      0.43      0.50       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 1, Step 21000, Loss: 0.40963777899742126, F1: 0.5536636465662202, Accuracy: 0.5168949143211066, Time Elapsed: 4208.63756108284 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.60      0.29      0.39       897\n",
      "           4       0.58      0.73      0.65       892\n",
      "           5       0.60      0.05      0.09       862\n",
      "           6       0.60      0.82      0.70       903\n",
      "           7       0.60      0.68      0.63       889\n",
      "           8       0.57      0.48      0.52       892\n",
      "           9       0.55      0.72      0.63       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 21100, Loss: 1.1164135932922363, F1: 0.5246573908987171, Accuracy: 0.5049205147615443, Time Elapsed: 4223.58807516098 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       912\n",
      "           1       0.58      0.93      0.72       885\n",
      "           2       0.57      0.53      0.55       877\n",
      "           3       0.57      0.72      0.64       897\n",
      "           4       0.58      0.73      0.65       892\n",
      "           5       0.56      0.47      0.51       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.59      0.76      0.67       889\n",
      "           8       0.56      0.15      0.24       892\n",
      "           9       0.56      0.66      0.61       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 21200, Loss: 1.0573261976242065, F1: 0.575206236922977, Accuracy: 0.5237767531484413, Time Elapsed: 4238.285116195679 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.51      0.82      0.63       877\n",
      "           3       0.59      0.66      0.63       897\n",
      "           4       0.63      0.19      0.30       892\n",
      "           5       0.48      0.76      0.59       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.50      0.00      0.00       892\n",
      "           9       0.48      0.82      0.61       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.58      0.51     14531\n",
      "weighted avg       0.50      0.50      0.46     14531\n",
      "\n",
      "Epoch 1, Step 21300, Loss: 0.7423765659332275, F1: 0.5134123889631199, Accuracy: 0.498313949487303, Time Elapsed: 4253.804592132568 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.20       912\n",
      "           1       0.61      0.67      0.63       885\n",
      "           2       0.59      0.37      0.45       877\n",
      "           3       0.61      0.59      0.60       897\n",
      "           4       0.62      0.18      0.28       892\n",
      "           5       0.57      0.53      0.55       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.61      0.72      0.66       889\n",
      "           8       0.59      0.51      0.55       892\n",
      "           9       0.58      0.56      0.57       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.49      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 21400, Loss: 1.9830946922302246, F1: 0.5074760761505366, Accuracy: 0.49631821622737593, Time Elapsed: 4269.757110118866 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.35      0.46       912\n",
      "           1       0.61      0.75      0.67       885\n",
      "           2       0.59      0.33      0.42       877\n",
      "           3       0.59      0.64      0.62       897\n",
      "           4       0.54      0.81      0.65       892\n",
      "           5       0.58      0.38      0.46       862\n",
      "           6       0.62      0.54      0.58       903\n",
      "           7       0.57      0.81      0.67       889\n",
      "           8       0.59      0.46      0.52       892\n",
      "           9       0.61      0.44      0.51       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.54     14531\n",
      "weighted avg       0.52      0.50      0.50     14531\n",
      "\n",
      "Epoch 1, Step 21500, Loss: 0.8077003359794617, F1: 0.5418072814342703, Accuracy: 0.5042323308788108, Time Elapsed: 4285.142764091492 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.50      0.00      0.00       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.60      0.44      0.51       897\n",
      "           4       0.58      0.51      0.54       892\n",
      "           5       0.57      0.30      0.39       862\n",
      "           6       0.62      0.10      0.18       903\n",
      "           7       0.56      0.85      0.67       889\n",
      "           8       0.52      0.76      0.62       892\n",
      "           9       0.61      0.57      0.59       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.49      0.48     14531\n",
      "weighted avg       0.50      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 21600, Loss: 1.7728458642959595, F1: 0.4756291993369661, Accuracy: 0.4872341889752942, Time Elapsed: 4300.235185146332 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.61      0.51      0.56       885\n",
      "           2       0.55      0.76      0.64       877\n",
      "           3       0.52      0.86      0.65       897\n",
      "           4       0.55      0.71      0.62       892\n",
      "           5       0.59      0.30      0.40       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.59      0.41      0.49       892\n",
      "           9       0.60      0.56      0.58       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 21700, Loss: 1.047255516052246, F1: 0.5759555428518316, Accuracy: 0.5206799256761406, Time Elapsed: 4314.894415140152 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.73       912\n",
      "           1       0.61      0.38      0.47       885\n",
      "           2       0.59      0.43      0.50       877\n",
      "           3       0.60      0.52      0.56       897\n",
      "           4       0.59      0.55      0.57       892\n",
      "           5       0.56      0.45      0.50       862\n",
      "           6       0.62      0.77      0.69       903\n",
      "           7       0.61      0.50      0.55       889\n",
      "           8       0.58      0.67      0.62       892\n",
      "           9       0.58      0.66      0.62       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.57      0.56     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 1, Step 21800, Loss: 1.0338637828826904, F1: 0.5629625909295869, Accuracy: 0.5153120913908197, Time Elapsed: 4330.636952161789 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.58      0.62      0.60       877\n",
      "           3       0.53      0.85      0.66       897\n",
      "           4       0.59      0.50      0.54       892\n",
      "           5       0.57      0.14      0.23       862\n",
      "           6       0.63      0.69      0.66       903\n",
      "           7       0.59      0.68      0.63       889\n",
      "           8       0.60      0.36      0.45       892\n",
      "           9       0.59      0.45      0.51       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 21900, Loss: 0.535881757736206, F1: 0.5469800628594556, Accuracy: 0.5118711719771523, Time Elapsed: 4346.343681097031 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66       912\n",
      "           1       0.61      0.68      0.64       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.60      0.61      0.60       897\n",
      "           4       0.59      0.71      0.64       892\n",
      "           5       0.57      0.40      0.47       862\n",
      "           6       0.61      0.76      0.67       903\n",
      "           7       0.62      0.43      0.51       889\n",
      "           8       0.60      0.46      0.52       892\n",
      "           9       0.60      0.53      0.56       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.56      0.57     14531\n",
      "weighted avg       0.52      0.52      0.52     14531\n",
      "\n",
      "Epoch 1, Step 22000, Loss: 0.8467578291893005, F1: 0.5665619170093104, Accuracy: 0.5179271901452068, Time Elapsed: 4361.251926183701 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       912\n",
      "           1       0.62      0.65      0.63       885\n",
      "           2       0.60      0.45      0.51       877\n",
      "           3       0.52      0.07      0.12       897\n",
      "           4       0.60      0.44      0.51       892\n",
      "           5       0.59      0.14      0.23       862\n",
      "           6       0.60      0.13      0.21       903\n",
      "           7       0.59      0.69      0.64       889\n",
      "           8       0.60      0.41      0.49       892\n",
      "           9       0.63      0.28      0.39       876\n",
      "          10       0.39      0.67      0.49      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.61      0.36      0.38     14531\n",
      "weighted avg       0.54      0.46      0.42     14531\n",
      "\n",
      "Epoch 1, Step 22100, Loss: 0.6935288310050964, F1: 0.38451391055180245, Accuracy: 0.4594315601128622, Time Elapsed: 4376.205197095871 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.50      0.01      0.01       897\n",
      "           4       0.60      0.62      0.61       892\n",
      "           5       0.58      0.27      0.37       862\n",
      "           6       0.61      0.13      0.21       903\n",
      "           7       0.61      0.57      0.59       889\n",
      "           8       0.56      0.67      0.61       892\n",
      "           9       0.52      0.83      0.64       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.49     14531\n",
      "weighted avg       0.50      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 22200, Loss: 0.8812829256057739, F1: 0.48557520468848286, Accuracy: 0.49198265776615513, Time Elapsed: 4391.804654121399 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       912\n",
      "           1       0.62      0.49      0.54       885\n",
      "           2       0.57      0.78      0.66       877\n",
      "           3       0.59      0.45      0.51       897\n",
      "           4       0.90      0.01      0.02       892\n",
      "           5       0.56      0.12      0.19       862\n",
      "           6       0.63      0.27      0.38       903\n",
      "           7       0.61      0.47      0.53       889\n",
      "           8       0.58      0.40      0.47       892\n",
      "           9       0.51      0.45      0.48       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.60      0.41      0.44     14531\n",
      "weighted avg       0.53      0.47      0.45     14531\n",
      "\n",
      "Epoch 1, Step 22300, Loss: 0.7168481349945068, F1: 0.4370317405072596, Accuracy: 0.47051132062487094, Time Elapsed: 4406.805517196655 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69       912\n",
      "           1       0.62      0.67      0.64       885\n",
      "           2       0.63      0.43      0.51       877\n",
      "           3       0.61      0.49      0.54       897\n",
      "           4       0.60      0.58      0.59       892\n",
      "           5       0.56      0.41      0.48       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.58      0.64      0.61       892\n",
      "           9       0.55      0.52      0.53       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 1, Step 22400, Loss: 0.47777116298675537, F1: 0.5637037752315558, Accuracy: 0.515587364943913, Time Elapsed: 4421.3996040821075 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.60      0.39      0.47       877\n",
      "           3       0.55      0.69      0.61       897\n",
      "           4       0.57      0.78      0.66       892\n",
      "           5       0.57      0.43      0.49       862\n",
      "           6       0.63      0.45      0.52       903\n",
      "           7       0.52      0.90      0.66       889\n",
      "           8       0.57      0.34      0.43       892\n",
      "           9       0.59      0.58      0.58       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 22500, Loss: 1.4097540378570557, F1: 0.564182652319499, Accuracy: 0.514004542013626, Time Elapsed: 4436.791557312012 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       912\n",
      "           1       0.61      0.17      0.26       885\n",
      "           2       0.65      0.09      0.15       877\n",
      "           3       0.58      0.62      0.60       897\n",
      "           4       0.60      0.61      0.60       892\n",
      "           5       0.56      0.31      0.40       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.56      0.12      0.20       892\n",
      "           9       0.58      0.43      0.49       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.48      0.47     14531\n",
      "weighted avg       0.52      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 22600, Loss: 0.27167192101478577, F1: 0.4722343217572703, Accuracy: 0.4909503819420549, Time Elapsed: 4452.271347999573 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.62      0.31      0.42       877\n",
      "           3       0.60      0.35      0.44       897\n",
      "           4       0.49      0.92      0.64       892\n",
      "           5       0.56      0.63      0.60       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.59      0.46      0.52       892\n",
      "           9       0.57      0.66      0.61       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 22700, Loss: 0.9196133613586426, F1: 0.567411073764491, Accuracy: 0.5164820039914665, Time Elapsed: 4467.569089174271 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.63      0.23      0.34       885\n",
      "           2       0.58      0.70      0.64       877\n",
      "           3       0.56      0.14      0.23       897\n",
      "           4       0.58      0.46      0.51       892\n",
      "           5       0.39      0.89      0.54       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.60      0.39      0.47       892\n",
      "           9       0.45      0.87      0.59       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.57      0.52     14531\n",
      "weighted avg       0.50      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 22800, Loss: 0.8669561147689819, F1: 0.5168995131986921, Accuracy: 0.48819764641112107, Time Elapsed: 4482.454294204712 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.69       912\n",
      "           1       0.33      0.00      0.00       885\n",
      "           2       0.49      0.74      0.59       877\n",
      "           3       0.60      0.16      0.25       897\n",
      "           4       0.56      0.66      0.61       892\n",
      "           5       0.52      0.54      0.53       862\n",
      "           6       0.62      0.63      0.63       903\n",
      "           7       0.61      0.43      0.51       889\n",
      "           8       0.60      0.35      0.44       892\n",
      "           9       0.56      0.73      0.63       876\n",
      "          10       0.38      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.53      0.51      0.48     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 22900, Loss: 0.1776837557554245, F1: 0.47954121811930733, Accuracy: 0.4817287179134265, Time Elapsed: 4497.836316347122 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.58      0.68      0.63       897\n",
      "           4       0.51      0.87      0.64       892\n",
      "           5       0.53      0.57      0.55       862\n",
      "           6       0.63      0.37      0.47       903\n",
      "           7       0.63      0.27      0.38       889\n",
      "           8       0.60      0.42      0.50       892\n",
      "           9       0.59      0.66      0.63       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 23000, Loss: 0.6696901917457581, F1: 0.5553119707556311, Accuracy: 0.5096689835524052, Time Elapsed: 4513.5030472278595 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       912\n",
      "           1       0.58      0.15      0.24       885\n",
      "           2       0.64      0.05      0.10       877\n",
      "           3       0.59      0.57      0.58       897\n",
      "           4       0.63      0.34      0.44       892\n",
      "           5       0.68      0.04      0.08       862\n",
      "           6       0.61      0.54      0.58       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.59      0.48      0.53       892\n",
      "           9       0.53      0.74      0.62       876\n",
      "          10       0.39      0.57      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.59      0.44      0.44     14531\n",
      "weighted avg       0.52      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 23100, Loss: 0.7386677861213684, F1: 0.4446594276552263, Accuracy: 0.4811781708072397, Time Elapsed: 4530.043892145157 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.62      0.46      0.53       885\n",
      "           2       0.58      0.61      0.59       877\n",
      "           3       0.51      0.87      0.64       897\n",
      "           4       0.61      0.33      0.43       892\n",
      "           5       0.57      0.52      0.54       862\n",
      "           6       0.63      0.63      0.63       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.58      0.67      0.62       892\n",
      "           9       0.53      0.82      0.65       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 23200, Loss: 0.9827738404273987, F1: 0.5779846245106159, Accuracy: 0.5204046521230473, Time Elapsed: 4545.735733032227 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.71       912\n",
      "           1       0.62      0.38      0.47       885\n",
      "           2       0.61      0.47      0.53       877\n",
      "           3       0.58      0.63      0.61       897\n",
      "           4       0.61      0.53      0.57       892\n",
      "           5       0.57      0.21      0.31       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.59      0.65      0.62       889\n",
      "           8       0.50      0.74      0.59       892\n",
      "           9       0.48      0.88      0.62       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 23300, Loss: 0.4115927219390869, F1: 0.5487920358450763, Accuracy: 0.5069162480214713, Time Elapsed: 4561.524015188217 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.64      0.53      0.58       885\n",
      "           2       0.62      0.31      0.41       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.62      0.03      0.05       892\n",
      "           5       0.56      0.30      0.39       862\n",
      "           6       0.65      0.34      0.45       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.60      0.30      0.40       892\n",
      "           9       0.59      0.63      0.61       876\n",
      "          10       0.39      0.54      0.46      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.59      0.46      0.48     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 23400, Loss: 0.5955274105072021, F1: 0.47676714703551165, Accuracy: 0.48964283256486135, Time Elapsed: 4576.978909254074 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.60      0.75      0.66       885\n",
      "           2       0.61      0.24      0.34       877\n",
      "           3       0.58      0.72      0.64       897\n",
      "           4       0.59      0.10      0.17       892\n",
      "           5       0.48      0.82      0.60       862\n",
      "           6       0.59      0.79      0.68       903\n",
      "           7       0.57      0.83      0.68       889\n",
      "           8       0.57      0.12      0.20       892\n",
      "           9       0.61      0.50      0.55       876\n",
      "          10       0.40      0.39      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.56      0.51     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 23500, Loss: 1.4048984050750732, F1: 0.5135721487846372, Accuracy: 0.5062280641387379, Time Elapsed: 4591.645740032196 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.64      0.10      0.18       877\n",
      "           3       0.60      0.24      0.35       897\n",
      "           4       0.60      0.58      0.59       892\n",
      "           5       0.56      0.20      0.29       862\n",
      "           6       0.57      0.84      0.68       903\n",
      "           7       0.60      0.22      0.32       889\n",
      "           8       0.59      0.12      0.19       892\n",
      "           9       0.59      0.73      0.65       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.49      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 23600, Loss: 5.133872985839844, F1: 0.4659897487615756, Accuracy: 0.49150092904824166, Time Elapsed: 4606.0710163116455 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.69       912\n",
      "           1       0.61      0.49      0.54       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.58      0.60      0.59       897\n",
      "           4       0.59      0.70      0.64       892\n",
      "           5       0.55      0.19      0.28       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.61      0.42      0.49       889\n",
      "           8       0.56      0.09      0.16       892\n",
      "           9       0.41      0.90      0.56       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 23700, Loss: 0.24254244565963745, F1: 0.5089201338967856, Accuracy: 0.49005574289450143, Time Elapsed: 4622.973166227341 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.63      0.34      0.44       877\n",
      "           3       0.55      0.07      0.12       897\n",
      "           4       0.54      0.85      0.66       892\n",
      "           5       0.55      0.50      0.53       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.55      0.65      0.59       892\n",
      "           9       0.58      0.64      0.61       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 1, Step 23800, Loss: 0.4099142551422119, F1: 0.5520196359451823, Accuracy: 0.5165508223797398, Time Elapsed: 5351.870916128159 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.02      0.04       912\n",
      "           1       0.61      0.82      0.70       885\n",
      "           2       0.60      0.38      0.46       877\n",
      "           3       0.55      0.13      0.21       897\n",
      "           4       0.60      0.60      0.60       892\n",
      "           5       0.58      0.13      0.21       862\n",
      "           6       0.63      0.49      0.55       903\n",
      "           7       0.62      0.35      0.45       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.62      0.42      0.50       876\n",
      "          10       0.39      0.67      0.49      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.54      0.36      0.38     14531\n",
      "weighted avg       0.49      0.46      0.42     14531\n",
      "\n",
      "Epoch 1, Step 23900, Loss: 1.061922311782837, F1: 0.3832569176021243, Accuracy: 0.46369830018580965, Time Elapsed: 5370.8088092803955 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.60      0.41      0.49       877\n",
      "           3       0.59      0.68      0.63       897\n",
      "           4       0.46      0.92      0.61       892\n",
      "           5       0.55      0.60      0.57       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.63      0.49      0.55       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.57      0.58       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.45      0.52      0.48     14531\n",
      "weighted avg       0.43      0.49      0.45     14531\n",
      "\n",
      "Epoch 1, Step 24000, Loss: 0.17836138606071472, F1: 0.47541288810697996, Accuracy: 0.48964283256486135, Time Elapsed: 5387.783933162689 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.61      0.36      0.45       877\n",
      "           3       0.59      0.68      0.63       897\n",
      "           4       0.58      0.72      0.64       892\n",
      "           5       0.55      0.18      0.28       862\n",
      "           6       0.62      0.42      0.50       903\n",
      "           7       0.62      0.07      0.13       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.56      0.74      0.63       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.46      0.43      0.41     14531\n",
      "weighted avg       0.44      0.47      0.42     14531\n",
      "\n",
      "Epoch 1, Step 24100, Loss: 1.920084834098816, F1: 0.40518505344442757, Accuracy: 0.4720253251668846, Time Elapsed: 5404.815759181976 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.56       912\n",
      "           1       0.61      0.88      0.72       885\n",
      "           2       0.59      0.70      0.64       877\n",
      "           3       0.59      0.61      0.60       897\n",
      "           4       0.60      0.63      0.61       892\n",
      "           5       0.56      0.44      0.49       862\n",
      "           6       0.62      0.53      0.57       903\n",
      "           7       0.56      0.83      0.67       889\n",
      "           8       0.57      0.70      0.63       892\n",
      "           9       0.59      0.42      0.49       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 1, Step 24200, Loss: 1.3070157766342163, F1: 0.5777052148712031, Accuracy: 0.5192347395224004, Time Elapsed: 5422.7292573452 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.61      0.49      0.55       885\n",
      "           2       0.58      0.61      0.60       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.60      0.62      0.61       892\n",
      "           5       0.57      0.52      0.55       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.60      0.45      0.51       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.59      0.58     14531\n",
      "weighted avg       0.52      0.52      0.52     14531\n",
      "\n",
      "Epoch 1, Step 24300, Loss: 0.7207112312316895, F1: 0.5797772138086259, Accuracy: 0.5210240176175074, Time Elapsed: 5438.7283091545105 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.57      0.29      0.38       897\n",
      "           4       0.58      0.34      0.43       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.61      0.03      0.06       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       1.00      0.01      0.02       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.56      0.41      0.40     14531\n",
      "weighted avg       0.50      0.47      0.43     14531\n",
      "\n",
      "Epoch 1, Step 24400, Loss: 1.8597675561904907, F1: 0.4045373064870839, Accuracy: 0.47119950450760445, Time Elapsed: 5454.580825090408 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.91      0.68       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.58      0.54      0.56       897\n",
      "           4       0.58      0.62      0.60       892\n",
      "           5       0.57      0.20      0.30       862\n",
      "           6       0.62      0.74      0.68       903\n",
      "           7       0.58      0.74      0.65       889\n",
      "           8       0.60      0.43      0.50       892\n",
      "           9       0.69      0.05      0.09       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.52     14531\n",
      "weighted avg       0.52      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 24500, Loss: 0.3804824948310852, F1: 0.5216278350833873, Accuracy: 0.5067786112449246, Time Elapsed: 5470.203194141388 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.69       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.55      0.76      0.64       877\n",
      "           3       0.58      0.54      0.56       897\n",
      "           4       0.53      0.77      0.63       892\n",
      "           5       0.52      0.60      0.56       862\n",
      "           6       0.63      0.76      0.68       903\n",
      "           7       0.62      0.42      0.50       889\n",
      "           8       0.59      0.48      0.53       892\n",
      "           9       0.63      0.26      0.37       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 24600, Loss: 2.841763973236084, F1: 0.5673027716418807, Accuracy: 0.5165508223797398, Time Elapsed: 5486.198887348175 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.51      0.82      0.63       897\n",
      "           4       0.52      0.85      0.65       892\n",
      "           5       0.59      0.18      0.27       862\n",
      "           6       0.63      0.61      0.62       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.48      0.81      0.60       892\n",
      "           9       0.62      0.23      0.33       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 24700, Loss: 1.7992315292358398, F1: 0.5478159476352729, Accuracy: 0.5113206248709655, Time Elapsed: 5504.664839267731 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.61      0.49      0.54       897\n",
      "           4       0.56      0.77      0.65       892\n",
      "           5       0.55      0.35      0.43       862\n",
      "           6       0.58      0.84      0.69       903\n",
      "           7       0.55      0.83      0.66       889\n",
      "           8       0.59      0.41      0.49       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.58      0.53     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 24800, Loss: 1.9584954977035522, F1: 0.5288971866751294, Accuracy: 0.5109765329295988, Time Elapsed: 5522.115790128708 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       912\n",
      "           1       0.58      0.92      0.71       885\n",
      "           2       0.61      0.33      0.43       877\n",
      "           3       0.58      0.27      0.37       897\n",
      "           4       0.57      0.83      0.68       892\n",
      "           5       0.59      0.22      0.32       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.50      0.77      0.61       892\n",
      "           9       0.61      0.60      0.60       876\n",
      "          10       0.40      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 24900, Loss: 0.2477983832359314, F1: 0.5569108988490066, Accuracy: 0.518753010804487, Time Elapsed: 5539.820263147354 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.33      0.43       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.58      0.55      0.57       877\n",
      "           3       0.60      0.63      0.61       897\n",
      "           4       0.57      0.74      0.64       892\n",
      "           5       0.62      0.05      0.10       862\n",
      "           6       0.63      0.62      0.62       903\n",
      "           7       0.58      0.74      0.65       889\n",
      "           8       0.57      0.13      0.21       892\n",
      "           9       0.64      0.11      0.18       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.48      0.47     14531\n",
      "weighted avg       0.52      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 25000, Loss: 1.1734364032745361, F1: 0.4713513514856748, Accuracy: 0.4923267497075218, Time Elapsed: 5554.933268070221 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.58      0.43      0.49       877\n",
      "           3       0.62      0.45      0.52       897\n",
      "           4       0.53      0.72      0.61       892\n",
      "           5       0.60      0.21      0.31       862\n",
      "           6       0.58      0.84      0.69       903\n",
      "           7       0.60      0.51      0.55       889\n",
      "           8       0.60      0.38      0.47       892\n",
      "           9       0.59      0.38      0.46       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.55      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 25100, Loss: 0.40680190920829773, F1: 0.5379847077124086, Accuracy: 0.5089119812813984, Time Elapsed: 5569.6794691085815 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.57      0.96      0.71       885\n",
      "           2       0.58      0.45      0.51       877\n",
      "           3       0.58      0.59      0.58       897\n",
      "           4       0.59      0.47      0.52       892\n",
      "           5       0.58      0.33      0.42       862\n",
      "           6       0.62      0.59      0.61       903\n",
      "           7       0.59      0.01      0.03       889\n",
      "           8       0.88      0.01      0.02       892\n",
      "           9       0.48      0.88      0.62       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.59      0.51      0.47     14531\n",
      "weighted avg       0.52      0.49      0.45     14531\n",
      "\n",
      "Epoch 1, Step 25200, Loss: 0.7233713269233704, F1: 0.46787866448762755, Accuracy: 0.48744064414011423, Time Elapsed: 5584.99076128006 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.61      0.88      0.72       885\n",
      "           2       0.60      0.36      0.45       877\n",
      "           3       0.59      0.56      0.58       897\n",
      "           4       0.58      0.63      0.61       892\n",
      "           5       0.63      0.13      0.22       862\n",
      "           6       0.59      0.77      0.67       903\n",
      "           7       0.62      0.23      0.34       889\n",
      "           8       0.56      0.14      0.22       892\n",
      "           9       0.63      0.30      0.41       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.49      0.49     14531\n",
      "weighted avg       0.52      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 25300, Loss: 0.2189921885728836, F1: 0.4869613828604545, Accuracy: 0.4961805794508293, Time Elapsed: 5599.721118211746 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       912\n",
      "           1       0.59      0.83      0.69       885\n",
      "           2       0.63      0.27      0.37       877\n",
      "           3       0.55      0.12      0.20       897\n",
      "           4       0.54      0.84      0.66       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.60      0.34      0.44       903\n",
      "           7       0.56      0.07      0.13       889\n",
      "           8       0.58      0.17      0.26       892\n",
      "           9       0.63      0.31      0.42       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.41      0.43     14531\n",
      "weighted avg       0.51      0.47      0.44     14531\n",
      "\n",
      "Epoch 1, Step 25400, Loss: 1.2604799270629883, F1: 0.4297883980793188, Accuracy: 0.4705801390131443, Time Elapsed: 5615.198386192322 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.56      0.97      0.71       885\n",
      "           2       0.55      0.77      0.64       877\n",
      "           3       0.60      0.59      0.59       897\n",
      "           4       0.57      0.78      0.66       892\n",
      "           5       0.56      0.61      0.59       862\n",
      "           6       0.56      0.93      0.70       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.55      0.05      0.10       892\n",
      "           9       0.62      0.36      0.46       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.56     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 1, Step 25500, Loss: 1.1544181108474731, F1: 0.5561275307741534, Accuracy: 0.5203358337347739, Time Elapsed: 5631.033472061157 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.60      0.82      0.70       885\n",
      "           2       0.55      0.69      0.61       877\n",
      "           3       0.61      0.56      0.58       897\n",
      "           4       0.60      0.55      0.57       892\n",
      "           5       0.56      0.59      0.58       862\n",
      "           6       0.58      0.82      0.68       903\n",
      "           7       0.59      0.69      0.64       889\n",
      "           8       0.60      0.33      0.43       892\n",
      "           9       0.60      0.54      0.57       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 1, Step 25600, Loss: 0.7084522843360901, F1: 0.5827868685509461, Accuracy: 0.5239832083132613, Time Elapsed: 5645.949129104614 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.63      0.28      0.39       877\n",
      "           3       0.57      0.14      0.23       897\n",
      "           4       0.58      0.66      0.62       892\n",
      "           5       0.58      0.19      0.28       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.59      0.76      0.66       889\n",
      "           8       0.58      0.51      0.55       892\n",
      "           9       0.60      0.54      0.57       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 1, Step 25700, Loss: 0.4511633515357971, F1: 0.5274097203456488, Accuracy: 0.5102883490468654, Time Elapsed: 5660.840628147125 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.61      0.62      0.62       885\n",
      "           2       0.58      0.46      0.51       877\n",
      "           3       0.58      0.19      0.29       897\n",
      "           4       0.59      0.35      0.44       892\n",
      "           5       0.46      0.75      0.57       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.60      0.19      0.29       889\n",
      "           8       0.56      0.10      0.17       892\n",
      "           9       0.59      0.62      0.60       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.49      0.48     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 25800, Loss: 2.0326414108276367, F1: 0.4825533090275439, Accuracy: 0.48702773381047415, Time Elapsed: 5676.101556062698 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.15      0.24       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.62      0.34      0.44       877\n",
      "           3       0.59      0.51      0.55       897\n",
      "           4       0.58      0.21      0.31       892\n",
      "           5       0.56      0.24      0.34       862\n",
      "           6       0.53      0.01      0.02       903\n",
      "           7       0.58      0.68      0.63       889\n",
      "           8       0.71      0.01      0.01       892\n",
      "           9       0.45      0.77      0.57       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.57      0.40      0.39     14531\n",
      "weighted avg       0.51      0.46      0.41     14531\n",
      "\n",
      "Epoch 1, Step 25900, Loss: 0.6219429969787598, F1: 0.3899364186923917, Accuracy: 0.45826164751221526, Time Elapsed: 5690.677087068558 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.15      0.24       912\n",
      "           1       0.54      0.98      0.69       885\n",
      "           2       0.58      0.65      0.61       877\n",
      "           3       0.62      0.18      0.28       897\n",
      "           4       0.63      0.29      0.39       892\n",
      "           5       0.56      0.23      0.33       862\n",
      "           6       0.61      0.30      0.41       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.61      0.27      0.37       892\n",
      "           9       0.59      0.38      0.46       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.58      0.42      0.44     14531\n",
      "weighted avg       0.51      0.47      0.45     14531\n",
      "\n",
      "Epoch 1, Step 26000, Loss: 0.612220048904419, F1: 0.4427272747113214, Accuracy: 0.47016722868350425, Time Elapsed: 5705.441449403763 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.56      0.11      0.19       897\n",
      "           4       0.57      0.22      0.31       892\n",
      "           5       0.43      0.68      0.53       862\n",
      "           6       0.63      0.30      0.40       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.54      0.65      0.59       892\n",
      "           9       0.62      0.09      0.15       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.47      0.47     14531\n",
      "weighted avg       0.50      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 26100, Loss: 2.0493316650390625, F1: 0.4657213843781997, Accuracy: 0.4771867042873856, Time Elapsed: 5720.691041231155 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.38      0.48       912\n",
      "           1       0.58      0.96      0.72       885\n",
      "           2       0.47      0.85      0.61       877\n",
      "           3       0.53      0.79      0.64       897\n",
      "           4       0.58      0.49      0.53       892\n",
      "           5       0.55      0.39      0.46       862\n",
      "           6       0.63      0.51      0.56       903\n",
      "           7       0.54      0.87      0.66       889\n",
      "           8       0.58      0.50      0.54       892\n",
      "           9       0.60      0.45      0.51       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.59      0.55     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 26200, Loss: 1.5938640832901, F1: 0.5503339056612743, Accuracy: 0.5025806895602505, Time Elapsed: 5735.629937171936 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       912\n",
      "           1       0.59      0.91      0.71       885\n",
      "           2       0.53      0.76      0.62       877\n",
      "           3       0.54      0.11      0.18       897\n",
      "           4       0.58      0.74      0.65       892\n",
      "           5       0.58      0.11      0.18       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.49      0.66      0.56       892\n",
      "           9       0.59      0.55      0.57       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.58      0.53     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 26300, Loss: 0.502835750579834, F1: 0.5302715780289501, Accuracy: 0.507260339962838, Time Elapsed: 5750.943241119385 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.62      0.45      0.52       877\n",
      "           3       0.60      0.45      0.51       897\n",
      "           4       0.55      0.65      0.60       892\n",
      "           5       0.52      0.43      0.47       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.52      0.87      0.65       889\n",
      "           8       0.58      0.41      0.48       892\n",
      "           9       0.61      0.21      0.32       876\n",
      "          10       0.40      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 26400, Loss: 1.1434506177902222, F1: 0.549475587049211, Accuracy: 0.5118711719771523, Time Elapsed: 5768.344147205353 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       912\n",
      "           1       0.61      0.64      0.62       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.52      0.73      0.61       897\n",
      "           4       0.60      0.54      0.57       892\n",
      "           5       0.58      0.13      0.21       862\n",
      "           6       0.61      0.27      0.37       903\n",
      "           7       0.60      0.60      0.60       889\n",
      "           8       0.51      0.74      0.60       892\n",
      "           9       0.59      0.60      0.59       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.52     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 26500, Loss: 1.0099680423736572, F1: 0.5241603114955166, Accuracy: 0.49556121395636915, Time Elapsed: 5787.415704250336 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.58      0.97      0.72       885\n",
      "           2       0.56      0.71      0.63       877\n",
      "           3       0.58      0.64      0.61       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.58      0.40      0.47       862\n",
      "           6       0.62      0.55      0.58       903\n",
      "           7       0.60      0.25      0.35       889\n",
      "           8       0.56      0.76      0.64       892\n",
      "           9       0.71      0.07      0.12       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.58      0.53     14531\n",
      "weighted avg       0.52      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 26600, Loss: 0.4444721043109894, F1: 0.5337327703245396, Accuracy: 0.5111829880944189, Time Elapsed: 5803.1386733055115 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.63      0.10      0.17       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.61      0.40      0.48       892\n",
      "           5       0.58      0.47      0.52       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.65      0.08      0.14       889\n",
      "           8       0.61      0.45      0.52       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.65      0.49      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.48      0.38      0.38     14531\n",
      "weighted avg       0.45      0.47      0.42     14531\n",
      "\n",
      "Epoch 1, Step 26700, Loss: 0.9911185503005981, F1: 0.3812241504802154, Accuracy: 0.46817149542357717, Time Elapsed: 5818.300986289978 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.62      0.26      0.37       877\n",
      "           3       0.54      0.77      0.63       897\n",
      "           4       0.56      0.77      0.65       892\n",
      "           5       0.53      0.66      0.59       862\n",
      "           6       0.63      0.68      0.65       903\n",
      "           7       0.64      0.08      0.15       889\n",
      "           8       0.59      0.30      0.40       892\n",
      "           9       0.59      0.54      0.56       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 26800, Loss: 0.40753093361854553, F1: 0.5290938137705609, Accuracy: 0.5080173422338449, Time Elapsed: 5834.280148983002 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.60      0.74      0.67       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.53      0.75      0.62       897\n",
      "           4       0.58      0.63      0.60       892\n",
      "           5       0.52      0.74      0.61       862\n",
      "           6       0.63      0.59      0.61       903\n",
      "           7       0.62      0.13      0.22       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.64      0.04      0.08       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 26900, Loss: 1.286307454109192, F1: 0.5143587515044747, Accuracy: 0.5023742343954305, Time Elapsed: 5848.763005256653 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68       912\n",
      "           1       0.62      0.34      0.44       885\n",
      "           2       0.58      0.51      0.54       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.54      0.66      0.59       892\n",
      "           5       0.52      0.50      0.51       862\n",
      "           6       0.63      0.50      0.56       903\n",
      "           7       0.62      0.51      0.56       889\n",
      "           8       0.54      0.69      0.61       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.49      0.50     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 27000, Loss: 0.7305819988250732, F1: 0.4961788104773523, Accuracy: 0.48957401417658797, Time Elapsed: 5864.427634239197 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.57       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.57      0.54      0.55       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.58      0.58      0.58       892\n",
      "           5       0.59      0.08      0.15       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.60      0.50      0.55       889\n",
      "           8       0.58      0.59      0.58       892\n",
      "           9       0.51      0.71      0.59       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 1, Step 27100, Loss: 0.40099456906318665, F1: 0.5289576865583169, Accuracy: 0.5006537746885968, Time Elapsed: 5879.354254245758 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.27      0.38       912\n",
      "           1       0.60      0.52      0.56       885\n",
      "           2       0.56      0.69      0.61       877\n",
      "           3       0.58      0.64      0.61       897\n",
      "           4       0.58      0.22      0.32       892\n",
      "           5       0.60      0.25      0.36       862\n",
      "           6       0.64      0.62      0.63       903\n",
      "           7       0.51      0.92      0.66       889\n",
      "           8       0.59      0.51      0.55       892\n",
      "           9       0.52      0.75      0.62       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.52     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 1, Step 27200, Loss: 0.9814985394477844, F1: 0.5162687193841532, Accuracy: 0.49115683710687497, Time Elapsed: 5894.951022148132 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.60      0.37      0.46       897\n",
      "           4       0.61      0.37      0.46       892\n",
      "           5       0.60      0.32      0.42       862\n",
      "           6       0.64      0.64      0.64       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.57      0.70      0.63       892\n",
      "           9       0.61      0.58      0.60       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.53      0.52      0.51     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 27300, Loss: 0.713289737701416, F1: 0.507739813325682, Accuracy: 0.5036129653843507, Time Elapsed: 5910.586131334305 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.72       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.56      0.68      0.62       897\n",
      "           4       0.55      0.86      0.67       892\n",
      "           5       0.48      0.78      0.59       862\n",
      "           6       0.63      0.77      0.69       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.58      0.67      0.62       892\n",
      "           9       0.56      0.79      0.66       876\n",
      "          10       0.39      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.71      0.61     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 1, Step 27400, Loss: 1.2189010381698608, F1: 0.6146790735560743, Accuracy: 0.5386415250154841, Time Elapsed: 5926.059720277786 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       912\n",
      "           1       0.70      0.02      0.04       885\n",
      "           2       0.60      0.56      0.57       877\n",
      "           3       0.46      0.85      0.59       897\n",
      "           4       0.57      0.55      0.56       892\n",
      "           5       0.52      0.66      0.58       862\n",
      "           6       0.64      0.31      0.42       903\n",
      "           7       0.56      0.76      0.64       889\n",
      "           8       0.55      0.73      0.63       892\n",
      "           9       0.63      0.29      0.40       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.53      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 27500, Loss: 0.6320061683654785, F1: 0.4989842713368294, Accuracy: 0.48806000963457435, Time Elapsed: 5941.322196006775 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.61      0.52      0.56       877\n",
      "           3       0.59      0.29      0.39       897\n",
      "           4       0.54      0.72      0.62       892\n",
      "           5       0.55      0.54      0.54       862\n",
      "           6       0.63      0.59      0.61       903\n",
      "           7       0.60      0.55      0.57       889\n",
      "           8       0.55      0.71      0.62       892\n",
      "           9       0.66      0.24      0.35       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.57      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 1, Step 27600, Loss: 1.304283618927002, F1: 0.5522369657073334, Accuracy: 0.5114582616475122, Time Elapsed: 5956.427254199982 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.71       912\n",
      "           1       0.58      0.93      0.71       885\n",
      "           2       0.45      0.88      0.59       877\n",
      "           3       0.59      0.53      0.56       897\n",
      "           4       0.57      0.66      0.61       892\n",
      "           5       0.57      0.42      0.48       862\n",
      "           6       0.62      0.77      0.69       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.60      0.41      0.49       892\n",
      "           9       0.56      0.74      0.64       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 27700, Loss: 1.632356882095337, F1: 0.5856309343151641, Accuracy: 0.5209551992292341, Time Elapsed: 5972.0493931770325 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.53      0.99      0.69       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.69      0.11      0.19       897\n",
      "           4       0.62      0.28      0.39       892\n",
      "           5       0.57      0.20      0.30       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.64      0.10      0.18       892\n",
      "           9       0.49      0.82      0.61       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.49     14531\n",
      "weighted avg       0.52      0.50      0.46     14531\n",
      "\n",
      "Epoch 1, Step 27800, Loss: 0.9046645760536194, F1: 0.4901469876454906, Accuracy: 0.49693758172183605, Time Elapsed: 5988.008958339691 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.29      0.40       912\n",
      "           1       0.59      0.85      0.70       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.53      0.63      0.58       892\n",
      "           5       0.56      0.08      0.14       862\n",
      "           6       0.63      0.62      0.63       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.58      0.47      0.52       892\n",
      "           9       0.59      0.45      0.51       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.47      0.47     14531\n",
      "weighted avg       0.48      0.49      0.46     14531\n",
      "\n",
      "Epoch 1, Step 27900, Loss: 0.47270968556404114, F1: 0.46769039072125335, Accuracy: 0.4873030073635675, Time Elapsed: 6003.44517827034 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.69       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.64      0.23      0.34       877\n",
      "           3       0.57      0.59      0.58       897\n",
      "           4       0.56      0.84      0.67       892\n",
      "           5       0.58      0.16      0.25       862\n",
      "           6       0.62      0.43      0.51       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.59      0.43      0.50       892\n",
      "           9       0.46      0.90      0.61       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 1, Step 28000, Loss: 0.6743113398551941, F1: 0.5356105555471662, Accuracy: 0.5056086986442777, Time Elapsed: 6019.046559095383 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.58      0.10      0.18       885\n",
      "           2       0.65      0.19      0.30       877\n",
      "           3       0.61      0.08      0.14       897\n",
      "           4       0.62      0.10      0.18       892\n",
      "           5       0.59      0.42      0.49       862\n",
      "           6       0.63      0.42      0.50       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.60      0.17      0.26       892\n",
      "           9       0.61      0.25      0.35       876\n",
      "          10       0.39      0.65      0.49      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.59      0.37      0.39     14531\n",
      "weighted avg       0.52      0.47      0.42     14531\n",
      "\n",
      "Epoch 1, Step 28100, Loss: 1.0730918645858765, F1: 0.3897186982627734, Accuracy: 0.46624458055192347, Time Elapsed: 6033.952179193497 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       912\n",
      "           1       0.60      0.37      0.46       885\n",
      "           2       0.58      0.62      0.60       877\n",
      "           3       0.52      0.73      0.61       897\n",
      "           4       0.62      0.23      0.34       892\n",
      "           5       0.57      0.26      0.35       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.60      0.34      0.43       892\n",
      "           9       0.51      0.82      0.63       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 1, Step 28200, Loss: 0.3827318251132965, F1: 0.5347403061680324, Accuracy: 0.5038194205491707, Time Elapsed: 6048.753785133362 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69       912\n",
      "           1       0.61      0.82      0.70       885\n",
      "           2       0.43      0.01      0.01       877\n",
      "           3       0.38      0.91      0.53       897\n",
      "           4       0.58      0.77      0.66       892\n",
      "           5       0.64      0.18      0.28       862\n",
      "           6       0.64      0.61      0.62       903\n",
      "           7       0.61      0.63      0.62       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.60      0.60      0.60       876\n",
      "          10       0.40      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.56      0.51     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 28300, Loss: 1.1405025720596313, F1: 0.5133316421732496, Accuracy: 0.49955268047622325, Time Elapsed: 6064.2362151145935 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.62      0.41      0.49       877\n",
      "           3       0.55      0.72      0.62       897\n",
      "           4       0.60      0.54      0.57       892\n",
      "           5       0.56      0.58      0.57       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.58      0.68      0.63       892\n",
      "           9       0.55      0.81      0.66       876\n",
      "          10       0.41      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 1, Step 28400, Loss: 1.135689377784729, F1: 0.6030198641201524, Accuracy: 0.5371963388617439, Time Elapsed: 6080.901220083237 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.37      0.01      0.02       877\n",
      "           3       0.60      0.15      0.24       897\n",
      "           4       0.52      0.89      0.66       892\n",
      "           5       0.59      0.28      0.38       862\n",
      "           6       0.63      0.70      0.66       903\n",
      "           7       0.59      0.61      0.60       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.61      0.44      0.51       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.53      0.50     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 1, Step 28500, Loss: 0.42371195554733276, F1: 0.5007775967910155, Accuracy: 0.5022365976188837, Time Elapsed: 6096.739154338837 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.77      0.66       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.58      0.70      0.64       877\n",
      "           3       0.53      0.83      0.65       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.54      0.56      0.55       862\n",
      "           6       0.61      0.82      0.69       903\n",
      "           7       0.59      0.62      0.61       889\n",
      "           8       0.51      0.79      0.62       892\n",
      "           9       0.53      0.77      0.63       876\n",
      "          10       0.39      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.70      0.61     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 1, Step 28600, Loss: 2.63447642326355, F1: 0.605958168153895, Accuracy: 0.5320349597412428, Time Elapsed: 6112.01034617424 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.61      0.57      0.59       877\n",
      "           3       0.58      0.58      0.58       897\n",
      "           4       0.59      0.48      0.53       892\n",
      "           5       0.53      0.65      0.58       862\n",
      "           6       0.60      0.25      0.35       903\n",
      "           7       0.60      0.59      0.59       889\n",
      "           8       0.52      0.80      0.63       892\n",
      "           9       0.57      0.67      0.61       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 28700, Loss: 1.458570122718811, F1: 0.567374553471631, Accuracy: 0.5151744546142729, Time Elapsed: 6126.830158233643 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70       912\n",
      "           1       0.62      0.76      0.68       885\n",
      "           2       0.56      0.76      0.65       877\n",
      "           3       0.58      0.62      0.60       897\n",
      "           4       0.57      0.55      0.56       892\n",
      "           5       0.52      0.63      0.57       862\n",
      "           6       0.63      0.67      0.65       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.60      0.53      0.56       892\n",
      "           9       0.62      0.17      0.27       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 1, Step 28800, Loss: 0.8676600456237793, F1: 0.5685938391871701, Accuracy: 0.5180648269217535, Time Elapsed: 6142.727077245712 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.55       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.68      0.05      0.09       897\n",
      "           4       0.57      0.31      0.40       892\n",
      "           5       0.67      0.01      0.02       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.62      0.39      0.48       889\n",
      "           8       0.59      0.24      0.34       892\n",
      "           9       0.59      0.48      0.53       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.59      0.45      0.45     14531\n",
      "weighted avg       0.53      0.48      0.45     14531\n",
      "\n",
      "Epoch 1, Step 28900, Loss: 2.9447827339172363, F1: 0.4458368095903971, Accuracy: 0.4828298121258, Time Elapsed: 6159.343508005142 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.05      0.09       912\n",
      "           1       0.55      0.97      0.71       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.59      0.43      0.50       897\n",
      "           4       0.62      0.50      0.55       892\n",
      "           5       0.57      0.21      0.31       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.58      0.77      0.66       889\n",
      "           8       0.55      0.60      0.57       892\n",
      "           9       0.66      0.16      0.26       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.50      0.48     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 1, Step 29000, Loss: 1.355710744857788, F1: 0.4838048697817221, Accuracy: 0.49308375197852866, Time Elapsed: 6175.260102272034 seconds\n",
      "Epoch 1 completed. Time: 6175.726010322571\n",
      "Logger {'time': {0: 0.021434307098388672, 100: 15.269880056381226, 200: 31.06825613975525, 300: 47.292030334472656, 400: 62.62403726577759, 500: 77.98690509796143, 600: 94.23091626167297, 700: 109.62935328483582, 800: 124.47921109199524, 900: 139.6343071460724, 1000: 154.9619562625885, 1100: 169.66386723518372, 1200: 185.83086800575256, 1300: 203.04708123207092, 1400: 219.69982528686523, 1500: 236.86441326141357, 1600: 252.90655636787415, 1700: 268.79133224487305, 1800: 286.5852563381195, 1900: 302.6791741847992, 2000: 319.11605310440063, 2100: 334.63271713256836, 2200: 349.120658159256, 2300: 364.4608871936798, 2400: 381.04984402656555, 2500: 395.9968452453613, 2600: 411.2067792415619, 2700: 427.0017321109772, 2800: 442.75356006622314, 2900: 457.61248111724854, 3000: 472.29511618614197, 3100: 487.64775705337524, 3200: 502.5124092102051, 3300: 517.2803483009338, 3400: 531.9595603942871, 3500: 547.6394312381744, 3600: 563.381085395813, 3700: 578.6994521617889, 3800: 593.2742252349854, 3900: 608.53360414505, 4000: 624.6793701648712, 4100: 641.1209061145782, 4200: 655.9542410373688, 4300: 670.7409541606903, 4400: 685.7808661460876, 4500: 700.989755153656, 4600: 942.8762581348419, 4700: 958.8052370548248, 4800: 974.6551780700684, 4900: 1016.5587861537933, 5000: 1032.1197550296783, 5100: 1047.6666250228882, 5200: 1130.607357263565, 5300: 1147.186202287674, 5400: 1162.9066643714905, 5500: 1177.8656811714172, 5600: 1193.0776951313019, 5700: 1208.586011171341, 5800: 1224.4589171409607, 5900: 1239.8399910926819, 6000: 1255.7311112880707, 6100: 1270.0591983795166, 6200: 1285.1240661144257, 6300: 1300.0841662883759, 6400: 1315.0091300010681, 6500: 1330.3163940906525, 6600: 1346.1576392650604, 6700: 1361.2709391117096, 6800: 1375.7135272026062, 6900: 1390.8658092021942, 7000: 1406.381236076355, 7100: 1421.3311891555786, 7200: 1435.7252161502838, 7300: 1454.50732421875, 7400: 1475.7529771327972, 7500: 1491.486619234085, 7600: 1506.362137079239, 7700: 1521.0352602005005, 7800: 1535.702275276184, 7900: 1551.7298312187195, 8000: 1566.6644961833954, 8100: 1581.8374621868134, 8200: 1596.9119772911072, 8300: 1611.4731121063232, 8400: 1626.45973610878, 8500: 1641.5488901138306, 8600: 1656.6674401760101, 8700: 1671.4218323230743, 8800: 1686.57666015625, 8900: 1702.522633075714, 9000: 1717.9782919883728, 9100: 1732.7616641521454, 9200: 1747.9300711154938, 9300: 2358.859049320221, 9400: 2375.669641971588, 9500: 2391.9133491516113, 9600: 2407.9447391033173, 9700: 2423.5280210971832, 9800: 2438.279149055481, 9900: 2452.6875760555267, 10000: 2468.129268169403, 10100: 2482.7726583480835, 10200: 2497.2177381515503, 10300: 2512.5913212299347, 10400: 2528.4318442344666, 10500: 2543.233656167984, 10600: 2557.5900552272797, 10700: 2572.782380104065, 10800: 2587.990046977997, 10900: 2603.4043312072754, 11000: 2617.9072992801666, 11100: 2632.6437861919403, 11200: 2648.592180967331, 11300: 2664.268012046814, 11400: 2680.2125902175903, 11500: 2695.584841966629, 11600: 2711.1969389915466, 11700: 2727.181540250778, 11800: 2741.8693182468414, 11900: 2756.7069902420044, 12000: 2773.2295422554016, 12100: 2796.9470031261444, 12200: 2812.18772315979, 12300: 2827.5475080013275, 12400: 2843.294077396393, 12500: 2859.1066172122955, 12600: 2875.233195066452, 12700: 2891.6377131938934, 12800: 2908.0962102413177, 12900: 2924.6765582561493, 13000: 2941.1024072170258, 13100: 2962.2394921779633, 13200: 2979.0803661346436, 13300: 2995.4937171936035, 13400: 3011.508269071579, 13500: 3028.6168081760406, 13600: 3046.152304172516, 13700: 3061.736268043518, 13800: 3081.1217143535614, 13900: 3095.767834186554, 14000: 3110.156370162964, 14100: 3125.751838207245, 14200: 3140.5174012184143, 14300: 3154.7302000522614, 14400: 3169.200949192047, 14500: 3183.797533273697, 14600: 3198.8139703273773, 14700: 3213.2259640693665, 14800: 3228.797575235367, 14900: 3244.2444462776184, 15000: 3260.7219231128693, 15100: 3276.015652179718, 15200: 3290.507392168045, 15300: 3305.899854183197, 15400: 3320.84307718277, 15500: 3336.3937520980835, 15600: 3351.4187421798706, 15700: 3367.586300134659, 15800: 3383.2583889961243, 15900: 3397.769942045212, 16000: 3412.605206012726, 16100: 3428.301740169525, 16200: 3443.370749235153, 16300: 3457.7963831424713, 16400: 3473.689752101898, 16500: 3489.619737148285, 16600: 3505.0038352012634, 16700: 3519.7743492126465, 16800: 3534.371595144272, 16900: 3549.5141232013702, 17000: 3565.1520550251007, 17100: 3579.93532538414, 17200: 3595.9149281978607, 17300: 3611.82039809227, 17400: 3628.3410091400146, 17500: 3645.394138097763, 17600: 3662.3627030849457, 17700: 3678.3506009578705, 17800: 3696.2356522083282, 17900: 3712.0579602718353, 18000: 3729.3220801353455, 18100: 3751.243894100189, 18200: 3766.609266281128, 18300: 3781.3491880893707, 18400: 3796.760621070862, 18500: 3811.601104259491, 18600: 3826.294412136078, 18700: 3841.380955219269, 18800: 3856.0826511383057, 18900: 3870.7359890937805, 19000: 3885.4119911193848, 19100: 3900.003044128418, 19200: 3915.266305208206, 19300: 3931.0228481292725, 19400: 3946.2133021354675, 19500: 3961.169720172882, 19600: 3976.529503107071, 19700: 3990.9931640625, 19800: 4006.3679070472717, 19900: 4021.8272199630737, 20000: 4037.761191368103, 20100: 4053.974983215332, 20200: 4068.6296923160553, 20300: 4084.698455095291, 20400: 4099.9966921806335, 20500: 4114.726976156235, 20600: 4129.611407279968, 20700: 4145.491770267487, 20800: 4161.382826089859, 20900: 4177.453081130981, 21000: 4193.097550153732, 21100: 4209.226341247559, 21200: 4224.141384363174, 21300: 4238.8478372097015, 21400: 4254.37689614296, 21500: 4270.345776319504, 21600: 4285.743047237396, 21700: 4300.779902219772, 21800: 4315.4729652404785, 21900: 4331.204913139343, 22000: 4346.929570198059, 22100: 4361.77934718132, 22200: 4376.780999183655, 22300: 4392.346985340118, 22400: 4407.372951030731, 22500: 4421.9247460365295, 22600: 4437.380058288574, 22700: 4452.840657234192, 22800: 4468.116425037384, 22900: 4482.999564170837, 23000: 4498.393356084824, 23100: 4514.09055519104, 23200: 4530.671049118042, 23300: 4546.3888330459595, 23400: 4562.064662218094, 23500: 4577.544015169144, 23600: 4592.177932024002, 23700: 4606.698182344437, 23800: 4623.586651325226, 23900: 5352.565582275391, 24000: 5371.4960770606995, 24100: 5388.4647381305695, 24200: 5405.522629261017, 24300: 5423.351496934891, 24400: 5439.325527191162, 24500: 5455.179260253906, 24600: 5470.7660343647, 24700: 5486.828236103058, 24800: 5505.283976316452, 24900: 5522.771423101425, 25000: 5540.410487174988, 25100: 5555.49317407608, 25200: 5570.2124700546265, 25300: 5585.5392010211945, 25400: 5600.278799295425, 25500: 5615.755434036255, 25600: 5631.604572296143, 25700: 5646.487953186035, 25800: 5661.404626369476, 25900: 5676.650181293488, 26000: 5691.223650217056, 26100: 5706.012686252594, 26200: 5721.234870195389, 26300: 5736.159389257431, 26400: 5751.523259162903, 26500: 5769.0149393081665, 26600: 5788.011831045151, 26700: 5803.7088623046875, 26800: 5818.861934185028, 26900: 5834.789784193039, 27000: 5849.294121980667, 27100: 5865.025718212128, 27200: 5879.879783153534, 27300: 5895.529732227325, 27400: 5911.141085386276, 27500: 5926.641081094742, 27600: 5941.87064909935, 27700: 5956.9719343185425, 27800: 5972.6377012729645, 27900: 5988.605641126633, 28000: 6004.02836728096, 28100: 6019.608531236649, 28200: 6034.500235080719, 28300: 6049.2910141944885, 28400: 6064.874034166336, 28500: 6081.479084014893, 28600: 6097.312618017197, 28700: 6112.529374361038, 28800: 6127.419503211975, 28900: 6143.364795207977, 29000: 6159.975320100784}, 'loss': {0: 2.4203009605407715, 100: 3.5031092166900635, 200: 3.043261766433716, 300: 0.8586784601211548, 400: 2.905369758605957, 500: 2.7015929222106934, 600: 1.099332332611084, 700: 1.6591286659240723, 800: 1.9338128566741943, 900: 0.7233871817588806, 1000: 2.9249792098999023, 1100: 0.7943834662437439, 1200: 2.0605263710021973, 1300: 1.1146883964538574, 1400: 0.7597019672393799, 1500: 0.7967299818992615, 1600: 0.9628119468688965, 1700: 0.9505224823951721, 1800: 0.7866067290306091, 1900: 0.933186948299408, 2000: 1.0499539375305176, 2100: 0.5745329260826111, 2200: 2.961423635482788, 2300: 2.1002864837646484, 2400: 1.7487837076187134, 2500: 1.9968363046646118, 2600: 1.1910966634750366, 2700: 3.195530891418457, 2800: 1.3049222230911255, 2900: 1.1272387504577637, 3000: 2.794877290725708, 3100: 1.5894628763198853, 3200: 0.8997759222984314, 3300: 1.4486511945724487, 3400: 1.973649263381958, 3500: 0.7031534314155579, 3600: 1.203021764755249, 3700: 0.6653522849082947, 3800: 2.761232376098633, 3900: 0.7781776785850525, 4000: 1.4311714172363281, 4100: 1.1060750484466553, 4200: 1.081134557723999, 4300: 1.3471254110336304, 4400: 1.803849458694458, 4500: 2.3561387062072754, 4600: 1.1643867492675781, 4700: 1.295391321182251, 4800: 0.8206798434257507, 4900: 2.093484878540039, 5000: 0.9772859811782837, 5100: 0.5452333092689514, 5200: 2.282413959503174, 5300: 1.0806505680084229, 5400: 1.6153478622436523, 5500: 0.9669377207756042, 5600: 2.685230255126953, 5700: 0.2888947129249573, 5800: 1.1996161937713623, 5900: 0.6877462267875671, 6000: 0.5530050992965698, 6100: 0.9552854299545288, 6200: 2.0667262077331543, 6300: 1.30466628074646, 6400: 0.9176557064056396, 6500: 0.9666669964790344, 6600: 0.8372871279716492, 6700: 4.440350532531738, 6800: 1.0890846252441406, 6900: 0.6775614023208618, 7000: 1.6020631790161133, 7100: 1.0170042514801025, 7200: 0.9098405838012695, 7300: 4.885929107666016, 7400: 1.028014898300171, 7500: 2.1470322608947754, 7600: 1.1246851682662964, 7700: 0.15340925753116608, 7800: 1.4554651975631714, 7900: 1.4274269342422485, 8000: 0.9207288026809692, 8100: 1.613781452178955, 8200: 0.7542456388473511, 8300: 0.7122849225997925, 8400: 0.5730993747711182, 8500: 1.2633931636810303, 8600: 1.3591738939285278, 8700: 0.8766217827796936, 8800: 1.7357361316680908, 8900: 1.0038273334503174, 9000: 0.5216660499572754, 9100: 0.8896001577377319, 9200: 0.48831507563591003, 9300: 0.9814693927764893, 9400: 1.0729398727416992, 9500: 0.4815584123134613, 9600: 1.2584247589111328, 9700: 0.43576186895370483, 9800: 0.5210085511207581, 9900: 1.1683557033538818, 10000: 2.6140737533569336, 10100: 0.9457253813743591, 10200: 1.8109784126281738, 10300: 1.3254399299621582, 10400: 1.7543001174926758, 10500: 0.5781559944152832, 10600: 0.9912089109420776, 10700: 1.8532965183258057, 10800: 2.728095054626465, 10900: 0.37291252613067627, 11000: 0.9023125171661377, 11100: 1.260650873184204, 11200: 1.4017447233200073, 11300: 1.0683178901672363, 11400: 1.3308582305908203, 11500: 0.7091379761695862, 11600: 0.9338041543960571, 11700: 3.1541056632995605, 11800: 1.350623607635498, 11900: 0.6149489879608154, 12000: 0.6006646156311035, 12100: 1.1075432300567627, 12200: 1.3863059282302856, 12300: 1.7259376049041748, 12400: 0.7083632946014404, 12500: 1.9083918333053589, 12600: 1.3972173929214478, 12700: 1.0038901567459106, 12800: 2.620351552963257, 12900: 1.1205741167068481, 13000: 1.5705983638763428, 13100: 1.281074047088623, 13200: 0.8102772831916809, 13300: 0.3570690155029297, 13400: 0.6454511284828186, 13500: 2.2684953212738037, 13600: 1.288863182067871, 13700: 2.3866589069366455, 13800: 0.24679876863956451, 13900: 1.0715200901031494, 14000: 0.4217621982097626, 14100: 1.2784910202026367, 14200: 0.44026926159858704, 14300: 1.9062397480010986, 14400: 3.4785075187683105, 14500: 0.47712668776512146, 14600: 3.4728546142578125, 14700: 1.9462782144546509, 14800: 0.8258118629455566, 14900: 1.1899354457855225, 15000: 0.34555545449256897, 15100: 0.8817962408065796, 15200: 0.5490255355834961, 15300: 1.8578310012817383, 15400: 0.8271118402481079, 15500: 0.9727210998535156, 15600: 0.8283507227897644, 15700: 1.4100275039672852, 15800: 0.8498361110687256, 15900: 0.822632372379303, 16000: 0.4285499155521393, 16100: 2.3408918380737305, 16200: 2.8618195056915283, 16300: 0.6792012453079224, 16400: 0.4169944226741791, 16500: 1.013197660446167, 16600: 1.1705729961395264, 16700: 0.8266847133636475, 16800: 0.5464031100273132, 16900: 1.1497366428375244, 17000: 0.716611921787262, 17100: 0.8524736762046814, 17200: 3.3135807514190674, 17300: 0.6233159899711609, 17400: 1.6769214868545532, 17500: 0.5362945795059204, 17600: 0.8157632946968079, 17700: 2.0572681427001953, 17800: 1.4420979022979736, 17900: 0.8142619729042053, 18000: 2.0791544914245605, 18100: 0.708750307559967, 18200: 0.9919490218162537, 18300: 2.251858711242676, 18400: 1.0385940074920654, 18500: 1.2341718673706055, 18600: 1.681744933128357, 18700: 1.5835142135620117, 18800: 4.450672149658203, 18900: 0.5967696905136108, 19000: 0.6148073077201843, 19100: 0.7577466368675232, 19200: 0.343881756067276, 19300: 0.3907598555088043, 19400: 0.8509786128997803, 19500: 3.4591336250305176, 19600: 0.85930335521698, 19700: 1.163724422454834, 19800: 0.6107730865478516, 19900: 0.4708186388015747, 20000: 0.4979970157146454, 20100: 0.6515260934829712, 20200: 0.7754760980606079, 20300: 1.240021824836731, 20400: 0.8868150115013123, 20500: 2.366136312484741, 20600: 1.0510544776916504, 20700: 0.9735929369926453, 20800: 1.1997294425964355, 20900: 0.7268274426460266, 21000: 0.40963777899742126, 21100: 1.1164135932922363, 21200: 1.0573261976242065, 21300: 0.7423765659332275, 21400: 1.9830946922302246, 21500: 0.8077003359794617, 21600: 1.7728458642959595, 21700: 1.047255516052246, 21800: 1.0338637828826904, 21900: 0.535881757736206, 22000: 0.8467578291893005, 22100: 0.6935288310050964, 22200: 0.8812829256057739, 22300: 0.7168481349945068, 22400: 0.47777116298675537, 22500: 1.4097540378570557, 22600: 0.27167192101478577, 22700: 0.9196133613586426, 22800: 0.8669561147689819, 22900: 0.1776837557554245, 23000: 0.6696901917457581, 23100: 0.7386677861213684, 23200: 0.9827738404273987, 23300: 0.4115927219390869, 23400: 0.5955274105072021, 23500: 1.4048984050750732, 23600: 5.133872985839844, 23700: 0.24254244565963745, 23800: 0.4099142551422119, 23900: 1.061922311782837, 24000: 0.17836138606071472, 24100: 1.920084834098816, 24200: 1.3070157766342163, 24300: 0.7207112312316895, 24400: 1.8597675561904907, 24500: 0.3804824948310852, 24600: 2.841763973236084, 24700: 1.7992315292358398, 24800: 1.9584954977035522, 24900: 0.2477983832359314, 25000: 1.1734364032745361, 25100: 0.40680190920829773, 25200: 0.7233713269233704, 25300: 0.2189921885728836, 25400: 1.2604799270629883, 25500: 1.1544181108474731, 25600: 0.7084522843360901, 25700: 0.4511633515357971, 25800: 2.0326414108276367, 25900: 0.6219429969787598, 26000: 0.612220048904419, 26100: 2.0493316650390625, 26200: 1.5938640832901, 26300: 0.502835750579834, 26400: 1.1434506177902222, 26500: 1.0099680423736572, 26600: 0.4444721043109894, 26700: 0.9911185503005981, 26800: 0.40753093361854553, 26900: 1.286307454109192, 27000: 0.7305819988250732, 27100: 0.40099456906318665, 27200: 0.9814985394477844, 27300: 0.713289737701416, 27400: 1.2189010381698608, 27500: 0.6320061683654785, 27600: 1.304283618927002, 27700: 1.632356882095337, 27800: 0.9046645760536194, 27900: 0.47270968556404114, 28000: 0.6743113398551941, 28100: 1.0730918645858765, 28200: 0.3827318251132965, 28300: 1.1405025720596313, 28400: 1.135689377784729, 28500: 0.42371195554733276, 28600: 2.63447642326355, 28700: 1.458570122718811, 28800: 0.8676600456237793, 28900: 2.9447827339172363, 29000: 1.355710744857788}, 'F1': {0: 0.01073743325896405, 100: 0.05087701117834438, 200: 0.05087701117834438, 300: 0.05087701117834438, 400: 0.05087701117834438, 500: 0.05087701117834438, 600: 0.05087701117834438, 700: 0.05087701117834438, 800: 0.05087701117834438, 900: 0.053689396127181106, 1000: 0.10046694851253948, 1100: 0.11374757978943505, 1200: 0.10098378469390475, 1300: 0.1081871567505937, 1400: 0.06341245656226632, 1500: 0.15716553239757722, 1600: 0.09548003256509206, 1700: 0.14956410485390034, 1800: 0.11314308458451389, 1900: 0.28456015981260135, 2000: 0.26496300848752996, 2100: 0.20654332408139273, 2200: 0.17974719645629122, 2300: 0.1432578237710499, 2400: 0.14900490802874666, 2500: 0.1256956909108766, 2600: 0.31100106154575985, 2700: 0.2623441590632922, 2800: 0.19433381506705255, 2900: 0.32392191430865097, 3000: 0.3235736974056821, 3100: 0.27069736196302224, 3200: 0.30320991520498397, 3300: 0.33113530989859113, 3400: 0.18034434759346143, 3500: 0.300648609417523, 3600: 0.3487793783153457, 3700: 0.32889518912086635, 3800: 0.40186382145962796, 3900: 0.48669928120760003, 4000: 0.40408187283079333, 4100: 0.17425701939009153, 4200: 0.36217924495923676, 4300: 0.34756285554125665, 4400: 0.2709955577058917, 4500: 0.38592493776991116, 4600: 0.34883354733384847, 4700: 0.21873348419053984, 4800: 0.3386377344714648, 4900: 0.3248168831622469, 5000: 0.3862945134671795, 5100: 0.43793244430702916, 5200: 0.364482662109112, 5300: 0.4661035457090364, 5400: 0.48583824002497916, 5500: 0.39927784723822257, 5600: 0.41679194447261453, 5700: 0.3723245753777906, 5800: 0.437068112897367, 5900: 0.364739203374186, 6000: 0.4714805904946729, 6100: 0.34264107768959756, 6200: 0.4526812297650315, 6300: 0.5147464499837507, 6400: 0.4179226389167292, 6500: 0.43797787755675105, 6600: 0.4918820715656789, 6700: 0.5353902249489363, 6800: 0.3584902181007991, 6900: 0.4618245747942165, 7000: 0.5116296945090445, 7100: 0.5119806996730124, 7200: 0.4417958150277572, 7300: 0.5312310412684252, 7400: 0.40447764052539215, 7500: 0.41465981728489376, 7600: 0.43773412009124013, 7700: 0.4524532294762334, 7800: 0.5056802069527895, 7900: 0.5043780618579695, 8000: 0.4863297326842536, 8100: 0.521801456964202, 8200: 0.4271500067650232, 8300: 0.4207713573090588, 8400: 0.41776534743355376, 8500: 0.43405387967669107, 8600: 0.4035608750269224, 8700: 0.5111253202232638, 8800: 0.569416451223823, 8900: 0.506820821743137, 9000: 0.3494462042857561, 9100: 0.5279021626897927, 9200: 0.509220149277091, 9300: 0.48868513380765893, 9400: 0.3622037470499385, 9500: 0.4374031388892814, 9600: 0.5591614853809996, 9700: 0.4745632026947945, 9800: 0.45702201818919375, 9900: 0.4324893134755174, 10000: 0.5469007719569985, 10100: 0.5550741545549168, 10200: 0.5064913413433628, 10300: 0.6039147319389001, 10400: 0.5003681976524023, 10500: 0.5315491932135579, 10600: 0.5730952769651365, 10700: 0.4829174233423078, 10800: 0.5093178734982322, 10900: 0.554779670094324, 11000: 0.46083313923401986, 11100: 0.4753356500646351, 11200: 0.47053213015888495, 11300: 0.46148400804052836, 11400: 0.5094029549104735, 11500: 0.4392081198085506, 11600: 0.5088874693049139, 11700: 0.4602662956860158, 11800: 0.5648069775295453, 11900: 0.5014686849555899, 12000: 0.36902546076812137, 12100: 0.5144867090387706, 12200: 0.5017786829819296, 12300: 0.38691339532826297, 12400: 0.4647163512026825, 12500: 0.5288757087545333, 12600: 0.4943214204946068, 12700: 0.49176514823590034, 12800: 0.3598005805493027, 12900: 0.426099893394806, 13000: 0.45698876029619967, 13100: 0.5102540879451541, 13200: 0.5733290605679813, 13300: 0.41296394532781466, 13400: 0.46858675847139997, 13500: 0.425603894214369, 13600: 0.3166662165052841, 13700: 0.4275420052064336, 13800: 0.4444813503712869, 13900: 0.5041162162563035, 14000: 0.38145117561162467, 14100: 0.5767584553106957, 14200: 0.49871647254687107, 14300: 0.48277913188915905, 14400: 0.47426455676375506, 14500: 0.4209240533631755, 14600: 0.5051784366032724, 14700: 0.5389089323413656, 14800: 0.5743269046929679, 14900: 0.5382868641932016, 15000: 0.3709730645488066, 15100: 0.4919932160704169, 15200: 0.5055323162215255, 15300: 0.48731900305617093, 15400: 0.4368777308577307, 15500: 0.3956602121865469, 15600: 0.4887902104948957, 15700: 0.5441788820560993, 15800: 0.5320012724080457, 15900: 0.5346707982477573, 16000: 0.5492289555848117, 16100: 0.4794082443440507, 16200: 0.5469272844159065, 16300: 0.49850422208182005, 16400: 0.48956677344223004, 16500: 0.45297658221299136, 16600: 0.5333978461335354, 16700: 0.458978630913904, 16800: 0.4962763293002426, 16900: 0.4855735426661367, 17000: 0.5404338600946199, 17100: 0.5210099629364676, 17200: 0.36299301110473237, 17300: 0.5007443525730785, 17400: 0.5173124325321579, 17500: 0.5814959228737916, 17600: 0.5398210790211572, 17700: 0.5284049887928008, 17800: 0.5191517240498068, 17900: 0.4718206352181443, 18000: 0.4875741434120691, 18100: 0.4385198089131034, 18200: 0.5013809907477751, 18300: 0.45377104656892586, 18400: 0.47443114933026836, 18500: 0.554353615046214, 18600: 0.4453371911839181, 18700: 0.5294394260606686, 18800: 0.5540413834647151, 18900: 0.5688537254041012, 19000: 0.5690346749476854, 19100: 0.5692468240423757, 19200: 0.4607596799250176, 19300: 0.5805262832807517, 19400: 0.5090553132704213, 19500: 0.5661468511891246, 19600: 0.6007995224135357, 19700: 0.6139778685397108, 19800: 0.5867599406660058, 19900: 0.5987889752256481, 20000: 0.5705637320569859, 20100: 0.47385699459644715, 20200: 0.556189008272936, 20300: 0.5384261590052016, 20400: 0.4163225339854868, 20500: 0.5169969550375112, 20600: 0.5975163586309068, 20700: 0.5222844534128567, 20800: 0.43065955619028445, 20900: 0.49528128170426594, 21000: 0.5536636465662202, 21100: 0.5246573908987171, 21200: 0.575206236922977, 21300: 0.5134123889631199, 21400: 0.5074760761505366, 21500: 0.5418072814342703, 21600: 0.4756291993369661, 21700: 0.5759555428518316, 21800: 0.5629625909295869, 21900: 0.5469800628594556, 22000: 0.5665619170093104, 22100: 0.38451391055180245, 22200: 0.48557520468848286, 22300: 0.4370317405072596, 22400: 0.5637037752315558, 22500: 0.564182652319499, 22600: 0.4722343217572703, 22700: 0.567411073764491, 22800: 0.5168995131986921, 22900: 0.47954121811930733, 23000: 0.5553119707556311, 23100: 0.4446594276552263, 23200: 0.5779846245106159, 23300: 0.5487920358450763, 23400: 0.47676714703551165, 23500: 0.5135721487846372, 23600: 0.4659897487615756, 23700: 0.5089201338967856, 23800: 0.5520196359451823, 23900: 0.3832569176021243, 24000: 0.47541288810697996, 24100: 0.40518505344442757, 24200: 0.5777052148712031, 24300: 0.5797772138086259, 24400: 0.4045373064870839, 24500: 0.5216278350833873, 24600: 0.5673027716418807, 24700: 0.5478159476352729, 24800: 0.5288971866751294, 24900: 0.5569108988490066, 25000: 0.4713513514856748, 25100: 0.5379847077124086, 25200: 0.46787866448762755, 25300: 0.4869613828604545, 25400: 0.4297883980793188, 25500: 0.5561275307741534, 25600: 0.5827868685509461, 25700: 0.5274097203456488, 25800: 0.4825533090275439, 25900: 0.3899364186923917, 26000: 0.4427272747113214, 26100: 0.4657213843781997, 26200: 0.5503339056612743, 26300: 0.5302715780289501, 26400: 0.549475587049211, 26500: 0.5241603114955166, 26600: 0.5337327703245396, 26700: 0.3812241504802154, 26800: 0.5290938137705609, 26900: 0.5143587515044747, 27000: 0.4961788104773523, 27100: 0.5289576865583169, 27200: 0.5162687193841532, 27300: 0.507739813325682, 27400: 0.6146790735560743, 27500: 0.4989842713368294, 27600: 0.5522369657073334, 27700: 0.5856309343151641, 27800: 0.4901469876454906, 27900: 0.46769039072125335, 28000: 0.5356105555471662, 28100: 0.3897186982627734, 28200: 0.5347403061680324, 28300: 0.5133316421732496, 28400: 0.6030198641201524, 28500: 0.5007775967910155, 28600: 0.605958168153895, 28700: 0.567374553471631, 28800: 0.5685938391871701, 28900: 0.4458368095903971, 29000: 0.4838048697817221}, 'Accuracy': {0: 0.06276237010529213, 100: 0.38854862019131514, 200: 0.38854862019131514, 300: 0.38854862019131514, 400: 0.38854862019131514, 500: 0.38854862019131514, 600: 0.38854862019131514, 700: 0.38854862019131514, 800: 0.38854862019131514, 900: 0.38916798568577526, 1000: 0.4007982933039708, 1100: 0.4091253182850458, 1200: 0.40141765879843094, 1300: 0.4057532172596518, 1400: 0.3901314431216021, 1500: 0.41724588810130064, 1600: 0.3987337416557704, 1700: 0.4125662376987131, 1800: 0.4077489505195788, 1900: 0.45069162480214714, 2000: 0.4384419516894914, 2100: 0.4311472025325167, 2200: 0.42226963044525495, 2300: 0.4140114238524534, 2400: 0.41380496868763333, 2500: 0.4071984034133921, 2600: 0.39790792099649025, 2700: 0.4436033308099924, 2800: 0.4230954511045351, 2900: 0.4524809028972541, 3000: 0.4515174454614273, 3100: 0.4366526735943844, 3200: 0.4508980799669672, 3300: 0.45612827747574153, 3400: 0.4202050787970546, 3500: 0.4436033308099924, 3600: 0.457022916523295, 3700: 0.4620466588672493, 3800: 0.47567269974537196, 3900: 0.48613309476292066, 4000: 0.4809028972541463, 4100: 0.4186222558667676, 4200: 0.4546142729337279, 4300: 0.4366526735943844, 4400: 0.43534512421719085, 4500: 0.4612896565962425, 4600: 0.44835179960085336, 4700: 0.4265363705182025, 4800: 0.4433968756451724, 4900: 0.45041635124905377, 5000: 0.46369830018580965, 5100: 0.4667263092698369, 5200: 0.45165508223797396, 5300: 0.4854449108801872, 5400: 0.49060629000068817, 5500: 0.4434656940334457, 5600: 0.4674144931525704, 5700: 0.4428463285389856, 5800: 0.47374578487371827, 5900: 0.4625972059734361, 6000: 0.4769114307342922, 6100: 0.46011974399559563, 6200: 0.49356548069644207, 6300: 0.5031312366664372, 6400: 0.4783566168880325, 6500: 0.44965934897804694, 6600: 0.49308375197852866, 6700: 0.5057463354208245, 6800: 0.44869589154222006, 6900: 0.48214162824306656, 7000: 0.5003785011355034, 7100: 0.5023742343954305, 7200: 0.470717775789691, 7300: 0.5037506021608974, 7400: 0.46782740348221047, 7500: 0.4608079278783291, 7600: 0.4817287179134265, 7700: 0.4672768563760237, 7800: 0.49762576560456956, 7900: 0.4968687633335627, 8000: 0.48792237285802764, 8100: 0.5005161379120501, 8200: 0.4648682127864565, 8300: 0.4668639460463836, 8400: 0.4773931594522056, 8500: 0.46824031381185055, 8600: 0.44436033308099926, 8700: 0.4952859404032758, 8800: 0.5149679994494529, 8900: 0.4966623081687427, 9000: 0.46073910949005575, 9100: 0.5040258757139908, 9200: 0.5007914114651435, 9300: 0.49790103915766293, 9400: 0.4481453444360333, 9500: 0.4690661344711307, 9600: 0.5120776271419724, 9700: 0.4888858302938545, 9800: 0.4848943637740004, 9900: 0.47918243754731266, 10000: 0.5133163581308926, 10100: 0.5060216089739178, 10200: 0.4952859404032758, 10300: 0.5377468859679306, 10400: 0.503888238937444, 10500: 0.5101507122703186, 10600: 0.5185465556396669, 10700: 0.48922992223522127, 10800: 0.49452893813226895, 10900: 0.511595898424059, 11000: 0.47849425366457915, 11100: 0.477461977840479, 11200: 0.48351799600853346, 11300: 0.47415869520335835, 11400: 0.49838276787557634, 11500: 0.47457160553299843, 11600: 0.506847429633198, 11700: 0.4882664647993944, 11800: 0.5067097928566513, 11900: 0.4952171220150024, 12000: 0.4544766361571812, 12100: 0.5069162480214713, 12200: 0.4953547587915491, 12300: 0.4539949074392678, 12400: 0.4782189801114858, 12500: 0.49790103915766293, 12600: 0.4888858302938545, 12700: 0.48303626729062005, 12800: 0.45826164751221526, 12900: 0.47656733879292545, 13000: 0.480834078865873, 13100: 0.49101920033032825, 13200: 0.5113206248709655, 13300: 0.46920377124767737, 13400: 0.4820728098547932, 13500: 0.4692725896359507, 13600: 0.44436033308099926, 13700: 0.47622324685155876, 13800: 0.4798018030417728, 13900: 0.49452893813226895, 14000: 0.4578487371825752, 14100: 0.5213681095588741, 14200: 0.4987268598169431, 14300: 0.4894363774000413, 14400: 0.4907439267772349, 14500: 0.47594797329846533, 14600: 0.4985892230403964, 14700: 0.505058151538091, 14800: 0.5192347395224004, 14900: 0.4941848461909022, 15000: 0.45475190971027457, 15100: 0.4926708416488886, 15200: 0.4882664647993944, 15300: 0.49335902553162203, 15400: 0.47959534787695274, 15500: 0.46665749088156355, 15600: 0.4939095726378088, 15700: 0.5015484137361503, 15800: 0.4992774069231299, 15900: 0.5038194205491707, 16000: 0.506640974468378, 16100: 0.47656733879292545, 16200: 0.5058151538090978, 16300: 0.49191383937788175, 16400: 0.4937719358612621, 16500: 0.48358681439680684, 16600: 0.5029935998898906, 16700: 0.4826921753492533, 16800: 0.4948042116853623, 16900: 0.49590530589773585, 17000: 0.49659348978046935, 17100: 0.4981763127107563, 17200: 0.45378845227444775, 17300: 0.49507948523845574, 17400: 0.49542357717982244, 17500: 0.5177895533686601, 17600: 0.5052646067029111, 17700: 0.5040946941022642, 17800: 0.4948042116853623, 17900: 0.48420617989126696, 18000: 0.48654600509256074, 18100: 0.4690661344711307, 18200: 0.49514830362672907, 18300: 0.4733328745440782, 18400: 0.48750946252838756, 18500: 0.5135228132957126, 18600: 0.48248572018443325, 18700: 0.5051269699263643, 18800: 0.508430252563485, 18900: 0.5119399903654256, 19000: 0.5138669052370793, 19100: 0.5184089188631202, 19200: 0.4797329846534994, 19300: 0.5208175624526874, 19400: 0.49156974743651505, 19500: 0.518753010804487, 19600: 0.5294198609868557, 19700: 0.5395361640630376, 19800: 0.524533755419448, 19900: 0.5314844126350561, 20000: 0.5246025738077215, 20100: 0.4888170119055812, 20200: 0.5178583717569335, 20300: 0.49941504369967654, 20400: 0.4679650402587571, 20500: 0.5025806895602505, 20600: 0.5320349597412428, 20700: 0.5010666850182369, 20800: 0.4813846259720597, 20900: 0.4952171220150024, 21000: 0.5168949143211066, 21100: 0.5049205147615443, 21200: 0.5237767531484413, 21300: 0.498313949487303, 21400: 0.49631821622737593, 21500: 0.5042323308788108, 21600: 0.4872341889752942, 21700: 0.5206799256761406, 21800: 0.5153120913908197, 21900: 0.5118711719771523, 22000: 0.5179271901452068, 22100: 0.4594315601128622, 22200: 0.49198265776615513, 22300: 0.47051132062487094, 22400: 0.515587364943913, 22500: 0.514004542013626, 22600: 0.4909503819420549, 22700: 0.5164820039914665, 22800: 0.48819764641112107, 22900: 0.4817287179134265, 23000: 0.5096689835524052, 23100: 0.4811781708072397, 23200: 0.5204046521230473, 23300: 0.5069162480214713, 23400: 0.48964283256486135, 23500: 0.5062280641387379, 23600: 0.49150092904824166, 23700: 0.49005574289450143, 23800: 0.5165508223797398, 23900: 0.46369830018580965, 24000: 0.48964283256486135, 24100: 0.4720253251668846, 24200: 0.5192347395224004, 24300: 0.5210240176175074, 24400: 0.47119950450760445, 24500: 0.5067786112449246, 24600: 0.5165508223797398, 24700: 0.5113206248709655, 24800: 0.5109765329295988, 24900: 0.518753010804487, 25000: 0.4923267497075218, 25100: 0.5089119812813984, 25200: 0.48744064414011423, 25300: 0.4961805794508293, 25400: 0.4705801390131443, 25500: 0.5203358337347739, 25600: 0.5239832083132613, 25700: 0.5102883490468654, 25800: 0.48702773381047415, 25900: 0.45826164751221526, 26000: 0.47016722868350425, 26100: 0.4771867042873856, 26200: 0.5025806895602505, 26300: 0.507260339962838, 26400: 0.5118711719771523, 26500: 0.49556121395636915, 26600: 0.5111829880944189, 26700: 0.46817149542357717, 26800: 0.5080173422338449, 26900: 0.5023742343954305, 27000: 0.48957401417658797, 27100: 0.5006537746885968, 27200: 0.49115683710687497, 27300: 0.5036129653843507, 27400: 0.5386415250154841, 27500: 0.48806000963457435, 27600: 0.5114582616475122, 27700: 0.5209551992292341, 27800: 0.49693758172183605, 27900: 0.4873030073635675, 28000: 0.5056086986442777, 28100: 0.46624458055192347, 28200: 0.5038194205491707, 28300: 0.49955268047622325, 28400: 0.5371963388617439, 28500: 0.5022365976188837, 28600: 0.5320349597412428, 28700: 0.5151744546142729, 28800: 0.5180648269217535, 28900: 0.4828298121258, 29000: 0.49308375197852866}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.72       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.60      0.57      0.58       877\n",
      "           3       0.59      0.53      0.56       897\n",
      "           4       0.57      0.76      0.66       892\n",
      "           5       0.58      0.49      0.53       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.57      0.83      0.68       889\n",
      "           8       0.59      0.37      0.45       892\n",
      "           9       0.58      0.68      0.63       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 0, Loss: 1.02662992477417, F1: 0.5928376635183397, Accuracy: 0.5321037781295163, Time Elapsed: 14.497785091400146 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.63      0.25      0.36       877\n",
      "           3       0.60      0.51      0.55       897\n",
      "           4       0.59      0.68      0.63       892\n",
      "           5       0.52      0.73      0.60       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.61      0.74      0.67       889\n",
      "           8       0.55      0.72      0.62       892\n",
      "           9       0.50      0.84      0.63       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.58      0.53     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 100, Loss: 3.1736302375793457, F1: 0.5265751095482181, Accuracy: 0.5078797054572982, Time Elapsed: 332.2375512123108 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.60      0.50      0.55       897\n",
      "           4       0.61      0.49      0.54       892\n",
      "           5       0.60      0.39      0.48       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.56      0.66      0.61       892\n",
      "           9       0.64      0.34      0.44       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.53      0.51     14531\n",
      "weighted avg       0.48      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 200, Loss: 0.8100726008415222, F1: 0.5145899766642761, Accuracy: 0.5058839721973711, Time Elapsed: 349.82083916664124 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.59      0.67      0.63       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.56      0.73      0.63       892\n",
      "           5       0.45      0.82      0.58       862\n",
      "           6       0.62      0.43      0.51       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.63      0.38      0.48       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 300, Loss: 0.9592094421386719, F1: 0.5779706028550169, Accuracy: 0.5183401004748469, Time Elapsed: 365.2589581012726 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65       912\n",
      "           1       0.63      0.38      0.47       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.55      0.77      0.64       897\n",
      "           4       0.60      0.26      0.36       892\n",
      "           5       0.54      0.71      0.61       862\n",
      "           6       0.63      0.44      0.51       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.54      0.79      0.64       892\n",
      "           9       0.57      0.69      0.62       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 400, Loss: 0.5077714920043945, F1: 0.554238703802342, Accuracy: 0.506640974468378, Time Elapsed: 679.8029670715332 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.61      0.23      0.33       885\n",
      "           2       0.58      0.63      0.61       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.58      0.78      0.67       892\n",
      "           5       0.58      0.29      0.39       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.56      0.71      0.63       892\n",
      "           9       0.56      0.71      0.63       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 500, Loss: 2.5837082862854004, F1: 0.5615089617939064, Accuracy: 0.5144174523432661, Time Elapsed: 695.4137620925903 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.94      0.73       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.53      0.78      0.63       897\n",
      "           4       0.54      0.83      0.66       892\n",
      "           5       0.57      0.58      0.57       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.59      0.71      0.64       889\n",
      "           8       0.59      0.68      0.63       892\n",
      "           9       0.61      0.43      0.50       876\n",
      "          10       0.39      0.21      0.28      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 2, Step 600, Loss: 1.732617974281311, F1: 0.6083548299127453, Accuracy: 0.5371963388617439, Time Elapsed: 710.9693591594696 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.57      0.69      0.62       892\n",
      "           5       0.55      0.54      0.55       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.57      0.67      0.62       892\n",
      "           9       0.59      0.54      0.57       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.53      0.52     14531\n",
      "\n",
      "Epoch 2, Step 700, Loss: 0.4581232964992523, F1: 0.5942834175828831, Accuracy: 0.5291445874337622, Time Elapsed: 1400.0194120407104 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.56       912\n",
      "           1       0.61      0.65      0.63       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.56      0.67      0.61       897\n",
      "           4       0.53      0.79      0.63       892\n",
      "           5       0.52      0.69      0.59       862\n",
      "           6       0.59      0.82      0.68       903\n",
      "           7       0.61      0.21      0.32       889\n",
      "           8       0.57      0.55      0.56       892\n",
      "           9       0.54      0.59      0.57       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 800, Loss: 1.8830678462982178, F1: 0.5564161012848794, Accuracy: 0.5056086986442777, Time Elapsed: 1417.3600940704346 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.69      0.10      0.17       885\n",
      "           2       0.53      0.83      0.65       877\n",
      "           3       0.57      0.48      0.52       897\n",
      "           4       0.59      0.33      0.43       892\n",
      "           5       0.57      0.32      0.41       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.61      0.47      0.53       889\n",
      "           8       0.55      0.07      0.12       892\n",
      "           9       0.64      0.32      0.42       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.46      0.46     14531\n",
      "weighted avg       0.52      0.48      0.46     14531\n",
      "\n",
      "Epoch 2, Step 900, Loss: 1.1026453971862793, F1: 0.46404305718283284, Accuracy: 0.4848943637740004, Time Elapsed: 1433.261981010437 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70       912\n",
      "           1       0.61      0.63      0.62       885\n",
      "           2       0.61      0.50      0.55       877\n",
      "           3       0.66      0.16      0.26       897\n",
      "           4       0.59      0.21      0.31       892\n",
      "           5       0.56      0.37      0.44       862\n",
      "           6       0.64      0.54      0.58       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.59      0.45      0.51       892\n",
      "           9       0.44      0.88      0.58       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.52      0.51     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 1000, Loss: 2.2199361324310303, F1: 0.5110156039029229, Accuracy: 0.49253320487234187, Time Elapsed: 1627.736244916916 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70       912\n",
      "           1       0.64      0.34      0.45       885\n",
      "           2       0.54      0.77      0.64       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.59      0.66      0.62       892\n",
      "           5       0.63      0.12      0.21       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.49      0.54       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.54      0.74      0.62       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.53      0.49     14531\n",
      "weighted avg       0.48      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 1100, Loss: 0.4997534453868866, F1: 0.4927781121135286, Accuracy: 0.4978322207693896, Time Elapsed: 1644.4852311611176 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       912\n",
      "           1       0.61      0.41      0.49       885\n",
      "           2       0.62      0.47      0.54       877\n",
      "           3       0.59      0.45      0.51       897\n",
      "           4       0.57      0.66      0.61       892\n",
      "           5       0.59      0.16      0.26       862\n",
      "           6       0.63      0.63      0.63       903\n",
      "           7       0.58      0.79      0.67       889\n",
      "           8       0.59      0.31      0.41       892\n",
      "           9       0.57      0.56      0.57       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.50      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 1200, Loss: 0.43592754006385803, F1: 0.5214910520146265, Accuracy: 0.50010322758241, Time Elapsed: 1659.528379201889 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.61      0.54      0.57       885\n",
      "           2       0.62      0.20      0.31       877\n",
      "           3       0.56      0.56      0.56       897\n",
      "           4       0.56      0.70      0.62       892\n",
      "           5       0.59      0.35      0.44       862\n",
      "           6       0.59      0.82      0.69       903\n",
      "           7       0.58      0.74      0.65       889\n",
      "           8       0.58      0.46      0.51       892\n",
      "           9       0.55      0.71      0.62       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 1300, Loss: 1.2423738241195679, F1: 0.5491034342262696, Accuracy: 0.5096689835524052, Time Elapsed: 1725.5729122161865 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.58      0.57      0.58       877\n",
      "           3       0.58      0.37      0.45       897\n",
      "           4       0.59      0.47      0.52       892\n",
      "           5       0.62      0.08      0.13       862\n",
      "           6       0.62      0.75      0.68       903\n",
      "           7       0.54      0.86      0.66       889\n",
      "           8       0.53      0.54      0.54       892\n",
      "           9       0.67      0.04      0.08       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.49     14531\n",
      "weighted avg       0.52      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 1400, Loss: 0.47224992513656616, F1: 0.490176481437992, Accuracy: 0.4966623081687427, Time Elapsed: 1741.8720581531525 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.63      0.67      0.64       885\n",
      "           2       0.58      0.60      0.59       877\n",
      "           3       0.60      0.41      0.49       897\n",
      "           4       0.56      0.81      0.66       892\n",
      "           5       0.57      0.17      0.26       862\n",
      "           6       0.63      0.74      0.68       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.56      0.68      0.61       892\n",
      "           9       0.60      0.14      0.22       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 1500, Loss: 0.837173342704773, F1: 0.5336559182251466, Accuracy: 0.5097378019406785, Time Elapsed: 2685.802664041519 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.59      0.09      0.15       897\n",
      "           4       0.56      0.55      0.56       892\n",
      "           5       0.44      0.72      0.55       862\n",
      "           6       0.63      0.55      0.59       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.55      0.76      0.64       892\n",
      "           9       0.61      0.19      0.29       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 1600, Loss: 1.99886155128479, F1: 0.5269790369746296, Accuracy: 0.5029247815016172, Time Elapsed: 2703.7495930194855 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.62      0.74      0.68       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.59      0.11      0.18       897\n",
      "           4       0.58      0.57      0.57       892\n",
      "           5       0.55      0.56      0.55       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.60      0.48      0.54       889\n",
      "           8       0.55      0.75      0.63       892\n",
      "           9       0.60      0.47      0.53       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 1700, Loss: 1.6293941736221313, F1: 0.5477476117362866, Accuracy: 0.5128346294129792, Time Elapsed: 2719.8256618976593 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.64      0.36      0.46       877\n",
      "           3       0.60      0.32      0.42       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.40      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.53      0.54      0.52     14531\n",
      "weighted avg       0.48      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 1800, Loss: 0.3250542879104614, F1: 0.5229603614573946, Accuracy: 0.5109077145413254, Time Elapsed: 3715.356700181961 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.72       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.54      0.79      0.64       877\n",
      "           3       0.58      0.15      0.24       897\n",
      "           4       0.51      0.91      0.65       892\n",
      "           5       0.57      0.26      0.36       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.62      0.30      0.41       889\n",
      "           8       0.56      0.57      0.56       892\n",
      "           9       0.62      0.32      0.43       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 1900, Loss: 1.0506837368011475, F1: 0.5266835089849452, Accuracy: 0.5051957883146376, Time Elapsed: 3731.3412222862244 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.55      0.72      0.62       877\n",
      "           3       0.55      0.68      0.61       897\n",
      "           4       0.55      0.83      0.66       892\n",
      "           5       0.50      0.70      0.58       862\n",
      "           6       0.56      0.88      0.69       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.60      0.42      0.49       892\n",
      "           9       0.58      0.45      0.51       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 2000, Loss: 1.9628316164016724, F1: 0.5827578682779692, Accuracy: 0.5196476498520405, Time Elapsed: 3746.919084072113 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.94      0.68       912\n",
      "           1       0.64      0.30      0.41       885\n",
      "           2       0.56      0.69      0.62       877\n",
      "           3       0.59      0.51      0.55       897\n",
      "           4       0.59      0.25      0.36       892\n",
      "           5       0.66      0.07      0.12       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.60      0.53      0.56       889\n",
      "           8       0.57      0.05      0.09       892\n",
      "           9       0.58      0.69      0.63       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.49      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 2100, Loss: 0.1992587447166443, F1: 0.46755422844655375, Accuracy: 0.48640836831601403, Time Elapsed: 4701.308146953583 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       912\n",
      "           1       0.62      0.87      0.73       885\n",
      "           2       0.58      0.61      0.60       877\n",
      "           3       0.58      0.49      0.53       897\n",
      "           4       0.58      0.64      0.61       892\n",
      "           5       0.56      0.36      0.44       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.59      0.71      0.64       889\n",
      "           8       0.56      0.68      0.62       892\n",
      "           9       0.58      0.74      0.65       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 2200, Loss: 3.047938585281372, F1: 0.5857429764112898, Accuracy: 0.5240520267015346, Time Elapsed: 4718.126728057861 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.61      0.92      0.73       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.57      0.29      0.38       897\n",
      "           4       0.56      0.64      0.60       892\n",
      "           5       0.53      0.31      0.39       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.58      0.66      0.62       889\n",
      "           8       0.57      0.47      0.52       892\n",
      "           9       0.61      0.52      0.56       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 2300, Loss: 0.9690263867378235, F1: 0.5504510732587111, Accuracy: 0.5076732502924781, Time Elapsed: 4737.072974205017 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.57      0.49      0.53       897\n",
      "           4       0.53      0.78      0.63       892\n",
      "           5       0.52      0.62      0.57       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.60      0.51      0.55       889\n",
      "           8       0.52      0.77      0.62       892\n",
      "           9       0.61      0.39      0.48       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 2400, Loss: 0.3642800748348236, F1: 0.5794505988770441, Accuracy: 0.5188218291927603, Time Elapsed: 5722.451278209686 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       912\n",
      "           1       0.62      0.63      0.63       885\n",
      "           2       0.69      0.11      0.19       877\n",
      "           3       0.58      0.28      0.37       897\n",
      "           4       0.61      0.26      0.37       892\n",
      "           5       0.49      0.77      0.60       862\n",
      "           6       0.62      0.49      0.55       903\n",
      "           7       0.62      0.57      0.59       889\n",
      "           8       0.55      0.52      0.54       892\n",
      "           9       0.61      0.51      0.55       876\n",
      "          10       0.40      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.50     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 2500, Loss: 0.9831814765930176, F1: 0.5038747967977723, Accuracy: 0.4952171220150024, Time Elapsed: 5739.371388196945 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.71      0.19      0.30       877\n",
      "           3       0.54      0.74      0.63       897\n",
      "           4       0.60      0.68      0.64       892\n",
      "           5       0.46      0.82      0.59       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.61      0.63      0.62       889\n",
      "           8       0.52      0.77      0.62       892\n",
      "           9       0.59      0.61      0.60       876\n",
      "          10       0.41      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.58     14531\n",
      "weighted avg       0.52      0.53      0.50     14531\n",
      "\n",
      "Epoch 2, Step 2600, Loss: 0.719196081161499, F1: 0.5800719742380823, Accuracy: 0.5257724864083683, Time Elapsed: 5755.478274106979 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.66       912\n",
      "           1       0.60      0.76      0.67       885\n",
      "           2       0.58      0.59      0.59       877\n",
      "           3       0.65      0.08      0.15       897\n",
      "           4       0.60      0.36      0.45       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.58      0.80      0.68       889\n",
      "           8       0.60      0.33      0.43       892\n",
      "           9       0.60      0.49      0.54       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.53     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 2700, Loss: 3.493514060974121, F1: 0.5281291469985058, Accuracy: 0.5049205147615443, Time Elapsed: 6813.298624992371 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.19      0.30       912\n",
      "           1       0.62      0.27      0.38       885\n",
      "           2       0.62      0.40      0.49       877\n",
      "           3       0.54      0.04      0.08       897\n",
      "           4       0.54      0.81      0.65       892\n",
      "           5       0.55      0.39      0.45       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.59      0.68      0.63       889\n",
      "           8       0.55      0.77      0.64       892\n",
      "           9       0.60      0.35      0.44       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.47      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 2800, Loss: 0.2395302951335907, F1: 0.4717864360567632, Accuracy: 0.4850320005505471, Time Elapsed: 6831.063983201981 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62       912\n",
      "           1       0.61      0.84      0.71       885\n",
      "           2       0.58      0.65      0.61       877\n",
      "           3       0.61      0.41      0.49       897\n",
      "           4       0.59      0.65      0.62       892\n",
      "           5       0.59      0.24      0.34       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.46      0.90      0.61       892\n",
      "           9       0.58      0.59      0.59       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 2900, Loss: 1.3495428562164307, F1: 0.5696922055160069, Accuracy: 0.5168949143211066, Time Elapsed: 6851.353686094284 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70       912\n",
      "           1       0.63      0.36      0.46       885\n",
      "           2       0.57      0.73      0.64       877\n",
      "           3       0.56      0.75      0.64       897\n",
      "           4       0.56      0.82      0.66       892\n",
      "           5       0.54      0.64      0.58       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.57      0.81      0.66       889\n",
      "           8       0.58      0.61      0.59       892\n",
      "           9       0.60      0.64      0.62       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 2, Step 3000, Loss: 0.6791083812713623, F1: 0.5959927827697258, Accuracy: 0.5301768632578625, Time Elapsed: 7851.354960203171 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56       912\n",
      "           1       0.62      0.65      0.63       885\n",
      "           2       0.61      0.42      0.50       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.59      0.49      0.54       892\n",
      "           5       0.50      0.75      0.60       862\n",
      "           6       0.54      0.93      0.68       903\n",
      "           7       0.63      0.38      0.47       889\n",
      "           8       0.55      0.70      0.62       892\n",
      "           9       0.58      0.67      0.62       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 3100, Loss: 1.0943806171417236, F1: 0.5576926257883611, Accuracy: 0.5071227031862914, Time Elapsed: 7872.042516946793 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.72       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.59      0.60      0.59       897\n",
      "           4       0.60      0.59      0.59       892\n",
      "           5       0.56      0.37      0.44       862\n",
      "           6       0.59      0.88      0.71       903\n",
      "           7       0.57      0.03      0.06       889\n",
      "           8       0.58      0.52      0.55       892\n",
      "           9       0.57      0.64      0.60       876\n",
      "          10       0.38      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 3200, Loss: 0.6510897874832153, F1: 0.5423291136578737, Accuracy: 0.5119399903654256, Time Elapsed: 8905.631053209305 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70       912\n",
      "           1       0.58      0.96      0.72       885\n",
      "           2       0.62      0.32      0.43       877\n",
      "           3       0.57      0.73      0.64       897\n",
      "           4       0.62      0.24      0.35       892\n",
      "           5       0.53      0.74      0.62       862\n",
      "           6       0.54      0.92      0.68       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.57      0.58      0.58       892\n",
      "           9       0.60      0.56      0.58       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.63      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 3300, Loss: 0.7027990818023682, F1: 0.5712403094893729, Accuracy: 0.5218498382767875, Time Elapsed: 8937.03594493866 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.84      0.69       912\n",
      "           1       0.60      0.13      0.22       885\n",
      "           2       0.66      0.21      0.32       877\n",
      "           3       0.58      0.44      0.50       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.58      0.36      0.44       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.60      0.03      0.06       889\n",
      "           8       0.57      0.62      0.59       892\n",
      "           9       0.66      0.07      0.13       876\n",
      "          10       0.39      0.66      0.49      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.53      0.36      0.37     14531\n",
      "weighted avg       0.49      0.46      0.41     14531\n",
      "\n",
      "Epoch 2, Step 3400, Loss: 0.6067671775817871, F1: 0.36972320999536074, Accuracy: 0.46149611176106253, Time Elapsed: 9960.504036188126 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.61      0.29      0.39       877\n",
      "           3       0.56      0.77      0.65       897\n",
      "           4       0.59      0.54      0.57       892\n",
      "           5       0.57      0.54      0.56       862\n",
      "           6       0.62      0.50      0.56       903\n",
      "           7       0.61      0.63      0.62       889\n",
      "           8       0.54      0.83      0.65       892\n",
      "           9       0.48      0.01      0.03       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 3500, Loss: 0.5310176014900208, F1: 0.5304890749739187, Accuracy: 0.5111829880944189, Time Elapsed: 9976.893208026886 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65       912\n",
      "           1       0.59      0.86      0.70       885\n",
      "           2       0.57      0.58      0.58       877\n",
      "           3       0.60      0.56      0.58       897\n",
      "           4       0.59      0.18      0.28       892\n",
      "           5       0.53      0.64      0.58       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.57      0.24      0.33       892\n",
      "           9       0.46      0.01      0.01       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.52      0.50     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 3600, Loss: 1.548814296722412, F1: 0.4965612493021204, Accuracy: 0.49707521849838276, Time Elapsed: 10954.215487957 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65       912\n",
      "           1       0.63      0.12      0.20       885\n",
      "           2       0.55      0.63      0.59       877\n",
      "           3       0.60      0.24      0.34       897\n",
      "           4       0.58      0.67      0.62       892\n",
      "           5       0.57      0.41      0.48       862\n",
      "           6       0.57      0.81      0.67       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.56      0.13      0.21       892\n",
      "           9       0.62      0.24      0.34       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.48      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 3700, Loss: 0.8607654571533203, F1: 0.4734260752127863, Accuracy: 0.4867524602573808, Time Elapsed: 10970.945693016052 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       912\n",
      "           1       0.58      0.88      0.70       885\n",
      "           2       0.58      0.58      0.58       877\n",
      "           3       0.55      0.70      0.61       897\n",
      "           4       0.58      0.76      0.66       892\n",
      "           5       0.54      0.56      0.55       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.58      0.30      0.39       892\n",
      "           9       0.60      0.41      0.49       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 3800, Loss: 1.5187904834747314, F1: 0.5730637704639676, Accuracy: 0.5186841924162137, Time Elapsed: 10986.31832408905 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.65       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.58      0.65      0.61       877\n",
      "           3       0.49      0.86      0.63       897\n",
      "           4       0.52      0.90      0.66       892\n",
      "           5       0.55      0.54      0.55       862\n",
      "           6       0.62      0.48      0.54       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.57      0.64      0.60       892\n",
      "           9       0.59      0.50      0.54       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 3900, Loss: 0.38801446557044983, F1: 0.5867032997402905, Accuracy: 0.5201981969582272, Time Elapsed: 11936.36575627327 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.69       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.60      0.41      0.49       897\n",
      "           4       0.58      0.64      0.61       892\n",
      "           5       0.55      0.59      0.57       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.55      0.85      0.67       889\n",
      "           8       0.58      0.67      0.62       892\n",
      "           9       0.41      0.01      0.02       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.61      0.55     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 4000, Loss: 0.7152345776557922, F1: 0.547440210725837, Accuracy: 0.5168260959328332, Time Elapsed: 11955.836644172668 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.24      0.35       912\n",
      "           1       0.67      0.22      0.33       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.60      0.31      0.41       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.56      0.19      0.29       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.63      0.34      0.44       889\n",
      "           8       0.57      0.71      0.63       892\n",
      "           9       0.54      0.51      0.53       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.53      0.41      0.43     14531\n",
      "weighted avg       0.48      0.47      0.44     14531\n",
      "\n",
      "Epoch 2, Step 4100, Loss: 1.7548611164093018, F1: 0.4311300396590735, Accuracy: 0.4718876883903379, Time Elapsed: 11971.686388015747 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65       912\n",
      "           1       0.61      0.16      0.25       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.59      0.33      0.42       897\n",
      "           4       0.44      0.96      0.61       892\n",
      "           5       0.59      0.29      0.39       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.57      0.38      0.46       892\n",
      "           9       0.60      0.38      0.46       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 4200, Loss: 1.0987321138381958, F1: 0.5088038941143467, Accuracy: 0.4887481935173078, Time Elapsed: 11986.384518146515 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.61       912\n",
      "           1       0.62      0.42      0.50       885\n",
      "           2       0.55      0.76      0.64       877\n",
      "           3       0.52      0.82      0.63       897\n",
      "           4       0.60      0.53      0.56       892\n",
      "           5       0.59      0.34      0.43       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.58      0.44      0.50       892\n",
      "           9       0.57      0.78      0.66       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 4300, Loss: 1.6619468927383423, F1: 0.5681451318264475, Accuracy: 0.5158626384970064, Time Elapsed: 12001.012403011322 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61       912\n",
      "           1       0.61      0.86      0.72       885\n",
      "           2       0.58      0.53      0.55       877\n",
      "           3       0.55      0.75      0.63       897\n",
      "           4       0.55      0.07      0.12       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.53      0.06      0.11       903\n",
      "           7       0.63      0.46      0.53       889\n",
      "           8       0.56      0.47      0.51       892\n",
      "           9       0.56      0.67      0.61       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.49      0.49     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 4400, Loss: 1.1741794347763062, F1: 0.4859076996065189, Accuracy: 0.489780469341408, Time Elapsed: 12951.987811088562 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.08      0.15       912\n",
      "           1       0.62      0.68      0.65       885\n",
      "           2       0.61      0.31      0.41       877\n",
      "           3       0.57      0.71      0.63       897\n",
      "           4       0.59      0.40      0.48       892\n",
      "           5       0.41      0.84      0.56       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.57      0.29      0.38       892\n",
      "           9       0.60      0.54      0.57       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.52      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 4500, Loss: 1.3351383209228516, F1: 0.5047169915338012, Accuracy: 0.48950519578831464, Time Elapsed: 12967.493539094925 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.46      0.53       912\n",
      "           1       0.62      0.62      0.62       885\n",
      "           2       0.55      0.78      0.65       877\n",
      "           3       0.61      0.47      0.53       897\n",
      "           4       0.60      0.43      0.50       892\n",
      "           5       0.57      0.44      0.49       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.60      0.53      0.56       892\n",
      "           9       0.60      0.53      0.57       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.57      0.57     14531\n",
      "weighted avg       0.52      0.51      0.51     14531\n",
      "\n",
      "Epoch 2, Step 4600, Loss: 1.9879069328308105, F1: 0.5650755232544357, Accuracy: 0.5140733604018994, Time Elapsed: 12984.02886915207 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.04      0.07       912\n",
      "           1       0.61      0.88      0.72       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.59      0.68      0.63       897\n",
      "           4       0.60      0.52      0.56       892\n",
      "           5       0.56      0.53      0.55       862\n",
      "           6       0.62      0.49      0.55       903\n",
      "           7       0.61      0.57      0.59       889\n",
      "           8       0.59      0.48      0.53       892\n",
      "           9       0.62      0.43      0.51       876\n",
      "          10       0.39      0.47      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.60      0.52      0.52     14531\n",
      "weighted avg       0.53      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 4700, Loss: 1.8270081281661987, F1: 0.5199554317077704, Accuracy: 0.5006537746885968, Time Elapsed: 13001.24887394905 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.60      0.45      0.52       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.53      0.88      0.66       892\n",
      "           5       0.56      0.26      0.36       862\n",
      "           6       0.62      0.50      0.56       903\n",
      "           7       0.59      0.76      0.67       889\n",
      "           8       0.57      0.23      0.33       892\n",
      "           9       0.65      0.13      0.21       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 4800, Loss: 0.4404740333557129, F1: 0.5134049987902075, Accuracy: 0.49893331498176313, Time Elapsed: 13015.857944011688 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.46      0.01      0.02       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.57      0.24      0.34       897\n",
      "           4       0.60      0.57      0.59       892\n",
      "           5       0.55      0.54      0.55       862\n",
      "           6       0.63      0.72      0.67       903\n",
      "           7       0.61      0.60      0.61       889\n",
      "           8       0.58      0.63      0.60       892\n",
      "           9       0.64      0.32      0.43       876\n",
      "          10       0.40      0.51      0.45      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.49      0.50     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 4900, Loss: 1.2619454860687256, F1: 0.4986338760125083, Accuracy: 0.4982451310990297, Time Elapsed: 13030.4489300251 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.57      0.66      0.62       877\n",
      "           3       0.59      0.60      0.59       897\n",
      "           4       0.60      0.38      0.47       892\n",
      "           5       0.59      0.23      0.33       862\n",
      "           6       0.61      0.43      0.51       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.58      0.61      0.59       892\n",
      "           9       0.61      0.41      0.49       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 5000, Loss: 1.735445499420166, F1: 0.5519393161717149, Accuracy: 0.5139357236253527, Time Elapsed: 13044.93812918663 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.58      0.67      0.62       897\n",
      "           4       0.54      0.82      0.65       892\n",
      "           5       0.54      0.66      0.59       862\n",
      "           6       0.63      0.26      0.37       903\n",
      "           7       0.58      0.83      0.69       889\n",
      "           8       0.57      0.61      0.59       892\n",
      "           9       0.60      0.41      0.49       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 5100, Loss: 0.17246684432029724, F1: 0.5780765095983015, Accuracy: 0.5224692037712477, Time Elapsed: 13059.677757024765 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.31      0.42       912\n",
      "           1       0.61      0.54      0.57       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.60      0.45      0.52       897\n",
      "           4       0.52      0.91      0.66       892\n",
      "           5       0.57      0.55      0.56       862\n",
      "           6       0.62      0.80      0.70       903\n",
      "           7       0.62      0.43      0.51       889\n",
      "           8       0.57      0.64      0.60       892\n",
      "           9       0.61      0.49      0.54       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 5200, Loss: 1.3229261636734009, F1: 0.5515416117395634, Accuracy: 0.5065721560801046, Time Elapsed: 13074.554750919342 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.56      0.69      0.62       877\n",
      "           3       0.58      0.68      0.63       897\n",
      "           4       0.58      0.63      0.60       892\n",
      "           5       0.56      0.65      0.60       862\n",
      "           6       0.52      0.94      0.67       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.59      0.31      0.41       892\n",
      "           9       0.59      0.58      0.59       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 2, Step 5300, Loss: 0.8322697281837463, F1: 0.589153989663569, Accuracy: 0.5265983070676484, Time Elapsed: 13089.770673274994 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.59      0.50      0.54       897\n",
      "           4       0.58      0.64      0.61       892\n",
      "           5       0.55      0.35      0.43       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.52      0.77      0.62       892\n",
      "           9       0.58      0.65      0.61       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 5400, Loss: 0.5321848392486572, F1: 0.5810864956552547, Accuracy: 0.5210240176175074, Time Elapsed: 13104.653641939163 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.57      0.74      0.64       877\n",
      "           3       0.60      0.50      0.55       897\n",
      "           4       0.60      0.21      0.31       892\n",
      "           5       0.61      0.15      0.25       862\n",
      "           6       0.62      0.67      0.65       903\n",
      "           7       0.59      0.17      0.27       889\n",
      "           8       0.60      0.35      0.44       892\n",
      "           9       0.35      0.93      0.51       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.53      0.49     14531\n",
      "weighted avg       0.51      0.48      0.46     14531\n",
      "\n",
      "Epoch 2, Step 5500, Loss: 0.3795253336429596, F1: 0.49297185993822956, Accuracy: 0.4823480834078866, Time Elapsed: 13119.228287935257 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.69       912\n",
      "           1       0.62      0.75      0.68       885\n",
      "           2       0.58      0.71      0.63       877\n",
      "           3       0.59      0.65      0.62       897\n",
      "           4       0.54      0.84      0.66       892\n",
      "           5       0.58      0.44      0.50       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.60      0.60      0.60       889\n",
      "           8       0.57      0.20      0.30       892\n",
      "           9       0.60      0.58      0.59       876\n",
      "          10       0.38      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 5600, Loss: 1.203205943107605, F1: 0.5745581482062514, Accuracy: 0.5201981969582272, Time Elapsed: 13134.656778097153 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.23      0.34       912\n",
      "           1       0.63      0.47      0.54       885\n",
      "           2       0.59      0.67      0.63       877\n",
      "           3       0.50      0.83      0.63       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.54      0.48      0.51       862\n",
      "           6       0.61      0.83      0.70       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.60      0.37      0.46       892\n",
      "           9       0.60      0.57      0.58       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 5700, Loss: 0.1957629919052124, F1: 0.5552651779684294, Accuracy: 0.5112518064826922, Time Elapsed: 13150.431738138199 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       912\n",
      "           1       0.64      0.40      0.49       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.55      0.79      0.65       897\n",
      "           4       0.58      0.60      0.59       892\n",
      "           5       0.55      0.38      0.45       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.56      0.89      0.69       889\n",
      "           8       0.60      0.30      0.40       892\n",
      "           9       0.55      0.75      0.64       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 5800, Loss: 1.0905712842941284, F1: 0.5600256396601875, Accuracy: 0.5126281742481591, Time Elapsed: 13165.74807024002 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.19      0.29       912\n",
      "           1       0.61      0.40      0.48       885\n",
      "           2       0.56      0.70      0.62       877\n",
      "           3       0.55      0.64      0.59       897\n",
      "           4       0.56      0.75      0.65       892\n",
      "           5       0.50      0.25      0.34       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.62      0.48      0.54       889\n",
      "           8       0.62      0.12      0.20       892\n",
      "           9       0.57      0.14      0.22       876\n",
      "          10       0.39      0.55      0.45      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.44      0.45     14531\n",
      "weighted avg       0.51      0.47      0.45     14531\n",
      "\n",
      "Epoch 2, Step 5900, Loss: 1.0985355377197266, F1: 0.45396238610928846, Accuracy: 0.47312641937925815, Time Elapsed: 13180.453202962875 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.59      0.49      0.53       877\n",
      "           3       0.52      0.75      0.61       897\n",
      "           4       0.59      0.56      0.57       892\n",
      "           5       0.55      0.47      0.51       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.60      0.54      0.57       889\n",
      "           8       0.59      0.35      0.44       892\n",
      "           9       0.48      0.84      0.61       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 6000, Loss: 0.6946715116500854, F1: 0.5685746251452299, Accuracy: 0.512008808753699, Time Elapsed: 13196.006869077682 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.70       912\n",
      "           1       0.61      0.68      0.64       885\n",
      "           2       0.64      0.08      0.15       877\n",
      "           3       0.64      0.14      0.23       897\n",
      "           4       0.56      0.15      0.23       892\n",
      "           5       0.56      0.35      0.43       862\n",
      "           6       0.63      0.60      0.62       903\n",
      "           7       0.58      0.83      0.69       889\n",
      "           8       0.58      0.36      0.44       892\n",
      "           9       0.60      0.41      0.49       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.45      0.46     14531\n",
      "weighted avg       0.52      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 6100, Loss: 0.6053436398506165, F1: 0.4609713377647568, Accuracy: 0.4853072741036405, Time Elapsed: 13211.336999177933 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.61      0.88      0.72       885\n",
      "           2       0.58      0.52      0.55       877\n",
      "           3       0.48      0.82      0.61       897\n",
      "           4       0.57      0.26      0.35       892\n",
      "           5       0.56      0.29      0.38       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.60      0.79      0.68       889\n",
      "           8       0.59      0.26      0.36       892\n",
      "           9       0.57      0.42      0.49       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.53     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 6200, Loss: 2.06076717376709, F1: 0.5314146111805217, Accuracy: 0.5016172321244237, Time Elapsed: 13225.479916095734 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.58      0.98      0.72       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.56      0.68      0.61       892\n",
      "           5       0.52      0.69      0.59       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.58      0.60      0.59       892\n",
      "           9       0.60      0.63      0.61       876\n",
      "          10       0.40      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 2, Step 6300, Loss: 0.7280096411705017, F1: 0.610437932243541, Accuracy: 0.5371963388617439, Time Elapsed: 13239.910892009735 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.41      0.50       912\n",
      "           1       0.58      0.96      0.73       885\n",
      "           2       0.63      0.10      0.18       877\n",
      "           3       0.54      0.75      0.63       897\n",
      "           4       0.60      0.48      0.53       892\n",
      "           5       0.56      0.42      0.48       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.60      0.63      0.62       889\n",
      "           8       0.58      0.39      0.47       892\n",
      "           9       0.63      0.42      0.50       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.53      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 6400, Loss: 0.8036624789237976, F1: 0.5225835544258435, Accuracy: 0.5038194205491707, Time Elapsed: 13254.138493061066 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.64       912\n",
      "           1       0.61      0.47      0.53       885\n",
      "           2       1.00      0.00      0.00       877\n",
      "           3       0.55      0.75      0.64       897\n",
      "           4       0.58      0.50      0.54       892\n",
      "           5       0.52      0.65      0.57       862\n",
      "           6       0.61      0.57      0.59       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.58      0.28      0.37       892\n",
      "           9       0.51      0.85      0.63       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.60      0.53      0.51     14531\n",
      "weighted avg       0.53      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 6500, Loss: 0.6190985441207886, F1: 0.5061340037909443, Accuracy: 0.4928084784254353, Time Elapsed: 13269.692626953125 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.71       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.64      0.25      0.36       877\n",
      "           3       0.58      0.58      0.58       897\n",
      "           4       0.60      0.46      0.52       892\n",
      "           5       0.57      0.40      0.47       862\n",
      "           6       0.60      0.48      0.54       903\n",
      "           7       0.58      0.78      0.66       889\n",
      "           8       0.54      0.65      0.59       892\n",
      "           9       0.49      0.78      0.60       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 6600, Loss: 0.7189517021179199, F1: 0.5536353136012425, Accuracy: 0.508430252563485, Time Elapsed: 13284.009932041168 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.72       912\n",
      "           1       0.61      0.47      0.53       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.58      0.33      0.42       897\n",
      "           4       0.56      0.68      0.61       892\n",
      "           5       0.56      0.34      0.42       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.52      0.65      0.58       892\n",
      "           9       0.62      0.09      0.15       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.52     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 6700, Loss: 6.376176357269287, F1: 0.5214053281147943, Accuracy: 0.5009290482416902, Time Elapsed: 13298.34298491478 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.70       912\n",
      "           1       0.60      0.77      0.67       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.55      0.27      0.36       897\n",
      "           4       0.51      0.90      0.65       892\n",
      "           5       0.47      0.70      0.56       862\n",
      "           6       0.61      0.38      0.47       903\n",
      "           7       0.60      0.65      0.62       889\n",
      "           8       0.54      0.48      0.51       892\n",
      "           9       0.63      0.40      0.49       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 6800, Loss: 0.991828978061676, F1: 0.5447988458394182, Accuracy: 0.5007225930768702, Time Elapsed: 13312.502398014069 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.57      0.36      0.44       897\n",
      "           4       0.55      0.86      0.67       892\n",
      "           5       0.51      0.66      0.58       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.61      0.39      0.48       889\n",
      "           8       0.51      0.74      0.60       892\n",
      "           9       0.62      0.37      0.47       876\n",
      "          10       0.40      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 6900, Loss: 0.9754921793937683, F1: 0.5658202104405163, Accuracy: 0.5153120913908197, Time Elapsed: 13327.386034965515 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.62      0.45      0.52       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.59      0.74      0.65       897\n",
      "           4       0.59      0.65      0.62       892\n",
      "           5       0.55      0.65      0.60       862\n",
      "           6       0.60      0.86      0.71       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.61      0.37      0.46       892\n",
      "           9       0.58      0.55      0.57       876\n",
      "          10       0.39      0.33      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 7000, Loss: 0.8609766960144043, F1: 0.5835226031657529, Accuracy: 0.5234326612070745, Time Elapsed: 13341.612675189972 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       912\n",
      "           1       0.62      0.62      0.62       885\n",
      "           2       0.62      0.47      0.53       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.60      0.51      0.55       892\n",
      "           5       0.54      0.63      0.58       862\n",
      "           6       0.58      0.86      0.69       903\n",
      "           7       0.58      0.74      0.65       889\n",
      "           8       0.55      0.71      0.62       892\n",
      "           9       0.60      0.59      0.60       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 7100, Loss: 0.9792210459709167, F1: 0.5933879079686117, Accuracy: 0.5287316771041222, Time Elapsed: 13356.33010315895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.58      0.59      0.59       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.45      0.95      0.61       892\n",
      "           5       0.59      0.15      0.24       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.59      0.51      0.55       892\n",
      "           9       0.59      0.58      0.59       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 7200, Loss: 0.6319195032119751, F1: 0.5558146152753909, Accuracy: 0.5131787213543458, Time Elapsed: 13370.589697122574 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.57      0.74      0.64       877\n",
      "           3       0.60      0.51      0.55       897\n",
      "           4       0.51      0.91      0.65       892\n",
      "           5       0.56      0.51      0.54       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.61      0.47      0.53       889\n",
      "           8       0.60      0.42      0.49       892\n",
      "           9       0.58      0.69      0.63       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 2, Step 7300, Loss: 4.698112964630127, F1: 0.5891777326176272, Accuracy: 0.5254283944670016, Time Elapsed: 13385.791410207748 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.63      0.57      0.60       885\n",
      "           2       0.61      0.19      0.29       877\n",
      "           3       0.59      0.65      0.62       897\n",
      "           4       0.55      0.85      0.67       892\n",
      "           5       0.58      0.32      0.42       862\n",
      "           6       0.57      0.06      0.11       903\n",
      "           7       0.60      0.69      0.65       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.59      0.34      0.43       876\n",
      "          10       0.39      0.47      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 7400, Loss: 0.8333465456962585, F1: 0.4953132757338467, Accuracy: 0.49404720941435554, Time Elapsed: 13400.357719182968 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.67       912\n",
      "           1       0.61      0.76      0.68       885\n",
      "           2       0.62      0.28      0.38       877\n",
      "           3       0.59      0.28      0.38       897\n",
      "           4       0.59      0.58      0.58       892\n",
      "           5       0.55      0.09      0.15       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.45      0.94      0.61       889\n",
      "           8       0.58      0.01      0.02       892\n",
      "           9       0.57      0.59      0.58       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.50      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 7500, Loss: 1.0570099353790283, F1: 0.47060314242557016, Accuracy: 0.4888170119055812, Time Elapsed: 13414.766779184341 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.62      0.70      0.66       885\n",
      "           2       0.65      0.12      0.20       877\n",
      "           3       0.60      0.58      0.59       897\n",
      "           4       0.58      0.49      0.53       892\n",
      "           5       0.59      0.05      0.09       862\n",
      "           6       0.62      0.75      0.68       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.59      0.35      0.44       892\n",
      "           9       0.60      0.21      0.31       876\n",
      "          10       0.40      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.49      0.48     14531\n",
      "weighted avg       0.52      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 7600, Loss: 0.6893099546432495, F1: 0.4844076953043972, Accuracy: 0.4992774069231299, Time Elapsed: 13429.501045942307 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.71       912\n",
      "           1       0.61      0.69      0.65       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.37      0.92      0.53       897\n",
      "           4       0.60      0.65      0.62       892\n",
      "           5       0.67      0.01      0.02       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.60      0.59      0.60       889\n",
      "           8       0.59      0.52      0.55       892\n",
      "           9       0.61      0.02      0.04       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.54      0.49     14531\n",
      "weighted avg       0.51      0.49      0.45     14531\n",
      "\n",
      "Epoch 2, Step 7700, Loss: 0.18096625804901123, F1: 0.4870076885640126, Accuracy: 0.48964283256486135, Time Elapsed: 13443.844373941422 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.71       912\n",
      "           1       0.60      0.55      0.57       885\n",
      "           2       0.59      0.42      0.49       877\n",
      "           3       0.53      0.61      0.57       897\n",
      "           4       0.54      0.54      0.54       892\n",
      "           5       0.56      0.58      0.57       862\n",
      "           6       0.55      0.85      0.67       903\n",
      "           7       0.55      0.86      0.67       889\n",
      "           8       0.58      0.36      0.44       892\n",
      "           9       0.60      0.28      0.38       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.55     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 7800, Loss: 0.9014942646026611, F1: 0.5453435812993138, Accuracy: 0.5045764228201776, Time Elapsed: 13458.888091087341 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63       912\n",
      "           1       0.56      0.53      0.55       885\n",
      "           2       0.61      0.45      0.52       877\n",
      "           3       0.56      0.54      0.55       897\n",
      "           4       0.58      0.71      0.64       892\n",
      "           5       0.57      0.35      0.44       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.58      0.80      0.67       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.59      0.66      0.62       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.57     14531\n",
      "weighted avg       0.51      0.51      0.51     14531\n",
      "\n",
      "Epoch 2, Step 7900, Loss: 0.5475212931632996, F1: 0.5652055924539982, Accuracy: 0.5139357236253527, Time Elapsed: 13473.262095212936 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.60      0.69      0.64       885\n",
      "           2       0.58      0.60      0.59       877\n",
      "           3       0.58      0.67      0.62       897\n",
      "           4       0.59      0.64      0.61       892\n",
      "           5       0.59      0.31      0.40       862\n",
      "           6       0.63      0.50      0.56       903\n",
      "           7       0.58      0.86      0.69       889\n",
      "           8       0.53      0.67      0.59       892\n",
      "           9       0.55      0.68      0.61       876\n",
      "          10       0.40      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 8000, Loss: 0.584839940071106, F1: 0.5781065515740695, Accuracy: 0.5208863808409607, Time Elapsed: 13488.433020114899 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.62      0.17      0.27       885\n",
      "           2       0.57      0.71      0.64       877\n",
      "           3       0.58      0.76      0.66       897\n",
      "           4       0.60      0.46      0.52       892\n",
      "           5       0.60      0.43      0.50       862\n",
      "           6       0.63      0.39      0.48       903\n",
      "           7       0.61      0.74      0.67       889\n",
      "           8       0.47      0.85      0.61       892\n",
      "           9       0.54      0.67      0.60       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 8100, Loss: 1.6885056495666504, F1: 0.5473131530659314, Accuracy: 0.5091184364462185, Time Elapsed: 13503.52461528778 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       912\n",
      "           1       0.60      0.39      0.47       885\n",
      "           2       0.61      0.52      0.56       877\n",
      "           3       0.60      0.40      0.48       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.57      0.35      0.43       862\n",
      "           6       0.62      0.44      0.52       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.59      0.10      0.16       892\n",
      "           9       0.59      0.54      0.56       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.47      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 8200, Loss: 0.355469286441803, F1: 0.4968868597129745, Accuracy: 0.48854173835248776, Time Elapsed: 13518.029892206192 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.59      0.69      0.64       885\n",
      "           2       0.60      0.60      0.60       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.54      0.62      0.58       892\n",
      "           5       0.56      0.54      0.55       862\n",
      "           6       0.63      0.68      0.65       903\n",
      "           7       0.62      0.47      0.53       889\n",
      "           8       0.57      0.51      0.54       892\n",
      "           9       0.66      0.12      0.20       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.54     14531\n",
      "weighted avg       0.52      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 8300, Loss: 0.9995742440223694, F1: 0.5382608875968349, Accuracy: 0.5049205147615443, Time Elapsed: 13532.589849233627 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.68       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.61      0.05      0.09       897\n",
      "           4       0.50      0.84      0.63       892\n",
      "           5       0.60      0.24      0.34       862\n",
      "           6       0.63      0.66      0.64       903\n",
      "           7       0.60      0.69      0.65       889\n",
      "           8       0.53      0.66      0.59       892\n",
      "           9       0.56      0.01      0.02       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.49     14531\n",
      "weighted avg       0.51      0.50      0.46     14531\n",
      "\n",
      "Epoch 2, Step 8400, Loss: 0.30839020013809204, F1: 0.4860136776716006, Accuracy: 0.4984515862638497, Time Elapsed: 13547.637122154236 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.60      0.59      0.60       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.54      0.74      0.62       892\n",
      "           5       0.45      0.75      0.56       862\n",
      "           6       0.63      0.43      0.51       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.53      0.10      0.17       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.38      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.50      0.54      0.50     14531\n",
      "weighted avg       0.46      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 8500, Loss: 1.3471421003341675, F1: 0.4973187714133689, Accuracy: 0.4939095726378088, Time Elapsed: 13562.079471111298 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.63      0.29      0.40       877\n",
      "           3       0.52      0.82      0.64       897\n",
      "           4       0.57      0.69      0.63       892\n",
      "           5       0.56      0.46      0.50       862\n",
      "           6       0.63      0.19      0.29       903\n",
      "           7       0.47      0.94      0.62       889\n",
      "           8       0.58      0.49      0.53       892\n",
      "           9       0.60      0.44      0.51       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.53     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 8600, Loss: 1.6884796619415283, F1: 0.5282252652760385, Accuracy: 0.49652467139219597, Time Elapsed: 13577.02696609497 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.95      0.73       912\n",
      "           1       0.60      0.76      0.67       885\n",
      "           2       0.64      0.42      0.50       877\n",
      "           3       0.60      0.51      0.55       897\n",
      "           4       0.49      0.92      0.64       892\n",
      "           5       0.54      0.68      0.60       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.56      0.62      0.59       892\n",
      "           9       0.58      0.62      0.60       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 2, Step 8700, Loss: 0.8278560638427734, F1: 0.594869203393393, Accuracy: 0.5281811299979354, Time Elapsed: 13592.43522310257 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.70       912\n",
      "           1       0.61      0.61      0.61       885\n",
      "           2       0.60      0.57      0.59       877\n",
      "           3       0.48      0.80      0.60       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.57      0.56      0.56       862\n",
      "           6       0.64      0.56      0.60       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.58      0.60      0.59       892\n",
      "           9       0.61      0.41      0.49       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 8800, Loss: 2.0401296615600586, F1: 0.5823447408241221, Accuracy: 0.5192347395224004, Time Elapsed: 13607.182934045792 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.62      0.23      0.33       877\n",
      "           3       0.56      0.61      0.58       897\n",
      "           4       0.58      0.76      0.66       892\n",
      "           5       0.58      0.46      0.51       862\n",
      "           6       0.62      0.48      0.54       903\n",
      "           7       0.53      0.91      0.67       889\n",
      "           8       0.58      0.60      0.59       892\n",
      "           9       0.59      0.46      0.52       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 8900, Loss: 1.3121962547302246, F1: 0.5605527200794168, Accuracy: 0.5156561833321863, Time Elapsed: 13622.633718013763 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       912\n",
      "           1       0.62      0.36      0.45       885\n",
      "           2       0.64      0.23      0.33       877\n",
      "           3       0.53      0.74      0.62       897\n",
      "           4       0.50      0.87      0.64       892\n",
      "           5       0.61      0.25      0.36       862\n",
      "           6       0.64      0.48      0.55       903\n",
      "           7       0.58      0.77      0.67       889\n",
      "           8       0.56      0.66      0.61       892\n",
      "           9       0.61      0.29      0.39       876\n",
      "          10       0.40      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 9000, Loss: 0.24283573031425476, F1: 0.5201942237473575, Accuracy: 0.49996559080586334, Time Elapsed: 13637.553410053253 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.66      0.13      0.22       885\n",
      "           2       0.61      0.50      0.55       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.59      0.69      0.63       892\n",
      "           5       0.58      0.40      0.47       862\n",
      "           6       0.63      0.66      0.64       903\n",
      "           7       0.63      0.22      0.33       889\n",
      "           8       0.55      0.65      0.59       892\n",
      "           9       0.58      0.48      0.52       876\n",
      "          10       0.40      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 9100, Loss: 0.6897115111351013, F1: 0.5039103659288137, Accuracy: 0.49652467139219597, Time Elapsed: 13651.891038894653 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       912\n",
      "           1       0.55      0.98      0.71       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.59      0.50      0.54       897\n",
      "           4       0.60      0.55      0.57       892\n",
      "           5       0.56      0.32      0.41       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.60      0.35      0.44       892\n",
      "           9       0.53      0.68      0.60       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 9200, Loss: 0.26655590534210205, F1: 0.5708008711209689, Accuracy: 0.5182712820865736, Time Elapsed: 13666.64615702629 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.56      0.73      0.64       877\n",
      "           3       0.59      0.46      0.52       897\n",
      "           4       0.60      0.43      0.50       892\n",
      "           5       0.58      0.34      0.43       862\n",
      "           6       0.62      0.75      0.68       903\n",
      "           7       0.61      0.77      0.68       889\n",
      "           8       0.57      0.57      0.57       892\n",
      "           9       0.62      0.23      0.33       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.57      0.55     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 9300, Loss: 1.4673515558242798, F1: 0.554924443509845, Accuracy: 0.5153120913908197, Time Elapsed: 13683.172176122665 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.65      0.21      0.31       885\n",
      "           2       0.63      0.27      0.37       877\n",
      "           3       0.57      0.65      0.61       897\n",
      "           4       0.62      0.33      0.43       892\n",
      "           5       0.53      0.13      0.21       862\n",
      "           6       0.64      0.39      0.49       903\n",
      "           7       0.60      0.65      0.62       889\n",
      "           8       0.49      0.73      0.59       892\n",
      "           9       0.52      0.01      0.03       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.43      0.44     14531\n",
      "weighted avg       0.51      0.48      0.45     14531\n",
      "\n",
      "Epoch 2, Step 9400, Loss: 0.8120174407958984, F1: 0.4371536398579496, Accuracy: 0.4753974261922786, Time Elapsed: 13698.200510978699 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.35      0.45       912\n",
      "           1       0.59      0.51      0.54       885\n",
      "           2       0.55      0.69      0.61       877\n",
      "           3       0.63      0.13      0.21       897\n",
      "           4       0.59      0.48      0.53       892\n",
      "           5       0.57      0.40      0.47       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.61      0.50      0.55       889\n",
      "           8       0.59      0.34      0.43       892\n",
      "           9       0.41      0.89      0.56       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.50      0.50     14531\n",
      "weighted avg       0.50      0.48      0.47     14531\n",
      "\n",
      "Epoch 2, Step 9500, Loss: 0.21427936851978302, F1: 0.49595022532947514, Accuracy: 0.4791136191590393, Time Elapsed: 13712.464423894882 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.56      0.70      0.62       877\n",
      "           3       0.59      0.45      0.51       897\n",
      "           4       0.58      0.31      0.41       892\n",
      "           5       0.55      0.47      0.50       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.57      0.58      0.58       892\n",
      "           9       0.54      0.64      0.59       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 9600, Loss: 1.1877329349517822, F1: 0.5763644708148971, Accuracy: 0.5204046521230473, Time Elapsed: 13728.10019826889 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.62      0.44      0.51       885\n",
      "           2       0.60      0.42      0.50       877\n",
      "           3       0.58      0.44      0.50       897\n",
      "           4       0.62      0.20      0.31       892\n",
      "           5       0.61      0.08      0.13       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.54      0.64      0.59       892\n",
      "           9       0.56      0.63      0.59       876\n",
      "          10       0.40      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 9700, Loss: 0.24384333193302155, F1: 0.5056047057096691, Accuracy: 0.49955268047622325, Time Elapsed: 13743.927054166794 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.90      0.70       912\n",
      "           1       0.66      0.15      0.24       885\n",
      "           2       0.69      0.05      0.09       877\n",
      "           3       0.58      0.59      0.59       897\n",
      "           4       0.58      0.64      0.61       892\n",
      "           5       0.57      0.41      0.48       862\n",
      "           6       0.62      0.53      0.57       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.58      0.52      0.55       892\n",
      "           9       0.50      0.79      0.61       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.52      0.50     14531\n",
      "weighted avg       0.52      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 9800, Loss: 0.4859638512134552, F1: 0.5016234148236832, Accuracy: 0.4961117610625559, Time Elapsed: 13759.611548900604 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       912\n",
      "           1       0.61      0.61      0.61       885\n",
      "           2       0.68      0.10      0.18       877\n",
      "           3       0.55      0.74      0.63       897\n",
      "           4       0.61      0.31      0.41       892\n",
      "           5       0.62      0.13      0.22       862\n",
      "           6       0.63      0.67      0.65       903\n",
      "           7       0.56      0.87      0.68       889\n",
      "           8       0.61      0.31      0.41       892\n",
      "           9       0.38      0.79      0.51       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.49     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 9900, Loss: 1.4000706672668457, F1: 0.4907886219539251, Accuracy: 0.487784736081481, Time Elapsed: 13773.921399116516 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       912\n",
      "           1       0.62      0.59      0.61       885\n",
      "           2       0.55      0.74      0.63       877\n",
      "           3       0.56      0.76      0.64       897\n",
      "           4       0.41      0.88      0.56       892\n",
      "           5       0.60      0.21      0.31       862\n",
      "           6       0.58      0.85      0.69       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.56      0.69      0.61       892\n",
      "           9       0.61      0.12      0.20       876\n",
      "          10       0.40      0.29      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 10000, Loss: 2.1385111808776855, F1: 0.5418270345079196, Accuracy: 0.5077420686807514, Time Elapsed: 13788.901740074158 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.33      0.42       912\n",
      "           1       1.00      0.00      0.01       885\n",
      "           2       0.58      0.62      0.60       877\n",
      "           3       0.51      0.67      0.58       897\n",
      "           4       0.57      0.64      0.60       892\n",
      "           5       0.50      0.70      0.58       862\n",
      "           6       0.63      0.51      0.57       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.58      0.51      0.54       892\n",
      "           9       0.52      0.76      0.61       876\n",
      "          10       0.38      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.59      0.54      0.51     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 10100, Loss: 0.46775543689727783, F1: 0.5076622941199194, Accuracy: 0.48819764641112107, Time Elapsed: 13804.15407705307 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.62      0.48      0.54       885\n",
      "           2       0.52      0.82      0.64       877\n",
      "           3       0.57      0.73      0.64       897\n",
      "           4       0.46      0.81      0.59       892\n",
      "           5       0.60      0.35      0.44       862\n",
      "           6       0.53      0.92      0.67       903\n",
      "           7       0.60      0.82      0.69       889\n",
      "           8       0.57      0.59      0.58       892\n",
      "           9       0.59      0.40      0.48       876\n",
      "          10       0.40      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 10200, Loss: 2.745028257369995, F1: 0.573393331197623, Accuracy: 0.5182712820865736, Time Elapsed: 13819.847823143005 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.96      0.73       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.56      0.71      0.63       897\n",
      "           4       0.50      0.88      0.64       892\n",
      "           5       0.61      0.22      0.32       862\n",
      "           6       0.53      0.95      0.68       903\n",
      "           7       0.60      0.74      0.67       889\n",
      "           8       0.51      0.74      0.61       892\n",
      "           9       0.57      0.64      0.60       876\n",
      "          10       0.40      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.69      0.59     14531\n",
      "weighted avg       0.50      0.53      0.48     14531\n",
      "\n",
      "Epoch 2, Step 10300, Loss: 1.1569106578826904, F1: 0.5883208554172311, Accuracy: 0.5288693138806689, Time Elapsed: 13834.07079410553 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.59      0.97      0.73       885\n",
      "           2       0.54      0.80      0.65       877\n",
      "           3       0.60      0.66      0.63       897\n",
      "           4       0.56      0.67      0.61       892\n",
      "           5       0.59      0.29      0.39       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.60      0.24      0.34       892\n",
      "           9       0.53      0.05      0.10       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.59      0.54     14531\n",
      "weighted avg       0.51      0.52      0.48     14531\n",
      "\n",
      "Epoch 2, Step 10400, Loss: 1.2414283752441406, F1: 0.5370106732149084, Accuracy: 0.5164820039914665, Time Elapsed: 14821.65642118454 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.57      0.76      0.65       877\n",
      "           3       0.63      0.28      0.39       897\n",
      "           4       0.47      0.66      0.55       892\n",
      "           5       0.56      0.43      0.49       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.61      0.61      0.61       889\n",
      "           8       0.58      0.39      0.47       892\n",
      "           9       0.60      0.01      0.01       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.52     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 10500, Loss: 0.7181145548820496, F1: 0.5178063851960796, Accuracy: 0.5052646067029111, Time Elapsed: 14838.99009013176 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.61      0.90      0.73       885\n",
      "           2       0.57      0.72      0.64       877\n",
      "           3       0.59      0.69      0.64       897\n",
      "           4       0.49      0.81      0.61       892\n",
      "           5       0.58      0.47      0.52       862\n",
      "           6       0.62      0.77      0.69       903\n",
      "           7       0.57      0.84      0.68       889\n",
      "           8       0.59      0.49      0.54       892\n",
      "           9       0.58      0.49      0.53       876\n",
      "          10       0.39      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 10600, Loss: 1.0187879800796509, F1: 0.5976926188858246, Accuracy: 0.5304521368109559, Time Elapsed: 15809.7344892025 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.58      0.10      0.17       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.60      0.48      0.53       897\n",
      "           4       0.59      0.55      0.57       892\n",
      "           5       0.60      0.37      0.46       862\n",
      "           6       0.62      0.69      0.66       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.60      0.54      0.57       892\n",
      "           9       0.53      0.69      0.60       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 10700, Loss: 1.705399513244629, F1: 0.5438579702590988, Accuracy: 0.5108388961530521, Time Elapsed: 15840.602097272873 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.61      0.53      0.57       897\n",
      "           4       0.46      0.90      0.61       892\n",
      "           5       0.62      0.22      0.32       862\n",
      "           6       0.63      0.51      0.56       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.59      0.52      0.55       892\n",
      "           9       0.60      0.14      0.23       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 10800, Loss: 5.337753772735596, F1: 0.5357268367195296, Accuracy: 0.507053884798018, Time Elapsed: 15860.894446134567 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       912\n",
      "           1       0.58      0.97      0.73       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.58      0.65      0.61       897\n",
      "           4       0.59      0.63      0.61       892\n",
      "           5       0.49      0.69      0.57       862\n",
      "           6       0.63      0.43      0.51       903\n",
      "           7       0.56      0.89      0.68       889\n",
      "           8       0.58      0.37      0.45       892\n",
      "           9       0.57      0.53      0.55       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 10900, Loss: 0.4027620851993561, F1: 0.5757945670159862, Accuracy: 0.5157250017204597, Time Elapsed: 15883.28673195839 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.55       912\n",
      "           1       0.61      0.45      0.52       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.57      0.67      0.62       897\n",
      "           4       0.60      0.40      0.48       892\n",
      "           5       0.53      0.63      0.57       862\n",
      "           6       0.64      0.06      0.11       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.56      0.26      0.35       892\n",
      "           9       0.58      0.45      0.51       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.49      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 11000, Loss: 1.4767640829086304, F1: 0.4951292582722857, Accuracy: 0.4869589154222008, Time Elapsed: 15903.911324977875 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.46      0.53       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.59      0.60      0.59       877\n",
      "           3       0.53      0.80      0.64       897\n",
      "           4       0.57      0.38      0.46       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.61      0.64      0.63       889\n",
      "           8       0.56      0.59      0.58       892\n",
      "           9       0.56      0.58      0.57       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.57     14531\n",
      "weighted avg       0.51      0.51      0.51     14531\n",
      "\n",
      "Epoch 2, Step 11100, Loss: 1.2066140174865723, F1: 0.5676436126190235, Accuracy: 0.5118711719771523, Time Elapsed: 16222.26372718811 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       912\n",
      "           1       0.58      0.97      0.73       885\n",
      "           2       0.53      0.79      0.63       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.49      0.75      0.59       892\n",
      "           5       0.58      0.50      0.54       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.62      0.50      0.56       889\n",
      "           8       0.57      0.62      0.60       892\n",
      "           9       0.61      0.36      0.45       876\n",
      "          10       0.39      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 11200, Loss: 1.6091675758361816, F1: 0.5743538942841881, Accuracy: 0.5179271901452068, Time Elapsed: 16237.995059013367 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.55      0.70      0.62       877\n",
      "           3       0.61      0.40      0.48       897\n",
      "           4       0.58      0.56      0.57       892\n",
      "           5       0.56      0.46      0.51       862\n",
      "           6       0.61      0.62      0.62       903\n",
      "           7       0.55      0.90      0.68       889\n",
      "           8       0.56      0.59      0.58       892\n",
      "           9       0.46      0.76      0.58       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 11300, Loss: 0.16741277277469635, F1: 0.5802558353835954, Accuracy: 0.5183401004748469, Time Elapsed: 16253.81256198883 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73       912\n",
      "           1       0.60      0.95      0.73       885\n",
      "           2       0.57      0.67      0.62       877\n",
      "           3       0.58      0.26      0.36       897\n",
      "           4       0.56      0.70      0.62       892\n",
      "           5       0.57      0.45      0.50       862\n",
      "           6       0.61      0.62      0.62       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.57      0.41      0.47       892\n",
      "           9       0.54      0.69      0.61       876\n",
      "          10       0.38      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 11400, Loss: 1.232555866241455, F1: 0.5697175008339367, Accuracy: 0.5171701878742, Time Elapsed: 16569.149378061295 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.54      0.77      0.63       877\n",
      "           3       0.60      0.40      0.48       897\n",
      "           4       0.50      0.87      0.63       892\n",
      "           5       0.52      0.65      0.58       862\n",
      "           6       0.62      0.59      0.60       903\n",
      "           7       0.62      0.65      0.63       889\n",
      "           8       0.57      0.48      0.52       892\n",
      "           9       0.60      0.35      0.44       876\n",
      "          10       0.38      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 11500, Loss: 0.8847300410270691, F1: 0.5689816262318955, Accuracy: 0.5119399903654256, Time Elapsed: 16585.129026174545 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.60      0.91      0.73       885\n",
      "           2       0.57      0.65      0.61       877\n",
      "           3       0.61      0.40      0.48       897\n",
      "           4       0.52      0.67      0.59       892\n",
      "           5       0.62      0.28      0.39       862\n",
      "           6       0.57      0.88      0.69       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.56      0.15      0.23       892\n",
      "           9       0.61      0.42      0.50       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 11600, Loss: 0.7315430045127869, F1: 0.5415137979970411, Accuracy: 0.5105636225999587, Time Elapsed: 16601.849219083786 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.57      0.40      0.47       885\n",
      "           2       0.61      0.44      0.51       877\n",
      "           3       0.51      0.10      0.17       897\n",
      "           4       0.60      0.39      0.47       892\n",
      "           5       0.61      0.17      0.26       862\n",
      "           6       0.61      0.79      0.68       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.49      0.77      0.60       892\n",
      "           9       0.61      0.29      0.40       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.49      0.49     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 11700, Loss: 3.70851469039917, F1: 0.4861268340954183, Accuracy: 0.4899181061179547, Time Elapsed: 16916.886032104492 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       912\n",
      "           1       0.58      0.96      0.73       885\n",
      "           2       0.54      0.80      0.64       877\n",
      "           3       0.59      0.64      0.62       897\n",
      "           4       0.52      0.89      0.66       892\n",
      "           5       0.59      0.48      0.53       862\n",
      "           6       0.63      0.64      0.64       903\n",
      "           7       0.59      0.82      0.68       889\n",
      "           8       0.56      0.76      0.64       892\n",
      "           9       0.53      0.79      0.63       876\n",
      "          10       0.39      0.18      0.25      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.71      0.61     14531\n",
      "weighted avg       0.50      0.54      0.49     14531\n",
      "\n",
      "Epoch 2, Step 11800, Loss: 1.6328386068344116, F1: 0.6109430584490705, Accuracy: 0.5376780675796573, Time Elapsed: 16932.156738996506 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.57      0.26      0.36       897\n",
      "           4       0.53      0.60      0.56       892\n",
      "           5       0.61      0.30      0.40       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.61      0.74      0.67       889\n",
      "           8       0.59      0.63      0.61       892\n",
      "           9       0.60      0.44      0.51       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 11900, Loss: 0.5674907565116882, F1: 0.5394404542286955, Accuracy: 0.5049205147615443, Time Elapsed: 16946.841553211212 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.58       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.53      0.61      0.57       892\n",
      "           5       0.51      0.68      0.59       862\n",
      "           6       0.66      0.27      0.38       903\n",
      "           7       0.56      0.88      0.68       889\n",
      "           8       0.60      0.43      0.50       892\n",
      "           9       0.59      0.49      0.53       876\n",
      "          10       0.40      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.52      0.50     14531\n",
      "weighted avg       0.48      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 12000, Loss: 0.7874510288238525, F1: 0.4993223991808576, Accuracy: 0.4957676691211892, Time Elapsed: 17862.801710128784 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.59      0.50      0.54       897\n",
      "           4       0.53      0.88      0.66       892\n",
      "           5       0.58      0.39      0.46       862\n",
      "           6       0.63      0.73      0.68       903\n",
      "           7       0.61      0.71      0.66       889\n",
      "           8       0.59      0.47      0.52       892\n",
      "           9       0.57      0.64      0.60       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 12100, Loss: 0.5989893078804016, F1: 0.5932818228719152, Accuracy: 0.5299704080930424, Time Elapsed: 17881.596696138382 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.60      0.80      0.69       885\n",
      "           2       0.57      0.73      0.64       877\n",
      "           3       0.56      0.78      0.65       897\n",
      "           4       0.59      0.64      0.62       892\n",
      "           5       0.64      0.05      0.09       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.63      0.50      0.56       889\n",
      "           8       0.59      0.58      0.58       892\n",
      "           9       0.56      0.50      0.53       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.59      0.56     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 12200, Loss: 0.9777748584747314, F1: 0.5560121713168727, Accuracy: 0.5204734705113206, Time Elapsed: 17898.875506162643 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.90      0.72       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.58      0.23      0.33       897\n",
      "           4       0.61      0.48      0.54       892\n",
      "           5       0.58      0.23      0.32       862\n",
      "           6       0.62      0.46      0.52       903\n",
      "           7       0.61      0.53      0.57       889\n",
      "           8       0.51      0.84      0.63       892\n",
      "           9       0.54      0.46      0.50       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 12300, Loss: 0.38865187764167786, F1: 0.5340885366689915, Accuracy: 0.5047828779849975, Time Elapsed: 18912.277519226074 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       912\n",
      "           1       0.59      0.40      0.48       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.57      0.68      0.62       897\n",
      "           4       0.60      0.41      0.48       892\n",
      "           5       0.57      0.39      0.46       862\n",
      "           6       0.61      0.43      0.51       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.60      0.51      0.55       892\n",
      "           9       0.56      0.48      0.52       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 12400, Loss: 1.172459363937378, F1: 0.5439970459800111, Accuracy: 0.5020989608423371, Time Elapsed: 18931.403482198715 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.42      0.50       912\n",
      "           1       0.55      0.97      0.70       885\n",
      "           2       0.47      0.84      0.61       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.55      0.80      0.65       892\n",
      "           5       0.51      0.69      0.59       862\n",
      "           6       0.61      0.43      0.50       903\n",
      "           7       0.62      0.44      0.52       889\n",
      "           8       0.53      0.76      0.63       892\n",
      "           9       0.61      0.41      0.49       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.61      0.56     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 12500, Loss: 1.750559687614441, F1: 0.5565273895533207, Accuracy: 0.5030624182781639, Time Elapsed: 18947.221874952316 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.91      0.70       912\n",
      "           1       0.60      0.92      0.72       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.61      0.30      0.40       897\n",
      "           4       0.59      0.22      0.32       892\n",
      "           5       0.55      0.43      0.48       862\n",
      "           6       0.62      0.78      0.69       903\n",
      "           7       0.61      0.50      0.55       889\n",
      "           8       0.59      0.58      0.58       892\n",
      "           9       0.45      0.78      0.57       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.54     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 12600, Loss: 1.4193828105926514, F1: 0.5396006933409662, Accuracy: 0.5047828779849975, Time Elapsed: 18961.81278204918 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55       912\n",
      "           1       0.62      0.51      0.56       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.59      0.53      0.56       897\n",
      "           4       0.59      0.65      0.62       892\n",
      "           5       0.53      0.62      0.57       862\n",
      "           6       0.63      0.69      0.66       903\n",
      "           7       0.60      0.41      0.49       889\n",
      "           8       0.58      0.64      0.61       892\n",
      "           9       0.51      0.72      0.60       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.56     14531\n",
      "weighted avg       0.51      0.51      0.51     14531\n",
      "\n",
      "Epoch 2, Step 12700, Loss: 1.6895060539245605, F1: 0.5623657167867747, Accuracy: 0.5082926157869383, Time Elapsed: 19901.627269268036 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.59      0.60      0.59       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.53      0.75      0.62       892\n",
      "           5       0.57      0.40      0.47       862\n",
      "           6       0.63      0.50      0.56       903\n",
      "           7       0.63      0.06      0.12       889\n",
      "           8       0.58      0.45      0.51       892\n",
      "           9       0.49      0.81      0.61       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.49      0.47     14531\n",
      "weighted avg       0.47      0.48      0.46     14531\n",
      "\n",
      "Epoch 2, Step 12800, Loss: 3.3466899394989014, F1: 0.47241562940327614, Accuracy: 0.4843438166678136, Time Elapsed: 19921.990955114365 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71       912\n",
      "           1       0.63      0.13      0.22       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.60      0.56      0.58       897\n",
      "           4       0.54      0.67      0.60       892\n",
      "           5       0.59      0.39      0.47       862\n",
      "           6       0.62      0.73      0.67       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.56      0.73      0.64       892\n",
      "           9       0.61      0.16      0.25       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.53     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 12900, Loss: 0.9876537322998047, F1: 0.5288362001659359, Accuracy: 0.5073979767393848, Time Elapsed: 20902.255403995514 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.56      0.73      0.64       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.53      0.69      0.60       892\n",
      "           5       0.52      0.74      0.61       862\n",
      "           6       0.63      0.48      0.54       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.56      0.71      0.63       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.45      0.52      0.48     14531\n",
      "weighted avg       0.43      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 13000, Loss: 1.5022363662719727, F1: 0.482426261999261, Accuracy: 0.4923267497075218, Time Elapsed: 20924.88951396942 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.60      0.41      0.48       897\n",
      "           4       0.57      0.78      0.66       892\n",
      "           5       0.48      0.76      0.59       862\n",
      "           6       0.63      0.50      0.56       903\n",
      "           7       0.61      0.57      0.59       889\n",
      "           8       0.56      0.67      0.61       892\n",
      "           9       0.57      0.46      0.51       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 13100, Loss: 1.478442668914795, F1: 0.5783062310105752, Accuracy: 0.5179960085334802, Time Elapsed: 21861.716639995575 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.59      0.72      0.65       897\n",
      "           4       0.57      0.77      0.65       892\n",
      "           5       0.52      0.72      0.61       862\n",
      "           6       0.64      0.56      0.60       903\n",
      "           7       0.62      0.56      0.59       889\n",
      "           8       0.56      0.77      0.65       892\n",
      "           9       0.44      0.89      0.59       876\n",
      "          10       0.39      0.19      0.26      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.69      0.60     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 2, Step 13200, Loss: 0.3990139663219452, F1: 0.6028802463138138, Accuracy: 0.527492946115202, Time Elapsed: 21881.138535261154 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.60      0.10      0.18       885\n",
      "           2       0.61      0.23      0.34       877\n",
      "           3       0.56      0.81      0.66       897\n",
      "           4       0.55      0.76      0.64       892\n",
      "           5       0.57      0.24      0.34       862\n",
      "           6       0.63      0.36      0.46       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.56      0.64      0.60       892\n",
      "           9       0.60      0.44      0.51       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 13300, Loss: 0.23146474361419678, F1: 0.4974633318203578, Accuracy: 0.4934278439198954, Time Elapsed: 21898.921473026276 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.61       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.55      0.71      0.62       877\n",
      "           3       0.61      0.47      0.53       897\n",
      "           4       0.40      0.88      0.55       892\n",
      "           5       0.58      0.35      0.44       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.58      0.62      0.60       892\n",
      "           9       0.53      0.03      0.05       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.56      0.52     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 13400, Loss: 0.9448168873786926, F1: 0.5197909514071583, Accuracy: 0.4943224829674489, Time Elapsed: 22942.734384059906 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.77      0.68       912\n",
      "           1       0.62      0.47      0.53       885\n",
      "           2       0.56      0.72      0.63       877\n",
      "           3       0.56      0.77      0.65       897\n",
      "           4       0.55      0.52      0.54       892\n",
      "           5       0.60      0.27      0.37       862\n",
      "           6       0.64      0.16      0.26       903\n",
      "           7       0.61      0.58      0.59       889\n",
      "           8       0.57      0.69      0.62       892\n",
      "           9       0.48      0.67      0.56       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 13500, Loss: 2.4934206008911133, F1: 0.5297332887141146, Accuracy: 0.49865804142866976, Time Elapsed: 22959.5585501194 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.51      0.80      0.62       877\n",
      "           3       0.61      0.31      0.41       897\n",
      "           4       0.54      0.63      0.58       892\n",
      "           5       0.59      0.34      0.43       862\n",
      "           6       0.62      0.19      0.29       903\n",
      "           7       0.63      0.20      0.31       889\n",
      "           8       0.59      0.29      0.39       892\n",
      "           9       0.60      0.19      0.29       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.52      0.40      0.41     14531\n",
      "weighted avg       0.47      0.46      0.43     14531\n",
      "\n",
      "Epoch 2, Step 13600, Loss: 0.7715439200401306, F1: 0.408005638242221, Accuracy: 0.46280366113825616, Time Elapsed: 23985.199004888535 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.56      0.98      0.71       885\n",
      "           2       0.52      0.82      0.63       877\n",
      "           3       0.59      0.64      0.61       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.56      0.21      0.30       862\n",
      "           6       0.66      0.09      0.16       903\n",
      "           7       0.61      0.52      0.56       889\n",
      "           8       0.58      0.39      0.47       892\n",
      "           9       0.33      0.00      0.01       876\n",
      "          10       0.38      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.52      0.48     14531\n",
      "weighted avg       0.49      0.49      0.45     14531\n",
      "\n",
      "Epoch 2, Step 13700, Loss: 1.729149341583252, F1: 0.47608451148044806, Accuracy: 0.49101920033032825, Time Elapsed: 24003.71158504486 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.57       912\n",
      "           1       0.61      0.64      0.63       885\n",
      "           2       0.56      0.74      0.63       877\n",
      "           3       0.59      0.37      0.46       897\n",
      "           4       0.59      0.71      0.64       892\n",
      "           5       0.51      0.02      0.04       862\n",
      "           6       0.55      0.86      0.67       903\n",
      "           7       0.63      0.37      0.46       889\n",
      "           8       0.59      0.18      0.28       892\n",
      "           9       0.56      0.53      0.54       876\n",
      "          10       0.40      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.49      0.49     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 13800, Loss: 0.29530611634254456, F1: 0.4875192036944256, Accuracy: 0.49308375197852866, Time Elapsed: 24019.86085820198 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.65       912\n",
      "           1       0.62      0.62      0.62       885\n",
      "           2       0.61      0.38      0.47       877\n",
      "           3       0.60      0.50      0.55       897\n",
      "           4       0.59      0.35      0.44       892\n",
      "           5       0.59      0.40      0.48       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.63      0.32      0.42       889\n",
      "           8       0.59      0.44      0.50       892\n",
      "           9       0.53      0.34      0.41       876\n",
      "          10       0.40      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.48      0.51     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 13900, Loss: 0.594210684299469, F1: 0.5149640453035715, Accuracy: 0.49652467139219597, Time Elapsed: 25082.705041885376 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.46      0.53       912\n",
      "           1       0.67      0.16      0.26       885\n",
      "           2       0.60      0.37      0.46       877\n",
      "           3       0.60      0.36      0.45       897\n",
      "           4       0.61      0.43      0.51       892\n",
      "           5       0.59      0.40      0.48       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.62      0.47      0.53       889\n",
      "           8       0.58      0.66      0.62       892\n",
      "           9       0.46      0.74      0.57       876\n",
      "          10       0.40      0.51      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.48      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 14000, Loss: 0.3676842451095581, F1: 0.5015495430640313, Accuracy: 0.4892987406234946, Time Elapsed: 25106.19269824028 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.54      0.78      0.64       877\n",
      "           3       0.60      0.66      0.63       897\n",
      "           4       0.53      0.87      0.66       892\n",
      "           5       0.57      0.52      0.54       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.61      0.59      0.60       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.56      0.58      0.57       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 14100, Loss: 1.2349634170532227, F1: 0.5944358314574143, Accuracy: 0.5285252219393022, Time Elapsed: 25125.599984169006 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       912\n",
      "           1       0.59      0.85      0.70       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.59      0.69      0.63       897\n",
      "           4       0.58      0.73      0.65       892\n",
      "           5       0.63      0.12      0.21       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.58      0.70      0.64       892\n",
      "           9       0.63      0.30      0.41       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.58      0.55     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 14200, Loss: 0.5014247298240662, F1: 0.5538345886938736, Accuracy: 0.5195100130754938, Time Elapsed: 25145.010187149048 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       912\n",
      "           1       0.60      0.70      0.65       885\n",
      "           2       0.61      0.42      0.50       877\n",
      "           3       0.59      0.17      0.26       897\n",
      "           4       0.58      0.63      0.60       892\n",
      "           5       0.56      0.53      0.54       862\n",
      "           6       0.56      0.90      0.69       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.59      0.54      0.56       892\n",
      "           9       0.53      0.78      0.63       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 14300, Loss: 2.0124592781066895, F1: 0.5502673946016, Accuracy: 0.5089119812813984, Time Elapsed: 26226.661199092865 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.71       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.61      0.15      0.24       897\n",
      "           4       0.60      0.24      0.35       892\n",
      "           5       0.60      0.49      0.54       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.60      0.42      0.50       892\n",
      "           9       0.43      0.85      0.57       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.54     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 14400, Loss: 4.620355606079102, F1: 0.5402797452475215, Accuracy: 0.506640974468378, Time Elapsed: 26249.224128961563 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.59      0.53      0.56       892\n",
      "           5       0.62      0.04      0.08       862\n",
      "           6       0.61      0.63      0.62       903\n",
      "           7       0.62      0.32      0.42       889\n",
      "           8       0.58      0.56      0.57       892\n",
      "           9       0.44      0.86      0.58       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.53      0.48     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 14500, Loss: 1.225121021270752, F1: 0.48163126070913714, Accuracy: 0.4923955680957952, Time Elapsed: 26357.601392269135 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.60      0.59      0.60       877\n",
      "           3       0.59      0.39      0.47       897\n",
      "           4       0.58      0.53      0.55       892\n",
      "           5       0.60      0.42      0.50       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.60      0.37      0.46       892\n",
      "           9       0.50      0.71      0.59       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 14600, Loss: 4.008049488067627, F1: 0.564057881942291, Accuracy: 0.5146239075080862, Time Elapsed: 26373.572193145752 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.60      0.59      0.60       897\n",
      "           4       0.54      0.87      0.67       892\n",
      "           5       0.61      0.34      0.43       862\n",
      "           6       0.62      0.63      0.62       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.57      0.12      0.20       892\n",
      "           9       0.52      0.82      0.64       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 14700, Loss: 1.4009418487548828, F1: 0.5609124178905073, Accuracy: 0.518753010804487, Time Elapsed: 26389.325092077255 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.59      0.74      0.66       885\n",
      "           2       0.61      0.44      0.51       877\n",
      "           3       0.58      0.36      0.45       897\n",
      "           4       0.58      0.69      0.63       892\n",
      "           5       0.57      0.59      0.58       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.61      0.81      0.70       889\n",
      "           8       0.56      0.67      0.61       892\n",
      "           9       0.60      0.58      0.59       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.62      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 14800, Loss: 1.001702070236206, F1: 0.5852901939232029, Accuracy: 0.5255660312435483, Time Elapsed: 27361.899562120438 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.69       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.55      0.71      0.62       877\n",
      "           3       0.51      0.86      0.64       897\n",
      "           4       0.58      0.65      0.62       892\n",
      "           5       0.57      0.45      0.50       862\n",
      "           6       0.63      0.64      0.64       903\n",
      "           7       0.66      0.18      0.28       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.43      0.86      0.58       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.62      0.56     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 14900, Loss: 0.7417786717414856, F1: 0.5597972032055677, Accuracy: 0.5098754387172253, Time Elapsed: 27380.177459955215 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       912\n",
      "           1       0.62      0.63      0.62       885\n",
      "           2       0.63      0.50      0.56       877\n",
      "           3       0.60      0.35      0.44       897\n",
      "           4       0.60      0.62      0.61       892\n",
      "           5       1.00      0.00      0.00       862\n",
      "           6       0.63      0.36      0.46       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.55      0.78      0.64       892\n",
      "           9       0.57      0.08      0.13       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.65      0.42      0.42     14531\n",
      "weighted avg       0.57      0.48      0.44     14531\n",
      "\n",
      "Epoch 2, Step 15000, Loss: 0.9017388820648193, F1: 0.4196425629621557, Accuracy: 0.4788383456059459, Time Elapsed: 27396.233658075333 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.06      0.11       912\n",
      "           1       0.64      0.38      0.48       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.58      0.68      0.63       892\n",
      "           5       0.57      0.50      0.53       862\n",
      "           6       0.64      0.67      0.65       903\n",
      "           7       0.61      0.54      0.58       889\n",
      "           8       0.57      0.64      0.60       892\n",
      "           9       0.59      0.07      0.13       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.48      0.48     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 15100, Loss: 0.7795913815498352, F1: 0.48339595261816637, Accuracy: 0.4908127451655082, Time Elapsed: 28335.701904058456 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.69       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.55      0.79      0.65       877\n",
      "           3       0.61      0.50      0.55       897\n",
      "           4       0.57      0.86      0.68       892\n",
      "           5       0.59      0.28      0.38       862\n",
      "           6       0.62      0.72      0.67       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.58      0.57      0.58       892\n",
      "           9       0.48      0.86      0.61       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 2, Step 15200, Loss: 0.8742626309394836, F1: 0.5879090943742002, Accuracy: 0.526116578349735, Time Elapsed: 28353.990564107895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.08      0.14       912\n",
      "           1       0.60      0.60      0.60       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.58      0.14      0.22       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.52      0.60      0.56       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.62      0.38      0.47       889\n",
      "           8       0.60      0.37      0.46       892\n",
      "           9       0.59      0.33      0.42       876\n",
      "          10       0.39      0.52      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.47      0.48     14531\n",
      "weighted avg       0.52      0.48      0.46     14531\n",
      "\n",
      "Epoch 2, Step 15300, Loss: 1.4727563858032227, F1: 0.47564914314893336, Accuracy: 0.4819351730782465, Time Elapsed: 29317.346555233 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.62      0.40      0.48       885\n",
      "           2       0.61      0.47      0.53       877\n",
      "           3       0.56      0.07      0.12       897\n",
      "           4       0.56      0.85      0.68       892\n",
      "           5       0.49      0.55      0.51       862\n",
      "           6       0.63      0.56      0.59       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.59      0.49      0.53       892\n",
      "           9       0.56      0.24      0.33       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.50      0.50     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 15400, Loss: 0.7840121388435364, F1: 0.4988813094314135, Accuracy: 0.4909503819420549, Time Elapsed: 29334.656472206116 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.19      0.29       912\n",
      "           1       0.61      0.40      0.48       885\n",
      "           2       0.60      0.55      0.58       877\n",
      "           3       0.64      0.20      0.30       897\n",
      "           4       0.58      0.86      0.69       892\n",
      "           5       0.58      0.42      0.48       862\n",
      "           6       0.60      0.71      0.65       903\n",
      "           7       0.61      0.62      0.62       889\n",
      "           8       0.60      0.39      0.48       892\n",
      "           9       0.57      0.51      0.54       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 15500, Loss: 1.3793389797210693, F1: 0.5037023146912126, Accuracy: 0.4908815635537816, Time Elapsed: 29351.58548092842 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.91      0.73       912\n",
      "           1       0.60      0.78      0.68       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.49      0.82      0.62       892\n",
      "           5       0.56      0.59      0.58       862\n",
      "           6       0.52      0.95      0.67       903\n",
      "           7       0.62      0.62      0.62       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.40      0.48       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.59      0.53     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 15600, Loss: 0.607339084148407, F1: 0.5321683998201819, Accuracy: 0.5084990709517583, Time Elapsed: 29368.878165960312 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.58      0.11      0.19       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.53      0.85      0.65       897\n",
      "           4       0.58      0.59      0.58       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.62      0.33      0.43       903\n",
      "           7       0.62      0.26      0.37       889\n",
      "           8       0.55      0.46      0.50       892\n",
      "           9       0.48      0.77      0.59       876\n",
      "          10       0.38      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.53      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 15700, Loss: 1.2730400562286377, F1: 0.5090814350764361, Accuracy: 0.4884041015759411, Time Elapsed: 30459.328818321228 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.90      0.70       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.58      0.73      0.65       877\n",
      "           3       0.60      0.54      0.56       897\n",
      "           4       0.55      0.79      0.65       892\n",
      "           5       0.49      0.79      0.61       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.59      0.26      0.36       889\n",
      "           8       0.55      0.67      0.61       892\n",
      "           9       0.55      0.70      0.62       876\n",
      "          10       0.38      0.24      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 15800, Loss: 0.9090813398361206, F1: 0.5833087547777408, Accuracy: 0.520542288899594, Time Elapsed: 30476.633963108063 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64       912\n",
      "           1       0.61      0.39      0.48       885\n",
      "           2       0.59      0.64      0.62       877\n",
      "           3       0.58      0.73      0.65       897\n",
      "           4       0.55      0.73      0.62       892\n",
      "           5       0.58      0.37      0.45       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.61      0.60      0.61       889\n",
      "           8       0.60      0.35      0.45       892\n",
      "           9       0.58      0.60      0.59       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 15900, Loss: 0.8913671970367432, F1: 0.56379337331093, Accuracy: 0.5154497281673663, Time Elapsed: 31516.15887403488 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66       912\n",
      "           1       0.59      0.79      0.68       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.61      0.55      0.57       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.55      0.64      0.60       862\n",
      "           6       0.57      0.84      0.68       903\n",
      "           7       0.60      0.74      0.67       889\n",
      "           8       0.59      0.56      0.57       892\n",
      "           9       0.55      0.75      0.63       876\n",
      "          10       0.38      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.60     14531\n",
      "weighted avg       0.50      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 16000, Loss: 0.5199030041694641, F1: 0.6009893635208114, Accuracy: 0.5268047622324685, Time Elapsed: 31533.397349119186 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.67       912\n",
      "           1       0.70      0.02      0.04       885\n",
      "           2       0.49      0.85      0.62       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.59      0.77      0.67       892\n",
      "           5       0.63      0.13      0.22       862\n",
      "           6       0.62      0.53      0.57       903\n",
      "           7       0.62      0.40      0.49       889\n",
      "           8       0.60      0.33      0.43       892\n",
      "           9       0.57      0.58      0.58       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.52      0.48     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 16100, Loss: 2.029370069503784, F1: 0.48190215387382307, Accuracy: 0.4868212786456541, Time Elapsed: 31549.548676013947 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.62      0.32      0.42       885\n",
      "           2       0.55      0.82      0.66       877\n",
      "           3       0.56      0.72      0.63       897\n",
      "           4       0.59      0.49      0.54       892\n",
      "           5       0.55      0.62      0.59       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.61      0.67      0.64       889\n",
      "           8       0.58      0.44      0.50       892\n",
      "           9       0.55      0.63      0.59       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 16200, Loss: 1.959826946258545, F1: 0.5672912586991622, Accuracy: 0.5135228132957126, Time Elapsed: 31566.27836704254 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.59      0.59      0.59       897\n",
      "           4       0.64      0.31      0.42       892\n",
      "           5       0.57      0.17      0.27       862\n",
      "           6       0.59      0.79      0.68       903\n",
      "           7       0.58      0.72      0.64       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.48      0.75      0.58       876\n",
      "          10       0.40      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 16300, Loss: 0.4023926556110382, F1: 0.5574686531087933, Accuracy: 0.5160002752735531, Time Elapsed: 31583.298588991165 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.69       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.17      0.00      0.00       877\n",
      "           3       0.55      0.74      0.63       897\n",
      "           4       0.60      0.16      0.25       892\n",
      "           5       0.59      0.24      0.35       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.59      0.69      0.64       889\n",
      "           8       0.57      0.74      0.64       892\n",
      "           9       0.58      0.48      0.52       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.53      0.54      0.50     14531\n",
      "weighted avg       0.49      0.51      0.47     14531\n",
      "\n",
      "Epoch 2, Step 16400, Loss: 0.31449753046035767, F1: 0.500963101263347, Accuracy: 0.5055398802560044, Time Elapsed: 31599.95764517784 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57       912\n",
      "           1       0.56      0.95      0.71       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.60      0.28      0.38       897\n",
      "           4       0.53      0.20      0.29       892\n",
      "           5       0.57      0.32      0.41       862\n",
      "           6       0.63      0.37      0.47       903\n",
      "           7       0.62      0.54      0.58       889\n",
      "           8       0.59      0.65      0.62       892\n",
      "           9       0.59      0.27      0.37       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.43      0.44     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 2, Step 16500, Loss: 0.6573219895362854, F1: 0.44151852176319917, Accuracy: 0.4768426123460189, Time Elapsed: 31616.28035211563 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.87      0.67       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.55      0.82      0.66       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.49      0.79      0.61       892\n",
      "           5       0.52      0.56      0.54       862\n",
      "           6       0.63      0.50      0.56       903\n",
      "           7       0.61      0.63      0.62       889\n",
      "           8       0.59      0.64      0.62       892\n",
      "           9       0.48      0.76      0.59       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.64      0.58     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 16600, Loss: 1.4146208763122559, F1: 0.5796814777627977, Accuracy: 0.5131099029660725, Time Elapsed: 31631.908455133438 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.58      0.78      0.66       877\n",
      "           3       0.61      0.43      0.51       897\n",
      "           4       0.48      0.61      0.54       892\n",
      "           5       0.53      0.59      0.56       862\n",
      "           6       0.63      0.47      0.54       903\n",
      "           7       0.64      0.33      0.43       889\n",
      "           8       0.59      0.56      0.57       892\n",
      "           9       0.56      0.48      0.52       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 16700, Loss: 0.6070358157157898, F1: 0.5448812532250903, Accuracy: 0.4993462253114032, Time Elapsed: 31646.77960395813 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.46      0.52       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.60      0.63      0.62       877\n",
      "           3       0.61      0.24      0.35       897\n",
      "           4       0.45      0.56      0.50       892\n",
      "           5       0.53      0.51      0.52       862\n",
      "           6       0.63      0.47      0.54       903\n",
      "           7       0.63      0.27      0.38       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.64      0.16      0.26       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.52      0.43      0.44     14531\n",
      "weighted avg       0.48      0.47      0.45     14531\n",
      "\n",
      "Epoch 2, Step 16800, Loss: 0.37382131814956665, F1: 0.4414539899866878, Accuracy: 0.4724382354965247, Time Elapsed: 31662.540598154068 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.61      0.13      0.21       877\n",
      "           3       0.62      0.32      0.42       897\n",
      "           4       0.49      0.73      0.58       892\n",
      "           5       0.57      0.19      0.29       862\n",
      "           6       0.59      0.73      0.65       903\n",
      "           7       0.61      0.51      0.55       889\n",
      "           8       0.55      0.57      0.56       892\n",
      "           9       0.50      0.62      0.56       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.52      0.50     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 16900, Loss: 0.8702138662338257, F1: 0.5034219746905129, Accuracy: 0.4899181061179547, Time Elapsed: 31677.426159143448 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.48      0.54       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.61      0.17      0.26       877\n",
      "           3       0.62      0.46      0.53       897\n",
      "           4       0.56      0.23      0.33       892\n",
      "           5       0.57      0.56      0.56       862\n",
      "           6       0.55      0.92      0.69       903\n",
      "           7       0.61      0.62      0.61       889\n",
      "           8       0.48      0.87      0.62       892\n",
      "           9       0.50      0.72      0.59       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.57      0.53     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 17000, Loss: 0.25325942039489746, F1: 0.5301357385327417, Accuracy: 0.5017548689009703, Time Elapsed: 32600.032942056656 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.33      0.43       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.60      0.35      0.44       877\n",
      "           3       0.60      0.59      0.60       897\n",
      "           4       0.55      0.09      0.16       892\n",
      "           5       0.37      0.81      0.51       862\n",
      "           6       0.58      0.82      0.68       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.56      0.77      0.65       892\n",
      "           9       0.49      0.75      0.60       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.59      0.53     14531\n",
      "weighted avg       0.49      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 17100, Loss: 0.8049993515014648, F1: 0.5267978342447509, Accuracy: 0.49349666230816874, Time Elapsed: 32618.178874254227 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60       912\n",
      "           1       0.62      0.66      0.64       885\n",
      "           2       0.56      0.72      0.63       877\n",
      "           3       0.61      0.58      0.59       897\n",
      "           4       0.54      0.30      0.39       892\n",
      "           5       0.61      0.26      0.36       862\n",
      "           6       0.61      0.46      0.52       903\n",
      "           7       0.59      0.67      0.63       889\n",
      "           8       0.60      0.36      0.45       892\n",
      "           9       0.62      0.38      0.47       876\n",
      "          10       0.40      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.50      0.52     14531\n",
      "weighted avg       0.52      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 17200, Loss: 2.9498510360717773, F1: 0.5209704994246943, Accuracy: 0.498313949487303, Time Elapsed: 32633.851612091064 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68       912\n",
      "           1       0.62      0.53      0.57       885\n",
      "           2       0.55      0.77      0.64       877\n",
      "           3       0.59      0.73      0.65       897\n",
      "           4       0.60      0.20      0.29       892\n",
      "           5       0.58      0.56      0.57       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.53      0.90      0.67       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.51      0.72      0.60       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 17300, Loss: 0.5204702019691467, F1: 0.5711924120433672, Accuracy: 0.5171701878742, Time Elapsed: 33667.048270225525 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.47      0.54       912\n",
      "           1       0.68      0.14      0.24       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.58      0.23      0.33       892\n",
      "           5       0.58      0.17      0.26       862\n",
      "           6       0.62      0.43      0.51       903\n",
      "           7       0.59      0.67      0.63       889\n",
      "           8       0.59      0.70      0.64       892\n",
      "           9       0.32      0.93      0.47       876\n",
      "          10       0.40      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.56      0.47      0.47     14531\n",
      "weighted avg       0.51      0.46      0.45     14531\n",
      "\n",
      "Epoch 2, Step 17400, Loss: 0.9053962826728821, F1: 0.46602274630709145, Accuracy: 0.4623219324203427, Time Elapsed: 33685.981170892715 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.57      0.96      0.71       885\n",
      "           2       0.61      0.60      0.60       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.53      0.73      0.62       892\n",
      "           5       0.58      0.60      0.59       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.54      0.89      0.67       889\n",
      "           8       0.49      0.83      0.62       892\n",
      "           9       0.53      0.61      0.57       876\n",
      "          10       0.40      0.16      0.23      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.71      0.61     14531\n",
      "weighted avg       0.50      0.53      0.48     14531\n",
      "\n",
      "Epoch 2, Step 17500, Loss: 0.703904390335083, F1: 0.6055152667144174, Accuracy: 0.5333425091184364, Time Elapsed: 33705.51167011261 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.60      0.63      0.61       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.53      0.67      0.59       892\n",
      "           5       0.56      0.47      0.51       862\n",
      "           6       0.62      0.57      0.59       903\n",
      "           7       0.62      0.19      0.30       889\n",
      "           8       0.60      0.33      0.43       892\n",
      "           9       0.49      0.72      0.58       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.54     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 17600, Loss: 0.6076278686523438, F1: 0.5412172648445135, Accuracy: 0.5007914114651435, Time Elapsed: 33723.85002326965 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.04      0.08       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.55      0.82      0.66       877\n",
      "           3       0.59      0.75      0.66       897\n",
      "           4       0.51      0.60      0.55       892\n",
      "           5       0.49      0.78      0.60       862\n",
      "           6       0.62      0.57      0.60       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.58      0.69      0.63       892\n",
      "           9       0.53      0.66      0.59       876\n",
      "          10       0.38      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.63      0.55     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 17700, Loss: 1.1053569316864014, F1: 0.5530940199367211, Accuracy: 0.510425985823412, Time Elapsed: 33739.007966041565 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.62      0.42      0.50       897\n",
      "           4       0.47      0.86      0.61       892\n",
      "           5       0.52      0.62      0.57       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.57      0.69      0.63       892\n",
      "           9       0.56      0.58      0.57       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 17800, Loss: 1.3234977722167969, F1: 0.5888183560185244, Accuracy: 0.5212304727823275, Time Elapsed: 34682.14851617813 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.61      0.51      0.56       897\n",
      "           4       0.57      0.40      0.47       892\n",
      "           5       0.57      0.42      0.49       862\n",
      "           6       0.61      0.68      0.64       903\n",
      "           7       0.58      0.73      0.65       889\n",
      "           8       0.60      0.45      0.52       892\n",
      "           9       0.56      0.64      0.60       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.57     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 17900, Loss: 1.28096342086792, F1: 0.5716248480631837, Accuracy: 0.5184089188631202, Time Elapsed: 34698.478507995605 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.19      0.30       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.60      0.37      0.46       877\n",
      "           3       0.62      0.35      0.44       897\n",
      "           4       0.57      0.47      0.51       892\n",
      "           5       0.57      0.43      0.49       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.63      0.44      0.52       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.66      0.28      0.39       876\n",
      "          10       0.40      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.50      0.50     14531\n",
      "weighted avg       0.53      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 18000, Loss: 2.2034661769866943, F1: 0.5047963077556851, Accuracy: 0.49748812882802285, Time Elapsed: 34715.06210708618 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00       912\n",
      "           1       0.59      0.79      0.68       885\n",
      "           2       0.53      0.84      0.65       877\n",
      "           3       0.60      0.44      0.51       897\n",
      "           4       0.52      0.72      0.60       892\n",
      "           5       0.58      0.54      0.56       862\n",
      "           6       0.61      0.78      0.69       903\n",
      "           7       0.62      0.45      0.52       889\n",
      "           8       0.59      0.58      0.58       892\n",
      "           9       0.66      0.25      0.36       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.53      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 18100, Loss: 0.7193950414657593, F1: 0.5067002756724399, Accuracy: 0.4987956782052164, Time Elapsed: 35650.358275175095 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.58      0.81      0.68       885\n",
      "           2       0.55      0.77      0.64       877\n",
      "           3       0.61      0.53      0.57       897\n",
      "           4       0.52      0.71      0.60       892\n",
      "           5       0.58      0.35      0.43       862\n",
      "           6       0.61      0.50      0.55       903\n",
      "           7       0.63      0.52      0.57       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.61      0.44      0.51       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 18200, Loss: 1.2894806861877441, F1: 0.561655289043273, Accuracy: 0.5131099029660725, Time Elapsed: 35668.05210328102 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       912\n",
      "           1       0.61      0.28      0.38       885\n",
      "           2       0.59      0.52      0.55       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.60      0.23      0.33       892\n",
      "           5       0.58      0.56      0.57       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.62      0.47      0.54       889\n",
      "           8       0.60      0.53      0.57       892\n",
      "           9       0.60      0.53      0.56       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.50      0.53     14531\n",
      "weighted avg       0.52      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 18300, Loss: 2.277346134185791, F1: 0.5259358630786185, Accuracy: 0.4994838620879499, Time Elapsed: 36673.28314590454 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.62      0.59      0.60       885\n",
      "           2       0.54      0.82      0.65       877\n",
      "           3       0.61      0.25      0.35       897\n",
      "           4       0.57      0.61      0.59       892\n",
      "           5       0.58      0.35      0.44       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.03      0.06       889\n",
      "           8       0.58      0.68      0.63       892\n",
      "           9       0.52      0.72      0.60       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.56      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 18400, Loss: 1.0363078117370605, F1: 0.5202859478742184, Accuracy: 0.5037506021608974, Time Elapsed: 36691.318654060364 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       912\n",
      "           1       0.62      0.78      0.69       885\n",
      "           2       0.57      0.75      0.65       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.60      0.27      0.37       892\n",
      "           5       0.59      0.27      0.37       862\n",
      "           6       0.60      0.80      0.68       903\n",
      "           7       0.61      0.41      0.49       889\n",
      "           8       0.62      0.35      0.45       892\n",
      "           9       0.40      0.86      0.55       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 18500, Loss: 1.0280210971832275, F1: 0.5398067282562242, Accuracy: 0.5014107769596036, Time Elapsed: 36708.15148997307 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.67       912\n",
      "           1       0.65      0.30      0.41       885\n",
      "           2       0.61      0.56      0.58       877\n",
      "           3       0.60      0.31      0.41       897\n",
      "           4       0.57      0.52      0.55       892\n",
      "           5       0.60      0.31      0.40       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.56      0.86      0.68       889\n",
      "           8       0.60      0.56      0.58       892\n",
      "           9       0.50      0.71      0.59       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 18600, Loss: 0.8663561940193176, F1: 0.5394979503843499, Accuracy: 0.5062280641387379, Time Elapsed: 37682.13547706604 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.63      0.38      0.47       885\n",
      "           2       0.60      0.59      0.59       877\n",
      "           3       0.56      0.74      0.64       897\n",
      "           4       0.58      0.50      0.54       892\n",
      "           5       0.57      0.30      0.40       862\n",
      "           6       0.62      0.54      0.58       903\n",
      "           7       0.57      0.71      0.63       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.46      0.64      0.54       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.55     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 18700, Loss: 0.7708379030227661, F1: 0.5474898012756152, Accuracy: 0.504851696373271, Time Elapsed: 37701.440948963165 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       912\n",
      "           1       0.60      0.68      0.64       885\n",
      "           2       0.64      0.36      0.46       877\n",
      "           3       0.55      0.80      0.66       897\n",
      "           4       0.46      0.88      0.60       892\n",
      "           5       0.49      0.53      0.51       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.63      0.37      0.46       889\n",
      "           8       0.58      0.63      0.60       892\n",
      "           9       0.56      0.61      0.58       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 18800, Loss: 5.486751079559326, F1: 0.5572548872939005, Accuracy: 0.5062968825270112, Time Elapsed: 37718.51927113533 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60       912\n",
      "           1       0.60      0.70      0.64       885\n",
      "           2       0.60      0.67      0.63       877\n",
      "           3       0.59      0.55      0.57       897\n",
      "           4       0.57      0.64      0.60       892\n",
      "           5       0.54      0.60      0.57       862\n",
      "           6       0.61      0.48      0.54       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.52      0.76      0.62       892\n",
      "           9       0.54      0.71      0.61       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 18900, Loss: 0.4858919382095337, F1: 0.5823000127210403, Accuracy: 0.5159314568852797, Time Elapsed: 37734.96686792374 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.57      0.71      0.64       877\n",
      "           3       0.60      0.65      0.62       897\n",
      "           4       0.57      0.09      0.16       892\n",
      "           5       0.52      0.50      0.51       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.56      0.61      0.58       892\n",
      "           9       0.46      0.61      0.53       876\n",
      "          10       0.39      0.33      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 19000, Loss: 0.2621467709541321, F1: 0.5555480945377437, Accuracy: 0.5124217190833391, Time Elapsed: 38050.63388323784 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.70       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.55      0.71      0.62       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.48      0.72      0.57       892\n",
      "           5       0.51      0.46      0.48       862\n",
      "           6       0.55      0.87      0.68       903\n",
      "           7       0.61      0.71      0.66       889\n",
      "           8       0.60      0.30      0.40       892\n",
      "           9       0.59      0.41      0.48       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 19100, Loss: 0.7506136298179626, F1: 0.5727205666537694, Accuracy: 0.5193035579106737, Time Elapsed: 38066.61630105972 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.39      0.48       912\n",
      "           1       0.63      0.54      0.58       885\n",
      "           2       0.52      0.83      0.64       877\n",
      "           3       0.60      0.42      0.50       897\n",
      "           4       0.45      0.84      0.59       892\n",
      "           5       0.55      0.13      0.21       862\n",
      "           6       0.62      0.35      0.45       903\n",
      "           7       0.61      0.71      0.66       889\n",
      "           8       0.61      0.29      0.40       892\n",
      "           9       0.56      0.47      0.51       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.49      0.49     14531\n",
      "weighted avg       0.50      0.48      0.47     14531\n",
      "\n",
      "Epoch 2, Step 19200, Loss: 0.3481728732585907, F1: 0.49380082954203613, Accuracy: 0.481040534030693, Time Elapsed: 38379.82361602783 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.58      0.97      0.73       885\n",
      "           2       0.55      0.83      0.66       877\n",
      "           3       0.59      0.75      0.66       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.63      0.71      0.67       903\n",
      "           7       0.58      0.87      0.69       889\n",
      "           8       0.60      0.51      0.55       892\n",
      "           9       0.54      0.73      0.62       876\n",
      "          10       0.39      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 2, Step 19300, Loss: 1.081466555595398, F1: 0.611309445749728, Accuracy: 0.5392608905099443, Time Elapsed: 38397.821521282196 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.72       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.58      0.72      0.64       877\n",
      "           3       0.58      0.23      0.33       897\n",
      "           4       0.45      0.88      0.60       892\n",
      "           5       0.59      0.49      0.53       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.53      0.91      0.67       889\n",
      "           8       0.58      0.71      0.64       892\n",
      "           9       0.61      0.33      0.42       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 19400, Loss: 0.3441566526889801, F1: 0.5552377270026426, Accuracy: 0.5102883490468654, Time Elapsed: 38415.653436899185 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.61      0.94      0.74       885\n",
      "           2       0.60      0.61      0.60       877\n",
      "           3       0.61      0.36      0.45       897\n",
      "           4       0.57      0.56      0.57       892\n",
      "           5       0.58      0.51      0.54       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.59      0.79      0.67       889\n",
      "           8       0.56      0.74      0.64       892\n",
      "           9       0.58      0.52      0.55       876\n",
      "          10       0.40      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 19500, Loss: 2.8975307941436768, F1: 0.5931631330637345, Accuracy: 0.5325166884591563, Time Elapsed: 39331.99855995178 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       912\n",
      "           1       0.60      0.95      0.73       885\n",
      "           2       0.61      0.48      0.54       877\n",
      "           3       0.53      0.88      0.66       897\n",
      "           4       0.47      0.89      0.62       892\n",
      "           5       0.53      0.76      0.62       862\n",
      "           6       0.62      0.77      0.68       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.57      0.74      0.64       892\n",
      "           9       0.58      0.59      0.59       876\n",
      "          10       0.40      0.17      0.24      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.72      0.61     14531\n",
      "weighted avg       0.50      0.54      0.49     14531\n",
      "\n",
      "Epoch 2, Step 19600, Loss: 1.0741825103759766, F1: 0.6109410534994111, Accuracy: 0.5380221595210241, Time Elapsed: 39349.24887919426 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.40      0.49       912\n",
      "           1       0.57      0.98      0.72       885\n",
      "           2       0.51      0.88      0.64       877\n",
      "           3       0.59      0.78      0.67       897\n",
      "           4       0.57      0.56      0.56       892\n",
      "           5       0.56      0.57      0.56       862\n",
      "           6       0.56      0.93      0.70       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.58      0.65      0.62       892\n",
      "           9       0.49      0.75      0.59       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 19700, Loss: 0.8931548595428467, F1: 0.5890772186503339, Accuracy: 0.5228132957126144, Time Elapsed: 39365.92841410637 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       912\n",
      "           1       0.58      0.96      0.72       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.58      0.76      0.66       897\n",
      "           4       0.60      0.41      0.49       892\n",
      "           5       0.57      0.47      0.52       862\n",
      "           6       0.61      0.78      0.69       903\n",
      "           7       0.56      0.85      0.68       889\n",
      "           8       0.59      0.37      0.46       892\n",
      "           9       0.50      0.79      0.61       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 19800, Loss: 0.4840651750564575, F1: 0.5805402991892566, Accuracy: 0.5210928360057807, Time Elapsed: 40296.519876241684 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.62      0.83      0.71       885\n",
      "           2       0.60      0.60      0.60       877\n",
      "           3       0.50      0.90      0.64       897\n",
      "           4       0.57      0.68      0.62       892\n",
      "           5       0.56      0.52      0.54       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.60      0.52      0.56       892\n",
      "           9       0.60      0.50      0.54       876\n",
      "          10       0.41      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.67      0.60     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 2, Step 19900, Loss: 0.5325339436531067, F1: 0.6025374447051134, Accuracy: 0.5361640630376436, Time Elapsed: 40312.76398015022 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.64       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.58      0.77      0.66       877\n",
      "           3       0.57      0.71      0.63       897\n",
      "           4       0.57      0.53      0.55       892\n",
      "           5       0.53      0.36      0.43       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.55      0.72      0.63       892\n",
      "           9       0.64      0.03      0.07       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 20000, Loss: 0.20865927636623383, F1: 0.5440273517511215, Accuracy: 0.5124905374716124, Time Elapsed: 41243.179821014404 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.60      0.32      0.42       892\n",
      "           5       0.61      0.14      0.23       862\n",
      "           6       0.62      0.65      0.63       903\n",
      "           7       0.59      0.31      0.41       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.51      0.60      0.55       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.51      0.49     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 20100, Loss: 0.7149640321731567, F1: 0.48513495060003586, Accuracy: 0.494735393297089, Time Elapsed: 41259.52907323837 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       912\n",
      "           1       0.58      0.97      0.72       885\n",
      "           2       0.56      0.83      0.67       877\n",
      "           3       0.51      0.86      0.64       897\n",
      "           4       0.42      0.85      0.57       892\n",
      "           5       0.60      0.14      0.22       862\n",
      "           6       0.58      0.91      0.71       903\n",
      "           7       0.60      0.44      0.51       889\n",
      "           8       0.52      0.73      0.61       892\n",
      "           9       0.60      0.22      0.33       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.62      0.54     14531\n",
      "weighted avg       0.49      0.50      0.46     14531\n",
      "\n",
      "Epoch 2, Step 20200, Loss: 0.9098084568977356, F1: 0.5362656868226726, Accuracy: 0.5026495079485238, Time Elapsed: 41276.091967105865 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.42      0.50       912\n",
      "           1       0.55      0.98      0.71       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.59      0.62      0.61       897\n",
      "           4       0.42      0.94      0.58       892\n",
      "           5       0.44      0.51      0.47       862\n",
      "           6       0.59      0.89      0.71       903\n",
      "           7       0.61      0.17      0.26       889\n",
      "           8       0.55      0.70      0.62       892\n",
      "           9       0.57      0.55      0.56       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.60      0.54     14531\n",
      "weighted avg       0.49      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 20300, Loss: 1.1105968952178955, F1: 0.5382630006929754, Accuracy: 0.49494184846190903, Time Elapsed: 42212.49461197853 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.31      0.41       912\n",
      "           1       0.62      0.19      0.29       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.55      0.68      0.61       897\n",
      "           4       0.56      0.53      0.55       892\n",
      "           5       0.38      0.27      0.32       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.59      0.02      0.04       889\n",
      "           8       0.48      0.83      0.61       892\n",
      "           9       0.69      0.05      0.09       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.56      0.42      0.42     14531\n",
      "weighted avg       0.50      0.46      0.43     14531\n",
      "\n",
      "Epoch 2, Step 20400, Loss: 1.0444982051849365, F1: 0.41666130611530067, Accuracy: 0.463973573738903, Time Elapsed: 42230.81999516487 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.51       912\n",
      "           1       0.57      0.85      0.68       885\n",
      "           2       0.60      0.57      0.59       877\n",
      "           3       0.58      0.75      0.66       897\n",
      "           4       0.56      0.42      0.48       892\n",
      "           5       0.49      0.54      0.51       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.60      0.40      0.48       889\n",
      "           8       0.59      0.46      0.52       892\n",
      "           9       0.51      0.68      0.58       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 20500, Loss: 1.4980573654174805, F1: 0.5445650345384069, Accuracy: 0.4978322207693896, Time Elapsed: 43299.43440890312 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.53       912\n",
      "           1       0.58      0.71      0.64       885\n",
      "           2       0.65      0.32      0.42       877\n",
      "           3       0.59      0.58      0.59       897\n",
      "           4       0.55      0.37      0.44       892\n",
      "           5       0.53      0.50      0.51       862\n",
      "           6       0.61      0.40      0.48       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.48      0.66      0.56       892\n",
      "           9       0.56      0.64      0.60       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.53     14531\n",
      "weighted avg       0.50      0.49      0.49     14531\n",
      "\n",
      "Epoch 2, Step 20600, Loss: 0.7772293090820312, F1: 0.5320385777217423, Accuracy: 0.49404720941435554, Time Elapsed: 43316.683847904205 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.24      0.35       912\n",
      "           1       0.61      0.42      0.50       885\n",
      "           2       0.62      0.45      0.52       877\n",
      "           3       0.57      0.74      0.64       897\n",
      "           4       0.47      0.92      0.62       892\n",
      "           5       0.46      0.48      0.47       862\n",
      "           6       0.62      0.24      0.35       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.56      0.38      0.46       892\n",
      "           9       0.56      0.71      0.62       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.52      0.51     14531\n",
      "weighted avg       0.50      0.48      0.47     14531\n",
      "\n",
      "Epoch 2, Step 20700, Loss: 3.038477659225464, F1: 0.5072616634053161, Accuracy: 0.4832427224554401, Time Elapsed: 43334.019267082214 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.16      0.26       912\n",
      "           1       0.60      0.39      0.47       885\n",
      "           2       0.62      0.37      0.47       877\n",
      "           3       0.51      0.89      0.65       897\n",
      "           4       0.57      0.53      0.55       892\n",
      "           5       0.57      0.23      0.33       862\n",
      "           6       0.61      0.48      0.54       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.57      0.39      0.46       892\n",
      "           9       0.64      0.07      0.12       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.44      0.45     14531\n",
      "weighted avg       0.52      0.48      0.45     14531\n",
      "\n",
      "Epoch 2, Step 20800, Loss: 0.5037722587585449, F1: 0.4523903965428151, Accuracy: 0.4762920652398321, Time Elapsed: 43349.83187913895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.30      0.40       912\n",
      "           1       0.58      0.33      0.43       885\n",
      "           2       0.61      0.40      0.48       877\n",
      "           3       0.51      0.82      0.63       897\n",
      "           4       0.56      0.58      0.57       892\n",
      "           5       0.58      0.25      0.35       862\n",
      "           6       0.60      0.45      0.51       903\n",
      "           7       0.60      0.61      0.60       889\n",
      "           8       0.48      0.49      0.48       892\n",
      "           9       0.47      0.76      0.58       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.49      0.50     14531\n",
      "weighted avg       0.49      0.48      0.47     14531\n",
      "\n",
      "Epoch 2, Step 20900, Loss: 1.19021475315094, F1: 0.49544414507277296, Accuracy: 0.47512215263918517, Time Elapsed: 43366.309410095215 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.65       912\n",
      "           1       0.54      0.96      0.69       885\n",
      "           2       0.54      0.65      0.59       877\n",
      "           3       0.48      0.81      0.60       897\n",
      "           4       0.56      0.50      0.53       892\n",
      "           5       0.58      0.10      0.18       862\n",
      "           6       0.60      0.66      0.63       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.59      0.12      0.20       892\n",
      "           9       0.57      0.26      0.36       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.54      0.50     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 21000, Loss: 0.4315224289894104, F1: 0.4998540993978571, Accuracy: 0.4957676691211892, Time Elapsed: 43382.14157104492 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.28      0.37       912\n",
      "           1       0.61      0.73      0.67       885\n",
      "           2       0.65      0.27      0.38       877\n",
      "           3       0.60      0.13      0.21       897\n",
      "           4       0.55      0.75      0.63       892\n",
      "           5       0.61      0.11      0.19       862\n",
      "           6       0.58      0.60      0.59       903\n",
      "           7       0.59      0.84      0.70       889\n",
      "           8       0.57      0.15      0.24       892\n",
      "           9       0.50      0.76      0.61       876\n",
      "          10       0.40      0.51      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.47      0.46     14531\n",
      "weighted avg       0.51      0.48      0.45     14531\n",
      "\n",
      "Epoch 2, Step 21100, Loss: 1.6502702236175537, F1: 0.4574020346995795, Accuracy: 0.48248572018443325, Time Elapsed: 43396.88384413719 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.62       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.61      0.39      0.48       877\n",
      "           3       0.59      0.71      0.64       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.55      0.50      0.52       862\n",
      "           6       0.59      0.49      0.54       903\n",
      "           7       0.61      0.77      0.68       889\n",
      "           8       0.49      0.05      0.09       892\n",
      "           9       0.55      0.68      0.61       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.57      0.54     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 21200, Loss: 1.6056725978851318, F1: 0.5367135755200517, Accuracy: 0.5085678893400316, Time Elapsed: 43411.76088809967 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.32      0.42       912\n",
      "           1       0.55      0.81      0.65       885\n",
      "           2       0.55      0.51      0.53       877\n",
      "           3       0.56      0.77      0.65       897\n",
      "           4       0.60      0.24      0.35       892\n",
      "           5       0.44      0.72      0.55       862\n",
      "           6       0.62      0.48      0.54       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.45      0.72      0.55       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.49      0.51      0.48     14531\n",
      "weighted avg       0.46      0.48      0.45     14531\n",
      "\n",
      "Epoch 2, Step 21300, Loss: 0.8250985145568848, F1: 0.47974950358074064, Accuracy: 0.4771867042873856, Time Elapsed: 43427.59052491188 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.35      0.45       912\n",
      "           1       0.59      0.86      0.70       885\n",
      "           2       0.63      0.35      0.45       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.61      0.31      0.41       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.57      0.65      0.61       903\n",
      "           7       0.61      0.76      0.68       889\n",
      "           8       0.54      0.74      0.62       892\n",
      "           9       0.55      0.69      0.61       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 21400, Loss: 1.2027132511138916, F1: 0.5543212321087267, Accuracy: 0.511595898424059, Time Elapsed: 43442.72923898697 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.37      0.45       912\n",
      "           1       0.65      0.37      0.47       885\n",
      "           2       0.63      0.33      0.43       877\n",
      "           3       0.59      0.66      0.63       897\n",
      "           4       0.46      0.90      0.61       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.61      0.49      0.54       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.55      0.62      0.59       892\n",
      "           9       0.60      0.47      0.53       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.54     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 21500, Loss: 1.2919994592666626, F1: 0.5376009708527232, Accuracy: 0.49900213337003646, Time Elapsed: 43457.97379112244 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38       912\n",
      "           1       1.00      0.00      0.01       885\n",
      "           2       0.53      0.57      0.55       877\n",
      "           3       0.60      0.50      0.55       897\n",
      "           4       0.61      0.21      0.32       892\n",
      "           5       0.57      0.37      0.44       862\n",
      "           6       0.66      0.20      0.31       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.52      0.75      0.62       892\n",
      "           9       0.54      0.59      0.57       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.60      0.43      0.44     14531\n",
      "weighted avg       0.53      0.47      0.45     14531\n",
      "\n",
      "Epoch 2, Step 21600, Loss: 1.5977520942687988, F1: 0.4386818458026646, Accuracy: 0.46961668157731745, Time Elapsed: 43473.25562810898 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       912\n",
      "           1       0.60      0.13      0.21       885\n",
      "           2       0.55      0.60      0.57       877\n",
      "           3       0.51      0.88      0.65       897\n",
      "           4       0.58      0.45      0.50       892\n",
      "           5       0.60      0.33      0.42       862\n",
      "           6       0.58      0.69      0.63       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.57      0.48      0.52       892\n",
      "           9       0.54      0.40      0.46       876\n",
      "          10       0.40      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.52      0.51     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 21700, Loss: 1.1074929237365723, F1: 0.5142350824649231, Accuracy: 0.49645585300392264, Time Elapsed: 43488.49943304062 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.81      0.68       912\n",
      "           1       0.64      0.37      0.47       885\n",
      "           2       0.60      0.42      0.50       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.59      0.30      0.40       892\n",
      "           5       0.57      0.58      0.57       862\n",
      "           6       0.57      0.64      0.60       903\n",
      "           7       0.62      0.43      0.51       889\n",
      "           8       0.53      0.78      0.63       892\n",
      "           9       0.50      0.70      0.58       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.56      0.54     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 21800, Loss: 0.9084478616714478, F1: 0.5448443020786041, Accuracy: 0.5058151538090978, Time Elapsed: 43503.93080306053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65       912\n",
      "           1       0.59      0.87      0.71       885\n",
      "           2       0.57      0.49      0.53       877\n",
      "           3       0.55      0.84      0.66       897\n",
      "           4       0.63      0.19      0.29       892\n",
      "           5       0.59      0.34      0.43       862\n",
      "           6       0.61      0.61      0.61       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.58      0.53      0.55       892\n",
      "           9       0.59      0.21      0.31       876\n",
      "          10       0.40      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 21900, Loss: 0.13517585396766663, F1: 0.5278919663705222, Accuracy: 0.5067097928566513, Time Elapsed: 43519.03735113144 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.24      0.35       912\n",
      "           1       0.61      0.61      0.61       885\n",
      "           2       0.61      0.34      0.44       877\n",
      "           3       0.58      0.69      0.63       897\n",
      "           4       0.59      0.37      0.46       892\n",
      "           5       0.57      0.49      0.53       862\n",
      "           6       0.62      0.42      0.50       903\n",
      "           7       0.60      0.55      0.58       889\n",
      "           8       0.56      0.51      0.53       892\n",
      "           9       0.63      0.29      0.39       876\n",
      "          10       0.39      0.54      0.46      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.46      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 22000, Loss: 0.7287719249725342, F1: 0.49729847061933924, Accuracy: 0.48716537058702086, Time Elapsed: 43534.81767010689 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.04      0.08       912\n",
      "           1       0.60      0.78      0.68       885\n",
      "           2       0.59      0.41      0.49       877\n",
      "           3       0.60      0.29      0.39       897\n",
      "           4       0.58      0.07      0.13       892\n",
      "           5       0.56      0.34      0.43       862\n",
      "           6       0.64      0.11      0.19       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.57      0.38      0.46       892\n",
      "           9       0.65      0.25      0.36       876\n",
      "          10       0.39      0.65      0.49      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.58      0.37      0.39     14531\n",
      "weighted avg       0.52      0.46      0.42     14531\n",
      "\n",
      "Epoch 2, Step 22100, Loss: 0.9755857586860657, F1: 0.3947369817497357, Accuracy: 0.46011974399559563, Time Elapsed: 43549.93149518967 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.07      0.13       912\n",
      "           1       0.58      0.97      0.72       885\n",
      "           2       0.58      0.49      0.53       877\n",
      "           3       0.61      0.10      0.18       897\n",
      "           4       0.60      0.17      0.27       892\n",
      "           5       0.56      0.41      0.47       862\n",
      "           6       0.63      0.08      0.14       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.57      0.60      0.58       892\n",
      "           9       0.41      0.83      0.55       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.56      0.45      0.42     14531\n",
      "weighted avg       0.50      0.46      0.43     14531\n",
      "\n",
      "Epoch 2, Step 22200, Loss: 0.709278404712677, F1: 0.42276351274792995, Accuracy: 0.4627348427499828, Time Elapsed: 43564.70133519173 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59       912\n",
      "           1       0.62      0.43      0.51       885\n",
      "           2       0.53      0.62      0.57       877\n",
      "           3       0.60      0.37      0.46       897\n",
      "           4       0.55      0.07      0.12       892\n",
      "           5       0.58      0.34      0.43       862\n",
      "           6       0.63      0.49      0.55       903\n",
      "           7       0.61      0.56      0.59       889\n",
      "           8       0.58      0.57      0.58       892\n",
      "           9       0.62      0.33      0.43       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.45      0.48     14531\n",
      "weighted avg       0.52      0.48      0.48     14531\n",
      "\n",
      "Epoch 2, Step 22300, Loss: 0.76930832862854, F1: 0.48066249075669343, Accuracy: 0.48448145344436033, Time Elapsed: 43581.60038614273 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.66      0.08      0.15       885\n",
      "           2       0.66      0.25      0.36       877\n",
      "           3       0.60      0.64      0.62       897\n",
      "           4       0.55      0.73      0.63       892\n",
      "           5       0.58      0.55      0.56       862\n",
      "           6       0.63      0.56      0.59       903\n",
      "           7       0.61      0.79      0.69       889\n",
      "           8       0.54      0.76      0.63       892\n",
      "           9       0.54      0.70      0.61       876\n",
      "          10       0.40      0.39      0.40      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.57      0.54     14531\n",
      "weighted avg       0.52      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 22400, Loss: 0.8518969416618347, F1: 0.5404729255690381, Accuracy: 0.515380909779093, Time Elapsed: 43596.592739105225 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.59      0.55      0.57       885\n",
      "           2       0.64      0.29      0.40       877\n",
      "           3       0.59      0.57      0.58       897\n",
      "           4       0.52      0.75      0.61       892\n",
      "           5       0.59      0.51      0.55       862\n",
      "           6       0.64      0.34      0.45       903\n",
      "           7       0.55      0.89      0.68       889\n",
      "           8       0.60      0.46      0.52       892\n",
      "           9       0.62      0.39      0.48       876\n",
      "          10       0.41      0.43      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 22500, Loss: 1.4002718925476074, F1: 0.5423734397724211, Accuracy: 0.5114582616475122, Time Elapsed: 43612.13708591461 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.72       912\n",
      "           1       0.66      0.34      0.45       885\n",
      "           2       0.64      0.11      0.19       877\n",
      "           3       0.59      0.65      0.62       897\n",
      "           4       0.54      0.66      0.60       892\n",
      "           5       0.57      0.36      0.44       862\n",
      "           6       0.62      0.57      0.59       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.60      0.61      0.60       892\n",
      "           9       0.62      0.48      0.54       876\n",
      "          10       0.40      0.46      0.43      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.59      0.53      0.53     14531\n",
      "weighted avg       0.53      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 22600, Loss: 0.2544505000114441, F1: 0.5323605053693634, Accuracy: 0.5116647168123323, Time Elapsed: 43627.189400196075 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.59      0.84      0.70       885\n",
      "           2       0.67      0.06      0.11       877\n",
      "           3       0.60      0.64      0.62       897\n",
      "           4       0.48      0.86      0.62       892\n",
      "           5       0.54      0.68      0.60       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.60      0.67      0.63       892\n",
      "           9       0.60      0.61      0.60       876\n",
      "          10       0.40      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.57     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 22700, Loss: 0.7726283669471741, F1: 0.5652827594430432, Accuracy: 0.5219186566650609, Time Elapsed: 43642.49544596672 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.73       912\n",
      "           1       0.61      0.63      0.62       885\n",
      "           2       0.55      0.73      0.63       877\n",
      "           3       0.58      0.31      0.40       897\n",
      "           4       0.57      0.23      0.33       892\n",
      "           5       0.42      0.87      0.57       862\n",
      "           6       0.61      0.63      0.62       903\n",
      "           7       0.60      0.84      0.70       889\n",
      "           8       0.61      0.53      0.56       892\n",
      "           9       0.49      0.80      0.61       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.62      0.55     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 22800, Loss: 0.3853302001953125, F1: 0.5531703658905486, Accuracy: 0.505471061867731, Time Elapsed: 43658.05658912659 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.70       912\n",
      "           1       0.65      0.14      0.23       885\n",
      "           2       0.49      0.77      0.60       877\n",
      "           3       0.62      0.55      0.58       897\n",
      "           4       0.57      0.43      0.49       892\n",
      "           5       0.55      0.50      0.52       862\n",
      "           6       0.63      0.42      0.51       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.61      0.34      0.44       892\n",
      "           9       0.43      0.82      0.56       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.54      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 22900, Loss: 0.17107446491718292, F1: 0.5137717286217766, Accuracy: 0.48702773381047415, Time Elapsed: 43673.86062526703 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.57      0.56      0.56       877\n",
      "           3       0.60      0.58      0.59       897\n",
      "           4       0.56      0.53      0.55       892\n",
      "           5       0.50      0.74      0.60       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.62      0.35      0.45       889\n",
      "           8       0.59      0.31      0.41       892\n",
      "           9       0.62      0.39      0.48       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 23000, Loss: 0.7898887395858765, F1: 0.5517702286244174, Accuracy: 0.5091872548344918, Time Elapsed: 43689.94598817825 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.69      0.13      0.21       885\n",
      "           2       0.63      0.08      0.14       877\n",
      "           3       0.58      0.66      0.62       897\n",
      "           4       0.59      0.52      0.55       892\n",
      "           5       0.59      0.30      0.40       862\n",
      "           6       0.63      0.45      0.52       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.57      0.64      0.60       876\n",
      "          10       0.40      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.49      0.49     14531\n",
      "weighted avg       0.53      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 23100, Loss: 0.49063751101493835, F1: 0.49258232511456446, Accuracy: 0.49707521849838276, Time Elapsed: 43704.66538310051 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.71       912\n",
      "           1       0.66      0.25      0.37       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.53      0.89      0.66       897\n",
      "           4       0.60      0.26      0.36       892\n",
      "           5       0.57      0.55      0.56       862\n",
      "           6       0.63      0.61      0.62       903\n",
      "           7       0.61      0.71      0.66       889\n",
      "           8       0.54      0.83      0.66       892\n",
      "           9       0.49      0.76      0.59       876\n",
      "          10       0.40      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 23200, Loss: 1.408890724182129, F1: 0.5550009142905502, Accuracy: 0.5129722661895258, Time Elapsed: 43720.021672964096 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       912\n",
      "           1       0.60      0.86      0.70       885\n",
      "           2       0.62      0.26      0.37       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.59      0.27      0.37       892\n",
      "           5       0.57      0.32      0.41       862\n",
      "           6       0.63      0.47      0.54       903\n",
      "           7       0.59      0.64      0.61       889\n",
      "           8       0.54      0.80      0.64       892\n",
      "           9       0.40      0.90      0.55       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.58      0.53     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 23300, Loss: 0.40427327156066895, F1: 0.5341451421898282, Accuracy: 0.4967999449452894, Time Elapsed: 43735.944904088974 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.64      0.45      0.53       885\n",
      "           2       0.65      0.21      0.31       877\n",
      "           3       0.60      0.57      0.58       897\n",
      "           4       0.58      0.14      0.23       892\n",
      "           5       0.56      0.40      0.47       862\n",
      "           6       0.66      0.18      0.28       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.60      0.62      0.61       892\n",
      "           9       0.58      0.51      0.54       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.59      0.47      0.49     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 23400, Loss: 0.6386728286743164, F1: 0.48817579062847716, Accuracy: 0.4923267497075218, Time Elapsed: 43750.57657504082 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.63      0.47      0.54       885\n",
      "           2       0.70      0.08      0.15       877\n",
      "           3       0.54      0.74      0.62       897\n",
      "           4       0.58      0.12      0.19       892\n",
      "           5       0.47      0.82      0.60       862\n",
      "           6       0.62      0.67      0.65       903\n",
      "           7       0.56      0.87      0.68       889\n",
      "           8       0.59      0.36      0.45       892\n",
      "           9       0.47      0.73      0.57       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.50     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 23500, Loss: 0.7375141978263855, F1: 0.5044490718182107, Accuracy: 0.496731126557016, Time Elapsed: 43766.02226829529 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.58      0.90      0.71       885\n",
      "           2       0.50      0.01      0.02       877\n",
      "           3       0.60      0.48      0.53       897\n",
      "           4       0.57      0.31      0.40       892\n",
      "           5       0.57      0.40      0.47       862\n",
      "           6       0.59      0.73      0.65       903\n",
      "           7       0.65      0.05      0.09       889\n",
      "           8       0.60      0.26      0.37       892\n",
      "           9       0.56      0.66      0.61       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.47      0.46     14531\n",
      "weighted avg       0.51      0.49      0.45     14531\n",
      "\n",
      "Epoch 2, Step 23600, Loss: 3.3461389541625977, F1: 0.45528814156310554, Accuracy: 0.4851696373270938, Time Elapsed: 43780.75355386734 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.51      0.80      0.63       892\n",
      "           5       0.57      0.31      0.40       862\n",
      "           6       0.60      0.77      0.67       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.59      0.26      0.36       892\n",
      "           9       0.55      0.77      0.64       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 23700, Loss: 0.5265831351280212, F1: 0.566547784370421, Accuracy: 0.5166884591562866, Time Elapsed: 43797.12153506279 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.55      0.46      0.50       885\n",
      "           2       0.63      0.31      0.41       877\n",
      "           3       0.54      0.09      0.15       897\n",
      "           4       0.50      0.79      0.61       892\n",
      "           5       0.52      0.61      0.56       862\n",
      "           6       0.55      0.89      0.68       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.56      0.63      0.59       892\n",
      "           9       0.58      0.55      0.57       876\n",
      "          10       0.38      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.56      0.53     14531\n",
      "weighted avg       0.49      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 23800, Loss: 0.43609288334846497, F1: 0.5264475053827602, Accuracy: 0.4962493978391026, Time Elapsed: 43812.56461310387 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.01      0.03       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.61      0.29      0.39       877\n",
      "           3       0.58      0.27      0.37       897\n",
      "           4       0.56      0.52      0.54       892\n",
      "           5       0.59      0.21      0.31       862\n",
      "           6       0.62      0.44      0.51       903\n",
      "           7       0.61      0.66      0.64       889\n",
      "           8       0.58      0.34      0.43       892\n",
      "           9       0.61      0.35      0.44       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.42      0.44     14531\n",
      "weighted avg       0.51      0.47      0.45     14531\n",
      "\n",
      "Epoch 2, Step 23900, Loss: 0.7937500476837158, F1: 0.43987685171497865, Accuracy: 0.4730576009909848, Time Elapsed: 43827.22113800049 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.01      0.02       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.61      0.39      0.48       877\n",
      "           3       0.58      0.65      0.61       897\n",
      "           4       0.47      0.92      0.62       892\n",
      "           5       0.56      0.62      0.59       862\n",
      "           6       0.62      0.67      0.64       903\n",
      "           7       0.63      0.37      0.47       889\n",
      "           8       0.60      0.32      0.42       892\n",
      "           9       0.62      0.49      0.55       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.53      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 24000, Loss: 0.2351541817188263, F1: 0.5022982171975682, Accuracy: 0.4934278439198954, Time Elapsed: 43842.77853012085 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.56      0.97      0.71       885\n",
      "           2       0.60      0.32      0.42       877\n",
      "           3       0.57      0.76      0.65       897\n",
      "           4       0.51      0.64      0.57       892\n",
      "           5       0.59      0.39      0.47       862\n",
      "           6       0.62      0.34      0.44       903\n",
      "           7       0.56      0.01      0.01       889\n",
      "           8       0.61      0.34      0.44       892\n",
      "           9       0.54      0.74      0.63       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.50      0.46      0.43     14531\n",
      "weighted avg       0.46      0.47      0.43     14531\n",
      "\n",
      "Epoch 2, Step 24100, Loss: 0.682172954082489, F1: 0.43369745753785943, Accuracy: 0.472507053884798, Time Elapsed: 43858.28495311737 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       912\n",
      "           1       0.60      0.86      0.70       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.55      0.66      0.60       892\n",
      "           5       0.57      0.50      0.53       862\n",
      "           6       0.63      0.55      0.58       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.55      0.75      0.63       892\n",
      "           9       0.60      0.42      0.50       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 24200, Loss: 1.278986930847168, F1: 0.5869692036061817, Accuracy: 0.524533755419448, Time Elapsed: 43873.1048309803 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68       912\n",
      "           1       0.61      0.59      0.60       885\n",
      "           2       0.57      0.72      0.64       877\n",
      "           3       0.58      0.75      0.65       897\n",
      "           4       0.54      0.65      0.59       892\n",
      "           5       0.58      0.44      0.50       862\n",
      "           6       0.62      0.59      0.60       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.56      0.74      0.64       892\n",
      "           9       0.52      0.62      0.57       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 2, Step 24300, Loss: 0.7850884795188904, F1: 0.5842877047830086, Accuracy: 0.5194411946872204, Time Elapsed: 43888.82294201851 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68       912\n",
      "           1       0.60      0.12      0.20       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.61      0.37      0.46       897\n",
      "           4       0.57      0.41      0.48       892\n",
      "           5       0.54      0.64      0.59       862\n",
      "           6       0.62      0.67      0.65       903\n",
      "           7       0.58      0.05      0.09       889\n",
      "           8       0.57      0.75      0.65       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.44      0.44     14531\n",
      "weighted avg       0.48      0.48      0.44     14531\n",
      "\n",
      "Epoch 2, Step 24400, Loss: 3.601393222808838, F1: 0.4363260221168143, Accuracy: 0.479251255935586, Time Elapsed: 43903.775930166245 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.56      0.97      0.71       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.60      0.38      0.46       897\n",
      "           4       0.51      0.73      0.60       892\n",
      "           5       0.58      0.39      0.46       862\n",
      "           6       0.61      0.71      0.66       903\n",
      "           7       0.60      0.68      0.63       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.63      0.05      0.09       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 24500, Loss: 0.9278960824012756, F1: 0.5303923290860113, Accuracy: 0.5062968825270112, Time Elapsed: 43919.62569594383 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.71       912\n",
      "           1       0.60      0.79      0.68       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.57      0.51      0.53       897\n",
      "           4       0.51      0.71      0.59       892\n",
      "           5       0.45      0.79      0.57       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.61      0.59      0.60       889\n",
      "           8       0.57      0.65      0.61       892\n",
      "           9       0.61      0.08      0.14       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.61      0.55     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 24600, Loss: 3.2150087356567383, F1: 0.551502190137461, Accuracy: 0.5102883490468654, Time Elapsed: 43934.326681137085 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.59      0.83      0.69       885\n",
      "           2       0.62      0.35      0.45       877\n",
      "           3       0.54      0.81      0.65       897\n",
      "           4       0.44      0.88      0.58       892\n",
      "           5       0.58      0.47      0.52       862\n",
      "           6       0.63      0.38      0.47       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.48      0.68      0.57       892\n",
      "           9       0.60      0.38      0.46       876\n",
      "          10       0.40      0.29      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.61      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 24700, Loss: 2.9584057331085205, F1: 0.5560999387599632, Accuracy: 0.507260339962838, Time Elapsed: 43950.034855127335 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.61      0.62      0.61       877\n",
      "           3       0.59      0.53      0.56       897\n",
      "           4       0.43      0.87      0.57       892\n",
      "           5       0.54      0.47      0.50       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.60      0.26      0.36       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 24800, Loss: 1.038134217262268, F1: 0.5735807349269829, Accuracy: 0.5175830982038401, Time Elapsed: 43965.26356506348 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.60      0.40      0.48       877\n",
      "           3       0.59      0.54      0.56       897\n",
      "           4       0.53      0.74      0.62       892\n",
      "           5       0.56      0.23      0.32       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.53      0.60      0.56       892\n",
      "           9       0.54      0.66      0.59       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 24900, Loss: 0.13626006245613098, F1: 0.5705759769334088, Accuracy: 0.5194411946872204, Time Elapsed: 43980.56645607948 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.27      0.37       912\n",
      "           1       0.60      0.95      0.73       885\n",
      "           2       0.60      0.45      0.52       877\n",
      "           3       0.59      0.64      0.61       897\n",
      "           4       0.43      0.87      0.57       892\n",
      "           5       0.48      0.03      0.06       862\n",
      "           6       0.62      0.39      0.48       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.61      0.54      0.57       892\n",
      "           9       0.61      0.21      0.31       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.50      0.48     14531\n",
      "weighted avg       0.50      0.49      0.46     14531\n",
      "\n",
      "Epoch 2, Step 25000, Loss: 1.5487511157989502, F1: 0.48225146640724675, Accuracy: 0.48510081893882046, Time Elapsed: 43995.646100997925 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.61      0.51      0.55       877\n",
      "           3       0.62      0.50      0.56       897\n",
      "           4       0.53      0.72      0.61       892\n",
      "           5       0.54      0.30      0.39       862\n",
      "           6       0.60      0.77      0.68       903\n",
      "           7       0.61      0.56      0.59       889\n",
      "           8       0.59      0.41      0.48       892\n",
      "           9       0.52      0.63      0.57       876\n",
      "          10       0.39      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 25100, Loss: 0.5183191299438477, F1: 0.566424929615406, Accuracy: 0.5165508223797398, Time Elapsed: 44011.149610996246 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.61      0.30      0.40       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.59      0.18      0.27       892\n",
      "           5       0.57      0.55      0.56       862\n",
      "           6       0.61      0.46      0.52       903\n",
      "           7       0.61      0.02      0.03       889\n",
      "           8       0.50      0.01      0.02       892\n",
      "           9       0.39      0.83      0.53       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.55      0.48      0.44     14531\n",
      "weighted avg       0.50      0.47      0.43     14531\n",
      "\n",
      "Epoch 2, Step 25200, Loss: 0.9329777956008911, F1: 0.4392681329890429, Accuracy: 0.4744339687564517, Time Elapsed: 44025.92062997818 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       912\n",
      "           1       0.58      0.74      0.65       885\n",
      "           2       0.61      0.40      0.48       877\n",
      "           3       0.64      0.39      0.49       897\n",
      "           4       0.54      0.24      0.33       892\n",
      "           5       0.61      0.28      0.39       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.60      0.15      0.24       889\n",
      "           8       0.58      0.15      0.24       892\n",
      "           9       0.65      0.18      0.28       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.59      0.43      0.45     14531\n",
      "weighted avg       0.52      0.48      0.46     14531\n",
      "\n",
      "Epoch 2, Step 25300, Loss: 0.35515618324279785, F1: 0.44998691793977036, Accuracy: 0.4824169017961599, Time Elapsed: 44041.54882621765 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67       912\n",
      "           1       0.56      0.96      0.71       885\n",
      "           2       0.60      0.45      0.52       877\n",
      "           3       0.62      0.45      0.52       897\n",
      "           4       0.51      0.67      0.58       892\n",
      "           5       0.57      0.46      0.51       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.61      0.53      0.57       889\n",
      "           8       0.58      0.50      0.54       892\n",
      "           9       0.51      0.76      0.61       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 25400, Loss: 0.7655463814735413, F1: 0.5638206054395011, Accuracy: 0.510632440988232, Time Elapsed: 44056.44137597084 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.58      0.97      0.72       885\n",
      "           2       0.56      0.76      0.65       877\n",
      "           3       0.65      0.31      0.42       897\n",
      "           4       0.55      0.67      0.60       892\n",
      "           5       0.54      0.65      0.59       862\n",
      "           6       0.57      0.91      0.70       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.61      0.46      0.53       892\n",
      "           9       0.57      0.55      0.56       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 2, Step 25500, Loss: 0.8982657194137573, F1: 0.5862516037393611, Accuracy: 0.5268047622324685, Time Elapsed: 44072.12681698799 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.62      0.67      0.64       885\n",
      "           2       0.54      0.76      0.63       877\n",
      "           3       0.58      0.73      0.65       897\n",
      "           4       0.55      0.57      0.56       892\n",
      "           5       0.55      0.62      0.59       862\n",
      "           6       0.62      0.69      0.66       903\n",
      "           7       0.58      0.72      0.65       889\n",
      "           8       0.57      0.66      0.61       892\n",
      "           9       0.49      0.62      0.55       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.60     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 25600, Loss: 0.9853630065917969, F1: 0.5959257242596807, Accuracy: 0.5235014795953479, Time Elapsed: 44087.80499005318 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.91      0.73       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.62      0.37      0.46       877\n",
      "           3       0.60      0.44      0.51       897\n",
      "           4       0.53      0.57      0.55       892\n",
      "           5       0.59      0.52      0.55       862\n",
      "           6       0.62      0.72      0.67       903\n",
      "           7       0.60      0.87      0.71       889\n",
      "           8       0.59      0.62      0.60       892\n",
      "           9       0.55      0.69      0.61       876\n",
      "          10       0.40      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 2, Step 25700, Loss: 0.37781450152397156, F1: 0.587592635404432, Accuracy: 0.5301080448695892, Time Elapsed: 44103.02740097046 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.59      0.62      0.60       897\n",
      "           4       0.59      0.31      0.40       892\n",
      "           5       0.54      0.73      0.62       862\n",
      "           6       0.61      0.68      0.65       903\n",
      "           7       0.63      0.26      0.37       889\n",
      "           8       0.61      0.38      0.47       892\n",
      "           9       0.49      0.78      0.60       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 25800, Loss: 1.0758228302001953, F1: 0.5537651461138217, Accuracy: 0.5108388961530521, Time Elapsed: 44118.05951809883 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.31      0.41       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.60      0.45      0.51       877\n",
      "           3       0.60      0.62      0.61       897\n",
      "           4       0.57      0.35      0.43       892\n",
      "           5       0.58      0.32      0.41       862\n",
      "           6       0.62      0.35      0.45       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.62      0.20      0.30       892\n",
      "           9       0.53      0.61      0.57       876\n",
      "          10       0.39      0.50      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.48      0.50     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 2, Step 25900, Loss: 0.6790552735328674, F1: 0.5000327246095386, Accuracy: 0.48806000963457435, Time Elapsed: 44133.45172405243 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.39      0.49       912\n",
      "           1       0.56      0.98      0.71       885\n",
      "           2       0.57      0.59      0.58       877\n",
      "           3       0.63      0.55      0.59       897\n",
      "           4       0.60      0.22      0.33       892\n",
      "           5       0.58      0.45      0.51       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.63      0.34      0.44       892\n",
      "           9       0.55      0.61      0.58       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 26000, Loss: 0.38447970151901245, F1: 0.5398351687150215, Accuracy: 0.5062968825270112, Time Elapsed: 44148.59672021866 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.67       912\n",
      "           1       0.56      0.98      0.71       885\n",
      "           2       0.58      0.54      0.56       877\n",
      "           3       0.64      0.34      0.45       897\n",
      "           4       0.56      0.07      0.13       892\n",
      "           5       0.54      0.69      0.61       862\n",
      "           6       0.64      0.19      0.29       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.55      0.74      0.63       892\n",
      "           9       0.57      0.18      0.27       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.49     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 26100, Loss: 3.6746861934661865, F1: 0.4892155036422999, Accuracy: 0.49335902553162203, Time Elapsed: 44164.03943300247 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.29      0.40       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.46      0.88      0.61       877\n",
      "           3       0.58      0.75      0.65       897\n",
      "           4       0.57      0.22      0.32       892\n",
      "           5       0.55      0.34      0.42       862\n",
      "           6       0.63      0.33      0.43       903\n",
      "           7       0.56      0.88      0.69       889\n",
      "           8       0.59      0.63      0.61       892\n",
      "           9       0.47      0.42      0.44       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.55      0.52     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 26200, Loss: 1.6781294345855713, F1: 0.5156194822311752, Accuracy: 0.4908815635537816, Time Elapsed: 44179.746004104614 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.52      0.79      0.63       877\n",
      "           3       0.63      0.35      0.45       897\n",
      "           4       0.53      0.76      0.63       892\n",
      "           5       0.58      0.26      0.36       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.56      0.74      0.64       892\n",
      "           9       0.57      0.50      0.53       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 26300, Loss: 0.39206522703170776, F1: 0.572458602802822, Accuracy: 0.5195100130754938, Time Elapsed: 44195.18491387367 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.69       912\n",
      "           1       0.57      0.08      0.14       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.57      0.26      0.36       897\n",
      "           4       0.55      0.69      0.61       892\n",
      "           5       0.51      0.47      0.49       862\n",
      "           6       0.59      0.77      0.67       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.60      0.64      0.62       892\n",
      "           9       0.62      0.15      0.24       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 2, Step 26400, Loss: 1.764375925064087, F1: 0.49608768647455065, Accuracy: 0.49411602780262887, Time Elapsed: 45176.96447515488 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65       912\n",
      "           1       0.57      0.52      0.55       885\n",
      "           2       0.60      0.63      0.61       877\n",
      "           3       0.49      0.86      0.63       897\n",
      "           4       0.59      0.33      0.42       892\n",
      "           5       0.56      0.41      0.48       862\n",
      "           6       0.64      0.36      0.46       903\n",
      "           7       0.59      0.76      0.66       889\n",
      "           8       0.56      0.79      0.65       892\n",
      "           9       0.52      0.40      0.45       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 26500, Loss: 0.7068564891815186, F1: 0.5402955811899608, Accuracy: 0.49900213337003646, Time Elapsed: 45194.45130228996 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.58      0.69      0.63       885\n",
      "           2       0.60      0.60      0.60       877\n",
      "           3       0.60      0.50      0.54       897\n",
      "           4       0.51      0.77      0.61       892\n",
      "           5       0.57      0.37      0.45       862\n",
      "           6       0.63      0.61      0.62       903\n",
      "           7       0.62      0.34      0.44       889\n",
      "           8       0.51      0.84      0.63       892\n",
      "           9       0.57      0.28      0.38       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.55     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 26600, Loss: 0.5480417013168335, F1: 0.5454673276545706, Accuracy: 0.5040946941022642, Time Elapsed: 45210.761367082596 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.66       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.65      0.12      0.21       877\n",
      "           3       0.59      0.60      0.60       897\n",
      "           4       0.58      0.25      0.35       892\n",
      "           5       0.54      0.37      0.44       862\n",
      "           6       0.67      0.19      0.29       903\n",
      "           7       0.63      0.37      0.47       889\n",
      "           8       0.60      0.48      0.53       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.61      0.48      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.42      0.43     14531\n",
      "weighted avg       0.49      0.48      0.45     14531\n",
      "\n",
      "Epoch 2, Step 26700, Loss: 1.175136685371399, F1: 0.4315486353473403, Accuracy: 0.47952652948867935, Time Elapsed: 46119.121415138245 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.63      0.12      0.20       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.48      0.79      0.60       892\n",
      "           5       0.48      0.81      0.60       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.62      0.06      0.11       889\n",
      "           8       0.60      0.52      0.56       892\n",
      "           9       0.58      0.36      0.45       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.51     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 26800, Loss: 0.4080737233161926, F1: 0.5105199947859469, Accuracy: 0.49996559080586334, Time Elapsed: 46138.844383955 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.58      0.77      0.66       897\n",
      "           4       0.46      0.81      0.58       892\n",
      "           5       0.53      0.68      0.59       862\n",
      "           6       0.62      0.44      0.51       903\n",
      "           7       0.56      0.02      0.03       889\n",
      "           8       0.60      0.59      0.59       892\n",
      "           9       0.60      0.33      0.42       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 26900, Loss: 1.302628755569458, F1: 0.5257678539568965, Accuracy: 0.5039570573257174, Time Elapsed: 46159.10675930977 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.61      0.06      0.12       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.59      0.45      0.51       897\n",
      "           4       0.49      0.72      0.59       892\n",
      "           5       0.50      0.59      0.54       862\n",
      "           6       0.63      0.47      0.54       903\n",
      "           7       0.60      0.33      0.42       889\n",
      "           8       0.52      0.74      0.61       892\n",
      "           9       0.57      0.02      0.04       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.48      0.46     14531\n",
      "weighted avg       0.50      0.48      0.45     14531\n",
      "\n",
      "Epoch 2, Step 27000, Loss: 1.0954886674880981, F1: 0.4610212730222227, Accuracy: 0.4788383456059459, Time Elapsed: 46176.37220096588 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.58      0.52      0.55       877\n",
      "           3       0.60      0.59      0.60       897\n",
      "           4       0.51      0.77      0.61       892\n",
      "           5       0.54      0.16      0.25       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.56      0.71      0.63       892\n",
      "           9       0.50      0.79      0.61       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 27100, Loss: 0.18629449605941772, F1: 0.5678225423287062, Accuracy: 0.5174454614272934, Time Elapsed: 46193.16545724869 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.63       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.57      0.76      0.65       877\n",
      "           3       0.59      0.73      0.65       897\n",
      "           4       0.59      0.20      0.30       892\n",
      "           5       0.59      0.30      0.40       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.58      0.88      0.70       889\n",
      "           8       0.61      0.64      0.63       892\n",
      "           9       0.45      0.78      0.57       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 27200, Loss: 0.8861851096153259, F1: 0.565304754847722, Accuracy: 0.5184777372513936, Time Elapsed: 46209.50924324989 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.60      0.02      0.03       885\n",
      "           2       0.60      0.64      0.62       877\n",
      "           3       0.60      0.67      0.63       897\n",
      "           4       0.60      0.31      0.41       892\n",
      "           5       0.57      0.32      0.41       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.60      0.66      0.62       892\n",
      "           9       0.58      0.53      0.55       876\n",
      "          10       0.40      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.52     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 2, Step 27300, Loss: 0.8293432593345642, F1: 0.5214499902534349, Accuracy: 0.5102195306585919, Time Elapsed: 46226.059114933014 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.87      0.70       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.61      0.45      0.52       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.49      0.84      0.62       892\n",
      "           5       0.43      0.81      0.56       862\n",
      "           6       0.62      0.67      0.65       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.57      0.62      0.59       892\n",
      "           9       0.57      0.56      0.57       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 27400, Loss: 1.206881046295166, F1: 0.5868461124322238, Accuracy: 0.518753010804487, Time Elapsed: 46243.29953408241 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.39      0.48       912\n",
      "           1       0.53      0.05      0.09       885\n",
      "           2       0.61      0.45      0.52       877\n",
      "           3       0.47      0.88      0.61       897\n",
      "           4       0.52      0.50      0.51       892\n",
      "           5       0.52      0.67      0.59       862\n",
      "           6       0.62      0.24      0.35       903\n",
      "           7       0.58      0.75      0.65       889\n",
      "           8       0.53      0.68      0.60       892\n",
      "           9       0.60      0.17      0.27       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.55      0.48      0.46     14531\n",
      "weighted avg       0.49      0.47      0.45     14531\n",
      "\n",
      "Epoch 2, Step 27500, Loss: 0.446243017911911, F1: 0.4635635695720213, Accuracy: 0.472300598719978, Time Elapsed: 46262.283089876175 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.50       912\n",
      "           1       0.57      0.92      0.71       885\n",
      "           2       0.63      0.34      0.44       877\n",
      "           3       0.58      0.46      0.51       897\n",
      "           4       0.52      0.75      0.61       892\n",
      "           5       0.55      0.61      0.58       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.62      0.61      0.62       889\n",
      "           8       0.53      0.83      0.65       892\n",
      "           9       0.57      0.22      0.32       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.54     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 27600, Loss: 0.6803175210952759, F1: 0.5406558387790049, Accuracy: 0.5037506021608974, Time Elapsed: 46279.22706604004 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.56      0.71      0.63       877\n",
      "           3       0.61      0.46      0.52       897\n",
      "           4       0.56      0.49      0.52       892\n",
      "           5       0.58      0.49      0.53       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.60      0.63      0.62       889\n",
      "           8       0.62      0.34      0.44       892\n",
      "           9       0.45      0.72      0.55       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 2, Step 27700, Loss: 1.2684158086776733, F1: 0.5689301130819046, Accuracy: 0.5136604500722594, Time Elapsed: 46296.04406404495 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.54      0.98      0.70       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.58      0.13      0.22       897\n",
      "           4       0.59      0.34      0.43       892\n",
      "           5       0.61      0.11      0.18       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.61      0.21      0.31       892\n",
      "           9       0.52      0.62      0.57       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.50     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 2, Step 27800, Loss: 0.9774202108383179, F1: 0.4977024988527867, Accuracy: 0.4963870346156493, Time Elapsed: 46314.10550713539 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.47      0.54       912\n",
      "           1       0.59      0.90      0.72       885\n",
      "           2       0.57      0.75      0.65       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.50      0.69      0.58       892\n",
      "           5       0.54      0.08      0.13       862\n",
      "           6       0.62      0.73      0.67       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.58      0.63      0.61       892\n",
      "           9       0.59      0.26      0.37       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.52      0.49     14531\n",
      "weighted avg       0.47      0.50      0.46     14531\n",
      "\n",
      "Epoch 2, Step 27900, Loss: 0.6921783685684204, F1: 0.4863229527951567, Accuracy: 0.49652467139219597, Time Elapsed: 46329.99759697914 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.61      0.90      0.73       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.60      0.71      0.65       897\n",
      "           4       0.55      0.61      0.58       892\n",
      "           5       0.62      0.10      0.16       862\n",
      "           6       0.64      0.28      0.39       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.61      0.43      0.50       892\n",
      "           9       0.43      0.86      0.57       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 28000, Loss: 0.39521440863609314, F1: 0.5335308778789929, Accuracy: 0.5063657009152845, Time Elapsed: 46346.876214027405 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.49      0.02      0.05       885\n",
      "           2       0.64      0.22      0.33       877\n",
      "           3       0.59      0.29      0.39       897\n",
      "           4       0.59      0.20      0.30       892\n",
      "           5       0.58      0.55      0.56       862\n",
      "           6       0.64      0.29      0.40       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.62      0.21      0.31       892\n",
      "           9       0.61      0.41      0.49       876\n",
      "          10       0.39      0.61      0.48      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.41      0.43     14531\n",
      "weighted avg       0.52      0.47      0.44     14531\n",
      "\n",
      "Epoch 2, Step 28100, Loss: 0.8792837262153625, F1: 0.42741153298496853, Accuracy: 0.4747092423095451, Time Elapsed: 46366.573462963104 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       912\n",
      "           1       1.00      0.00      0.01       885\n",
      "           2       0.59      0.67      0.63       877\n",
      "           3       0.57      0.78      0.66       897\n",
      "           4       0.56      0.12      0.20       892\n",
      "           5       0.60      0.34      0.44       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.61      0.42      0.50       892\n",
      "           9       0.44      0.87      0.58       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.56      0.50     14531\n",
      "weighted avg       0.53      0.50      0.46     14531\n",
      "\n",
      "Epoch 2, Step 28200, Loss: 0.2929173707962036, F1: 0.4956854563115076, Accuracy: 0.49590530589773585, Time Elapsed: 46382.62393403053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.72      0.06      0.11       877\n",
      "           3       0.42      0.93      0.58       897\n",
      "           4       0.55      0.52      0.54       892\n",
      "           5       0.57      0.43      0.49       862\n",
      "           6       0.62      0.59      0.60       903\n",
      "           7       0.62      0.51      0.56       889\n",
      "           8       0.59      0.36      0.45       892\n",
      "           9       0.57      0.63      0.60       876\n",
      "          10       0.40      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.56      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 28300, Loss: 1.0981382131576538, F1: 0.5217630539790941, Accuracy: 0.4987956782052164, Time Elapsed: 46397.42970705032 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.70       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.63      0.43      0.51       877\n",
      "           3       0.59      0.71      0.65       897\n",
      "           4       0.55      0.43      0.48       892\n",
      "           5       0.56      0.54      0.55       862\n",
      "           6       0.62      0.73      0.67       903\n",
      "           7       0.57      0.86      0.69       889\n",
      "           8       0.56      0.65      0.60       892\n",
      "           9       0.47      0.86      0.60       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 2, Step 28400, Loss: 1.1247621774673462, F1: 0.5871100644145774, Accuracy: 0.5231573876539811, Time Elapsed: 46413.40183925629 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.70       912\n",
      "           1       0.60      0.89      0.71       885\n",
      "           2       0.60      0.02      0.05       877\n",
      "           3       0.60      0.39      0.47       897\n",
      "           4       0.46      0.90      0.61       892\n",
      "           5       0.58      0.27      0.37       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.59      0.76      0.66       889\n",
      "           8       0.59      0.51      0.54       892\n",
      "           9       0.59      0.60      0.60       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.56      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 2, Step 28500, Loss: 0.3124723732471466, F1: 0.5211956621671215, Accuracy: 0.5028559631133439, Time Elapsed: 46428.29996204376 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.57      0.93      0.70       885\n",
      "           2       0.60      0.61      0.60       877\n",
      "           3       0.57      0.80      0.67       897\n",
      "           4       0.56      0.49      0.52       892\n",
      "           5       0.58      0.49      0.53       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.49      0.88      0.63       892\n",
      "           9       0.48      0.81      0.60       876\n",
      "          10       0.39      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.69      0.60     14531\n",
      "weighted avg       0.50      0.53      0.48     14531\n",
      "\n",
      "Epoch 2, Step 28600, Loss: 3.0076045989990234, F1: 0.5970117687685043, Accuracy: 0.5267359438441952, Time Elapsed: 46443.09011721611 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.56      0.27      0.36       892\n",
      "           5       0.54      0.68      0.60       862\n",
      "           6       0.63      0.47      0.54       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.53      0.81      0.64       892\n",
      "           9       0.47      0.74      0.58       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 2, Step 28700, Loss: 1.2434978485107422, F1: 0.5749018843090682, Accuracy: 0.5183401004748469, Time Elapsed: 46458.59612607956 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.93      0.73       912\n",
      "           1       0.65      0.29      0.40       885\n",
      "           2       0.54      0.75      0.63       877\n",
      "           3       0.60      0.69      0.64       897\n",
      "           4       0.59      0.30      0.40       892\n",
      "           5       0.55      0.71      0.62       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.60      0.28      0.38       892\n",
      "           9       0.64      0.01      0.02       876\n",
      "          10       0.40      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.51     14531\n",
      "weighted avg       0.52      0.51      0.48     14531\n",
      "\n",
      "Epoch 2, Step 28800, Loss: 1.559671401977539, F1: 0.5072556612661079, Accuracy: 0.5052646067029111, Time Elapsed: 46474.40365791321 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.63      0.27      0.38       897\n",
      "           4       0.61      0.19      0.29       892\n",
      "           5       0.58      0.39      0.47       862\n",
      "           6       0.61      0.68      0.64       903\n",
      "           7       0.60      0.61      0.61       889\n",
      "           8       0.60      0.30      0.40       892\n",
      "           9       0.59      0.41      0.48       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 2, Step 28900, Loss: 1.670086145401001, F1: 0.5151563576591157, Accuracy: 0.5001720459706833, Time Elapsed: 46489.084210157394 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.35      0.45       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.59      0.60      0.60       897\n",
      "           4       0.58      0.48      0.52       892\n",
      "           5       0.57      0.34      0.42       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.58      0.69      0.63       889\n",
      "           8       0.55      0.58      0.57       892\n",
      "           9       0.57      0.33      0.42       876\n",
      "          10       0.38      0.43      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 2, Step 29000, Loss: 0.7842233180999756, F1: 0.5398282846245568, Accuracy: 0.5014107769596036, Time Elapsed: 46505.0084400177 seconds\n",
      "Epoch 2 completed. Time: 46505.53460907936\n",
      "Logger {'time': {0: 0.007950067520141602, 100: 15.032687187194824, 200: 333.05727219581604, 300: 350.3706841468811, 400: 365.80769300460815, 500: 680.3622090816498, 600: 695.9776031970978, 700: 711.5307550430298, 800: 1400.5814809799194, 900: 1417.9003021717072, 1000: 1433.870812177658, 1100: 1628.292358160019, 1200: 1645.04230093956, 1300: 1710.5825381278992, 1400: 1726.1577961444855, 1500: 1742.4100890159607, 1600: 2686.565222263336, 1700: 2704.323049068451, 1800: 2720.395408153534, 1900: 3716.143319129944, 2000: 3731.947513103485, 2100: 3747.4568560123444, 2200: 4702.293127298355, 2300: 4718.800239086151, 2400: 4737.779019117355, 2500: 5722.997336149216, 2600: 5739.934084177017, 2700: 5756.049424171448, 2800: 6813.951940059662, 2900: 6832.269334077835, 3000: 6852.020951032639, 3100: 7851.991570949554, 3200: 7872.691563129425, 3300: 8906.396472215652, 3400: 8937.859162092209, 3500: 9961.246692180634, 3600: 9977.468689203262, 3700: 10954.80652999878, 3800: 10971.51385807991, 3900: 10986.85212802887, 4000: 11937.745533943176, 4100: 11956.487001180649, 4200: 11972.230837106705, 4300: 11986.89844918251, 4400: 12935.63119506836, 4500: 12952.532216072083, 4600: 12968.114754199982, 4700: 12984.691914081573, 4800: 13001.809792995453, 4900: 13016.415282964706, 5000: 13030.946068048477, 5100: 13045.443597078323, 5200: 13060.191642045975, 5300: 13075.16204214096, 5400: 13090.302630186081, 5500: 13105.158041238785, 5600: 13119.777465105057, 5700: 13135.23532485962, 5800: 13150.988636255264, 5900: 13166.254445075989, 6000: 13180.977896928787, 6100: 13196.585244894028, 6200: 13211.843524217606, 6300: 13226.004753112793, 6400: 13240.446679115295, 6500: 13254.643133878708, 6600: 13270.398064136505, 6700: 13284.544706106186, 6800: 13298.842875242233, 6900: 13313.036072015762, 7000: 13327.889788866043, 7100: 13342.121203899384, 7200: 13356.827291250229, 7300: 13371.094123125076, 7400: 13386.323730945587, 7500: 13400.867360115051, 7600: 13415.295940160751, 7700: 13430.030875205994, 7800: 13444.365220069885, 7900: 13459.450416088104, 8000: 13473.767658948898, 8100: 13488.974489212036, 8200: 13504.087761163712, 8300: 13518.544666051865, 8400: 13533.177845954895, 8500: 13548.160022974014, 8600: 13562.602842092514, 8700: 13577.53750705719, 8800: 13592.971548080444, 8900: 13607.705188035965, 9000: 13623.197653055191, 9100: 13638.058703184128, 9200: 13652.439534187317, 9300: 13667.209228038788, 9400: 13683.738208055496, 9500: 13698.713675022125, 9600: 13713.010209083557, 9700: 13728.674706935883, 9800: 13744.496829986572, 9900: 13760.144410133362, 10000: 13774.449657201767, 10100: 13789.463083028793, 10200: 13804.735465049744, 10300: 13820.402966976166, 10400: 13834.58638215065, 10500: 14822.197792053223, 10600: 14839.562256097794, 10700: 15811.275840997696, 10800: 15841.267627000809, 10900: 15861.610787153244, 11000: 15883.979615926743, 11100: 15904.555271863937, 11200: 16222.878849983215, 11300: 16238.596217155457, 11400: 16254.391459226608, 11500: 16569.838641166687, 11600: 16585.707850933075, 11700: 16602.43789100647, 11800: 16917.45203614235, 11900: 16932.688544988632, 12000: 16947.35277915001, 12100: 17863.785207033157, 12200: 17882.16246700287, 12300: 17899.634124040604, 12400: 18912.862666130066, 12500: 18931.99510908127, 12600: 18947.751897096634, 12700: 18962.356362104416, 12800: 19902.239695072174, 12900: 19922.70153594017, 13000: 20902.964391231537, 13100: 20925.54917907715, 13200: 21862.470738887787, 13300: 21881.70550918579, 13400: 21899.46527004242, 13500: 22943.377948999405, 13600: 22960.12895011902, 13700: 23986.41721701622, 13800: 24004.46692299843, 13900: 24020.400334119797, 14000: 25083.466532230377, 14100: 25106.866452932358, 14200: 25126.271499156952, 14300: 25145.614154100418, 14400: 26228.31441307068, 14500: 26249.788416147232, 14600: 26358.18062210083, 14700: 26374.165671110153, 14800: 26389.88772201538, 14900: 27362.46781015396, 15000: 27380.72762107849, 15100: 27396.797950983047, 15200: 28336.434459209442, 15300: 28354.77052807808, 15400: 29318.027906179428, 15500: 29335.221003055573, 15600: 29352.173169136047, 15700: 29369.438712120056, 15800: 30459.899359941483, 15900: 30477.194384098053, 16000: 31517.242343902588, 16100: 31533.954924106598, 16200: 31550.111054182053, 16300: 31566.880582094193, 16400: 31583.85107398033, 16500: 31600.550980091095, 16600: 31616.88621211052, 16700: 31632.41516327858, 16800: 31647.334332227707, 16900: 31663.064393997192, 17000: 31677.984050273895, 17100: 32600.616334199905, 17200: 32618.741400003433, 17300: 32634.383196115494, 17400: 33667.71125292778, 17500: 33686.82123327255, 17600: 33706.20239901543, 17700: 33724.42707300186, 17800: 33739.54184603691, 17900: 34682.734245061874, 18000: 34699.09123110771, 18100: 34715.62961626053, 18200: 35651.01370716095, 18300: 35668.699451208115, 18400: 36673.86657309532, 18500: 36691.87362623215, 18600: 36709.743440151215, 18700: 37683.28000712395, 18800: 37702.020401239395, 18900: 37719.078506946564, 19000: 37735.54912209511, 19100: 38051.294044971466, 19200: 38067.16186714172, 19300: 38380.67150592804, 19400: 38398.57001495361, 19500: 38416.22815108299, 19600: 39332.55918908119, 19700: 39349.82202124596, 19800: 39366.70337200165, 19900: 40297.09227013588, 20000: 40313.321711063385, 20100: 41243.81368494034, 20200: 41260.089138269424, 20300: 41276.672193050385, 20400: 42213.14171695709, 20500: 42231.42638516426, 20600: 43300.07673215866, 20700: 43317.30657887459, 20800: 43334.57293319702, 20900: 43350.40821003914, 21000: 43366.875349998474, 21100: 43382.67470097542, 21200: 43397.43408727646, 21300: 43412.31145119667, 21400: 43428.164506196976, 21500: 43443.25351715088, 21600: 43458.51281094551, 21700: 43473.74568295479, 21800: 43489.07289123535, 21900: 43504.46310710907, 22000: 43519.608209848404, 22100: 43535.348438978195, 22200: 43550.48176527023, 22300: 43565.238064050674, 22400: 43582.16790294647, 22500: 43597.12172007561, 22600: 43612.6898329258, 22700: 43627.6941781044, 22800: 43643.23927116394, 22900: 43658.65001702309, 23000: 43674.44356417656, 23100: 43690.50485301018, 23200: 43705.186665058136, 23300: 43720.64486813545, 23400: 43736.45823097229, 23500: 43751.11172103882, 23600: 43766.56359124184, 23700: 43781.29158401489, 23800: 43797.678458213806, 23900: 43813.10237598419, 24000: 43827.738356113434, 24100: 43843.33991909027, 24200: 43858.79988908768, 24300: 43873.64435195923, 24400: 43889.334568977356, 24500: 43904.33522820473, 24600: 43920.167937994, 24700: 43934.85709309578, 24800: 43950.60218501091, 24900: 43965.78590321541, 25000: 43981.07697105408, 25100: 43996.20539307594, 25200: 44011.68538403511, 25300: 44026.43653297424, 25400: 44042.09186410904, 25500: 44056.949447155, 25600: 44072.68547415733, 25700: 44088.41459989548, 25800: 44103.53653407097, 25900: 44118.621467113495, 26000: 44133.94519114494, 26100: 44149.13279700279, 26200: 44164.549721241, 26300: 44180.32089018822, 26400: 44195.714786052704, 26500: 45177.60190200806, 26600: 45195.01675415039, 26700: 45211.28487920761, 26800: 46120.148965120316, 26900: 46139.54974627495, 27000: 46159.70974421501, 27100: 46177.0362701416, 27200: 46193.75512218475, 27300: 46210.09878611565, 27400: 46226.721744060516, 27500: 46243.880907058716, 27600: 46263.00564813614, 27700: 46279.79716706276, 27800: 46296.73539710045, 27900: 46314.66510605812, 28000: 46330.53393626213, 28100: 46347.43326210976, 28200: 46367.181425094604, 28300: 46383.18152308464, 28400: 46397.9369468689, 28500: 46414.00502824783, 28600: 46428.79852414131, 28700: 46443.619254112244, 28800: 46459.192021131516, 28900: 46474.98540019989, 29000: 46489.57349395752}, 'loss': {0: 1.02662992477417, 100: 3.1736302375793457, 200: 0.8100726008415222, 300: 0.9592094421386719, 400: 0.5077714920043945, 500: 2.5837082862854004, 600: 1.732617974281311, 700: 0.4581232964992523, 800: 1.8830678462982178, 900: 1.1026453971862793, 1000: 2.2199361324310303, 1100: 0.4997534453868866, 1200: 0.43592754006385803, 1300: 1.2423738241195679, 1400: 0.47224992513656616, 1500: 0.837173342704773, 1600: 1.99886155128479, 1700: 1.6293941736221313, 1800: 0.3250542879104614, 1900: 1.0506837368011475, 2000: 1.9628316164016724, 2100: 0.1992587447166443, 2200: 3.047938585281372, 2300: 0.9690263867378235, 2400: 0.3642800748348236, 2500: 0.9831814765930176, 2600: 0.719196081161499, 2700: 3.493514060974121, 2800: 0.2395302951335907, 2900: 1.3495428562164307, 3000: 0.6791083812713623, 3100: 1.0943806171417236, 3200: 0.6510897874832153, 3300: 0.7027990818023682, 3400: 0.6067671775817871, 3500: 0.5310176014900208, 3600: 1.548814296722412, 3700: 0.8607654571533203, 3800: 1.5187904834747314, 3900: 0.38801446557044983, 4000: 0.7152345776557922, 4100: 1.7548611164093018, 4200: 1.0987321138381958, 4300: 1.6619468927383423, 4400: 1.1741794347763062, 4500: 1.3351383209228516, 4600: 1.9879069328308105, 4700: 1.8270081281661987, 4800: 0.4404740333557129, 4900: 1.2619454860687256, 5000: 1.735445499420166, 5100: 0.17246684432029724, 5200: 1.3229261636734009, 5300: 0.8322697281837463, 5400: 0.5321848392486572, 5500: 0.3795253336429596, 5600: 1.203205943107605, 5700: 0.1957629919052124, 5800: 1.0905712842941284, 5900: 1.0985355377197266, 6000: 0.6946715116500854, 6100: 0.6053436398506165, 6200: 2.06076717376709, 6300: 0.7280096411705017, 6400: 0.8036624789237976, 6500: 0.6190985441207886, 6600: 0.7189517021179199, 6700: 6.376176357269287, 6800: 0.991828978061676, 6900: 0.9754921793937683, 7000: 0.8609766960144043, 7100: 0.9792210459709167, 7200: 0.6319195032119751, 7300: 4.698112964630127, 7400: 0.8333465456962585, 7500: 1.0570099353790283, 7600: 0.6893099546432495, 7700: 0.18096625804901123, 7800: 0.9014942646026611, 7900: 0.5475212931632996, 8000: 0.584839940071106, 8100: 1.6885056495666504, 8200: 0.355469286441803, 8300: 0.9995742440223694, 8400: 0.30839020013809204, 8500: 1.3471421003341675, 8600: 1.6884796619415283, 8700: 0.8278560638427734, 8800: 2.0401296615600586, 8900: 1.3121962547302246, 9000: 0.24283573031425476, 9100: 0.6897115111351013, 9200: 0.26655590534210205, 9300: 1.4673515558242798, 9400: 0.8120174407958984, 9500: 0.21427936851978302, 9600: 1.1877329349517822, 9700: 0.24384333193302155, 9800: 0.4859638512134552, 9900: 1.4000706672668457, 10000: 2.1385111808776855, 10100: 0.46775543689727783, 10200: 2.745028257369995, 10300: 1.1569106578826904, 10400: 1.2414283752441406, 10500: 0.7181145548820496, 10600: 1.0187879800796509, 10700: 1.705399513244629, 10800: 5.337753772735596, 10900: 0.4027620851993561, 11000: 1.4767640829086304, 11100: 1.2066140174865723, 11200: 1.6091675758361816, 11300: 0.16741277277469635, 11400: 1.232555866241455, 11500: 0.8847300410270691, 11600: 0.7315430045127869, 11700: 3.70851469039917, 11800: 1.6328386068344116, 11900: 0.5674907565116882, 12000: 0.7874510288238525, 12100: 0.5989893078804016, 12200: 0.9777748584747314, 12300: 0.38865187764167786, 12400: 1.172459363937378, 12500: 1.750559687614441, 12600: 1.4193828105926514, 12700: 1.6895060539245605, 12800: 3.3466899394989014, 12900: 0.9876537322998047, 13000: 1.5022363662719727, 13100: 1.478442668914795, 13200: 0.3990139663219452, 13300: 0.23146474361419678, 13400: 0.9448168873786926, 13500: 2.4934206008911133, 13600: 0.7715439200401306, 13700: 1.729149341583252, 13800: 0.29530611634254456, 13900: 0.594210684299469, 14000: 0.3676842451095581, 14100: 1.2349634170532227, 14200: 0.5014247298240662, 14300: 2.0124592781066895, 14400: 4.620355606079102, 14500: 1.225121021270752, 14600: 4.008049488067627, 14700: 1.4009418487548828, 14800: 1.001702070236206, 14900: 0.7417786717414856, 15000: 0.9017388820648193, 15100: 0.7795913815498352, 15200: 0.8742626309394836, 15300: 1.4727563858032227, 15400: 0.7840121388435364, 15500: 1.3793389797210693, 15600: 0.607339084148407, 15700: 1.2730400562286377, 15800: 0.9090813398361206, 15900: 0.8913671970367432, 16000: 0.5199030041694641, 16100: 2.029370069503784, 16200: 1.959826946258545, 16300: 0.4023926556110382, 16400: 0.31449753046035767, 16500: 0.6573219895362854, 16600: 1.4146208763122559, 16700: 0.6070358157157898, 16800: 0.37382131814956665, 16900: 0.8702138662338257, 17000: 0.25325942039489746, 17100: 0.8049993515014648, 17200: 2.9498510360717773, 17300: 0.5204702019691467, 17400: 0.9053962826728821, 17500: 0.703904390335083, 17600: 0.6076278686523438, 17700: 1.1053569316864014, 17800: 1.3234977722167969, 17900: 1.28096342086792, 18000: 2.2034661769866943, 18100: 0.7193950414657593, 18200: 1.2894806861877441, 18300: 2.277346134185791, 18400: 1.0363078117370605, 18500: 1.0280210971832275, 18600: 0.8663561940193176, 18700: 0.7708379030227661, 18800: 5.486751079559326, 18900: 0.4858919382095337, 19000: 0.2621467709541321, 19100: 0.7506136298179626, 19200: 0.3481728732585907, 19300: 1.081466555595398, 19400: 0.3441566526889801, 19500: 2.8975307941436768, 19600: 1.0741825103759766, 19700: 0.8931548595428467, 19800: 0.4840651750564575, 19900: 0.5325339436531067, 20000: 0.20865927636623383, 20100: 0.7149640321731567, 20200: 0.9098084568977356, 20300: 1.1105968952178955, 20400: 1.0444982051849365, 20500: 1.4980573654174805, 20600: 0.7772293090820312, 20700: 3.038477659225464, 20800: 0.5037722587585449, 20900: 1.19021475315094, 21000: 0.4315224289894104, 21100: 1.6502702236175537, 21200: 1.6056725978851318, 21300: 0.8250985145568848, 21400: 1.2027132511138916, 21500: 1.2919994592666626, 21600: 1.5977520942687988, 21700: 1.1074929237365723, 21800: 0.9084478616714478, 21900: 0.13517585396766663, 22000: 0.7287719249725342, 22100: 0.9755857586860657, 22200: 0.709278404712677, 22300: 0.76930832862854, 22400: 0.8518969416618347, 22500: 1.4002718925476074, 22600: 0.2544505000114441, 22700: 0.7726283669471741, 22800: 0.3853302001953125, 22900: 0.17107446491718292, 23000: 0.7898887395858765, 23100: 0.49063751101493835, 23200: 1.408890724182129, 23300: 0.40427327156066895, 23400: 0.6386728286743164, 23500: 0.7375141978263855, 23600: 3.3461389541625977, 23700: 0.5265831351280212, 23800: 0.43609288334846497, 23900: 0.7937500476837158, 24000: 0.2351541817188263, 24100: 0.682172954082489, 24200: 1.278986930847168, 24300: 0.7850884795188904, 24400: 3.601393222808838, 24500: 0.9278960824012756, 24600: 3.2150087356567383, 24700: 2.9584057331085205, 24800: 1.038134217262268, 24900: 0.13626006245613098, 25000: 1.5487511157989502, 25100: 0.5183191299438477, 25200: 0.9329777956008911, 25300: 0.35515618324279785, 25400: 0.7655463814735413, 25500: 0.8982657194137573, 25600: 0.9853630065917969, 25700: 0.37781450152397156, 25800: 1.0758228302001953, 25900: 0.6790552735328674, 26000: 0.38447970151901245, 26100: 3.6746861934661865, 26200: 1.6781294345855713, 26300: 0.39206522703170776, 26400: 1.764375925064087, 26500: 0.7068564891815186, 26600: 0.5480417013168335, 26700: 1.175136685371399, 26800: 0.4080737233161926, 26900: 1.302628755569458, 27000: 1.0954886674880981, 27100: 0.18629449605941772, 27200: 0.8861851096153259, 27300: 0.8293432593345642, 27400: 1.206881046295166, 27500: 0.446243017911911, 27600: 0.6803175210952759, 27700: 1.2684158086776733, 27800: 0.9774202108383179, 27900: 0.6921783685684204, 28000: 0.39521440863609314, 28100: 0.8792837262153625, 28200: 0.2929173707962036, 28300: 1.0981382131576538, 28400: 1.1247621774673462, 28500: 0.3124723732471466, 28600: 3.0076045989990234, 28700: 1.2434978485107422, 28800: 1.559671401977539, 28900: 1.670086145401001, 29000: 0.7842233180999756}, 'F1': {0: 0.5928376635183397, 100: 0.5265751095482181, 200: 0.5145899766642761, 300: 0.5779706028550169, 400: 0.554238703802342, 500: 0.5615089617939064, 600: 0.6083548299127453, 700: 0.5942834175828831, 800: 0.5564161012848794, 900: 0.46404305718283284, 1000: 0.5110156039029229, 1100: 0.4927781121135286, 1200: 0.5214910520146265, 1300: 0.5491034342262696, 1400: 0.490176481437992, 1500: 0.5336559182251466, 1600: 0.5269790369746296, 1700: 0.5477476117362866, 1800: 0.5229603614573946, 1900: 0.5266835089849452, 2000: 0.5827578682779692, 2100: 0.46755422844655375, 2200: 0.5857429764112898, 2300: 0.5504510732587111, 2400: 0.5794505988770441, 2500: 0.5038747967977723, 2600: 0.5800719742380823, 2700: 0.5281291469985058, 2800: 0.4717864360567632, 2900: 0.5696922055160069, 3000: 0.5959927827697258, 3100: 0.5576926257883611, 3200: 0.5423291136578737, 3300: 0.5712403094893729, 3400: 0.36972320999536074, 3500: 0.5304890749739187, 3600: 0.4965612493021204, 3700: 0.4734260752127863, 3800: 0.5730637704639676, 3900: 0.5867032997402905, 4000: 0.547440210725837, 4100: 0.4311300396590735, 4200: 0.5088038941143467, 4300: 0.5681451318264475, 4400: 0.4859076996065189, 4500: 0.5047169915338012, 4600: 0.5650755232544357, 4700: 0.5199554317077704, 4800: 0.5134049987902075, 4900: 0.4986338760125083, 5000: 0.5519393161717149, 5100: 0.5780765095983015, 5200: 0.5515416117395634, 5300: 0.589153989663569, 5400: 0.5810864956552547, 5500: 0.49297185993822956, 5600: 0.5745581482062514, 5700: 0.5552651779684294, 5800: 0.5600256396601875, 5900: 0.45396238610928846, 6000: 0.5685746251452299, 6100: 0.4609713377647568, 6200: 0.5314146111805217, 6300: 0.610437932243541, 6400: 0.5225835544258435, 6500: 0.5061340037909443, 6600: 0.5536353136012425, 6700: 0.5214053281147943, 6800: 0.5447988458394182, 6900: 0.5658202104405163, 7000: 0.5835226031657529, 7100: 0.5933879079686117, 7200: 0.5558146152753909, 7300: 0.5891777326176272, 7400: 0.4953132757338467, 7500: 0.47060314242557016, 7600: 0.4844076953043972, 7700: 0.4870076885640126, 7800: 0.5453435812993138, 7900: 0.5652055924539982, 8000: 0.5781065515740695, 8100: 0.5473131530659314, 8200: 0.4968868597129745, 8300: 0.5382608875968349, 8400: 0.4860136776716006, 8500: 0.4973187714133689, 8600: 0.5282252652760385, 8700: 0.594869203393393, 8800: 0.5823447408241221, 8900: 0.5605527200794168, 9000: 0.5201942237473575, 9100: 0.5039103659288137, 9200: 0.5708008711209689, 9300: 0.554924443509845, 9400: 0.4371536398579496, 9500: 0.49595022532947514, 9600: 0.5763644708148971, 9700: 0.5056047057096691, 9800: 0.5016234148236832, 9900: 0.4907886219539251, 10000: 0.5418270345079196, 10100: 0.5076622941199194, 10200: 0.573393331197623, 10300: 0.5883208554172311, 10400: 0.5370106732149084, 10500: 0.5178063851960796, 10600: 0.5976926188858246, 10700: 0.5438579702590988, 10800: 0.5357268367195296, 10900: 0.5757945670159862, 11000: 0.4951292582722857, 11100: 0.5676436126190235, 11200: 0.5743538942841881, 11300: 0.5802558353835954, 11400: 0.5697175008339367, 11500: 0.5689816262318955, 11600: 0.5415137979970411, 11700: 0.4861268340954183, 11800: 0.6109430584490705, 11900: 0.5394404542286955, 12000: 0.4993223991808576, 12100: 0.5932818228719152, 12200: 0.5560121713168727, 12300: 0.5340885366689915, 12400: 0.5439970459800111, 12500: 0.5565273895533207, 12600: 0.5396006933409662, 12700: 0.5623657167867747, 12800: 0.47241562940327614, 12900: 0.5288362001659359, 13000: 0.482426261999261, 13100: 0.5783062310105752, 13200: 0.6028802463138138, 13300: 0.4974633318203578, 13400: 0.5197909514071583, 13500: 0.5297332887141146, 13600: 0.408005638242221, 13700: 0.47608451148044806, 13800: 0.4875192036944256, 13900: 0.5149640453035715, 14000: 0.5015495430640313, 14100: 0.5944358314574143, 14200: 0.5538345886938736, 14300: 0.5502673946016, 14400: 0.5402797452475215, 14500: 0.48163126070913714, 14600: 0.564057881942291, 14700: 0.5609124178905073, 14800: 0.5852901939232029, 14900: 0.5597972032055677, 15000: 0.4196425629621557, 15100: 0.48339595261816637, 15200: 0.5879090943742002, 15300: 0.47564914314893336, 15400: 0.4988813094314135, 15500: 0.5037023146912126, 15600: 0.5321683998201819, 15700: 0.5090814350764361, 15800: 0.5833087547777408, 15900: 0.56379337331093, 16000: 0.6009893635208114, 16100: 0.48190215387382307, 16200: 0.5672912586991622, 16300: 0.5574686531087933, 16400: 0.500963101263347, 16500: 0.44151852176319917, 16600: 0.5796814777627977, 16700: 0.5448812532250903, 16800: 0.4414539899866878, 16900: 0.5034219746905129, 17000: 0.5301357385327417, 17100: 0.5267978342447509, 17200: 0.5209704994246943, 17300: 0.5711924120433672, 17400: 0.46602274630709145, 17500: 0.6055152667144174, 17600: 0.5412172648445135, 17700: 0.5530940199367211, 17800: 0.5888183560185244, 17900: 0.5716248480631837, 18000: 0.5047963077556851, 18100: 0.5067002756724399, 18200: 0.561655289043273, 18300: 0.5259358630786185, 18400: 0.5202859478742184, 18500: 0.5398067282562242, 18600: 0.5394979503843499, 18700: 0.5474898012756152, 18800: 0.5572548872939005, 18900: 0.5823000127210403, 19000: 0.5555480945377437, 19100: 0.5727205666537694, 19200: 0.49380082954203613, 19300: 0.611309445749728, 19400: 0.5552377270026426, 19500: 0.5931631330637345, 19600: 0.6109410534994111, 19700: 0.5890772186503339, 19800: 0.5805402991892566, 19900: 0.6025374447051134, 20000: 0.5440273517511215, 20100: 0.48513495060003586, 20200: 0.5362656868226726, 20300: 0.5382630006929754, 20400: 0.41666130611530067, 20500: 0.5445650345384069, 20600: 0.5320385777217423, 20700: 0.5072616634053161, 20800: 0.4523903965428151, 20900: 0.49544414507277296, 21000: 0.4998540993978571, 21100: 0.4574020346995795, 21200: 0.5367135755200517, 21300: 0.47974950358074064, 21400: 0.5543212321087267, 21500: 0.5376009708527232, 21600: 0.4386818458026646, 21700: 0.5142350824649231, 21800: 0.5448443020786041, 21900: 0.5278919663705222, 22000: 0.49729847061933924, 22100: 0.3947369817497357, 22200: 0.42276351274792995, 22300: 0.48066249075669343, 22400: 0.5404729255690381, 22500: 0.5423734397724211, 22600: 0.5323605053693634, 22700: 0.5652827594430432, 22800: 0.5531703658905486, 22900: 0.5137717286217766, 23000: 0.5517702286244174, 23100: 0.49258232511456446, 23200: 0.5550009142905502, 23300: 0.5341451421898282, 23400: 0.48817579062847716, 23500: 0.5044490718182107, 23600: 0.45528814156310554, 23700: 0.566547784370421, 23800: 0.5264475053827602, 23900: 0.43987685171497865, 24000: 0.5022982171975682, 24100: 0.43369745753785943, 24200: 0.5869692036061817, 24300: 0.5842877047830086, 24400: 0.4363260221168143, 24500: 0.5303923290860113, 24600: 0.551502190137461, 24700: 0.5560999387599632, 24800: 0.5735807349269829, 24900: 0.5705759769334088, 25000: 0.48225146640724675, 25100: 0.566424929615406, 25200: 0.4392681329890429, 25300: 0.44998691793977036, 25400: 0.5638206054395011, 25500: 0.5862516037393611, 25600: 0.5959257242596807, 25700: 0.587592635404432, 25800: 0.5537651461138217, 25900: 0.5000327246095386, 26000: 0.5398351687150215, 26100: 0.4892155036422999, 26200: 0.5156194822311752, 26300: 0.572458602802822, 26400: 0.49608768647455065, 26500: 0.5402955811899608, 26600: 0.5454673276545706, 26700: 0.4315486353473403, 26800: 0.5105199947859469, 26900: 0.5257678539568965, 27000: 0.4610212730222227, 27100: 0.5678225423287062, 27200: 0.565304754847722, 27300: 0.5214499902534349, 27400: 0.5868461124322238, 27500: 0.4635635695720213, 27600: 0.5406558387790049, 27700: 0.5689301130819046, 27800: 0.4977024988527867, 27900: 0.4863229527951567, 28000: 0.5335308778789929, 28100: 0.42741153298496853, 28200: 0.4956854563115076, 28300: 0.5217630539790941, 28400: 0.5871100644145774, 28500: 0.5211956621671215, 28600: 0.5970117687685043, 28700: 0.5749018843090682, 28800: 0.5072556612661079, 28900: 0.5151563576591157, 29000: 0.5398282846245568}, 'Accuracy': {0: 0.5321037781295163, 100: 0.5078797054572982, 200: 0.5058839721973711, 300: 0.5183401004748469, 400: 0.506640974468378, 500: 0.5144174523432661, 600: 0.5371963388617439, 700: 0.5291445874337622, 800: 0.5056086986442777, 900: 0.4848943637740004, 1000: 0.49253320487234187, 1100: 0.4978322207693896, 1200: 0.50010322758241, 1300: 0.5096689835524052, 1400: 0.4966623081687427, 1500: 0.5097378019406785, 1600: 0.5029247815016172, 1700: 0.5128346294129792, 1800: 0.5109077145413254, 1900: 0.5051957883146376, 2000: 0.5196476498520405, 2100: 0.48640836831601403, 2200: 0.5240520267015346, 2300: 0.5076732502924781, 2400: 0.5188218291927603, 2500: 0.4952171220150024, 2600: 0.5257724864083683, 2700: 0.5049205147615443, 2800: 0.4850320005505471, 2900: 0.5168949143211066, 3000: 0.5301768632578625, 3100: 0.5071227031862914, 3200: 0.5119399903654256, 3300: 0.5218498382767875, 3400: 0.46149611176106253, 3500: 0.5111829880944189, 3600: 0.49707521849838276, 3700: 0.4867524602573808, 3800: 0.5186841924162137, 3900: 0.5201981969582272, 4000: 0.5168260959328332, 4100: 0.4718876883903379, 4200: 0.4887481935173078, 4300: 0.5158626384970064, 4400: 0.489780469341408, 4500: 0.48950519578831464, 4600: 0.5140733604018994, 4700: 0.5006537746885968, 4800: 0.49893331498176313, 4900: 0.4982451310990297, 5000: 0.5139357236253527, 5100: 0.5224692037712477, 5200: 0.5065721560801046, 5300: 0.5265983070676484, 5400: 0.5210240176175074, 5500: 0.4823480834078866, 5600: 0.5201981969582272, 5700: 0.5112518064826922, 5800: 0.5126281742481591, 5900: 0.47312641937925815, 6000: 0.512008808753699, 6100: 0.4853072741036405, 6200: 0.5016172321244237, 6300: 0.5371963388617439, 6400: 0.5038194205491707, 6500: 0.4928084784254353, 6600: 0.508430252563485, 6700: 0.5009290482416902, 6800: 0.5007225930768702, 6900: 0.5153120913908197, 7000: 0.5234326612070745, 7100: 0.5287316771041222, 7200: 0.5131787213543458, 7300: 0.5254283944670016, 7400: 0.49404720941435554, 7500: 0.4888170119055812, 7600: 0.4992774069231299, 7700: 0.48964283256486135, 7800: 0.5045764228201776, 7900: 0.5139357236253527, 8000: 0.5208863808409607, 8100: 0.5091184364462185, 8200: 0.48854173835248776, 8300: 0.5049205147615443, 8400: 0.4984515862638497, 8500: 0.4939095726378088, 8600: 0.49652467139219597, 8700: 0.5281811299979354, 8800: 0.5192347395224004, 8900: 0.5156561833321863, 9000: 0.49996559080586334, 9100: 0.49652467139219597, 9200: 0.5182712820865736, 9300: 0.5153120913908197, 9400: 0.4753974261922786, 9500: 0.4791136191590393, 9600: 0.5204046521230473, 9700: 0.49955268047622325, 9800: 0.4961117610625559, 9900: 0.487784736081481, 10000: 0.5077420686807514, 10100: 0.48819764641112107, 10200: 0.5182712820865736, 10300: 0.5288693138806689, 10400: 0.5164820039914665, 10500: 0.5052646067029111, 10600: 0.5304521368109559, 10700: 0.5108388961530521, 10800: 0.507053884798018, 10900: 0.5157250017204597, 11000: 0.4869589154222008, 11100: 0.5118711719771523, 11200: 0.5179271901452068, 11300: 0.5183401004748469, 11400: 0.5171701878742, 11500: 0.5119399903654256, 11600: 0.5105636225999587, 11700: 0.4899181061179547, 11800: 0.5376780675796573, 11900: 0.5049205147615443, 12000: 0.4957676691211892, 12100: 0.5299704080930424, 12200: 0.5204734705113206, 12300: 0.5047828779849975, 12400: 0.5020989608423371, 12500: 0.5030624182781639, 12600: 0.5047828779849975, 12700: 0.5082926157869383, 12800: 0.4843438166678136, 12900: 0.5073979767393848, 13000: 0.4923267497075218, 13100: 0.5179960085334802, 13200: 0.527492946115202, 13300: 0.4934278439198954, 13400: 0.4943224829674489, 13500: 0.49865804142866976, 13600: 0.46280366113825616, 13700: 0.49101920033032825, 13800: 0.49308375197852866, 13900: 0.49652467139219597, 14000: 0.4892987406234946, 14100: 0.5285252219393022, 14200: 0.5195100130754938, 14300: 0.5089119812813984, 14400: 0.506640974468378, 14500: 0.4923955680957952, 14600: 0.5146239075080862, 14700: 0.518753010804487, 14800: 0.5255660312435483, 14900: 0.5098754387172253, 15000: 0.4788383456059459, 15100: 0.4908127451655082, 15200: 0.526116578349735, 15300: 0.4819351730782465, 15400: 0.4909503819420549, 15500: 0.4908815635537816, 15600: 0.5084990709517583, 15700: 0.4884041015759411, 15800: 0.520542288899594, 15900: 0.5154497281673663, 16000: 0.5268047622324685, 16100: 0.4868212786456541, 16200: 0.5135228132957126, 16300: 0.5160002752735531, 16400: 0.5055398802560044, 16500: 0.4768426123460189, 16600: 0.5131099029660725, 16700: 0.4993462253114032, 16800: 0.4724382354965247, 16900: 0.4899181061179547, 17000: 0.5017548689009703, 17100: 0.49349666230816874, 17200: 0.498313949487303, 17300: 0.5171701878742, 17400: 0.4623219324203427, 17500: 0.5333425091184364, 17600: 0.5007914114651435, 17700: 0.510425985823412, 17800: 0.5212304727823275, 17900: 0.5184089188631202, 18000: 0.49748812882802285, 18100: 0.4987956782052164, 18200: 0.5131099029660725, 18300: 0.4994838620879499, 18400: 0.5037506021608974, 18500: 0.5014107769596036, 18600: 0.5062280641387379, 18700: 0.504851696373271, 18800: 0.5062968825270112, 18900: 0.5159314568852797, 19000: 0.5124217190833391, 19100: 0.5193035579106737, 19200: 0.481040534030693, 19300: 0.5392608905099443, 19400: 0.5102883490468654, 19500: 0.5325166884591563, 19600: 0.5380221595210241, 19700: 0.5228132957126144, 19800: 0.5210928360057807, 19900: 0.5361640630376436, 20000: 0.5124905374716124, 20100: 0.494735393297089, 20200: 0.5026495079485238, 20300: 0.49494184846190903, 20400: 0.463973573738903, 20500: 0.4978322207693896, 20600: 0.49404720941435554, 20700: 0.4832427224554401, 20800: 0.4762920652398321, 20900: 0.47512215263918517, 21000: 0.4957676691211892, 21100: 0.48248572018443325, 21200: 0.5085678893400316, 21300: 0.4771867042873856, 21400: 0.511595898424059, 21500: 0.49900213337003646, 21600: 0.46961668157731745, 21700: 0.49645585300392264, 21800: 0.5058151538090978, 21900: 0.5067097928566513, 22000: 0.48716537058702086, 22100: 0.46011974399559563, 22200: 0.4627348427499828, 22300: 0.48448145344436033, 22400: 0.515380909779093, 22500: 0.5114582616475122, 22600: 0.5116647168123323, 22700: 0.5219186566650609, 22800: 0.505471061867731, 22900: 0.48702773381047415, 23000: 0.5091872548344918, 23100: 0.49707521849838276, 23200: 0.5129722661895258, 23300: 0.4967999449452894, 23400: 0.4923267497075218, 23500: 0.496731126557016, 23600: 0.4851696373270938, 23700: 0.5166884591562866, 23800: 0.4962493978391026, 23900: 0.4730576009909848, 24000: 0.4934278439198954, 24100: 0.472507053884798, 24200: 0.524533755419448, 24300: 0.5194411946872204, 24400: 0.479251255935586, 24500: 0.5062968825270112, 24600: 0.5102883490468654, 24700: 0.507260339962838, 24800: 0.5175830982038401, 24900: 0.5194411946872204, 25000: 0.48510081893882046, 25100: 0.5165508223797398, 25200: 0.4744339687564517, 25300: 0.4824169017961599, 25400: 0.510632440988232, 25500: 0.5268047622324685, 25600: 0.5235014795953479, 25700: 0.5301080448695892, 25800: 0.5108388961530521, 25900: 0.48806000963457435, 26000: 0.5062968825270112, 26100: 0.49335902553162203, 26200: 0.4908815635537816, 26300: 0.5195100130754938, 26400: 0.49411602780262887, 26500: 0.49900213337003646, 26600: 0.5040946941022642, 26700: 0.47952652948867935, 26800: 0.49996559080586334, 26900: 0.5039570573257174, 27000: 0.4788383456059459, 27100: 0.5174454614272934, 27200: 0.5184777372513936, 27300: 0.5102195306585919, 27400: 0.518753010804487, 27500: 0.472300598719978, 27600: 0.5037506021608974, 27700: 0.5136604500722594, 27800: 0.4963870346156493, 27900: 0.49652467139219597, 28000: 0.5063657009152845, 28100: 0.4747092423095451, 28200: 0.49590530589773585, 28300: 0.4987956782052164, 28400: 0.5231573876539811, 28500: 0.5028559631133439, 28600: 0.5267359438441952, 28700: 0.5183401004748469, 28800: 0.5052646067029111, 28900: 0.5001720459706833, 29000: 0.5014107769596036}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.59      0.87      0.70       885\n",
      "           2       0.58      0.36      0.45       877\n",
      "           3       0.60      0.57      0.58       897\n",
      "           4       0.50      0.83      0.62       892\n",
      "           5       0.54      0.53      0.53       862\n",
      "           6       0.63      0.52      0.57       903\n",
      "           7       0.56      0.84      0.67       889\n",
      "           8       0.59      0.20      0.30       892\n",
      "           9       0.56      0.64      0.60       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 0, Loss: 2.3051939010620117, F1: 0.5542318748111204, Accuracy: 0.5094625283875852, Time Elapsed: 17.05475401878357 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.68      0.06      0.10       885\n",
      "           2       0.61      0.41      0.49       877\n",
      "           3       0.61      0.49      0.54       897\n",
      "           4       0.59      0.44      0.50       892\n",
      "           5       0.56      0.66      0.60       862\n",
      "           6       0.61      0.59      0.60       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.53      0.79      0.63       892\n",
      "           9       0.56      0.72      0.63       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.54     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 100, Loss: 3.989603281021118, F1: 0.5357402721537755, Accuracy: 0.5092560732227651, Time Elapsed: 36.003166913986206 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.63      0.35      0.45       885\n",
      "           2       0.60      0.59      0.60       877\n",
      "           3       0.58      0.79      0.67       897\n",
      "           4       0.60      0.40      0.48       892\n",
      "           5       0.58      0.45      0.51       862\n",
      "           6       0.62      0.77      0.68       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.57      0.62      0.59       892\n",
      "           9       0.60      0.47      0.52       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.59      0.57     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 200, Loss: 0.39107653498649597, F1: 0.5712434482395199, Accuracy: 0.5210928360057807, Time Elapsed: 52.68890905380249 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.89      0.73       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.57      0.65      0.61       892\n",
      "           5       0.54      0.69      0.61       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.59      0.66      0.62       892\n",
      "           9       0.62      0.40      0.49       876\n",
      "          10       0.39      0.29      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.58      0.65      0.60     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 300, Loss: 1.0229110717773438, F1: 0.6014133288851773, Accuracy: 0.5332736907301631, Time Elapsed: 67.31319904327393 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.63      0.37      0.46       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.57      0.79      0.66       897\n",
      "           4       0.60      0.22      0.33       892\n",
      "           5       0.49      0.81      0.61       862\n",
      "           6       0.62      0.48      0.54       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.54      0.78      0.64       892\n",
      "           9       0.58      0.45      0.51       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 400, Loss: 0.46313557028770447, F1: 0.5456097308527303, Accuracy: 0.5062968825270112, Time Elapsed: 83.16081809997559 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69       912\n",
      "           1       0.63      0.31      0.41       885\n",
      "           2       0.58      0.62      0.60       877\n",
      "           3       0.60      0.66      0.63       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.56      0.37      0.44       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.60      0.61      0.60       889\n",
      "           8       0.58      0.72      0.64       892\n",
      "           9       0.55      0.63      0.59       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 500, Loss: 1.3991789817810059, F1: 0.5727570119567089, Accuracy: 0.5191659211341271, Time Elapsed: 102.38523483276367 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.58      0.98      0.72       885\n",
      "           2       0.58      0.56      0.57       877\n",
      "           3       0.53      0.81      0.64       897\n",
      "           4       0.46      0.91      0.61       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.60      0.47      0.53       889\n",
      "           8       0.59      0.65      0.62       892\n",
      "           9       0.55      0.53      0.54       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 600, Loss: 1.7029423713684082, F1: 0.5912517328736506, Accuracy: 0.5237767531484413, Time Elapsed: 119.36452507972717 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.70       912\n",
      "           1       0.60      0.94      0.74       885\n",
      "           2       0.59      0.55      0.56       877\n",
      "           3       0.61      0.58      0.60       897\n",
      "           4       0.55      0.76      0.64       892\n",
      "           5       0.50      0.74      0.60       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.60      0.70      0.64       889\n",
      "           8       0.60      0.51      0.55       892\n",
      "           9       0.55      0.65      0.59       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 3, Step 700, Loss: 0.48403382301330566, F1: 0.6012553274432287, Accuracy: 0.5297639529282224, Time Elapsed: 137.34730315208435 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.59      0.72      0.65       897\n",
      "           4       0.56      0.64      0.60       892\n",
      "           5       0.52      0.73      0.61       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.62      0.54      0.58       889\n",
      "           8       0.60      0.55      0.57       892\n",
      "           9       0.58      0.68      0.62       876\n",
      "          10       0.40      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.52      0.53      0.52     14531\n",
      "\n",
      "Epoch 3, Step 800, Loss: 2.0307705402374268, F1: 0.5922797606711494, Accuracy: 0.5273553093386553, Time Elapsed: 154.83257222175598 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.60      0.47      0.53       885\n",
      "           2       0.53      0.82      0.64       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.63      0.22      0.32       892\n",
      "           5       0.59      0.48      0.53       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.59      0.47      0.52       892\n",
      "           9       0.57      0.60      0.59       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 900, Loss: 1.2995331287384033, F1: 0.5504581399444329, Accuracy: 0.5093937099993118, Time Elapsed: 171.6772379875183 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.61      0.59      0.60       885\n",
      "           2       0.59      0.41      0.48       877\n",
      "           3       0.60      0.38      0.46       897\n",
      "           4       0.61      0.12      0.20       892\n",
      "           5       0.59      0.54      0.56       862\n",
      "           6       0.61      0.52      0.56       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.60      0.44      0.51       892\n",
      "           9       0.50      0.83      0.63       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.52     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 1000, Loss: 2.160174608230591, F1: 0.523858507523407, Accuracy: 0.4987268598169431, Time Elapsed: 189.16892004013062 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.72       912\n",
      "           1       0.61      0.68      0.64       885\n",
      "           2       0.53      0.70      0.61       877\n",
      "           3       0.59      0.18      0.27       897\n",
      "           4       0.57      0.46      0.51       892\n",
      "           5       0.60      0.32      0.42       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.61      0.37      0.46       889\n",
      "           8       0.59      0.46      0.51       892\n",
      "           9       0.52      0.77      0.62       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 1100, Loss: 0.9979056715965271, F1: 0.5317076927518071, Accuracy: 0.503268873442984, Time Elapsed: 210.08226799964905 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       912\n",
      "           1       0.33      0.00      0.00       885\n",
      "           2       0.62      0.25      0.36       877\n",
      "           3       0.58      0.36      0.45       897\n",
      "           4       0.56      0.41      0.47       892\n",
      "           5       0.60      0.31      0.41       862\n",
      "           6       0.61      0.65      0.63       903\n",
      "           7       0.61      0.66      0.63       889\n",
      "           8       0.61      0.36      0.45       892\n",
      "           9       0.57      0.58      0.57       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.45      0.47     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 1200, Loss: 0.5871980786323547, F1: 0.4660937463299359, Accuracy: 0.4853072741036405, Time Elapsed: 227.8965470790863 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.70       912\n",
      "           1       0.61      0.39      0.47       885\n",
      "           2       0.63      0.19      0.29       877\n",
      "           3       0.58      0.71      0.63       897\n",
      "           4       0.56      0.64      0.60       892\n",
      "           5       0.58      0.51      0.54       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.59      0.79      0.67       889\n",
      "           8       0.61      0.55      0.58       892\n",
      "           9       0.56      0.72      0.63       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 1300, Loss: 1.017005205154419, F1: 0.5597390005092364, Accuracy: 0.5169637327093799, Time Elapsed: 246.87971091270447 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.63      0.55      0.59       885\n",
      "           2       0.57      0.67      0.62       877\n",
      "           3       0.59      0.54      0.56       897\n",
      "           4       0.59      0.27      0.38       892\n",
      "           5       0.56      0.10      0.17       862\n",
      "           6       0.61      0.67      0.63       903\n",
      "           7       0.57      0.85      0.69       889\n",
      "           8       0.61      0.43      0.50       892\n",
      "           9       0.59      0.42      0.49       876\n",
      "          10       0.40      0.48      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 1400, Loss: 0.43248283863067627, F1: 0.5184565019539208, Accuracy: 0.5033376918312573, Time Elapsed: 266.11835408210754 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       912\n",
      "           1       0.63      0.32      0.42       885\n",
      "           2       0.58      0.51      0.54       877\n",
      "           3       0.60      0.34      0.44       897\n",
      "           4       0.49      0.84      0.62       892\n",
      "           5       0.54      0.35      0.43       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.61      0.60      0.60       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.59      0.51      0.55       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 3, Step 1500, Loss: 0.8065310120582581, F1: 0.5402540632302356, Accuracy: 0.5025806895602505, Time Elapsed: 282.4198839664459 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.56      0.97      0.71       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.59      0.14      0.23       897\n",
      "           4       0.56      0.69      0.62       892\n",
      "           5       0.52      0.77      0.62       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.54      0.80      0.65       892\n",
      "           9       0.56      0.64      0.60       876\n",
      "          10       0.40      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.58     14531\n",
      "weighted avg       0.51      0.53      0.49     14531\n",
      "\n",
      "Epoch 3, Step 1600, Loss: 1.46786367893219, F1: 0.5785387720316897, Accuracy: 0.5261853967380083, Time Elapsed: 300.6726219654083 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.61      0.47      0.53       885\n",
      "           2       0.62      0.35      0.45       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.58      0.61      0.60       892\n",
      "           5       0.57      0.50      0.53       862\n",
      "           6       0.62      0.73      0.67       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.54      0.80      0.64       892\n",
      "           9       0.55      0.59      0.57       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.54      0.52     14531\n",
      "weighted avg       0.48      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 1700, Loss: 2.1024653911590576, F1: 0.5211201548093599, Accuracy: 0.5055398802560044, Time Elapsed: 322.42789602279663 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.63      0.12      0.20       877\n",
      "           3       0.60      0.37      0.46       897\n",
      "           4       0.59      0.68      0.63       892\n",
      "           5       0.58      0.50      0.54       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.59      0.51      0.55       892\n",
      "           9       0.62      0.16      0.25       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.53      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 1800, Loss: 0.17947052419185638, F1: 0.5179392747272518, Accuracy: 0.5049893331498176, Time Elapsed: 338.78155493736267 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.72       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.57      0.76      0.65       877\n",
      "           3       0.61      0.38      0.47       897\n",
      "           4       0.46      0.91      0.61       892\n",
      "           5       0.58      0.40      0.48       862\n",
      "           6       0.62      0.73      0.67       903\n",
      "           7       0.61      0.47      0.53       889\n",
      "           8       0.61      0.63      0.62       892\n",
      "           9       0.53      0.50      0.52       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 1900, Loss: 0.8789610266685486, F1: 0.5726635600700647, Accuracy: 0.5168260959328332, Time Elapsed: 356.99519205093384 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.56      0.98      0.71       885\n",
      "           2       0.56      0.71      0.63       877\n",
      "           3       0.60      0.61      0.61       897\n",
      "           4       0.57      0.39      0.47       892\n",
      "           5       0.56      0.72      0.63       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.60      0.59      0.60       889\n",
      "           8       0.60      0.60      0.60       892\n",
      "           9       0.56      0.71      0.63       876\n",
      "          10       0.40      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 3, Step 2000, Loss: 1.4791946411132812, F1: 0.599185451911745, Accuracy: 0.5329295987887964, Time Elapsed: 377.99791407585144 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69       912\n",
      "           1       0.60      0.28      0.38       885\n",
      "           2       0.57      0.64      0.60       877\n",
      "           3       0.61      0.37      0.46       897\n",
      "           4       0.51      0.07      0.12       892\n",
      "           5       0.58      0.09      0.15       862\n",
      "           6       0.56      0.90      0.69       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.61      0.22      0.33       892\n",
      "           9       0.54      0.71      0.62       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.48      0.46     14531\n",
      "weighted avg       0.50      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 2100, Loss: 0.601864218711853, F1: 0.46316852208721665, Accuracy: 0.48358681439680684, Time Elapsed: 396.1146779060364 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70       912\n",
      "           1       0.58      0.91      0.71       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.57      0.68      0.62       897\n",
      "           4       0.58      0.38      0.46       892\n",
      "           5       0.56      0.35      0.43       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.61      0.74      0.67       889\n",
      "           8       0.60      0.50      0.54       892\n",
      "           9       0.56      0.60      0.58       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 2200, Loss: 1.743896245956421, F1: 0.571726333760608, Accuracy: 0.5190282843575803, Time Elapsed: 418.5050160884857 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       912\n",
      "           1       0.59      0.97      0.73       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.60      0.25      0.35       897\n",
      "           4       0.58      0.45      0.50       892\n",
      "           5       0.57      0.36      0.44       862\n",
      "           6       0.62      0.65      0.63       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.61      0.39      0.48       892\n",
      "           9       0.59      0.48      0.53       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 2300, Loss: 0.5872783660888672, F1: 0.544200980701787, Accuracy: 0.5099442571054986, Time Elapsed: 435.6720130443573 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.61      0.45      0.52       877\n",
      "           3       0.59      0.53      0.56       897\n",
      "           4       0.55      0.57      0.56       892\n",
      "           5       0.48      0.73      0.58       862\n",
      "           6       0.61      0.50      0.55       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.57      0.56      0.57       892\n",
      "           9       0.59      0.61      0.60       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 2400, Loss: 0.5708857178688049, F1: 0.5768472202531199, Accuracy: 0.5160002752735531, Time Elapsed: 451.3570580482483 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.72       912\n",
      "           1       0.61      0.78      0.69       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.59      0.49      0.53       897\n",
      "           4       0.52      0.06      0.10       892\n",
      "           5       0.46      0.83      0.59       862\n",
      "           6       0.62      0.21      0.32       903\n",
      "           7       0.61      0.61      0.61       889\n",
      "           8       0.58      0.33      0.42       892\n",
      "           9       0.60      0.40      0.48       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.50      0.47      0.45     14531\n",
      "weighted avg       0.47      0.48      0.44     14531\n",
      "\n",
      "Epoch 3, Step 2500, Loss: 1.0015186071395874, F1: 0.4451345245322029, Accuracy: 0.47766843300529904, Time Elapsed: 467.3242747783661 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.91      0.73       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.60      0.00      0.01       877\n",
      "           3       0.57      0.77      0.66       897\n",
      "           4       0.57      0.50      0.53       892\n",
      "           5       0.44      0.84      0.58       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.54      0.63      0.58       892\n",
      "           9       0.57      0.42      0.48       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.61      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 2600, Loss: 0.40014728903770447, F1: 0.5415253469872213, Accuracy: 0.5111829880944189, Time Elapsed: 482.36312913894653 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56       912\n",
      "           1       0.61      0.73      0.66       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.59      0.27      0.37       897\n",
      "           4       0.54      0.12      0.20       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.57      0.81      0.67       889\n",
      "           8       0.60      0.29      0.39       892\n",
      "           9       0.64      0.15      0.25       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.47      0.48     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 2700, Loss: 3.196885108947754, F1: 0.48204653921963964, Accuracy: 0.4870965521987475, Time Elapsed: 498.6112868785858 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.35      0.46       912\n",
      "           1       0.61      0.47      0.53       885\n",
      "           2       0.61      0.38      0.47       877\n",
      "           3       0.54      0.07      0.12       897\n",
      "           4       0.57      0.63      0.60       892\n",
      "           5       0.52      0.45      0.49       862\n",
      "           6       0.61      0.76      0.67       903\n",
      "           7       0.61      0.69      0.64       889\n",
      "           8       0.48      0.74      0.59       892\n",
      "           9       0.53      0.74      0.62       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.52      0.51     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 3, Step 2800, Loss: 0.1142575591802597, F1: 0.5090287620517608, Accuracy: 0.4908127451655082, Time Elapsed: 514.3368418216705 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.66       912\n",
      "           1       0.60      0.70      0.65       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.63      0.46      0.53       897\n",
      "           4       0.56      0.75      0.64       892\n",
      "           5       0.56      0.19      0.28       862\n",
      "           6       0.61      0.81      0.70       903\n",
      "           7       0.61      0.66      0.63       889\n",
      "           8       0.46      0.85      0.60       892\n",
      "           9       0.53      0.68      0.60       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 2900, Loss: 1.133739709854126, F1: 0.5702965853014832, Accuracy: 0.5172390062624733, Time Elapsed: 529.5739560127258 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.60      0.20      0.30       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.58      0.55      0.57       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.53      0.70      0.60       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.59      0.79      0.67       889\n",
      "           8       0.58      0.52      0.55       892\n",
      "           9       0.52      0.80      0.63       876\n",
      "          10       0.40      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 3000, Loss: 1.2223150730133057, F1: 0.5738833470856235, Accuracy: 0.5200605601816806, Time Elapsed: 545.1509690284729 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.59      0.62      0.60       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.58      0.55      0.56       897\n",
      "           4       0.59      0.39      0.47       892\n",
      "           5       0.47      0.79      0.59       862\n",
      "           6       0.58      0.87      0.69       903\n",
      "           7       0.60      0.61      0.61       889\n",
      "           8       0.59      0.66      0.62       892\n",
      "           9       0.55      0.76      0.64       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 3100, Loss: 0.5486159324645996, F1: 0.5795320959464016, Accuracy: 0.5163443672149198, Time Elapsed: 560.3302011489868 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.54      0.98      0.70       885\n",
      "           2       0.59      0.67      0.63       877\n",
      "           3       0.58      0.69      0.63       897\n",
      "           4       0.57      0.67      0.62       892\n",
      "           5       0.53      0.56      0.55       862\n",
      "           6       0.59      0.81      0.69       903\n",
      "           7       0.62      0.23      0.34       889\n",
      "           8       0.60      0.60      0.60       892\n",
      "           9       0.58      0.67      0.63       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 3200, Loss: 1.0524144172668457, F1: 0.5822135057213209, Accuracy: 0.5236391163718945, Time Elapsed: 576.8940069675446 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.61      0.35      0.45       877\n",
      "           3       0.57      0.78      0.66       897\n",
      "           4       0.62      0.14      0.23       892\n",
      "           5       0.54      0.60      0.57       862\n",
      "           6       0.58      0.93      0.71       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.61      0.51      0.56       892\n",
      "           9       0.61      0.53      0.56       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 3300, Loss: 0.9275966882705688, F1: 0.5624946001614849, Accuracy: 0.5224003853829743, Time Elapsed: 592.3177740573883 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.69      0.14      0.23       885\n",
      "           2       0.63      0.19      0.29       877\n",
      "           3       0.59      0.56      0.57       897\n",
      "           4       0.60      0.00      0.01       892\n",
      "           5       0.58      0.27      0.37       862\n",
      "           6       0.62      0.52      0.57       903\n",
      "           7       0.63      0.19      0.29       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.64      0.17      0.27       876\n",
      "          10       0.39      0.66      0.49      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.60      0.37      0.40     14531\n",
      "weighted avg       0.53      0.47      0.43     14531\n",
      "\n",
      "Epoch 3, Step 3400, Loss: 0.6217947602272034, F1: 0.3981910991534493, Accuracy: 0.4694102264124974, Time Elapsed: 606.9710168838501 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.63      0.39      0.49       877\n",
      "           3       0.57      0.77      0.65       897\n",
      "           4       0.58      0.15      0.23       892\n",
      "           5       0.56      0.57      0.57       862\n",
      "           6       0.63      0.54      0.58       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.56      0.82      0.66       892\n",
      "           9       0.63      0.13      0.22       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 3500, Loss: 0.7378378510475159, F1: 0.5299927471911954, Accuracy: 0.5095313467758585, Time Elapsed: 623.2973120212555 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.59      0.83      0.69       885\n",
      "           2       0.58      0.65      0.62       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.66      0.09      0.15       892\n",
      "           5       0.52      0.71      0.60       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.61      0.45      0.52       892\n",
      "           9       0.64      0.11      0.18       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.52     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 3600, Loss: 1.3263416290283203, F1: 0.522664953918312, Accuracy: 0.5082926157869383, Time Elapsed: 643.6227130889893 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.60      0.54      0.57       885\n",
      "           2       0.57      0.64      0.61       877\n",
      "           3       0.59      0.25      0.35       897\n",
      "           4       0.55      0.40      0.47       892\n",
      "           5       0.52      0.58      0.55       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.55      0.02      0.04       892\n",
      "           9       0.62      0.17      0.27       876\n",
      "          10       0.39      0.46      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.49     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 3700, Loss: 0.9482681751251221, F1: 0.4861696728382285, Accuracy: 0.49301493359025533, Time Elapsed: 661.2745850086212 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.66       912\n",
      "           1       0.56      0.97      0.71       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.58      0.75      0.65       897\n",
      "           4       0.56      0.55      0.56       892\n",
      "           5       0.56      0.54      0.55       862\n",
      "           6       0.62      0.52      0.56       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.61      0.42      0.49       892\n",
      "           9       0.60      0.30      0.40       876\n",
      "          10       0.40      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 3800, Loss: 1.5620522499084473, F1: 0.5672377417008174, Accuracy: 0.5179960085334802, Time Elapsed: 677.255448102951 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.70       912\n",
      "           1       0.55      0.98      0.71       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.52      0.88      0.65       897\n",
      "           4       0.54      0.78      0.64       892\n",
      "           5       0.57      0.64      0.60       862\n",
      "           6       0.61      0.50      0.55       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.57      0.69      0.63       892\n",
      "           9       0.56      0.65      0.60       876\n",
      "          10       0.39      0.21      0.27      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.69      0.60     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 3, Step 3900, Loss: 0.24886365234851837, F1: 0.6032079475841716, Accuracy: 0.5300392264813159, Time Elapsed: 692.6915700435638 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.61      0.54      0.57       877\n",
      "           3       0.60      0.72      0.65       897\n",
      "           4       0.59      0.47      0.53       892\n",
      "           5       0.56      0.67      0.61       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.59      0.73      0.65       892\n",
      "           9       0.64      0.07      0.13       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.58      0.61      0.57     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 4000, Loss: 0.5486193299293518, F1: 0.5675476394647787, Accuracy: 0.5299704080930424, Time Elapsed: 708.818638086319 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.42      0.51       912\n",
      "           1       0.60      0.59      0.60       885\n",
      "           2       0.58      0.62      0.60       877\n",
      "           3       0.61      0.52      0.56       897\n",
      "           4       0.70      0.05      0.09       892\n",
      "           5       0.59      0.27      0.37       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.61      0.53      0.57       892\n",
      "           9       0.55      0.62      0.58       876\n",
      "          10       0.40      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.49      0.50     14531\n",
      "weighted avg       0.53      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 4100, Loss: 0.9452401995658875, F1: 0.5047649209306736, Accuracy: 0.49748812882802285, Time Elapsed: 736.1957569122314 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.61      0.60      0.61       885\n",
      "           2       0.56      0.76      0.64       877\n",
      "           3       0.61      0.49      0.55       897\n",
      "           4       0.43      0.96      0.59       892\n",
      "           5       0.60      0.43      0.50       862\n",
      "           6       0.61      0.50      0.55       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.60      0.54      0.57       892\n",
      "           9       0.59      0.34      0.43       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 4200, Loss: 0.5287258625030518, F1: 0.5574223209070363, Accuracy: 0.5052646067029111, Time Elapsed: 762.7224712371826 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67       912\n",
      "           1       0.61      0.40      0.48       885\n",
      "           2       0.57      0.67      0.62       877\n",
      "           3       0.58      0.78      0.66       897\n",
      "           4       0.57      0.58      0.58       892\n",
      "           5       0.57      0.46      0.51       862\n",
      "           6       0.61      0.71      0.66       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.60      0.65      0.62       892\n",
      "           9       0.56      0.64      0.59       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.58     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 4300, Loss: 1.7784841060638428, F1: 0.5832913016166015, Accuracy: 0.5226068405477944, Time Elapsed: 791.5137069225311 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.58      0.61      0.60       877\n",
      "           3       0.58      0.70      0.63       897\n",
      "           4       0.63      0.29      0.39       892\n",
      "           5       0.56      0.52      0.54       862\n",
      "           6       0.68      0.06      0.11       903\n",
      "           7       0.63      0.47      0.54       889\n",
      "           8       0.59      0.66      0.62       892\n",
      "           9       0.51      0.55      0.53       876\n",
      "          10       0.40      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.53      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 4400, Loss: 1.3229526281356812, F1: 0.52169716190113, Accuracy: 0.503268873442984, Time Elapsed: 819.7747991085052 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.35      0.45       912\n",
      "           1       0.61      0.76      0.67       885\n",
      "           2       0.63      0.31      0.42       877\n",
      "           3       0.54      0.70      0.61       897\n",
      "           4       0.59      0.38      0.47       892\n",
      "           5       0.45      0.84      0.58       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.61      0.55      0.58       892\n",
      "           9       0.57      0.66      0.61       876\n",
      "          10       0.40      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 4500, Loss: 1.1152455806732178, F1: 0.5541845684893223, Accuracy: 0.508430252563485, Time Elapsed: 848.0764739513397 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.43      0.51       912\n",
      "           1       0.62      0.75      0.67       885\n",
      "           2       0.54      0.79      0.65       877\n",
      "           3       0.60      0.65      0.62       897\n",
      "           4       0.62      0.32      0.42       892\n",
      "           5       0.56      0.49      0.52       862\n",
      "           6       0.63      0.71      0.67       903\n",
      "           7       0.57      0.82      0.68       889\n",
      "           8       0.61      0.58      0.59       892\n",
      "           9       0.59      0.58      0.58       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.59      0.57     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 4600, Loss: 1.704445242881775, F1: 0.5732598781804878, Accuracy: 0.5204734705113206, Time Elapsed: 871.5424361228943 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.05      0.09       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.59      0.69      0.63       877\n",
      "           3       0.59      0.65      0.62       897\n",
      "           4       0.58      0.24      0.34       892\n",
      "           5       0.58      0.37      0.45       862\n",
      "           6       0.62      0.43      0.51       903\n",
      "           7       0.60      0.45      0.52       889\n",
      "           8       0.60      0.42      0.49       892\n",
      "           9       0.55      0.67      0.61       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 4700, Loss: 1.5828299522399902, F1: 0.4925600879512649, Accuracy: 0.48998692450622805, Time Elapsed: 894.2390749454498 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57       912\n",
      "           1       0.58      0.89      0.70       885\n",
      "           2       0.61      0.53      0.57       877\n",
      "           3       0.59      0.66      0.63       897\n",
      "           4       0.55      0.55      0.55       892\n",
      "           5       0.57      0.10      0.17       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.60      0.61      0.61       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.40      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.51      0.50     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 4800, Loss: 0.7237018346786499, F1: 0.4978684683482289, Accuracy: 0.501479595347877, Time Elapsed: 915.535206079483 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.62      0.58      0.60       885\n",
      "           2       0.57      0.69      0.62       877\n",
      "           3       0.61      0.48      0.54       897\n",
      "           4       0.54      0.67      0.60       892\n",
      "           5       0.57      0.37      0.45       862\n",
      "           6       0.62      0.67      0.64       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.60      0.65      0.62       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.40      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.53      0.52     14531\n",
      "weighted avg       0.48      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 4900, Loss: 2.3260550498962402, F1: 0.5249479212306326, Accuracy: 0.5077420686807514, Time Elapsed: 934.9425818920135 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.62      0.57      0.59       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.59      0.51      0.55       897\n",
      "           4       0.61      0.16      0.26       892\n",
      "           5       0.56      0.23      0.33       862\n",
      "           6       0.64      0.31      0.42       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.61      0.59      0.60       892\n",
      "           9       0.60      0.58      0.59       876\n",
      "          10       0.40      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.52      0.52     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 5000, Loss: 0.9239354729652405, F1: 0.5237207405582784, Accuracy: 0.5060904273621912, Time Elapsed: 951.1299388408661 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.71       912\n",
      "           1       0.56      0.40      0.47       885\n",
      "           2       0.60      0.61      0.60       877\n",
      "           3       0.56      0.51      0.53       897\n",
      "           4       0.55      0.78      0.65       892\n",
      "           5       0.52      0.76      0.62       862\n",
      "           6       0.63      0.27      0.37       903\n",
      "           7       0.59      0.85      0.70       889\n",
      "           8       0.51      0.83      0.64       892\n",
      "           9       0.61      0.64      0.62       876\n",
      "          10       0.40      0.30      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 5100, Loss: 0.10699130594730377, F1: 0.5687140968843634, Accuracy: 0.5168260959328332, Time Elapsed: 966.5363278388977 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.46      0.54       912\n",
      "           1       0.56      0.07      0.13       885\n",
      "           2       0.59      0.49      0.54       877\n",
      "           3       0.60      0.62      0.61       897\n",
      "           4       0.55      0.82      0.66       892\n",
      "           5       0.57      0.57      0.57       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.61      0.61      0.61       889\n",
      "           8       0.59      0.64      0.61       892\n",
      "           9       0.59      0.43      0.50       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 5200, Loss: 1.1979455947875977, F1: 0.5302553291406645, Accuracy: 0.5042323308788108, Time Elapsed: 982.4898040294647 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.68       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.58      0.75      0.66       897\n",
      "           4       0.59      0.52      0.55       892\n",
      "           5       0.55      0.66      0.60       862\n",
      "           6       0.55      0.92      0.69       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.63      0.30      0.40       892\n",
      "           9       0.60      0.57      0.59       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 5300, Loss: 1.077502727508545, F1: 0.5912198650524811, Accuracy: 0.5318285045764228, Time Elapsed: 997.311863899231 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.57      0.72      0.64       877\n",
      "           3       0.59      0.56      0.58       897\n",
      "           4       0.57      0.72      0.63       892\n",
      "           5       0.55      0.51      0.53       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.61      0.66      0.63       889\n",
      "           8       0.53      0.84      0.65       892\n",
      "           9       0.58      0.60      0.59       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 5400, Loss: 0.7661776542663574, F1: 0.6004856163581017, Accuracy: 0.532654325235703, Time Elapsed: 1013.0059251785278 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.60      0.66      0.63       885\n",
      "           2       0.56      0.78      0.65       877\n",
      "           3       0.59      0.70      0.64       897\n",
      "           4       0.60      0.47      0.52       892\n",
      "           5       0.58      0.15      0.24       862\n",
      "           6       0.64      0.53      0.58       903\n",
      "           7       0.66      0.19      0.30       889\n",
      "           8       0.61      0.51      0.55       892\n",
      "           9       0.45      0.87      0.59       876\n",
      "          10       0.40      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.53     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 5500, Loss: 0.7787296772003174, F1: 0.5262247944326763, Accuracy: 0.5026495079485238, Time Elapsed: 1027.7949359416962 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.66       912\n",
      "           1       0.61      0.61      0.61       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.58      0.72      0.64       897\n",
      "           4       0.52      0.87      0.65       892\n",
      "           5       0.56      0.42      0.48       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.62      0.53      0.57       889\n",
      "           8       0.62      0.32      0.42       892\n",
      "           9       0.60      0.54      0.57       876\n",
      "          10       0.40      0.35      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.58     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 5600, Loss: 2.2343435287475586, F1: 0.5750655159747025, Accuracy: 0.5220562934416076, Time Elapsed: 1043.0486688613892 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.57      0.77      0.65       897\n",
      "           4       0.51      0.80      0.62       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.80      0.68       889\n",
      "           8       0.60      0.61      0.61       892\n",
      "           9       0.59      0.54      0.56       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.59      0.54     14531\n",
      "weighted avg       0.47      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 5700, Loss: 0.2966063618659973, F1: 0.5435894018660631, Accuracy: 0.5141421787901728, Time Elapsed: 1057.886193037033 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.79      0.69       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.56      0.77      0.65       897\n",
      "           4       0.58      0.49      0.53       892\n",
      "           5       0.57      0.43      0.49       862\n",
      "           6       0.63      0.69      0.65       903\n",
      "           7       0.59      0.85      0.69       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.62      0.60       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.46      0.53      0.49     14531\n",
      "weighted avg       0.44      0.50      0.46     14531\n",
      "\n",
      "Epoch 3, Step 5800, Loss: 0.7696855068206787, F1: 0.4886330591467163, Accuracy: 0.5014107769596036, Time Elapsed: 1072.548199892044 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.23      0.34       912\n",
      "           1       0.59      0.76      0.66       885\n",
      "           2       0.59      0.68      0.63       877\n",
      "           3       0.57      0.75      0.65       897\n",
      "           4       0.51      0.68      0.58       892\n",
      "           5       0.57      0.35      0.43       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.60      0.56      0.58       889\n",
      "           8       0.80      0.00      0.01       892\n",
      "           9       0.47      0.17      0.25       876\n",
      "          10       0.40      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.48     14531\n",
      "weighted avg       0.52      0.49      0.46     14531\n",
      "\n",
      "Epoch 3, Step 5900, Loss: 0.7663536071777344, F1: 0.4753040207204473, Accuracy: 0.48861055674076115, Time Elapsed: 1088.1821010112762 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70       912\n",
      "           1       0.61      0.81      0.70       885\n",
      "           2       0.62      0.46      0.53       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.57      0.36      0.45       892\n",
      "           5       0.55      0.59      0.57       862\n",
      "           6       0.62      0.61      0.61       903\n",
      "           7       0.59      0.66      0.62       889\n",
      "           8       0.61      0.28      0.38       892\n",
      "           9       0.47      0.82      0.59       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 6000, Loss: 0.36249110102653503, F1: 0.5611226802710712, Accuracy: 0.5131099029660725, Time Elapsed: 1105.8042159080505 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.62      0.75      0.68       885\n",
      "           2       0.65      0.13      0.22       877\n",
      "           3       0.59      0.36      0.44       897\n",
      "           4       0.64      0.16      0.26       892\n",
      "           5       0.60      0.39      0.48       862\n",
      "           6       0.63      0.53      0.58       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.57      0.40      0.47       892\n",
      "           9       0.61      0.35      0.44       876\n",
      "          10       0.40      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.48      0.49     14531\n",
      "weighted avg       0.53      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 6100, Loss: 0.3623797595500946, F1: 0.4908348660678028, Accuracy: 0.4962493978391026, Time Elapsed: 1121.6776821613312 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.62      0.39      0.48       877\n",
      "           3       0.50      0.83      0.63       897\n",
      "           4       0.59      0.27      0.37       892\n",
      "           5       0.59      0.33      0.43       862\n",
      "           6       0.61      0.52      0.56       903\n",
      "           7       0.59      0.69      0.64       889\n",
      "           8       0.58      0.17      0.27       892\n",
      "           9       0.57      0.40      0.47       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 6200, Loss: 1.2192720174789429, F1: 0.5161589881339709, Accuracy: 0.49803867593420964, Time Elapsed: 1137.5426909923553 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.59      0.56      0.58       897\n",
      "           4       0.53      0.75      0.62       892\n",
      "           5       0.48      0.73      0.58       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.52      0.32      0.40       892\n",
      "           9       0.55      0.59      0.57       876\n",
      "          10       0.38      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.63      0.57     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 6300, Loss: 0.7957590818405151, F1: 0.5725989971985609, Accuracy: 0.5133851765191659, Time Elapsed: 1153.0249781608582 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.25      0.00      0.00       877\n",
      "           3       0.53      0.82      0.64       897\n",
      "           4       0.59      0.46      0.52       892\n",
      "           5       0.57      0.34      0.43       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.57      0.28      0.38       892\n",
      "           9       0.60      0.32      0.41       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.50      0.49     14531\n",
      "weighted avg       0.49      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 6400, Loss: 0.8203390836715698, F1: 0.4898297211938567, Accuracy: 0.49397839102608215, Time Elapsed: 1168.6064810752869 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       912\n",
      "           1       0.62      0.39      0.48       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.57      0.77      0.66       897\n",
      "           4       0.58      0.39      0.47       892\n",
      "           5       0.50      0.75      0.60       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.56      0.24      0.34       892\n",
      "           9       0.45      0.82      0.58       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.50      0.54      0.50     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 6500, Loss: 0.6183543801307678, F1: 0.5010565378566731, Accuracy: 0.49294611520198195, Time Elapsed: 1183.0594968795776 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.67      0.26      0.38       877\n",
      "           3       0.60      0.44      0.51       897\n",
      "           4       0.59      0.65      0.62       892\n",
      "           5       0.56      0.55      0.56       862\n",
      "           6       0.62      0.77      0.68       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.54      0.73      0.62       892\n",
      "           9       0.54      0.74      0.62       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 6600, Loss: 0.4317423701286316, F1: 0.5827521654786904, Accuracy: 0.5277682196682953, Time Elapsed: 1198.7355670928955 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       912\n",
      "           1       0.61      0.90      0.72       885\n",
      "           2       0.58      0.72      0.64       877\n",
      "           3       0.61      0.49      0.55       897\n",
      "           4       0.55      0.79      0.65       892\n",
      "           5       0.57      0.49      0.53       862\n",
      "           6       0.60      0.88      0.72       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.57      0.45      0.50       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 6700, Loss: 7.090464115142822, F1: 0.5960130234302992, Accuracy: 0.5323790516826096, Time Elapsed: 1213.5296640396118 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.68       912\n",
      "           1       0.61      0.82      0.70       885\n",
      "           2       0.59      0.47      0.52       877\n",
      "           3       0.61      0.35      0.45       897\n",
      "           4       0.47      0.89      0.61       892\n",
      "           5       0.52      0.41      0.46       862\n",
      "           6       0.61      0.20      0.30       903\n",
      "           7       0.60      0.55      0.58       889\n",
      "           8       0.56      0.38      0.45       892\n",
      "           9       0.56      0.54      0.55       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.52     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 3, Step 6800, Loss: 1.1538145542144775, F1: 0.5189433445953667, Accuracy: 0.491363292271695, Time Elapsed: 1229.6256129741669 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.60      0.50      0.54       897\n",
      "           4       0.46      0.93      0.62       892\n",
      "           5       0.51      0.68      0.58       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.60      0.57      0.59       889\n",
      "           8       0.50      0.68      0.58       892\n",
      "           9       0.61      0.45      0.52       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 6900, Loss: 0.5641670227050781, F1: 0.5792294057732544, Accuracy: 0.5154497281673663, Time Elapsed: 1245.4459040164948 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.61      0.88      0.72       885\n",
      "           2       0.62      0.48      0.54       877\n",
      "           3       0.60      0.65      0.63       897\n",
      "           4       0.56      0.65      0.60       892\n",
      "           5       0.56      0.58      0.57       862\n",
      "           6       0.59      0.82      0.68       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.57      0.71      0.63       892\n",
      "           9       0.58      0.54      0.56       876\n",
      "          10       0.40      0.27      0.33      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.66      0.60     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 3, Step 7000, Loss: 0.92751544713974, F1: 0.604219924458943, Accuracy: 0.5369210653086505, Time Elapsed: 1261.7635550498962 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.61      0.90      0.72       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.59      0.30      0.40       892\n",
      "           5       0.58      0.42      0.49       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.58      0.78      0.66       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.52      0.74      0.61       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.59      0.53     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 7100, Loss: 1.0296071767807007, F1: 0.5347106725375027, Accuracy: 0.5149679994494529, Time Elapsed: 1278.3693318367004 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.61      0.41      0.49       877\n",
      "           3       0.59      0.41      0.48       897\n",
      "           4       0.47      0.85      0.60       892\n",
      "           5       0.60      0.32      0.41       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.55      0.83      0.66       889\n",
      "           8       0.58      0.62      0.60       892\n",
      "           9       0.60      0.43      0.50       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 7200, Loss: 0.5872665047645569, F1: 0.55753669802881, Accuracy: 0.5110453513178721, Time Elapsed: 1293.6302750110626 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.60      0.92      0.72       885\n",
      "           2       0.60      0.70      0.65       877\n",
      "           3       0.61      0.57      0.59       897\n",
      "           4       0.54      0.79      0.64       892\n",
      "           5       0.56      0.62      0.59       862\n",
      "           6       0.63      0.71      0.66       903\n",
      "           7       0.62      0.45      0.52       889\n",
      "           8       0.60      0.56      0.58       892\n",
      "           9       0.53      0.71      0.61       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 7300, Loss: 4.869577884674072, F1: 0.5999466352020338, Accuracy: 0.5330672355653431, Time Elapsed: 1309.2135410308838 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       912\n",
      "           1       0.64      0.47      0.54       885\n",
      "           2       0.66      0.09      0.16       877\n",
      "           3       0.61      0.61      0.61       897\n",
      "           4       0.47      0.85      0.60       892\n",
      "           5       0.58      0.40      0.47       862\n",
      "           6       0.61      0.05      0.09       903\n",
      "           7       0.61      0.42      0.50       889\n",
      "           8       0.60      0.53      0.56       892\n",
      "           9       0.59      0.24      0.34       876\n",
      "          10       0.40      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.46      0.46     14531\n",
      "weighted avg       0.52      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 7400, Loss: 0.7792521119117737, F1: 0.4583448210149182, Accuracy: 0.4823480834078866, Time Elapsed: 1325.1715559959412 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.61      0.71      0.66       885\n",
      "           2       0.71      0.09      0.17       877\n",
      "           3       0.59      0.37      0.46       897\n",
      "           4       0.56      0.43      0.49       892\n",
      "           5       0.56      0.16      0.25       862\n",
      "           6       0.62      0.74      0.67       903\n",
      "           7       0.45      0.94      0.61       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.49      0.65      0.56       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.48      0.45     14531\n",
      "weighted avg       0.47      0.48      0.44     14531\n",
      "\n",
      "Epoch 3, Step 7500, Loss: 1.0611329078674316, F1: 0.45051522138860567, Accuracy: 0.47808134333493907, Time Elapsed: 1341.1996879577637 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.63      0.06      0.11       877\n",
      "           3       0.59      0.73      0.65       897\n",
      "           4       0.57      0.41      0.48       892\n",
      "           5       0.58      0.20      0.29       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.60      0.33      0.43       892\n",
      "           9       0.59      0.53      0.56       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 7600, Loss: 1.1926907300949097, F1: 0.5075159035931432, Accuracy: 0.5016172321244237, Time Elapsed: 1356.6987709999084 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.62      0.69      0.65       885\n",
      "           2       0.64      0.23      0.34       877\n",
      "           3       0.43      0.93      0.59       897\n",
      "           4       0.55      0.72      0.63       892\n",
      "           5       0.56      0.14      0.22       862\n",
      "           6       0.60      0.86      0.71       903\n",
      "           7       0.63      0.33      0.43       889\n",
      "           8       0.60      0.57      0.58       892\n",
      "           9       0.61      0.17      0.26       876\n",
      "          10       0.40      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.50     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 7700, Loss: 0.1951131373643875, F1: 0.5018508276056819, Accuracy: 0.4958364875094625, Time Elapsed: 1371.409292936325 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.61      0.59      0.60       877\n",
      "           3       0.53      0.85      0.66       897\n",
      "           4       0.59      0.52      0.55       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.47      0.89      0.62       889\n",
      "           8       0.59      0.56      0.57       892\n",
      "           9       0.59      0.39      0.47       876\n",
      "          10       0.40      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 7800, Loss: 0.8131570219993591, F1: 0.5855435114604721, Accuracy: 0.5240520267015346, Time Elapsed: 1386.9606289863586 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62       912\n",
      "           1       0.61      0.73      0.66       885\n",
      "           2       0.61      0.53      0.57       877\n",
      "           3       0.60      0.55      0.57       897\n",
      "           4       0.53      0.69      0.60       892\n",
      "           5       0.57      0.51      0.54       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.55      0.80      0.65       889\n",
      "           8       0.58      0.43      0.50       892\n",
      "           9       0.61      0.31      0.41       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.56     14531\n",
      "weighted avg       0.51      0.51      0.51     14531\n",
      "\n",
      "Epoch 3, Step 7900, Loss: 0.883981466293335, F1: 0.5601355647167993, Accuracy: 0.5109765329295988, Time Elapsed: 1404.3328349590302 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59       912\n",
      "           1       0.60      0.61      0.61       885\n",
      "           2       0.60      0.64      0.61       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.55      0.58      0.56       892\n",
      "           5       0.58      0.18      0.27       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.53      0.76      0.62       892\n",
      "           9       0.54      0.67      0.60       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 8000, Loss: 0.6326078772544861, F1: 0.5474590164926073, Accuracy: 0.507260339962838, Time Elapsed: 1420.3308169841766 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       912\n",
      "           1       0.61      0.81      0.70       885\n",
      "           2       0.57      0.77      0.65       877\n",
      "           3       0.57      0.77      0.66       897\n",
      "           4       0.57      0.48      0.52       892\n",
      "           5       0.57      0.30      0.39       862\n",
      "           6       0.63      0.63      0.63       903\n",
      "           7       0.61      0.52      0.56       889\n",
      "           8       0.55      0.77      0.64       892\n",
      "           9       0.50      0.54      0.52       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 8100, Loss: 1.566864013671875, F1: 0.5657655176668022, Accuracy: 0.5131099029660725, Time Elapsed: 1437.0731618404388 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.58      0.59      0.59       897\n",
      "           4       0.55      0.68      0.61       892\n",
      "           5       0.58      0.38      0.46       862\n",
      "           6       0.64      0.58      0.61       903\n",
      "           7       0.60      0.52      0.56       889\n",
      "           8       0.60      0.32      0.42       892\n",
      "           9       0.55      0.65      0.59       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.55     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 3, Step 8200, Loss: 0.6544318199157715, F1: 0.5481222238508087, Accuracy: 0.5040258757139908, Time Elapsed: 1455.398360967636 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.58      0.73      0.64       897\n",
      "           4       0.55      0.73      0.63       892\n",
      "           5       0.56      0.63      0.59       862\n",
      "           6       0.62      0.71      0.67       903\n",
      "           7       0.61      0.51      0.55       889\n",
      "           8       0.57      0.65      0.61       892\n",
      "           9       0.62      0.19      0.30       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.58      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 8300, Loss: 1.0988614559173584, F1: 0.5641807847611506, Accuracy: 0.515587364943913, Time Elapsed: 1474.0905990600586 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.34      0.44       912\n",
      "           1       0.57      0.92      0.71       885\n",
      "           2       0.59      0.65      0.61       877\n",
      "           3       0.58      0.13      0.21       897\n",
      "           4       0.49      0.89      0.63       892\n",
      "           5       0.56      0.38      0.45       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.61      0.62      0.61       889\n",
      "           8       0.55      0.76      0.64       892\n",
      "           9       0.66      0.11      0.19       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.51     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 8400, Loss: 0.2806614339351654, F1: 0.5073416176513892, Accuracy: 0.4952859404032758, Time Elapsed: 1491.8870949745178 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.54       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.59      0.67      0.63       877\n",
      "           3       0.58      0.42      0.49       897\n",
      "           4       0.56      0.69      0.62       892\n",
      "           5       0.52      0.69      0.59       862\n",
      "           6       0.65      0.39      0.49       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.60      0.43      0.51       892\n",
      "           9       0.67      0.09      0.16       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.53      0.53     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 8500, Loss: 0.3371838927268982, F1: 0.5265369020767071, Accuracy: 0.5024430527837038, Time Elapsed: 1508.2140400409698 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.24      0.35       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.62      0.40      0.49       877\n",
      "           3       0.58      0.77      0.66       897\n",
      "           4       0.54      0.78      0.64       892\n",
      "           5       0.59      0.42      0.49       862\n",
      "           6       0.65      0.35      0.46       903\n",
      "           7       0.55      0.91      0.69       889\n",
      "           8       0.58      0.63      0.60       892\n",
      "           9       0.57      0.22      0.32       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.53     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 8600, Loss: 0.909440279006958, F1: 0.5273354980790423, Accuracy: 0.5045764228201776, Time Elapsed: 1525.0252132415771 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71       912\n",
      "           1       0.59      0.49      0.54       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.59      0.52      0.56       897\n",
      "           4       0.50      0.80      0.62       892\n",
      "           5       0.57      0.51      0.54       862\n",
      "           6       0.60      0.74      0.66       903\n",
      "           7       0.57      0.86      0.69       889\n",
      "           8       0.52      0.78      0.63       892\n",
      "           9       0.54      0.58      0.56       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 8700, Loss: 1.6721217632293701, F1: 0.5809283629083271, Accuracy: 0.5179960085334802, Time Elapsed: 1540.761381149292 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.67       912\n",
      "           1       0.61      0.69      0.65       885\n",
      "           2       0.57      0.76      0.65       877\n",
      "           3       0.55      0.80      0.65       897\n",
      "           4       0.48      0.87      0.62       892\n",
      "           5       0.55      0.64      0.59       862\n",
      "           6       0.62      0.67      0.64       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.51      0.81      0.63       892\n",
      "           9       0.59      0.32      0.41       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 8800, Loss: 1.536877155303955, F1: 0.5887107671044336, Accuracy: 0.5228132957126144, Time Elapsed: 1557.102068901062 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.60       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.62      0.46      0.53       877\n",
      "           3       0.59      0.75      0.66       897\n",
      "           4       0.49      0.86      0.62       892\n",
      "           5       0.52      0.63      0.57       862\n",
      "           6       0.62      0.67      0.65       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.57      0.77      0.66       892\n",
      "           9       0.60      0.41      0.49       876\n",
      "          10       0.40      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 3, Step 8900, Loss: 1.2355690002441406, F1: 0.5905426635990745, Accuracy: 0.5272176725621086, Time Elapsed: 1574.2957229614258 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.65       912\n",
      "           1       0.62      0.62      0.62       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.59      0.74      0.65       897\n",
      "           4       0.53      0.79      0.64       892\n",
      "           5       0.57      0.27      0.36       862\n",
      "           6       0.63      0.52      0.57       903\n",
      "           7       0.60      0.59      0.60       889\n",
      "           8       0.59      0.66      0.62       892\n",
      "           9       0.58      0.23      0.33       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.51      0.50     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 9000, Loss: 1.0621178150177002, F1: 0.49744005921041407, Accuracy: 0.49796985754593626, Time Elapsed: 1590.1985001564026 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.81      0.68       912\n",
      "           1       0.50      0.02      0.03       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.60      0.34      0.44       897\n",
      "           4       0.57      0.57      0.57       892\n",
      "           5       0.59      0.40      0.48       862\n",
      "           6       0.62      0.65      0.63       903\n",
      "           7       0.58      0.33      0.42       889\n",
      "           8       0.58      0.70      0.64       892\n",
      "           9       0.55      0.60      0.58       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.50      0.50     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 3, Step 9100, Loss: 0.457677960395813, F1: 0.5002203780101935, Accuracy: 0.4941848461909022, Time Elapsed: 1604.8655049800873 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69       912\n",
      "           1       0.54      0.99      0.70       885\n",
      "           2       0.60      0.65      0.62       877\n",
      "           3       0.60      0.35      0.44       897\n",
      "           4       0.58      0.52      0.55       892\n",
      "           5       0.59      0.45      0.51       862\n",
      "           6       0.63      0.72      0.67       903\n",
      "           7       0.60      0.82      0.69       889\n",
      "           8       0.60      0.55      0.57       892\n",
      "           9       0.53      0.74      0.62       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 9200, Loss: 0.4025226831436157, F1: 0.5834635783300832, Accuracy: 0.5254283944670016, Time Elapsed: 1619.700313091278 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.56      0.81      0.66       877\n",
      "           3       0.62      0.51      0.56       897\n",
      "           4       0.60      0.45      0.51       892\n",
      "           5       0.59      0.30      0.40       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.57      0.33      0.42       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.60      0.57     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 9300, Loss: 0.4032084047794342, F1: 0.5725935381530566, Accuracy: 0.5240520267015346, Time Elapsed: 1634.756690979004 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.65       912\n",
      "           1       0.63      0.48      0.54       885\n",
      "           2       0.63      0.41      0.50       877\n",
      "           3       0.61      0.45      0.51       897\n",
      "           4       0.61      0.29      0.40       892\n",
      "           5       0.58      0.18      0.28       862\n",
      "           6       0.63      0.39      0.49       903\n",
      "           7       0.60      0.55      0.58       889\n",
      "           8       0.53      0.72      0.61       892\n",
      "           9       0.58      0.12      0.20       876\n",
      "          10       0.39      0.57      0.47      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.44      0.48     14531\n",
      "weighted avg       0.52      0.48      0.47     14531\n",
      "\n",
      "Epoch 3, Step 9400, Loss: 0.7479690909385681, F1: 0.4752264830823212, Accuracy: 0.4848255453857271, Time Elapsed: 1652.7428340911865 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.19      0.29       912\n",
      "           1       0.58      0.41      0.48       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.58      0.41      0.48       892\n",
      "           5       0.56      0.44      0.49       862\n",
      "           6       0.58      0.84      0.69       903\n",
      "           7       0.60      0.28      0.38       889\n",
      "           8       0.61      0.30      0.40       892\n",
      "           9       0.51      0.84      0.63       876\n",
      "          10       0.38      0.52      0.44      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.51      0.45      0.45     14531\n",
      "weighted avg       0.47      0.47      0.44     14531\n",
      "\n",
      "Epoch 3, Step 9500, Loss: 0.5014516711235046, F1: 0.4458729918482765, Accuracy: 0.46899731608285733, Time Elapsed: 1669.674332857132 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67       912\n",
      "           1       0.58      0.12      0.20       885\n",
      "           2       0.57      0.72      0.63       877\n",
      "           3       0.59      0.39      0.47       897\n",
      "           4       0.58      0.56      0.57       892\n",
      "           5       0.56      0.53      0.55       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.60      0.52      0.55       892\n",
      "           9       0.62      0.53      0.57       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 9600, Loss: 1.127721905708313, F1: 0.5455520814320146, Accuracy: 0.5100818938820453, Time Elapsed: 1686.1556451320648 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.86      0.69       912\n",
      "           1       0.54      0.03      0.06       885\n",
      "           2       0.57      0.70      0.62       877\n",
      "           3       0.60      0.48      0.53       897\n",
      "           4       0.61      0.33      0.42       892\n",
      "           5       0.59      0.12      0.20       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.59      0.67      0.62       892\n",
      "           9       0.58      0.15      0.24       876\n",
      "          10       0.40      0.51      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.48      0.47     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 3, Step 9700, Loss: 0.1550794392824173, F1: 0.4683045048301551, Accuracy: 0.49205147615442846, Time Elapsed: 1702.531728029251 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68       912\n",
      "           1       0.41      0.02      0.04       885\n",
      "           2       0.63      0.21      0.32       877\n",
      "           3       0.59      0.29      0.39       897\n",
      "           4       0.52      0.79      0.62       892\n",
      "           5       0.55      0.32      0.40       862\n",
      "           6       0.59      0.57      0.58       903\n",
      "           7       0.60      0.49      0.54       889\n",
      "           8       0.59      0.56      0.58       892\n",
      "           9       0.55      0.70      0.62       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.47      0.47     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 9800, Loss: 0.6701760292053223, F1: 0.47164650443222733, Accuracy: 0.4817975363016998, Time Elapsed: 1718.8085050582886 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.89      0.66       912\n",
      "           1       0.48      0.02      0.05       885\n",
      "           2       0.62      0.06      0.11       877\n",
      "           3       0.53      0.80      0.64       897\n",
      "           4       0.59      0.46      0.52       892\n",
      "           5       0.55      0.32      0.41       862\n",
      "           6       0.60      0.73      0.66       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.59      0.38      0.46       892\n",
      "           9       0.53      0.78      0.63       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.51      0.47     14531\n",
      "weighted avg       0.50      0.49      0.45     14531\n",
      "\n",
      "Epoch 3, Step 9900, Loss: 1.1340914964675903, F1: 0.4707244105263989, Accuracy: 0.4864771867042874, Time Elapsed: 1734.3204860687256 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.44      0.08      0.14       885\n",
      "           2       0.56      0.66      0.61       877\n",
      "           3       0.56      0.69      0.62       897\n",
      "           4       0.45      0.88      0.59       892\n",
      "           5       0.56      0.31      0.40       862\n",
      "           6       0.57      0.84      0.68       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.56      0.69      0.62       892\n",
      "           9       0.60      0.44      0.51       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.59      0.53     14531\n",
      "weighted avg       0.49      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 10000, Loss: 1.9551894664764404, F1: 0.5337902782548328, Accuracy: 0.5012731401830569, Time Elapsed: 1749.969276189804 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.32      0.42       912\n",
      "           1       0.58      0.21      0.31       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.58      0.75      0.65       897\n",
      "           4       0.56      0.55      0.56       892\n",
      "           5       0.49      0.65      0.56       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.57      0.88      0.69       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.46      0.84      0.60       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.58      0.54     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 10100, Loss: 1.3857285976409912, F1: 0.5436143626364659, Accuracy: 0.5009978666299635, Time Elapsed: 1765.9517228603363 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.62      0.01      0.03       885\n",
      "           2       0.43      0.87      0.57       877\n",
      "           3       0.58      0.72      0.64       897\n",
      "           4       0.43      0.89      0.58       892\n",
      "           5       0.57      0.25      0.35       862\n",
      "           6       0.56      0.89      0.68       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.58      0.34      0.43       892\n",
      "           9       0.60      0.43      0.50       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.57      0.50     14531\n",
      "weighted avg       0.49      0.49      0.45     14531\n",
      "\n",
      "Epoch 3, Step 10200, Loss: 1.6032382249832153, F1: 0.4983623076269193, Accuracy: 0.48558254765673386, Time Elapsed: 1781.0554258823395 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71       912\n",
      "           1       0.59      0.73      0.65       885\n",
      "           2       0.55      0.72      0.63       877\n",
      "           3       0.52      0.85      0.65       897\n",
      "           4       0.51      0.79      0.62       892\n",
      "           5       0.58      0.37      0.45       862\n",
      "           6       0.56      0.91      0.69       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.56      0.69      0.61       892\n",
      "           9       0.54      0.79      0.64       876\n",
      "          10       0.39      0.16      0.23      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.54      0.70      0.60     14531\n",
      "weighted avg       0.49      0.53      0.48     14531\n",
      "\n",
      "Epoch 3, Step 10300, Loss: 1.2614867687225342, F1: 0.5970502078376172, Accuracy: 0.5283875851627555, Time Elapsed: 1796.477651834488 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.59      0.81      0.68       897\n",
      "           4       0.58      0.53      0.56       892\n",
      "           5       0.57      0.48      0.52       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.61      0.50      0.55       892\n",
      "           9       0.58      0.19      0.28       876\n",
      "          10       0.40      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 10400, Loss: 1.6393486261367798, F1: 0.5735936946359161, Accuracy: 0.5252907576904549, Time Elapsed: 1812.3673009872437 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.60      0.38      0.46       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.59      0.44      0.51       897\n",
      "           4       0.58      0.65      0.61       892\n",
      "           5       0.57      0.48      0.52       862\n",
      "           6       0.60      0.82      0.70       903\n",
      "           7       0.60      0.39      0.47       889\n",
      "           8       0.59      0.41      0.49       892\n",
      "           9       0.66      0.09      0.15       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 10500, Loss: 0.5810733437538147, F1: 0.5151474465404179, Accuracy: 0.4985892230403964, Time Elapsed: 1828.7433462142944 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.69       912\n",
      "           1       0.61      0.67      0.64       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.61      0.62      0.61       897\n",
      "           4       0.53      0.88      0.66       892\n",
      "           5       0.54      0.63      0.58       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.58      0.87      0.69       889\n",
      "           8       0.61      0.55      0.58       892\n",
      "           9       0.55      0.77      0.64       876\n",
      "          10       0.40      0.23      0.30      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.68      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 3, Step 10600, Loss: 0.7603214383125305, F1: 0.6097777869575195, Accuracy: 0.5371275204734706, Time Elapsed: 1843.938346862793 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66       912\n",
      "           1       0.66      0.03      0.06       885\n",
      "           2       0.49      0.79      0.61       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.60      0.42      0.50       892\n",
      "           5       0.56      0.36      0.44       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.57      0.88      0.69       889\n",
      "           8       0.58      0.27      0.37       892\n",
      "           9       0.53      0.69      0.60       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 10700, Loss: 2.4402525424957275, F1: 0.5023909541708124, Accuracy: 0.494735393297089, Time Elapsed: 1858.7207548618317 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.60      0.71      0.65       885\n",
      "           2       0.62      0.43      0.50       877\n",
      "           3       0.60      0.55      0.57       897\n",
      "           4       0.50      0.92      0.65       892\n",
      "           5       0.56      0.23      0.33       862\n",
      "           6       0.63      0.37      0.46       903\n",
      "           7       0.58      0.73      0.65       889\n",
      "           8       0.58      0.55      0.57       892\n",
      "           9       0.61      0.53      0.57       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 10800, Loss: 2.7124814987182617, F1: 0.5485642279559239, Accuracy: 0.5091872548344918, Time Elapsed: 1874.709682226181 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.55      0.91      0.69       885\n",
      "           2       0.57      0.67      0.62       877\n",
      "           3       0.59      0.60      0.59       897\n",
      "           4       0.56      0.76      0.65       892\n",
      "           5       0.56      0.45      0.50       862\n",
      "           6       0.63      0.71      0.66       903\n",
      "           7       0.56      0.89      0.69       889\n",
      "           8       0.59      0.47      0.52       892\n",
      "           9       0.58      0.66      0.62       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 10900, Loss: 0.20909130573272705, F1: 0.5944741459053569, Accuracy: 0.5295574977634023, Time Elapsed: 1890.3714890480042 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39       912\n",
      "           1       0.47      0.01      0.02       885\n",
      "           2       0.61      0.55      0.58       877\n",
      "           3       0.52      0.69      0.59       897\n",
      "           4       0.57      0.62      0.59       892\n",
      "           5       0.54      0.46      0.49       862\n",
      "           6       0.61      0.22      0.33       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.49      0.53      0.51       892\n",
      "           9       0.57      0.69      0.62       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.47      0.47     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 11000, Loss: 1.3959529399871826, F1: 0.471992421085908, Accuracy: 0.477461977840479, Time Elapsed: 1905.8256680965424 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.02      0.03       912\n",
      "           1       0.59      0.59      0.59       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.47      0.87      0.61       897\n",
      "           4       0.59      0.16      0.25       892\n",
      "           5       0.53      0.60      0.56       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.60      0.48      0.53       889\n",
      "           8       0.53      0.50      0.52       892\n",
      "           9       0.55      0.78      0.65       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.51      0.49     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 11100, Loss: 1.0909596681594849, F1: 0.48820987086030404, Accuracy: 0.48262335696097997, Time Elapsed: 1920.7403161525726 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       912\n",
      "           1       0.56      0.69      0.62       885\n",
      "           2       0.57      0.65      0.61       877\n",
      "           3       0.61      0.36      0.46       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.50      0.56      0.53       862\n",
      "           6       0.63      0.63      0.63       903\n",
      "           7       0.62      0.24      0.34       889\n",
      "           8       0.51      0.45      0.48       892\n",
      "           9       0.58      0.57      0.58       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 11200, Loss: 1.6325223445892334, F1: 0.5409337901684754, Accuracy: 0.5007914114651435, Time Elapsed: 1936.8553869724274 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.61      0.84      0.71       885\n",
      "           2       0.55      0.75      0.64       877\n",
      "           3       0.59      0.62      0.60       897\n",
      "           4       0.58      0.44      0.50       892\n",
      "           5       0.59      0.40      0.48       862\n",
      "           6       0.61      0.70      0.66       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.55      0.53      0.54       892\n",
      "           9       0.48      0.72      0.57       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 11300, Loss: 0.218738853931427, F1: 0.5815533280372995, Accuracy: 0.5183401004748469, Time Elapsed: 1953.162931919098 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.68       912\n",
      "           1       0.57      0.88      0.69       885\n",
      "           2       0.55      0.73      0.63       877\n",
      "           3       0.59      0.19      0.28       897\n",
      "           4       0.61      0.27      0.38       892\n",
      "           5       0.55      0.18      0.27       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.57      0.52      0.54       892\n",
      "           9       0.43      0.14      0.22       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.51      0.49     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 11400, Loss: 1.5457310676574707, F1: 0.49384622849028176, Accuracy: 0.49260202326061525, Time Elapsed: 1967.9640529155731 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.60      0.66      0.63       885\n",
      "           2       0.55      0.74      0.63       877\n",
      "           3       0.58      0.73      0.64       897\n",
      "           4       0.56      0.55      0.55       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.63      0.56      0.59       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.54      0.60      0.56       892\n",
      "           9       0.58      0.37      0.46       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.51      0.51     14531\n",
      "\n",
      "Epoch 3, Step 11500, Loss: 0.577633261680603, F1: 0.5740887719445568, Accuracy: 0.5147615442846328, Time Elapsed: 1983.651239156723 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69       912\n",
      "           1       0.60      0.82      0.70       885\n",
      "           2       0.56      0.70      0.63       877\n",
      "           3       0.60      0.68      0.64       897\n",
      "           4       0.54      0.78      0.64       892\n",
      "           5       0.58      0.33      0.42       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.61      0.18      0.27       892\n",
      "           9       0.55      0.74      0.63       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.58     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 3, Step 11600, Loss: 0.5558343529701233, F1: 0.5757931953758099, Accuracy: 0.5257724864083683, Time Elapsed: 1999.394634962082 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.71       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.62      0.46      0.53       897\n",
      "           4       0.57      0.67      0.62       892\n",
      "           5       0.58      0.16      0.24       862\n",
      "           6       0.60      0.79      0.69       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.53      0.79      0.64       892\n",
      "           9       0.54      0.61      0.57       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 11700, Loss: 4.388785362243652, F1: 0.572760589540502, Accuracy: 0.5244649370311747, Time Elapsed: 2015.6046109199524 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.58      0.89      0.70       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.60      0.65      0.62       897\n",
      "           4       0.48      0.93      0.63       892\n",
      "           5       0.54      0.51      0.53       862\n",
      "           6       0.61      0.46      0.52       903\n",
      "           7       0.60      0.60      0.60       889\n",
      "           8       0.55      0.70      0.62       892\n",
      "           9       0.51      0.79      0.62       876\n",
      "          10       0.38      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.58     14531\n",
      "weighted avg       0.49      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 11800, Loss: 1.1065807342529297, F1: 0.5843858670941359, Accuracy: 0.5152432730025462, Time Elapsed: 2030.4486620426178 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.72       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.58      0.54      0.56       877\n",
      "           3       0.61      0.63      0.62       897\n",
      "           4       0.56      0.54      0.55       892\n",
      "           5       0.56      0.26      0.36       862\n",
      "           6       0.63      0.39      0.48       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.59      0.56      0.57       892\n",
      "           9       0.60      0.60      0.60       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 11900, Loss: 0.5579276084899902, F1: 0.5671959372539436, Accuracy: 0.5182024636983001, Time Elapsed: 2045.3440492153168 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.17      0.26       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.58      0.52      0.55       892\n",
      "           5       0.53      0.58      0.56       862\n",
      "           6       0.62      0.11      0.18       903\n",
      "           7       0.58      0.87      0.69       889\n",
      "           8       0.59      0.45      0.51       892\n",
      "           9       0.53      0.67      0.60       876\n",
      "          10       0.38      0.50      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.47      0.46     14531\n",
      "weighted avg       0.47      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 12000, Loss: 1.0206608772277832, F1: 0.45717268023223206, Accuracy: 0.48007707659486615, Time Elapsed: 2061.496286869049 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.59      0.67      0.63       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.50      0.92      0.64       892\n",
      "           5       0.57      0.47      0.51       862\n",
      "           6       0.63      0.62      0.63       903\n",
      "           7       0.61      0.39      0.48       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.59      0.69      0.63       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 12100, Loss: 0.5765864253044128, F1: 0.5847500728612203, Accuracy: 0.5246025738077215, Time Elapsed: 2076.892565011978 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.59      0.86      0.70       885\n",
      "           2       0.57      0.71      0.64       877\n",
      "           3       0.58      0.78      0.67       897\n",
      "           4       0.59      0.58      0.58       892\n",
      "           5       0.57      0.19      0.28       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.62      0.49      0.55       889\n",
      "           8       0.60      0.61      0.60       892\n",
      "           9       0.57      0.65      0.61       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 12200, Loss: 0.748683750629425, F1: 0.5806004746116165, Accuracy: 0.5283187667744822, Time Elapsed: 2091.5792129039764 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.73       912\n",
      "           1       0.60      0.85      0.71       885\n",
      "           2       0.58      0.65      0.61       877\n",
      "           3       0.62      0.51      0.56       897\n",
      "           4       0.62      0.36      0.45       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.63      0.73      0.67       903\n",
      "           7       0.62      0.57      0.59       889\n",
      "           8       0.53      0.82      0.64       892\n",
      "           9       0.58      0.64      0.61       876\n",
      "          10       0.40      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.58      0.62      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 12300, Loss: 0.7343854904174805, F1: 0.5868192526198756, Accuracy: 0.5288693138806689, Time Elapsed: 2111.9430000782013 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.72       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.55      0.80      0.65       877\n",
      "           3       0.58      0.78      0.67       897\n",
      "           4       0.61      0.28      0.38       892\n",
      "           5       0.59      0.33      0.43       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.61      0.53      0.57       892\n",
      "           9       0.56      0.53      0.54       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 12400, Loss: 0.9534815549850464, F1: 0.5773596162633777, Accuracy: 0.5250154841373615, Time Elapsed: 2133.165477991104 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.56      0.77      0.65       877\n",
      "           3       0.61      0.62      0.61       897\n",
      "           4       0.53      0.88      0.66       892\n",
      "           5       0.51      0.72      0.60       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.55      0.76      0.64       892\n",
      "           9       0.57      0.69      0.63       876\n",
      "          10       0.39      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.70      0.61     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 3, Step 12500, Loss: 1.6312772035598755, F1: 0.6077422697988173, Accuracy: 0.5335489642832565, Time Elapsed: 2154.336280107498 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.58      0.49      0.54       877\n",
      "           3       0.61      0.59      0.60       897\n",
      "           4       0.64      0.19      0.29       892\n",
      "           5       0.52      0.52      0.52       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.61      0.72      0.66       889\n",
      "           8       0.60      0.47      0.52       892\n",
      "           9       0.51      0.80      0.62       876\n",
      "          10       0.39      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 12600, Loss: 1.778548002243042, F1: 0.5651887300440674, Accuracy: 0.5182712820865736, Time Elapsed: 2171.6853580474854 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.68      0.64       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.61      0.65      0.63       897\n",
      "           4       0.55      0.74      0.63       892\n",
      "           5       0.53      0.60      0.57       862\n",
      "           6       0.61      0.49      0.54       903\n",
      "           7       0.61      0.70      0.65       889\n",
      "           8       0.60      0.53      0.56       892\n",
      "           9       0.55      0.73      0.63       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.55      0.53     14531\n",
      "weighted avg       0.47      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 12700, Loss: 0.605501115322113, F1: 0.5303812884128055, Accuracy: 0.5035441469960773, Time Elapsed: 2187.2541530132294 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.30      0.41       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.59      0.58      0.59       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.58      0.64      0.61       892\n",
      "           5       0.56      0.28      0.37       862\n",
      "           6       0.63      0.33      0.43       903\n",
      "           7       0.61      0.45      0.52       889\n",
      "           8       0.60      0.35      0.44       892\n",
      "           9       0.51      0.84      0.63       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.47      0.47     14531\n",
      "weighted avg       0.48      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 12800, Loss: 0.8983965516090393, F1: 0.4690717306076266, Accuracy: 0.4823480834078866, Time Elapsed: 2201.7373859882355 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.62      0.64      0.63       885\n",
      "           2       0.57      0.47      0.52       877\n",
      "           3       0.61      0.56      0.59       897\n",
      "           4       0.58      0.59      0.58       892\n",
      "           5       0.58      0.35      0.44       862\n",
      "           6       0.61      0.83      0.70       903\n",
      "           7       0.60      0.59      0.60       889\n",
      "           8       0.56      0.68      0.61       892\n",
      "           9       0.59      0.50      0.55       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 12900, Loss: 1.7353123426437378, F1: 0.5720432975271609, Accuracy: 0.5188218291927603, Time Elapsed: 2216.715036869049 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.59      0.60      0.59       897\n",
      "           4       0.56      0.73      0.64       892\n",
      "           5       0.51      0.67      0.58       862\n",
      "           6       0.63      0.61      0.62       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.55      0.67      0.60       892\n",
      "           9       0.62      0.20      0.30       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.54      0.51     14531\n",
      "weighted avg       0.47      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 13000, Loss: 1.7297009229660034, F1: 0.5102043234650413, Accuracy: 0.49652467139219597, Time Elapsed: 2231.5391330718994 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.59      0.65      0.62       897\n",
      "           4       0.56      0.79      0.65       892\n",
      "           5       0.48      0.76      0.59       862\n",
      "           6       0.62      0.42      0.50       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.56      0.69      0.62       892\n",
      "           9       0.57      0.69      0.63       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 3, Step 13100, Loss: 1.1326991319656372, F1: 0.597968216144788, Accuracy: 0.5271488541738353, Time Elapsed: 2246.887871980667 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.58      0.68      0.63       877\n",
      "           3       0.56      0.82      0.67       897\n",
      "           4       0.54      0.73      0.62       892\n",
      "           5       0.50      0.67      0.57       862\n",
      "           6       0.63      0.58      0.60       903\n",
      "           7       0.61      0.57      0.59       889\n",
      "           8       0.56      0.60      0.58       892\n",
      "           9       0.42      0.91      0.58       876\n",
      "          10       0.39      0.19      0.26      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.68      0.59     14531\n",
      "weighted avg       0.49      0.52      0.48     14531\n",
      "\n",
      "Epoch 3, Step 13200, Loss: 0.5106571316719055, F1: 0.5903928168787177, Accuracy: 0.5178583717569335, Time Elapsed: 2261.357962846756 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.63      0.24      0.35       885\n",
      "           2       0.59      0.43      0.49       877\n",
      "           3       0.61      0.68      0.65       897\n",
      "           4       0.55      0.78      0.65       892\n",
      "           5       0.55      0.33      0.41       862\n",
      "           6       0.62      0.53      0.57       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.51      0.79      0.62       892\n",
      "           9       0.59      0.59      0.59       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 13300, Loss: 0.21636413037776947, F1: 0.5476368024468745, Accuracy: 0.5064345193035579, Time Elapsed: 2276.811710834503 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.54      0.75      0.63       892\n",
      "           5       0.57      0.35      0.44       862\n",
      "           6       0.62      0.54      0.58       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.57      0.64      0.60       892\n",
      "           9       0.61      0.11      0.19       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 13400, Loss: 1.164119005203247, F1: 0.5556066044373694, Accuracy: 0.5153120913908197, Time Elapsed: 2292.458275079727 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.89      0.70       912\n",
      "           1       0.44      0.00      0.01       885\n",
      "           2       0.56      0.75      0.64       877\n",
      "           3       0.54      0.82      0.65       897\n",
      "           4       0.60      0.35      0.44       892\n",
      "           5       0.57      0.37      0.45       862\n",
      "           6       0.62      0.24      0.35       903\n",
      "           7       0.61      0.56      0.59       889\n",
      "           8       0.57      0.62      0.59       892\n",
      "           9       0.57      0.67      0.62       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.52      0.50     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 13500, Loss: 2.946742057800293, F1: 0.49549773615165355, Accuracy: 0.4923267497075218, Time Elapsed: 2308.1142020225525 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.60      0.57      0.58       897\n",
      "           4       0.57      0.57      0.57       892\n",
      "           5       0.58      0.42      0.49       862\n",
      "           6       0.64      0.52      0.58       903\n",
      "           7       0.62      0.27      0.37       889\n",
      "           8       0.60      0.48      0.53       892\n",
      "           9       0.59      0.42      0.49       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.49      0.49     14531\n",
      "weighted avg       0.48      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 13600, Loss: 0.5496973395347595, F1: 0.4898275989350683, Accuracy: 0.49108801871860164, Time Elapsed: 2323.1641578674316 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.59      0.74      0.66       897\n",
      "           4       0.50      0.83      0.62       892\n",
      "           5       0.57      0.44      0.49       862\n",
      "           6       0.64      0.33      0.43       903\n",
      "           7       0.63      0.32      0.42       889\n",
      "           8       0.58      0.66      0.61       892\n",
      "           9       0.60      0.35      0.44       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.60      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 13700, Loss: 1.1174652576446533, F1: 0.5578749790987494, Accuracy: 0.5136604500722594, Time Elapsed: 2337.7930240631104 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.65       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.55      0.79      0.65       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.55      0.64      0.59       892\n",
      "           5       0.59      0.04      0.07       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.59      0.56      0.58       889\n",
      "           8       0.60      0.45      0.52       892\n",
      "           9       0.60      0.40      0.48       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.54     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 13800, Loss: 0.42494142055511475, F1: 0.5372539679834971, Accuracy: 0.5118711719771523, Time Elapsed: 2352.8050439357758 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.58      0.80      0.67       897\n",
      "           4       0.59      0.39      0.47       892\n",
      "           5       0.55      0.38      0.45       862\n",
      "           6       0.63      0.71      0.66       903\n",
      "           7       0.61      0.58      0.59       889\n",
      "           8       0.57      0.66      0.61       892\n",
      "           9       0.57      0.49      0.53       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 13900, Loss: 1.1835496425628662, F1: 0.5755830259462471, Accuracy: 0.521161654394054, Time Elapsed: 2368.662461042404 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.63      0.48      0.55       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.60      0.42      0.50       897\n",
      "           4       0.65      0.29      0.40       892\n",
      "           5       0.53      0.23      0.32       862\n",
      "           6       0.62      0.50      0.55       903\n",
      "           7       0.63      0.31      0.41       889\n",
      "           8       0.55      0.74      0.63       892\n",
      "           9       0.53      0.76      0.62       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.44      0.46     14531\n",
      "weighted avg       0.48      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 14000, Loss: 0.2803606390953064, F1: 0.45856249449903186, Accuracy: 0.4783566168880325, Time Elapsed: 2383.541666030884 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.73       912\n",
      "           1       0.62      0.88      0.72       885\n",
      "           2       0.57      0.72      0.64       877\n",
      "           3       0.59      0.74      0.65       897\n",
      "           4       0.53      0.85      0.66       892\n",
      "           5       0.55      0.34      0.42       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.57      0.66      0.62       892\n",
      "           9       0.53      0.83      0.65       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 3, Step 14100, Loss: 1.4774439334869385, F1: 0.6027660741606188, Accuracy: 0.5351317872135435, Time Elapsed: 2398.5432460308075 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.90      0.70       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.57      0.67      0.62       892\n",
      "           5       0.57      0.12      0.19       862\n",
      "           6       0.62      0.52      0.57       903\n",
      "           7       0.56      0.83      0.67       889\n",
      "           8       0.56      0.74      0.64       892\n",
      "           9       0.63      0.20      0.30       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 14200, Loss: 0.31485024094581604, F1: 0.5503178745735883, Accuracy: 0.5180648269217535, Time Elapsed: 2709.635496854782 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.61      0.50      0.55       885\n",
      "           2       0.56      0.78      0.65       877\n",
      "           3       0.59      0.20      0.30       897\n",
      "           4       0.59      0.53      0.56       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.57      0.86      0.69       903\n",
      "           7       0.57      0.80      0.67       889\n",
      "           8       0.59      0.59      0.59       892\n",
      "           9       0.54      0.75      0.63       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 14300, Loss: 0.7776796817779541, F1: 0.5666638408084611, Accuracy: 0.5150368178377263, Time Elapsed: 2727.428771018982 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.57      0.75      0.65       877\n",
      "           3       0.62      0.30      0.41       897\n",
      "           4       0.62      0.24      0.34       892\n",
      "           5       0.54      0.49      0.51       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.61      0.43      0.50       892\n",
      "           9       0.47      0.83      0.60       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 14400, Loss: 7.9825310707092285, F1: 0.5554632565471772, Accuracy: 0.5125593558598858, Time Elapsed: 2748.9989109039307 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.57      0.78      0.66       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.57      0.42      0.48       892\n",
      "           5       0.57      0.17      0.26       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.62      0.35      0.45       889\n",
      "           8       0.60      0.63      0.61       892\n",
      "           9       0.47      0.86      0.61       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.55      0.50     14531\n",
      "weighted avg       0.47      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 14500, Loss: 0.5603703260421753, F1: 0.5027904406337028, Accuracy: 0.501686050512697, Time Elapsed: 2765.172590970993 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.73       912\n",
      "           1       0.58      0.96      0.72       885\n",
      "           2       0.60      0.60      0.60       877\n",
      "           3       0.61      0.56      0.58       897\n",
      "           4       0.60      0.47      0.53       892\n",
      "           5       0.55      0.38      0.45       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.62      0.52      0.57       889\n",
      "           8       0.61      0.51      0.56       892\n",
      "           9       0.55      0.74      0.63       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.61      0.58     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 14600, Loss: 5.294471740722656, F1: 0.579455138695674, Accuracy: 0.5247402105842681, Time Elapsed: 2781.4986889362335 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.56      0.71      0.63       877\n",
      "           3       0.57      0.74      0.64       897\n",
      "           4       0.54      0.73      0.62       892\n",
      "           5       0.54      0.43      0.48       862\n",
      "           6       0.62      0.35      0.45       903\n",
      "           7       0.60      0.56      0.58       889\n",
      "           8       0.61      0.17      0.27       892\n",
      "           9       0.48      0.85      0.62       876\n",
      "          10       0.38      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.55     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 14700, Loss: 2.136337995529175, F1: 0.5503856523482803, Accuracy: 0.5074667951276581, Time Elapsed: 2796.857545852661 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.58      0.54      0.56       897\n",
      "           4       0.56      0.53      0.54       892\n",
      "           5       0.55      0.59      0.57       862\n",
      "           6       0.62      0.50      0.55       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.55      0.64      0.59       892\n",
      "           9       0.60      0.66      0.63       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 14800, Loss: 1.19759202003479, F1: 0.5861361299596468, Accuracy: 0.5224692037712477, Time Elapsed: 2811.503327846527 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.62      0.75      0.67       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.58      0.73      0.64       897\n",
      "           4       0.57      0.60      0.58       892\n",
      "           5       0.52      0.61      0.56       862\n",
      "           6       0.62      0.65      0.64       903\n",
      "           7       0.62      0.42      0.50       889\n",
      "           8       0.50      0.58      0.54       892\n",
      "           9       0.49      0.85      0.62       876\n",
      "          10       0.38      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 14900, Loss: 1.3942902088165283, F1: 0.5826939929462855, Accuracy: 0.5158626384970064, Time Elapsed: 2826.774173974991 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.49      0.55       885\n",
      "           2       0.61      0.57      0.59       877\n",
      "           3       0.58      0.36      0.45       897\n",
      "           4       0.57      0.72      0.64       892\n",
      "           5       0.83      0.01      0.02       862\n",
      "           6       0.60      0.30      0.40       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.51      0.75      0.60       892\n",
      "           9       0.61      0.39      0.48       876\n",
      "          10       0.39      0.54      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.45      0.44     14531\n",
      "weighted avg       0.49      0.48      0.44     14531\n",
      "\n",
      "Epoch 3, Step 15000, Loss: 1.048850655555725, F1: 0.44044901060219316, Accuracy: 0.47670497556947217, Time Elapsed: 2841.5325739383698 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.23      0.34       912\n",
      "           1       0.62      0.69      0.65       885\n",
      "           2       0.59      0.62      0.61       877\n",
      "           3       0.58      0.59      0.58       897\n",
      "           4       0.57      0.68      0.62       892\n",
      "           5       0.54      0.41      0.47       862\n",
      "           6       0.62      0.69      0.66       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.58      0.60      0.59       892\n",
      "           9       0.61      0.41      0.49       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 15100, Loss: 0.8325331807136536, F1: 0.5517032335371823, Accuracy: 0.508430252563485, Time Elapsed: 2856.4656550884247 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.23      0.34       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.54      0.80      0.65       877\n",
      "           3       0.59      0.59      0.59       897\n",
      "           4       0.55      0.81      0.65       892\n",
      "           5       0.54      0.22      0.31       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.60      0.59      0.59       892\n",
      "           9       0.54      0.82      0.65       876\n",
      "          10       0.38      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 15200, Loss: 0.6918210387229919, F1: 0.5614216165133903, Accuracy: 0.5154497281673663, Time Elapsed: 2871.3693640232086 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.38      0.47       912\n",
      "           1       0.60      0.82      0.70       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.71      0.07      0.14       897\n",
      "           4       0.52      0.87      0.65       892\n",
      "           5       0.55      0.56      0.55       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.62      0.37      0.47       889\n",
      "           8       0.58      0.23      0.33       892\n",
      "           9       0.61      0.57      0.59       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.51      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 3, Step 15300, Loss: 0.632685124874115, F1: 0.5043081126554748, Accuracy: 0.4934278439198954, Time Elapsed: 2886.099654197693 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.33      0.00      0.00       885\n",
      "           2       0.58      0.37      0.45       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.51      0.84      0.63       892\n",
      "           5       0.54      0.51      0.53       862\n",
      "           6       0.61      0.71      0.66       903\n",
      "           7       0.62      0.43      0.51       889\n",
      "           8       0.59      0.34      0.43       892\n",
      "           9       0.62      0.45      0.52       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.49      0.45      0.44     14531\n",
      "weighted avg       0.46      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 15400, Loss: 0.6708773970603943, F1: 0.44456062438112975, Accuracy: 0.4797329846534994, Time Elapsed: 2901.4170999526978 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.63      0.42      0.51       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.60      0.09      0.16       897\n",
      "           4       0.50      0.82      0.62       892\n",
      "           5       0.55      0.39      0.46       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.61      0.68      0.64       889\n",
      "           8       0.61      0.20      0.30       892\n",
      "           9       0.61      0.39      0.48       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.52      0.50     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 15500, Loss: 1.0360605716705322, F1: 0.5042597089431665, Accuracy: 0.4956988507329158, Time Elapsed: 2916.1860961914062 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.71       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.61      0.35      0.44       897\n",
      "           4       0.57      0.66      0.61       892\n",
      "           5       0.50      0.62      0.55       862\n",
      "           6       0.56      0.85      0.68       903\n",
      "           7       0.61      0.75      0.67       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.53      0.56       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.58      0.53     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 15600, Loss: 0.5172858834266663, F1: 0.5304261409186307, Accuracy: 0.5083614341752116, Time Elapsed: 2931.5337011814117 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.71       912\n",
      "           1       0.62      0.58      0.60       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.57      0.82      0.68       897\n",
      "           4       0.55      0.75      0.64       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.60      0.42      0.49       889\n",
      "           8       0.60      0.44      0.51       892\n",
      "           9       0.48      0.86      0.61       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 15700, Loss: 1.2227962017059326, F1: 0.5800919122135798, Accuracy: 0.5180648269217535, Time Elapsed: 2947.3751339912415 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.60      0.62      0.61       877\n",
      "           3       0.61      0.57      0.59       897\n",
      "           4       0.52      0.84      0.65       892\n",
      "           5       0.47      0.74      0.58       862\n",
      "           6       0.61      0.68      0.64       903\n",
      "           7       0.62      0.35      0.45       889\n",
      "           8       0.55      0.69      0.61       892\n",
      "           9       0.54      0.74      0.62       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 15800, Loss: 0.9792490005493164, F1: 0.5873000444494386, Accuracy: 0.5212304727823275, Time Elapsed: 2962.851649045944 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       912\n",
      "           1       0.63      0.39      0.48       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.61      0.74      0.67       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.56      0.44      0.49       862\n",
      "           6       0.58      0.87      0.70       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.59      0.51      0.55       892\n",
      "           9       0.58      0.60      0.59       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 15900, Loss: 0.5463705658912659, F1: 0.5796903781361441, Accuracy: 0.522538022159521, Time Elapsed: 2977.5682809352875 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.62      0.71      0.66       885\n",
      "           2       0.60      0.65      0.63       877\n",
      "           3       0.59      0.71      0.64       897\n",
      "           4       0.58      0.64      0.60       892\n",
      "           5       0.54      0.61      0.57       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.59      0.44      0.50       892\n",
      "           9       0.55      0.80      0.65       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 16000, Loss: 0.7245826125144958, F1: 0.600657678074698, Accuracy: 0.5298327713164958, Time Elapsed: 2992.383013010025 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.61      0.37      0.46       885\n",
      "           2       0.55      0.77      0.64       877\n",
      "           3       0.58      0.71      0.64       897\n",
      "           4       0.54      0.74      0.63       892\n",
      "           5       0.56      0.23      0.32       862\n",
      "           6       0.62      0.55      0.58       903\n",
      "           7       0.63      0.40      0.49       889\n",
      "           8       0.60      0.29      0.39       892\n",
      "           9       0.59      0.68      0.63       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.54     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 16100, Loss: 1.8041870594024658, F1: 0.5361671041252968, Accuracy: 0.503888238937444, Time Elapsed: 3008.4531288146973 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.53      0.80      0.64       877\n",
      "           3       0.53      0.86      0.66       897\n",
      "           4       0.59      0.39      0.47       892\n",
      "           5       0.57      0.56      0.57       862\n",
      "           6       0.62      0.50      0.55       903\n",
      "           7       0.61      0.39      0.47       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.57      0.73      0.64       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 16200, Loss: 1.0725057125091553, F1: 0.5751821407363029, Accuracy: 0.5182712820865736, Time Elapsed: 3024.36190700531 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.56      0.69      0.62       877\n",
      "           3       0.55      0.82      0.66       897\n",
      "           4       0.60      0.36      0.45       892\n",
      "           5       0.55      0.22      0.32       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.61      0.51      0.56       889\n",
      "           8       0.59      0.54      0.56       892\n",
      "           9       0.57      0.75      0.65       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 16300, Loss: 0.3830254375934601, F1: 0.5663029580313848, Accuracy: 0.5176519165921134, Time Elapsed: 3039.93132519722 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62       912\n",
      "           1       0.58      0.80      0.67       885\n",
      "           2       0.65      0.21      0.32       877\n",
      "           3       0.43      0.88      0.58       897\n",
      "           4       0.55      0.33      0.41       892\n",
      "           5       0.56      0.35      0.43       862\n",
      "           6       0.61      0.70      0.66       903\n",
      "           7       0.62      0.56      0.59       889\n",
      "           8       0.55      0.48      0.52       892\n",
      "           9       0.60      0.61      0.60       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 16400, Loss: 0.8732719421386719, F1: 0.527126984185397, Accuracy: 0.4958364875094625, Time Elapsed: 3055.888067007065 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.59      0.80      0.68       885\n",
      "           2       0.64      0.20      0.31       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.55      0.66      0.60       892\n",
      "           5       0.57      0.38      0.45       862\n",
      "           6       0.62      0.16      0.26       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.58      0.66      0.62       892\n",
      "           9       0.61      0.59      0.60       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 16500, Loss: 0.7436233162879944, F1: 0.5264028742962675, Accuracy: 0.5051957883146376, Time Elapsed: 3071.0699150562286 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       912\n",
      "           1       0.62      0.38      0.47       885\n",
      "           2       0.55      0.76      0.64       877\n",
      "           3       0.61      0.43      0.50       897\n",
      "           4       0.54      0.87      0.66       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.62      0.52      0.57       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.58      0.77      0.66       892\n",
      "           9       0.52      0.85      0.64       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.65      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 16600, Loss: 0.413596510887146, F1: 0.5818098172577607, Accuracy: 0.5208175624526874, Time Elapsed: 3085.831260204315 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.91      0.73       912\n",
      "           1       0.63      0.36      0.46       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.63      0.21      0.31       897\n",
      "           4       0.56      0.59      0.58       892\n",
      "           5       0.57      0.54      0.55       862\n",
      "           6       0.62      0.30      0.41       903\n",
      "           7       0.60      0.20      0.30       889\n",
      "           8       0.60      0.33      0.42       892\n",
      "           9       0.58      0.64      0.60       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.48      0.49     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 3, Step 16700, Loss: 0.8674027919769287, F1: 0.4940872385776759, Accuracy: 0.48964283256486135, Time Elapsed: 3102.22780418396 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.61      0.55      0.58       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.59      0.49      0.53       897\n",
      "           4       0.50      0.83      0.62       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.63      0.35      0.45       903\n",
      "           7       0.64      0.23      0.33       889\n",
      "           8       0.60      0.25      0.35       892\n",
      "           9       0.60      0.26      0.36       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.50      0.50     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 3, Step 16800, Loss: 0.6098858714103699, F1: 0.5044361098240661, Accuracy: 0.49012456128277476, Time Elapsed: 3118.0009829998016 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.59      0.91      0.71       885\n",
      "           2       0.61      0.30      0.40       877\n",
      "           3       0.61      0.40      0.48       897\n",
      "           4       0.53      0.82      0.65       892\n",
      "           5       0.56      0.26      0.36       862\n",
      "           6       0.61      0.57      0.59       903\n",
      "           7       0.62      0.55      0.58       889\n",
      "           8       0.56      0.71      0.63       892\n",
      "           9       0.56      0.75      0.64       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 16900, Loss: 0.8900026679039001, F1: 0.5552619768894947, Accuracy: 0.5129034478012525, Time Elapsed: 3132.57693195343 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.64      0.17      0.27       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.62      0.27      0.38       892\n",
      "           5       0.55      0.36      0.44       862\n",
      "           6       0.58      0.90      0.71       903\n",
      "           7       0.60      0.61      0.61       889\n",
      "           8       0.47      0.87      0.61       892\n",
      "           9       0.43      0.90      0.58       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.60      0.54     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 17000, Loss: 0.2912898659706116, F1: 0.5365516346279221, Accuracy: 0.5019613240657904, Time Elapsed: 3147.21036195755 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.63      0.34      0.44       885\n",
      "           2       0.62      0.45      0.52       877\n",
      "           3       0.60      0.65      0.63       897\n",
      "           4       0.58      0.29      0.39       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.49      0.82      0.62       892\n",
      "           9       0.49      0.80      0.61       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.50      0.54      0.50     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 17100, Loss: 0.7382040619850159, F1: 0.49990427854040986, Accuracy: 0.4921202945427018, Time Elapsed: 3162.4689099788666 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.16      0.26       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.58      0.72      0.64       877\n",
      "           3       0.59      0.77      0.67       897\n",
      "           4       0.59      0.47      0.52       892\n",
      "           5       0.54      0.31      0.39       862\n",
      "           6       0.63      0.53      0.58       903\n",
      "           7       0.59      0.62      0.60       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.55      0.13      0.21       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.50      0.50     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 3, Step 17200, Loss: 1.4304922819137573, F1: 0.5042078952936614, Accuracy: 0.49349666230816874, Time Elapsed: 3178.299325942993 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.62      0.51      0.56       885\n",
      "           2       0.57      0.76      0.65       877\n",
      "           3       0.58      0.76      0.66       897\n",
      "           4       0.60      0.39      0.47       892\n",
      "           5       0.56      0.39      0.46       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.55      0.90      0.68       889\n",
      "           8       0.60      0.25      0.35       892\n",
      "           9       0.45      0.43      0.44       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 17300, Loss: 0.5811054110527039, F1: 0.5502571828423061, Accuracy: 0.510632440988232, Time Elapsed: 3193.446014881134 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.26      0.37       912\n",
      "           1       0.63      0.35      0.45       885\n",
      "           2       0.62      0.37      0.46       877\n",
      "           3       0.59      0.47      0.53       897\n",
      "           4       0.57      0.75      0.64       892\n",
      "           5       0.58      0.35      0.44       862\n",
      "           6       0.60      0.73      0.66       903\n",
      "           7       0.58      0.08      0.14       889\n",
      "           8       0.60      0.55      0.57       892\n",
      "           9       0.48      0.87      0.62       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.48      0.48     14531\n",
      "weighted avg       0.51      0.48      0.47     14531\n",
      "\n",
      "Epoch 3, Step 17400, Loss: 0.8811078071594238, F1: 0.48353267076540407, Accuracy: 0.48365563278508017, Time Elapsed: 3208.0598220825195 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.54      0.97      0.70       885\n",
      "           2       0.61      0.56      0.58       877\n",
      "           3       0.59      0.71      0.64       897\n",
      "           4       0.55      0.82      0.66       892\n",
      "           5       0.55      0.53      0.54       862\n",
      "           6       0.59      0.85      0.69       903\n",
      "           7       0.58      0.86      0.70       889\n",
      "           8       0.51      0.79      0.62       892\n",
      "           9       0.57      0.67      0.61       876\n",
      "          10       0.40      0.18      0.24      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.55      0.71      0.61     14531\n",
      "weighted avg       0.50      0.54      0.49     14531\n",
      "\n",
      "Epoch 3, Step 17500, Loss: 0.4404444098472595, F1: 0.6085303885775383, Accuracy: 0.536232881425917, Time Elapsed: 3223.4567070007324 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       912\n",
      "           1       0.61      0.92      0.73       885\n",
      "           2       0.59      0.68      0.63       877\n",
      "           3       0.59      0.74      0.65       897\n",
      "           4       0.54      0.84      0.66       892\n",
      "           5       0.51      0.65      0.57       862\n",
      "           6       0.60      0.61      0.61       903\n",
      "           7       0.62      0.31      0.41       889\n",
      "           8       0.62      0.40      0.49       892\n",
      "           9       0.49      0.84      0.62       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 17600, Loss: 0.4818248450756073, F1: 0.5738021231578778, Accuracy: 0.5173078246507467, Time Elapsed: 3238.554871082306 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.58      0.72      0.64       877\n",
      "           3       0.59      0.64      0.62       897\n",
      "           4       0.53      0.80      0.64       892\n",
      "           5       0.46      0.75      0.57       862\n",
      "           6       0.60      0.40      0.48       903\n",
      "           7       0.60      0.53      0.56       889\n",
      "           8       0.59      0.65      0.62       892\n",
      "           9       0.55      0.74      0.63       876\n",
      "          10       0.38      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.50      0.58      0.53     14531\n",
      "weighted avg       0.46      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 17700, Loss: 2.3620033264160156, F1: 0.5260820372248621, Accuracy: 0.49659348978046935, Time Elapsed: 3254.3550000190735 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.10      0.17       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.57      0.72      0.64       877\n",
      "           3       0.61      0.61      0.61       897\n",
      "           4       0.51      0.66      0.58       892\n",
      "           5       0.48      0.62      0.54       862\n",
      "           6       0.61      0.66      0.63       903\n",
      "           7       0.60      0.65      0.62       889\n",
      "           8       0.59      0.62      0.60       892\n",
      "           9       0.45      0.83      0.58       876\n",
      "          10       0.38      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.61      0.55     14531\n",
      "weighted avg       0.49      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 17800, Loss: 2.2582485675811768, F1: 0.5475221927409207, Accuracy: 0.50010322758241, Time Elapsed: 3269.8203110694885 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       912\n",
      "           1       0.60      0.38      0.46       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.61      0.44      0.51       897\n",
      "           4       0.57      0.44      0.50       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.60      0.72      0.65       903\n",
      "           7       0.58      0.79      0.67       889\n",
      "           8       0.59      0.44      0.51       892\n",
      "           9       0.58      0.43      0.49       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.55     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 3, Step 17900, Loss: 0.8733226656913757, F1: 0.545132447763791, Accuracy: 0.5043699676553575, Time Elapsed: 3286.5131499767303 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.62      0.43      0.51       885\n",
      "           2       0.66      0.18      0.29       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.58      0.47      0.52       892\n",
      "           5       0.56      0.30      0.39       862\n",
      "           6       0.58      0.87      0.70       903\n",
      "           7       0.60      0.45      0.51       889\n",
      "           8       0.61      0.44      0.51       892\n",
      "           9       0.51      0.02      0.05       876\n",
      "          10       0.39      0.63      0.48      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.52      0.38      0.41     14531\n",
      "weighted avg       0.48      0.47      0.43     14531\n",
      "\n",
      "Epoch 3, Step 18000, Loss: 1.4610944986343384, F1: 0.4053162641261761, Accuracy: 0.46617576216365014, Time Elapsed: 3302.6424050331116 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.62      0.50      0.56       885\n",
      "           2       0.45      0.77      0.57       877\n",
      "           3       0.62      0.51      0.56       897\n",
      "           4       0.54      0.70      0.61       892\n",
      "           5       0.52      0.56      0.54       862\n",
      "           6       0.59      0.82      0.69       903\n",
      "           7       0.60      0.54      0.57       889\n",
      "           8       0.60      0.60      0.60       892\n",
      "           9       0.55      0.11      0.18       876\n",
      "          10       0.38      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.50      0.50      0.48     14531\n",
      "weighted avg       0.46      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 18100, Loss: 0.5951346755027771, F1: 0.4803938342498613, Accuracy: 0.4811781708072397, Time Elapsed: 3318.62250995636 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.71       912\n",
      "           1       0.60      0.80      0.69       885\n",
      "           2       0.49      0.80      0.61       877\n",
      "           3       0.60      0.32      0.42       897\n",
      "           4       0.51      0.86      0.64       892\n",
      "           5       0.55      0.25      0.34       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.59      0.52      0.55       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.61      0.25      0.35       876\n",
      "          10       0.38      0.35      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 18200, Loss: 0.978776216506958, F1: 0.5340201647097426, Accuracy: 0.4985892230403964, Time Elapsed: 3333.832818031311 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.68       912\n",
      "           1       0.62      0.61      0.62       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.63      0.48      0.54       897\n",
      "           4       0.58      0.69      0.63       892\n",
      "           5       0.54      0.45      0.49       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.63      0.50      0.56       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.56      0.57     14531\n",
      "weighted avg       0.52      0.52      0.52     14531\n",
      "\n",
      "Epoch 3, Step 18300, Loss: 2.197563409805298, F1: 0.5684463140715418, Accuracy: 0.5177895533686601, Time Elapsed: 3352.8033430576324 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.71       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.55      0.73      0.63       877\n",
      "           3       0.60      0.19      0.28       897\n",
      "           4       0.57      0.76      0.65       892\n",
      "           5       0.55      0.26      0.35       862\n",
      "           6       0.61      0.78      0.69       903\n",
      "           7       0.60      0.06      0.10       889\n",
      "           8       0.56      0.65      0.60       892\n",
      "           9       0.58      0.66      0.62       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.52     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 18400, Loss: 1.0949002504348755, F1: 0.5190240082374322, Accuracy: 0.5062280641387379, Time Elapsed: 4276.946590900421 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.96      0.72       912\n",
      "           1       0.62      0.79      0.69       885\n",
      "           2       0.54      0.72      0.62       877\n",
      "           3       0.59      0.70      0.64       897\n",
      "           4       0.66      0.22      0.33       892\n",
      "           5       0.56      0.49      0.52       862\n",
      "           6       0.62      0.78      0.69       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.62      0.06      0.11       892\n",
      "           9       0.56      0.76      0.64       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.59      0.54     14531\n",
      "weighted avg       0.52      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 18500, Loss: 0.8308669924736023, F1: 0.5421549058677465, Accuracy: 0.5157938201087331, Time Elapsed: 4294.997726917267 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       912\n",
      "           1       0.63      0.27      0.38       885\n",
      "           2       0.64      0.31      0.42       877\n",
      "           3       0.60      0.25      0.35       897\n",
      "           4       0.55      0.81      0.65       892\n",
      "           5       0.57      0.28      0.38       862\n",
      "           6       0.62      0.67      0.64       903\n",
      "           7       0.58      0.84      0.68       889\n",
      "           8       0.59      0.49      0.54       892\n",
      "           9       0.54      0.79      0.64       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 18600, Loss: 0.7313578724861145, F1: 0.529278644553066, Accuracy: 0.5062968825270112, Time Elapsed: 4310.111664056778 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.65      0.37      0.47       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.58      0.57      0.58       897\n",
      "           4       0.59      0.67      0.63       892\n",
      "           5       0.57      0.34      0.42       862\n",
      "           6       0.61      0.43      0.50       903\n",
      "           7       0.57      0.81      0.67       889\n",
      "           8       0.59      0.31      0.41       892\n",
      "           9       0.56      0.73      0.63       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.55      0.54     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 18700, Loss: 0.8673983216285706, F1: 0.5441218384432309, Accuracy: 0.505471061867731, Time Elapsed: 4325.445375919342 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       912\n",
      "           1       0.62      0.62      0.62       885\n",
      "           2       0.61      0.31      0.41       877\n",
      "           3       0.52      0.77      0.62       897\n",
      "           4       0.47      0.77      0.58       892\n",
      "           5       0.54      0.61      0.57       862\n",
      "           6       0.62      0.78      0.69       903\n",
      "           7       0.60      0.53      0.56       889\n",
      "           8       0.55      0.52      0.54       892\n",
      "           9       0.57      0.48      0.52       876\n",
      "          10       0.40      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 18800, Loss: 4.551797389984131, F1: 0.5629980499826986, Accuracy: 0.5119399903654256, Time Elapsed: 4340.297821998596 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       912\n",
      "           1       0.62      0.42      0.50       885\n",
      "           2       0.57      0.69      0.62       877\n",
      "           3       0.58      0.61      0.60       897\n",
      "           4       0.56      0.77      0.65       892\n",
      "           5       0.53      0.56      0.54       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.52      0.77      0.62       892\n",
      "           9       0.55      0.72      0.63       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.58     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 18900, Loss: 0.6246597170829773, F1: 0.5753768425389667, Accuracy: 0.5133851765191659, Time Elapsed: 4354.690588951111 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73       912\n",
      "           1       0.56      0.89      0.69       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.57      0.72      0.64       897\n",
      "           4       0.60      0.34      0.43       892\n",
      "           5       0.55      0.60      0.57       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.61      0.76      0.68       889\n",
      "           8       0.55      0.60      0.57       892\n",
      "           9       0.57      0.72      0.64       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 19000, Loss: 0.7272583842277527, F1: 0.596678503503772, Accuracy: 0.5321725965177896, Time Elapsed: 4369.86079621315 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.53      0.94      0.68       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.58      0.76      0.66       897\n",
      "           4       0.52      0.81      0.64       892\n",
      "           5       0.57      0.55      0.56       862\n",
      "           6       0.58      0.89      0.70       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.59      0.30      0.40       892\n",
      "           9       0.59      0.66      0.62       876\n",
      "          10       0.39      0.24      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.59     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 3, Step 19100, Loss: 0.5297366380691528, F1: 0.5914070597203707, Accuracy: 0.5287316771041222, Time Elapsed: 4384.661777019501 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.28      0.38       912\n",
      "           1       0.50      0.00      0.00       885\n",
      "           2       0.52      0.77      0.62       877\n",
      "           3       0.60      0.58      0.59       897\n",
      "           4       0.51      0.88      0.65       892\n",
      "           5       0.60      0.08      0.13       862\n",
      "           6       0.60      0.53      0.57       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.60      0.17      0.27       892\n",
      "           9       0.60      0.45      0.52       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.46      0.44     14531\n",
      "weighted avg       0.50      0.48      0.44     14531\n",
      "\n",
      "Epoch 3, Step 19200, Loss: 0.29636815190315247, F1: 0.4400426888912212, Accuracy: 0.47505333425091184, Time Elapsed: 4398.931528806686 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.59      0.87      0.71       885\n",
      "           2       0.56      0.75      0.65       877\n",
      "           3       0.56      0.51      0.53       897\n",
      "           4       0.54      0.80      0.64       892\n",
      "           5       0.56      0.33      0.41       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.56      0.86      0.68       889\n",
      "           8       0.57      0.49      0.53       892\n",
      "           9       0.55      0.75      0.63       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 19300, Loss: 0.6835434436798096, F1: 0.5848620750618965, Accuracy: 0.5237767531484413, Time Elapsed: 4413.457042217255 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.61      0.78      0.69       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.58      0.36      0.45       897\n",
      "           4       0.49      0.92      0.64       892\n",
      "           5       0.55      0.40      0.46       862\n",
      "           6       0.63      0.55      0.58       903\n",
      "           7       0.55      0.89      0.68       889\n",
      "           8       0.59      0.21      0.31       892\n",
      "           9       0.64      0.39      0.49       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 19400, Loss: 0.7764901518821716, F1: 0.5458230324894731, Accuracy: 0.5093248916110384, Time Elapsed: 4429.823480129242 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.58      0.91      0.71       885\n",
      "           2       0.58      0.50      0.54       877\n",
      "           3       0.59      0.41      0.49       897\n",
      "           4       0.57      0.68      0.62       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.60      0.80      0.68       903\n",
      "           7       0.59      0.86      0.70       889\n",
      "           8       0.55      0.69      0.61       892\n",
      "           9       0.59      0.59      0.59       876\n",
      "          10       0.40      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 19500, Loss: 4.143259525299072, F1: 0.5922970745614081, Accuracy: 0.5295574977634023, Time Elapsed: 4445.91594004631 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.63      0.38      0.48       877\n",
      "           3       0.56      0.80      0.66       897\n",
      "           4       0.52      0.90      0.65       892\n",
      "           5       0.57      0.63      0.59       862\n",
      "           6       0.61      0.71      0.65       903\n",
      "           7       0.56      0.87      0.68       889\n",
      "           8       0.57      0.69      0.62       892\n",
      "           9       0.61      0.54      0.57       876\n",
      "          10       0.41      0.24      0.31      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.68      0.60     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 3, Step 19600, Loss: 0.6436047554016113, F1: 0.6032290717875651, Accuracy: 0.5371963388617439, Time Elapsed: 4460.951909065247 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.44      0.88      0.59       877\n",
      "           3       0.55      0.85      0.67       897\n",
      "           4       0.55      0.71      0.62       892\n",
      "           5       0.52      0.58      0.55       862\n",
      "           6       0.58      0.86      0.69       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.58      0.65      0.61       892\n",
      "           9       0.55      0.75      0.63       876\n",
      "          10       0.38      0.16      0.23      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.54      0.70      0.60     14531\n",
      "weighted avg       0.49      0.52      0.48     14531\n",
      "\n",
      "Epoch 3, Step 19700, Loss: 0.7396442890167236, F1: 0.5984282869832825, Accuracy: 0.5232262060422544, Time Elapsed: 4475.646910905838 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.60      0.78      0.68       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.56      0.65      0.60       897\n",
      "           4       0.57      0.48      0.52       892\n",
      "           5       0.55      0.48      0.51       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.54      0.89      0.67       889\n",
      "           8       0.58      0.28      0.38       892\n",
      "           9       0.52      0.83      0.64       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 19800, Loss: 0.426420658826828, F1: 0.5710990513449618, Accuracy: 0.5157938201087331, Time Elapsed: 4493.290022134781 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.63      0.51      0.56       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.54      0.86      0.66       897\n",
      "           4       0.57      0.63      0.60       892\n",
      "           5       0.57      0.47      0.51       862\n",
      "           6       0.56      0.91      0.69       903\n",
      "           7       0.56      0.89      0.69       889\n",
      "           8       0.60      0.37      0.46       892\n",
      "           9       0.57      0.65      0.61       876\n",
      "          10       0.40      0.29      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 19900, Loss: 0.33505722880363464, F1: 0.5776244847656924, Accuracy: 0.5224692037712477, Time Elapsed: 5419.546463012695 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.58      0.87      0.69       885\n",
      "           2       0.56      0.53      0.54       877\n",
      "           3       0.58      0.61      0.59       897\n",
      "           4       0.59      0.57      0.58       892\n",
      "           5       0.59      0.22      0.32       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.55      0.63      0.59       892\n",
      "           9       0.61      0.16      0.26       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 20000, Loss: 0.2881277799606323, F1: 0.5498364294547237, Accuracy: 0.51737664303902, Time Elapsed: 5436.0967669487 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.58      0.57      0.58       877\n",
      "           3       0.59      0.61      0.60       897\n",
      "           4       0.61      0.35      0.44       892\n",
      "           5       0.59      0.13      0.21       862\n",
      "           6       0.62      0.61      0.61       903\n",
      "           7       0.62      0.29      0.40       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.49      0.67      0.57       876\n",
      "          10       0.40      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.49      0.48     14531\n",
      "weighted avg       0.48      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 20100, Loss: 0.9330406785011292, F1: 0.4764121006681774, Accuracy: 0.4926708416488886, Time Elapsed: 6500.071303129196 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.70       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.53      0.77      0.63       877\n",
      "           3       0.54      0.85      0.66       897\n",
      "           4       0.50      0.86      0.64       892\n",
      "           5       0.59      0.13      0.22       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.59      0.65      0.62       889\n",
      "           8       0.52      0.78      0.62       892\n",
      "           9       0.58      0.41      0.48       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.57     14531\n",
      "weighted avg       0.50      0.52      0.48     14531\n",
      "\n",
      "Epoch 3, Step 20200, Loss: 0.864387571811676, F1: 0.5687856049000545, Accuracy: 0.5202670153465005, Time Elapsed: 6523.954636096954 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.50      0.94      0.66       885\n",
      "           2       0.60      0.39      0.47       877\n",
      "           3       0.60      0.56      0.58       897\n",
      "           4       0.38      0.98      0.55       892\n",
      "           5       0.49      0.67      0.57       862\n",
      "           6       0.59      0.85      0.69       903\n",
      "           7       0.63      0.14      0.22       889\n",
      "           8       0.55      0.69      0.61       892\n",
      "           9       0.53      0.58      0.55       876\n",
      "          10       0.38      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.53      0.62      0.53     14531\n",
      "weighted avg       0.48      0.49      0.45     14531\n",
      "\n",
      "Epoch 3, Step 20300, Loss: 1.6755421161651611, F1: 0.533453161865774, Accuracy: 0.48806000963457435, Time Elapsed: 6541.3523581027985 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.27      0.37       912\n",
      "           1       0.62      0.67      0.64       885\n",
      "           2       0.55      0.67      0.60       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.60      0.63      0.61       892\n",
      "           5       0.53      0.44      0.48       862\n",
      "           6       0.63      0.70      0.66       903\n",
      "           7       0.00      0.00      0.00       889\n",
      "           8       0.44      0.89      0.59       892\n",
      "           9       0.71      0.09      0.16       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.48      0.46     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 20400, Loss: 0.9301566481590271, F1: 0.4619915006974923, Accuracy: 0.4801458949831395, Time Elapsed: 6564.635300159454 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       912\n",
      "           1       0.58      0.91      0.71       885\n",
      "           2       0.56      0.70      0.62       877\n",
      "           3       0.59      0.69      0.64       897\n",
      "           4       0.60      0.50      0.54       892\n",
      "           5       0.52      0.69      0.59       862\n",
      "           6       0.62      0.77      0.68       903\n",
      "           7       0.61      0.38      0.46       889\n",
      "           8       0.59      0.52      0.55       892\n",
      "           9       0.59      0.64      0.61       876\n",
      "          10       0.39      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 20500, Loss: 1.284062147140503, F1: 0.5761298439158079, Accuracy: 0.5179271901452068, Time Elapsed: 6584.811186790466 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.60      0.79      0.68       885\n",
      "           2       0.61      0.35      0.44       877\n",
      "           3       0.60      0.61      0.60       897\n",
      "           4       0.59      0.66      0.63       892\n",
      "           5       0.53      0.60      0.56       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.59      0.85      0.69       889\n",
      "           8       0.51      0.82      0.63       892\n",
      "           9       0.61      0.59      0.60       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 20600, Loss: 1.0796513557434082, F1: 0.593956774898084, Accuracy: 0.5288693138806689, Time Elapsed: 6603.202741861343 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.18      0.27       912\n",
      "           1       0.62      0.51      0.56       885\n",
      "           2       0.55      0.66      0.60       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.53      0.87      0.66       892\n",
      "           5       0.54      0.62      0.57       862\n",
      "           6       0.62      0.34      0.44       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.55      0.65      0.60       892\n",
      "           9       0.57      0.70      0.63       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 20700, Loss: 0.7912596464157104, F1: 0.5484919110959019, Accuracy: 0.5045076044319042, Time Elapsed: 6626.365921974182 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.72      0.66       885\n",
      "           2       0.65      0.09      0.15       877\n",
      "           3       0.56      0.83      0.67       897\n",
      "           4       0.55      0.82      0.66       892\n",
      "           5       0.54      0.30      0.39       862\n",
      "           6       0.63      0.73      0.68       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.59      0.36      0.45       892\n",
      "           9       0.53      0.05      0.09       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.48      0.44     14531\n",
      "weighted avg       0.47      0.48      0.44     14531\n",
      "\n",
      "Epoch 3, Step 20800, Loss: 1.2304741144180298, F1: 0.4431024358873451, Accuracy: 0.48496318216227374, Time Elapsed: 6651.057363986969 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.86      0.69       912\n",
      "           1       0.63      0.60      0.61       885\n",
      "           2       0.62      0.47      0.53       877\n",
      "           3       0.58      0.69      0.63       897\n",
      "           4       0.57      0.65      0.61       892\n",
      "           5       0.54      0.20      0.29       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.59      0.64      0.62       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.53      0.81      0.64       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 20900, Loss: 0.9351352453231812, F1: 0.5639680257311857, Accuracy: 0.5147615442846328, Time Elapsed: 6665.637128829956 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70       912\n",
      "           1       0.54      0.94      0.69       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.55      0.71      0.62       897\n",
      "           4       0.58      0.73      0.64       892\n",
      "           5       0.55      0.17      0.26       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.56      0.77      0.65       889\n",
      "           8       0.60      0.24      0.34       892\n",
      "           9       0.61      0.59      0.60       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.56     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 21000, Loss: 0.43350735306739807, F1: 0.5619720386964074, Accuracy: 0.5191659211341271, Time Elapsed: 6680.161602020264 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.68       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.59      0.49      0.54       877\n",
      "           3       0.63      0.43      0.51       897\n",
      "           4       0.58      0.76      0.66       892\n",
      "           5       0.56      0.20      0.30       862\n",
      "           6       0.57      0.89      0.69       903\n",
      "           7       0.57      0.70      0.63       889\n",
      "           8       0.58      0.64      0.61       892\n",
      "           9       0.57      0.67      0.61       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 21100, Loss: 0.9237954616546631, F1: 0.5733920954656967, Accuracy: 0.5233638428188012, Time Elapsed: 6695.117080926895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.59      0.49      0.54       877\n",
      "           3       0.58      0.73      0.65       897\n",
      "           4       0.53      0.88      0.66       892\n",
      "           5       0.55      0.60      0.57       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.58      0.73      0.65       889\n",
      "           8       0.59      0.40      0.48       892\n",
      "           9       0.53      0.83      0.64       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 3, Step 21200, Loss: 1.254602074623108, F1: 0.5975928521950965, Accuracy: 0.5297639529282224, Time Elapsed: 6709.481720924377 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       912\n",
      "           1       0.56      0.96      0.71       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.55      0.73      0.63       897\n",
      "           4       0.59      0.48      0.53       892\n",
      "           5       0.53      0.65      0.58       862\n",
      "           6       0.62      0.51      0.56       903\n",
      "           7       0.58      0.78      0.67       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.54      0.79      0.64       876\n",
      "          10       0.38      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.50      0.58      0.53     14531\n",
      "weighted avg       0.46      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 21300, Loss: 0.523834228515625, F1: 0.5318585393561305, Accuracy: 0.503475328607804, Time Elapsed: 6724.694540977478 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.28      0.39       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.58      0.39      0.47       877\n",
      "           3       0.60      0.70      0.64       897\n",
      "           4       0.62      0.30      0.40       892\n",
      "           5       0.54      0.62      0.58       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.56      0.70      0.63       892\n",
      "           9       0.57      0.68      0.62       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 21400, Loss: 0.7178162932395935, F1: 0.5620867635116361, Accuracy: 0.5175142798155667, Time Elapsed: 6738.955883026123 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.39      0.48       912\n",
      "           1       0.60      0.53      0.56       885\n",
      "           2       0.63      0.18      0.28       877\n",
      "           3       0.60      0.73      0.66       897\n",
      "           4       0.53      0.86      0.66       892\n",
      "           5       0.55      0.56      0.56       862\n",
      "           6       0.64      0.31      0.42       903\n",
      "           7       0.57      0.84      0.68       889\n",
      "           8       0.58      0.63      0.60       892\n",
      "           9       0.60      0.58      0.59       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 21500, Loss: 0.968723475933075, F1: 0.5346456095727645, Accuracy: 0.501686050512697, Time Elapsed: 6754.535413980484 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.59      0.54      0.56       897\n",
      "           4       0.60      0.56      0.58       892\n",
      "           5       0.57      0.37      0.44       862\n",
      "           6       0.80      0.01      0.02       903\n",
      "           7       0.58      0.83      0.69       889\n",
      "           8       0.57      0.74      0.64       892\n",
      "           9       0.58      0.35      0.43       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.53      0.48      0.46     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 21600, Loss: 1.645923376083374, F1: 0.4605074382026441, Accuracy: 0.4843438166678136, Time Elapsed: 6769.930688858032 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       912\n",
      "           1       0.63      0.24      0.35       885\n",
      "           2       0.57      0.69      0.63       877\n",
      "           3       0.51      0.82      0.63       897\n",
      "           4       0.58      0.64      0.61       892\n",
      "           5       0.57      0.22      0.31       862\n",
      "           6       0.60      0.77      0.68       903\n",
      "           7       0.58      0.83      0.69       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.53      0.63      0.57       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 21700, Loss: 0.8964558243751526, F1: 0.5559375017256644, Accuracy: 0.513798086848806, Time Elapsed: 6784.812717914581 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.62      0.55      0.58       885\n",
      "           2       0.62      0.38      0.48       877\n",
      "           3       0.60      0.64      0.62       897\n",
      "           4       0.56      0.57      0.56       892\n",
      "           5       0.52      0.64      0.58       862\n",
      "           6       0.62      0.74      0.68       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.54      0.77      0.63       892\n",
      "           9       0.49      0.81      0.61       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.59     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 21800, Loss: 0.8853956460952759, F1: 0.5857959907994018, Accuracy: 0.522331566994701, Time Elapsed: 6799.363943815231 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       912\n",
      "           1       0.61      0.91      0.73       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.53      0.84      0.65       897\n",
      "           4       0.57      0.57      0.57       892\n",
      "           5       0.52      0.15      0.23       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.58      0.50      0.53       892\n",
      "           9       0.54      0.65      0.59       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 21900, Loss: 0.49531418085098267, F1: 0.5733713900791483, Accuracy: 0.5232262060422544, Time Elapsed: 6814.738371133804 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       912\n",
      "           1       0.63      0.54      0.58       885\n",
      "           2       0.60      0.43      0.50       877\n",
      "           3       0.59      0.65      0.62       897\n",
      "           4       0.54      0.67      0.60       892\n",
      "           5       0.54      0.37      0.44       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.59      0.31      0.41       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.58      0.38      0.46       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.52      0.53     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 3, Step 22000, Loss: 0.8265661001205444, F1: 0.5335745431659032, Accuracy: 0.49810749432248297, Time Elapsed: 6830.326359033585 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.63      0.34      0.44       877\n",
      "           3       0.62      0.43      0.51       897\n",
      "           4       0.57      0.47      0.51       892\n",
      "           5       0.57      0.35      0.43       862\n",
      "           6       0.62      0.48      0.54       903\n",
      "           7       0.61      0.68      0.64       889\n",
      "           8       0.60      0.60      0.60       892\n",
      "           9       0.53      0.08      0.13       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.44      0.45     14531\n",
      "weighted avg       0.48      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 22100, Loss: 0.9535820484161377, F1: 0.4528416295276323, Accuracy: 0.4819351730782465, Time Elapsed: 6845.834110021591 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.63      0.35      0.45       877\n",
      "           3       0.55      0.04      0.07       897\n",
      "           4       0.58      0.61      0.59       892\n",
      "           5       0.55      0.37      0.45       862\n",
      "           6       0.61      0.26      0.36       903\n",
      "           7       0.61      0.42      0.50       889\n",
      "           8       0.58      0.68      0.62       892\n",
      "           9       0.54      0.70      0.61       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.49      0.49     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 22200, Loss: 0.4486490488052368, F1: 0.48972045641862977, Accuracy: 0.48902346707040123, Time Elapsed: 6861.087766885757 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       912\n",
      "           1       0.59      0.67      0.63       885\n",
      "           2       0.51      0.78      0.62       877\n",
      "           3       0.58      0.43      0.50       897\n",
      "           4       0.58      0.04      0.08       892\n",
      "           5       0.57      0.23      0.32       862\n",
      "           6       0.64      0.37      0.47       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.58      0.42      0.49       892\n",
      "           9       0.54      0.45      0.49       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.46      0.47     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 3, Step 22300, Loss: 0.9181960225105286, F1: 0.4740118048459289, Accuracy: 0.4771867042873856, Time Elapsed: 6876.83015704155 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.69       912\n",
      "           1       0.63      0.30      0.40       885\n",
      "           2       0.62      0.10      0.17       877\n",
      "           3       0.56      0.73      0.63       897\n",
      "           4       0.54      0.75      0.63       892\n",
      "           5       0.56      0.49      0.53       862\n",
      "           6       0.62      0.59      0.61       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.58      0.63      0.60       892\n",
      "           9       0.53      0.76      0.63       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 22400, Loss: 0.5894383788108826, F1: 0.5396770581772005, Accuracy: 0.5077420686807514, Time Elapsed: 6891.3284158706665 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.62      0.31      0.42       877\n",
      "           3       0.58      0.51      0.54       897\n",
      "           4       0.55      0.80      0.65       892\n",
      "           5       0.55      0.61      0.58       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.55      0.91      0.68       889\n",
      "           8       0.60      0.48      0.53       892\n",
      "           9       0.59      0.59      0.59       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 22500, Loss: 0.522270917892456, F1: 0.5792505630356045, Accuracy: 0.5224003853829743, Time Elapsed: 6906.396201848984 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.70       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.58      0.63      0.61       897\n",
      "           4       0.55      0.79      0.65       892\n",
      "           5       0.58      0.40      0.47       862\n",
      "           6       0.58      0.79      0.67       903\n",
      "           7       0.57      0.82      0.67       889\n",
      "           8       0.61      0.45      0.51       892\n",
      "           9       0.59      0.71      0.64       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.52      0.60      0.55     14531\n",
      "weighted avg       0.48      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 22600, Loss: 0.23564735054969788, F1: 0.5457850866993401, Accuracy: 0.5203358337347739, Time Elapsed: 6921.049749851227 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.63      0.03      0.06       877\n",
      "           3       0.58      0.62      0.60       897\n",
      "           4       0.47      0.89      0.61       892\n",
      "           5       0.53      0.61      0.57       862\n",
      "           6       0.58      0.56      0.57       903\n",
      "           7       0.58      0.66      0.62       889\n",
      "           8       0.60      0.58      0.59       892\n",
      "           9       0.55      0.70      0.61       876\n",
      "          10       0.38      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.60      0.54     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 22700, Loss: 0.7024903893470764, F1: 0.5405719023807968, Accuracy: 0.5044387860436309, Time Elapsed: 6935.729995012283 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.56      0.67      0.61       877\n",
      "           3       0.59      0.51      0.55       897\n",
      "           4       0.58      0.45      0.51       892\n",
      "           5       0.44      0.86      0.58       862\n",
      "           6       0.61      0.66      0.63       903\n",
      "           7       0.57      0.86      0.69       889\n",
      "           8       0.59      0.60      0.59       892\n",
      "           9       0.52      0.83      0.64       876\n",
      "          10       0.39      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.49      0.52      0.48     14531\n",
      "\n",
      "Epoch 3, Step 22800, Loss: 0.32824796438217163, F1: 0.5872229092149384, Accuracy: 0.5185465556396669, Time Elapsed: 6950.3938200473785 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.97      0.66       912\n",
      "           1       0.62      0.11      0.19       885\n",
      "           2       0.53      0.73      0.62       877\n",
      "           3       0.59      0.66      0.62       897\n",
      "           4       0.58      0.48      0.53       892\n",
      "           5       0.54      0.64      0.59       862\n",
      "           6       0.61      0.49      0.54       903\n",
      "           7       0.60      0.80      0.68       889\n",
      "           8       0.58      0.66      0.62       892\n",
      "           9       0.55      0.80      0.65       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.55     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 22900, Loss: 0.1860615462064743, F1: 0.5494370656894136, Accuracy: 0.5065033376918313, Time Elapsed: 6965.219824075699 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.55      0.74      0.63       877\n",
      "           3       0.56      0.75      0.64       897\n",
      "           4       0.57      0.57      0.57       892\n",
      "           5       0.52      0.69      0.59       862\n",
      "           6       0.62      0.57      0.59       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.60      0.41      0.49       892\n",
      "           9       0.61      0.52      0.56       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 23000, Loss: 0.39757251739501953, F1: 0.5875883022868682, Accuracy: 0.524120845089808, Time Elapsed: 6979.956299066544 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72       912\n",
      "           1       0.66      0.09      0.16       885\n",
      "           2       0.62      0.35      0.45       877\n",
      "           3       0.58      0.68      0.63       897\n",
      "           4       0.62      0.41      0.49       892\n",
      "           5       0.52      0.08      0.14       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.57      0.63      0.60       892\n",
      "           9       0.58      0.75      0.65       876\n",
      "          10       0.40      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.50     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 23100, Loss: 0.46492624282836914, F1: 0.5045655245847812, Accuracy: 0.5044387860436309, Time Elapsed: 6996.394920825958 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.65      0.41      0.50       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.55      0.72      0.63       897\n",
      "           4       0.60      0.41      0.49       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.62      0.78      0.69       903\n",
      "           7       0.60      0.84      0.70       889\n",
      "           8       0.54      0.59      0.56       892\n",
      "           9       0.57      0.78      0.66       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 23200, Loss: 1.3523638248443604, F1: 0.5804499674783347, Accuracy: 0.5235702979836212, Time Elapsed: 7010.7949249744415 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.58      0.93      0.71       885\n",
      "           2       0.59      0.43      0.50       877\n",
      "           3       0.58      0.62      0.60       897\n",
      "           4       0.60      0.48      0.53       892\n",
      "           5       0.56      0.31      0.40       862\n",
      "           6       0.61      0.68      0.65       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.54      0.61      0.57       892\n",
      "           9       0.51      0.88      0.65       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 23300, Loss: 0.3526262938976288, F1: 0.5720537161703416, Accuracy: 0.5180648269217535, Time Elapsed: 7025.8173089027405 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.72       912\n",
      "           1       0.63      0.42      0.50       885\n",
      "           2       0.61      0.39      0.48       877\n",
      "           3       0.58      0.69      0.63       897\n",
      "           4       0.63      0.21      0.31       892\n",
      "           5       0.56      0.46      0.51       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.55      0.66      0.60       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.53      0.54     14531\n",
      "weighted avg       0.52      0.50      0.50     14531\n",
      "\n",
      "Epoch 3, Step 23400, Loss: 1.1033642292022705, F1: 0.5351185794682198, Accuracy: 0.5034065102195306, Time Elapsed: 7040.394158124924 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.70       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.58      0.41      0.48       877\n",
      "           3       0.57      0.78      0.66       897\n",
      "           4       0.64      0.06      0.12       892\n",
      "           5       0.50      0.79      0.61       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.61      0.32      0.42       892\n",
      "           9       0.57      0.71      0.63       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 23500, Loss: 0.4087134599685669, F1: 0.5510880896758658, Accuracy: 0.5183401004748469, Time Elapsed: 7055.406578779221 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.71       912\n",
      "           1       0.59      0.91      0.71       885\n",
      "           2       0.65      0.18      0.28       877\n",
      "           3       0.63      0.34      0.44       897\n",
      "           4       0.57      0.33      0.42       892\n",
      "           5       0.53      0.30      0.38       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.61      0.25      0.36       889\n",
      "           8       0.63      0.19      0.29       892\n",
      "           9       0.55      0.71      0.62       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 23600, Loss: 2.3910417556762695, F1: 0.48565216335226435, Accuracy: 0.49198265776615513, Time Elapsed: 7070.010349988937 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.59      0.85      0.70       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.49      0.92      0.64       892\n",
      "           5       0.53      0.19      0.28       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.59      0.66      0.63       889\n",
      "           8       0.65      0.17      0.27       892\n",
      "           9       0.56      0.77      0.65       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 23700, Loss: 0.42877745628356934, F1: 0.5534902339758555, Accuracy: 0.5151056362259996, Time Elapsed: 7084.862919092178 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.60      0.85      0.71       885\n",
      "           2       0.63      0.37      0.47       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.54      0.83      0.65       892\n",
      "           5       0.55      0.43      0.48       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.58      0.80      0.67       889\n",
      "           8       0.57      0.65      0.61       892\n",
      "           9       0.59      0.70      0.64       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 23800, Loss: 0.49499842524528503, F1: 0.590502142352154, Accuracy: 0.5292134058220357, Time Elapsed: 7099.639866113663 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.60      0.36      0.45       877\n",
      "           3       0.59      0.50      0.54       897\n",
      "           4       0.58      0.57      0.58       892\n",
      "           5       0.58      0.32      0.41       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.59      0.57      0.58       889\n",
      "           8       0.60      0.02      0.03       892\n",
      "           9       0.62      0.36      0.46       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.44      0.45     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 23900, Loss: 0.9787629842758179, F1: 0.44551306176840755, Accuracy: 0.48152226274860643, Time Elapsed: 7115.374708890915 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.59      0.73      0.65       897\n",
      "           4       0.50      0.90      0.65       892\n",
      "           5       0.52      0.66      0.58       862\n",
      "           6       0.60      0.70      0.65       903\n",
      "           7       0.58      0.50      0.54       889\n",
      "           8       0.58      0.04      0.07       892\n",
      "           9       0.60      0.61      0.60       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.50      0.54      0.49     14531\n",
      "weighted avg       0.46      0.49      0.46     14531\n",
      "\n",
      "Epoch 3, Step 24000, Loss: 0.20165862143039703, F1: 0.4886201556405083, Accuracy: 0.49335902553162203, Time Elapsed: 7129.814404010773 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.55      0.93      0.69       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.54      0.76      0.64       897\n",
      "           4       0.56      0.77      0.65       892\n",
      "           5       0.54      0.41      0.47       862\n",
      "           6       0.60      0.66      0.63       903\n",
      "           7       0.33      0.00      0.00       889\n",
      "           8       0.61      0.32      0.42       892\n",
      "           9       0.59      0.48      0.53       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.48      0.49      0.46     14531\n",
      "weighted avg       0.45      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 24100, Loss: 0.7528786063194275, F1: 0.45574730347477943, Accuracy: 0.48262335696097997, Time Elapsed: 7144.751101970673 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.60      0.69      0.64       897\n",
      "           4       0.55      0.81      0.66       892\n",
      "           5       0.54      0.41      0.47       862\n",
      "           6       0.62      0.72      0.67       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.56      0.80      0.65       892\n",
      "           9       0.60      0.42      0.49       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 24200, Loss: 1.8227043151855469, F1: 0.6001571852422516, Accuracy: 0.53444360333081, Time Elapsed: 7159.197932958603 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.82      0.68       912\n",
      "           1       0.61      0.68      0.65       885\n",
      "           2       0.55      0.67      0.60       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.57      0.70      0.63       892\n",
      "           5       0.54      0.55      0.55       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.59      0.57      0.58       889\n",
      "           8       0.54      0.67      0.60       892\n",
      "           9       0.59      0.22      0.32       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 24300, Loss: 0.6423332691192627, F1: 0.5670925625268516, Accuracy: 0.5138669052370793, Time Elapsed: 7174.253330945969 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.67      0.02      0.04       885\n",
      "           2       0.59      0.47      0.53       877\n",
      "           3       0.59      0.26      0.36       897\n",
      "           4       0.59      0.38      0.46       892\n",
      "           5       0.53      0.56      0.55       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.63      0.20      0.30       889\n",
      "           8       0.56      0.77      0.65       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.44      0.43     14531\n",
      "weighted avg       0.48      0.48      0.44     14531\n",
      "\n",
      "Epoch 3, Step 24400, Loss: 1.9321801662445068, F1: 0.43082758784948805, Accuracy: 0.47773725139357237, Time Elapsed: 7188.823892831802 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.60      0.37      0.46       897\n",
      "           4       0.56      0.55      0.55       892\n",
      "           5       0.56      0.41      0.47       862\n",
      "           6       0.60      0.77      0.68       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.57      0.73      0.64       892\n",
      "           9       0.66      0.03      0.06       876\n",
      "          10       0.38      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 24500, Loss: 0.6547260284423828, F1: 0.5294304850736494, Accuracy: 0.5051269699263643, Time Elapsed: 7203.61993598938 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69       912\n",
      "           1       0.61      0.78      0.69       885\n",
      "           2       0.53      0.75      0.62       877\n",
      "           3       0.59      0.60      0.60       897\n",
      "           4       0.49      0.74      0.59       892\n",
      "           5       0.50      0.68      0.57       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.60      0.54      0.57       889\n",
      "           8       0.56      0.69      0.61       892\n",
      "           9       0.60      0.02      0.03       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.61      0.54     14531\n",
      "weighted avg       0.49      0.51      0.47     14531\n",
      "\n",
      "Epoch 3, Step 24600, Loss: 3.22259259223938, F1: 0.5408489978032596, Accuracy: 0.5053334250911844, Time Elapsed: 7218.003406047821 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.62      0.44      0.51       877\n",
      "           3       0.54      0.83      0.66       897\n",
      "           4       0.44      0.85      0.58       892\n",
      "           5       0.56      0.39      0.46       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.51      0.85      0.64       892\n",
      "           9       0.59      0.13      0.21       876\n",
      "          10       0.40      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.63      0.55     14531\n",
      "weighted avg       0.50      0.51      0.47     14531\n",
      "\n",
      "Epoch 3, Step 24700, Loss: 1.58344566822052, F1: 0.5515335604900905, Accuracy: 0.5102195306585919, Time Elapsed: 7233.244833946228 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.56      0.97      0.71       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.59      0.57      0.58       897\n",
      "           4       0.55      0.79      0.65       892\n",
      "           5       0.56      0.41      0.48       862\n",
      "           6       0.58      0.87      0.69       903\n",
      "           7       0.58      0.86      0.69       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.64      0.26      0.37       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 24800, Loss: 1.6795337200164795, F1: 0.5765187866137346, Accuracy: 0.524327300254628, Time Elapsed: 7247.81290602684 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69       912\n",
      "           1       0.53      0.98      0.69       885\n",
      "           2       0.61      0.39      0.47       877\n",
      "           3       0.60      0.63      0.62       897\n",
      "           4       0.55      0.81      0.66       892\n",
      "           5       0.55      0.18      0.27       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.53      0.79      0.63       892\n",
      "           9       0.57      0.59      0.58       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 24900, Loss: 0.2405516356229782, F1: 0.5739939631805052, Accuracy: 0.5230885692657078, Time Elapsed: 7262.625236988068 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.00      0.01       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.61      0.35      0.44       877\n",
      "           3       0.61      0.60      0.60       897\n",
      "           4       0.56      0.76      0.65       892\n",
      "           5       0.51      0.04      0.08       862\n",
      "           6       0.61      0.49      0.55       903\n",
      "           7       0.59      0.64      0.61       889\n",
      "           8       0.61      0.46      0.52       892\n",
      "           9       0.60      0.29      0.39       876\n",
      "          10       0.39      0.52      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.46      0.46     14531\n",
      "weighted avg       0.51      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 25000, Loss: 1.4298652410507202, F1: 0.4553556326238711, Accuracy: 0.4843438166678136, Time Elapsed: 7277.349817991257 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68       912\n",
      "           1       0.57      0.95      0.72       885\n",
      "           2       0.62      0.34      0.44       877\n",
      "           3       0.61      0.62      0.62       897\n",
      "           4       0.53      0.82      0.65       892\n",
      "           5       0.54      0.37      0.44       862\n",
      "           6       0.58      0.86      0.69       903\n",
      "           7       0.59      0.42      0.49       889\n",
      "           8       0.60      0.59      0.59       892\n",
      "           9       0.53      0.77      0.63       876\n",
      "          10       0.38      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 25100, Loss: 0.620222270488739, F1: 0.5712948728049299, Accuracy: 0.5161379120500997, Time Elapsed: 7292.775486946106 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.63      0.24      0.35       877\n",
      "           3       0.59      0.69      0.64       897\n",
      "           4       0.58      0.44      0.50       892\n",
      "           5       0.56      0.45      0.50       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.53      0.01      0.02       889\n",
      "           8       0.50      0.00      0.00       892\n",
      "           9       0.53      0.82      0.64       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.52      0.47     14531\n",
      "weighted avg       0.50      0.49      0.45     14531\n",
      "\n",
      "Epoch 3, Step 25200, Loss: 0.6894649267196655, F1: 0.46944050154314054, Accuracy: 0.49466657490881566, Time Elapsed: 7307.389128923416 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.61      0.82      0.70       885\n",
      "           2       0.62      0.29      0.39       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.58      0.56      0.57       892\n",
      "           5       0.55      0.22      0.31       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.20      0.30       889\n",
      "           8       0.67      0.00      0.00       892\n",
      "           9       0.61      0.63      0.62       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.49     14531\n",
      "weighted avg       0.52      0.50      0.47     14531\n",
      "\n",
      "Epoch 3, Step 25300, Loss: 0.3175992965698242, F1: 0.48856233418640377, Accuracy: 0.5014107769596036, Time Elapsed: 7322.25551199913 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.60      0.89      0.71       885\n",
      "           2       0.64      0.34      0.45       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.51      0.85      0.64       892\n",
      "           5       0.52      0.60      0.56       862\n",
      "           6       0.62      0.54      0.58       903\n",
      "           7       0.58      0.31      0.41       889\n",
      "           8       0.60      0.34      0.43       892\n",
      "           9       0.61      0.53      0.57       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 25400, Loss: 1.0845673084259033, F1: 0.5472492910923132, Accuracy: 0.5073979767393848, Time Elapsed: 7336.922091007233 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.71       912\n",
      "           1       0.58      0.94      0.71       885\n",
      "           2       0.59      0.70      0.64       877\n",
      "           3       0.61      0.50      0.55       897\n",
      "           4       0.54      0.87      0.67       892\n",
      "           5       0.52      0.71      0.60       862\n",
      "           6       0.59      0.90      0.71       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.59      0.60      0.60       892\n",
      "           9       0.57      0.71      0.64       876\n",
      "          10       0.39      0.21      0.27      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 3, Step 25500, Loss: 0.9492177367210388, F1: 0.60891851623052, Accuracy: 0.5357511527080036, Time Elapsed: 7352.448989868164 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       912\n",
      "           1       0.60      0.60      0.60       885\n",
      "           2       0.53      0.71      0.60       877\n",
      "           3       0.60      0.57      0.58       897\n",
      "           4       0.59      0.45      0.51       892\n",
      "           5       0.54      0.56      0.55       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.58      0.66      0.62       892\n",
      "           9       0.57      0.70      0.63       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.59     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 25600, Loss: 1.2187035083770752, F1: 0.5898071191800012, Accuracy: 0.523707934760168, Time Elapsed: 7367.369973897934 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.70       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.61      0.32      0.42       877\n",
      "           3       0.63      0.31      0.41       897\n",
      "           4       0.57      0.50      0.53       892\n",
      "           5       0.50      0.22      0.31       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.59      0.58      0.59       892\n",
      "           9       0.57      0.68      0.62       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 25700, Loss: 0.2975495755672455, F1: 0.5471782342811179, Accuracy: 0.5115270800357855, Time Elapsed: 7381.9375 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.64      0.46      0.54       897\n",
      "           4       0.60      0.51      0.55       892\n",
      "           5       0.51      0.69      0.59       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.59      0.16      0.25       889\n",
      "           8       0.61      0.41      0.49       892\n",
      "           9       0.56      0.73      0.63       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 25800, Loss: 1.5657424926757812, F1: 0.5521407364638469, Accuracy: 0.511595898424059, Time Elapsed: 7396.230943918228 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.08      0.14       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.61      0.40      0.48       877\n",
      "           3       0.61      0.53      0.57       897\n",
      "           4       0.59      0.49      0.53       892\n",
      "           5       0.54      0.31      0.39       862\n",
      "           6       0.76      0.04      0.07       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.44      0.01      0.02       892\n",
      "           9       0.57      0.74      0.64       876\n",
      "          10       0.38      0.55      0.45      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.57      0.44      0.43     14531\n",
      "weighted avg       0.51      0.47      0.43     14531\n",
      "\n",
      "Epoch 3, Step 25900, Loss: 0.6503640413284302, F1: 0.4250799042262186, Accuracy: 0.4729199642144381, Time Elapsed: 7411.869276762009 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00       912\n",
      "           1       0.56      0.96      0.70       885\n",
      "           2       0.55      0.73      0.63       877\n",
      "           3       0.61      0.53      0.57       897\n",
      "           4       0.61      0.43      0.50       892\n",
      "           5       0.51      0.21      0.30       862\n",
      "           6       0.61      0.47      0.53       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.60      0.53      0.56       892\n",
      "           9       0.59      0.54      0.57       876\n",
      "          10       0.38      0.47      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.50      0.49     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 26000, Loss: 0.44444704055786133, F1: 0.488658336859716, Accuracy: 0.48750946252838756, Time Elapsed: 7429.110507965088 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.24      0.34       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.60      0.52      0.55       897\n",
      "           4       0.60      0.15      0.24       892\n",
      "           5       0.49      0.72      0.59       862\n",
      "           6       0.63      0.37      0.47       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.57      0.72      0.64       892\n",
      "           9       0.63      0.51      0.56       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 26100, Loss: 0.797187089920044, F1: 0.5197275971484961, Accuracy: 0.4968687633335627, Time Elapsed: 7665.425925016403 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00       912\n",
      "           1       0.61      0.86      0.72       885\n",
      "           2       0.50      0.81      0.62       877\n",
      "           3       0.58      0.78      0.67       897\n",
      "           4       0.59      0.50      0.54       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.62      0.47      0.53       903\n",
      "           7       0.55      0.90      0.69       889\n",
      "           8       0.59      0.70      0.64       892\n",
      "           9       0.59      0.57      0.58       876\n",
      "          10       0.38      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.59      0.53     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 26200, Loss: 1.6231496334075928, F1: 0.5335824027150066, Accuracy: 0.5051957883146376, Time Elapsed: 7682.854354143143 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.57      0.74      0.64       877\n",
      "           3       0.63      0.35      0.45       897\n",
      "           4       0.58      0.73      0.64       892\n",
      "           5       0.56      0.09      0.16       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.57      0.80      0.67       889\n",
      "           8       0.56      0.76      0.65       892\n",
      "           9       0.58      0.59      0.58       876\n",
      "          10       0.38      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 26300, Loss: 0.8548079133033752, F1: 0.5581174633735192, Accuracy: 0.5175142798155667, Time Elapsed: 7705.826586008072 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.62      0.51      0.56       877\n",
      "           3       0.58      0.51      0.54       897\n",
      "           4       0.57      0.76      0.65       892\n",
      "           5       0.55      0.44      0.49       862\n",
      "           6       0.62      0.82      0.70       903\n",
      "           7       0.53      0.89      0.67       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.63      0.43      0.51       876\n",
      "          10       0.40      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 26400, Loss: 0.6245496273040771, F1: 0.5856557369060386, Accuracy: 0.5281811299979354, Time Elapsed: 7721.038534164429 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.62      0.47      0.54       885\n",
      "           2       0.61      0.49      0.54       877\n",
      "           3       0.55      0.76      0.64       897\n",
      "           4       0.62      0.23      0.33       892\n",
      "           5       0.54      0.36      0.43       862\n",
      "           6       0.62      0.57      0.59       903\n",
      "           7       0.58      0.66      0.61       889\n",
      "           8       0.56      0.77      0.65       892\n",
      "           9       0.57      0.68      0.62       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 26500, Loss: 1.0952048301696777, F1: 0.5475570327046855, Accuracy: 0.5073291583511114, Time Elapsed: 7735.931198835373 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.55      0.89      0.68       885\n",
      "           2       0.59      0.62      0.61       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.56      0.62      0.59       892\n",
      "           5       0.55      0.49      0.52       862\n",
      "           6       0.61      0.65      0.63       903\n",
      "           7       0.59      0.19      0.29       889\n",
      "           8       0.50      0.82      0.62       892\n",
      "           9       0.58      0.51      0.54       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 26600, Loss: 0.46530336141586304, F1: 0.5562005603612539, Accuracy: 0.5102883490468654, Time Elapsed: 7752.859260082245 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       912\n",
      "           1       0.58      0.89      0.70       885\n",
      "           2       0.62      0.21      0.31       877\n",
      "           3       0.57      0.76      0.65       897\n",
      "           4       0.60      0.32      0.41       892\n",
      "           5       0.53      0.62      0.58       862\n",
      "           6       0.62      0.39      0.48       903\n",
      "           7       0.60      0.29      0.39       889\n",
      "           8       0.57      0.39      0.46       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.47      0.47     14531\n",
      "weighted avg       0.48      0.49      0.46     14531\n",
      "\n",
      "Epoch 3, Step 26700, Loss: 1.131869912147522, F1: 0.46703145696028847, Accuracy: 0.48599545798637395, Time Elapsed: 7768.023874998093 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.58      0.75      0.65       885\n",
      "           2       0.66      0.14      0.24       877\n",
      "           3       0.55      0.84      0.66       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.49      0.72      0.58       862\n",
      "           6       0.62      0.59      0.60       903\n",
      "           7       0.58      0.13      0.21       889\n",
      "           8       0.60      0.28      0.38       892\n",
      "           9       0.62      0.39      0.48       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 26800, Loss: 0.34059634804725647, F1: 0.5063414206372185, Accuracy: 0.49852040465212305, Time Elapsed: 7783.807350873947 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.61      0.90      0.73       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.55      0.80      0.65       897\n",
      "           4       0.56      0.66      0.60       892\n",
      "           5       0.51      0.71      0.60       862\n",
      "           6       0.61      0.63      0.62       903\n",
      "           7       0.58      0.09      0.15       889\n",
      "           8       0.58      0.57      0.58       892\n",
      "           9       0.63      0.37      0.47       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 26900, Loss: 1.2098608016967773, F1: 0.5500732006373634, Accuracy: 0.5147615442846328, Time Elapsed: 7799.792837142944 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.61      0.07      0.13       885\n",
      "           2       0.58      0.59      0.58       877\n",
      "           3       0.63      0.33      0.43       897\n",
      "           4       0.58      0.55      0.56       892\n",
      "           5       0.50      0.71      0.59       862\n",
      "           6       0.63      0.59      0.61       903\n",
      "           7       0.60      0.27      0.38       889\n",
      "           8       0.55      0.72      0.62       892\n",
      "           9       0.33      0.00      0.01       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.47      0.46     14531\n",
      "weighted avg       0.49      0.48      0.45     14531\n",
      "\n",
      "Epoch 3, Step 27000, Loss: 0.47753679752349854, F1: 0.4594721101102287, Accuracy: 0.4820728098547932, Time Elapsed: 7815.322779178619 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.58      0.54      0.56       877\n",
      "           3       0.63      0.40      0.49       897\n",
      "           4       0.57      0.66      0.61       892\n",
      "           5       0.53      0.25      0.34       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.59      0.24      0.34       889\n",
      "           8       0.54      0.71      0.61       892\n",
      "           9       0.52      0.85      0.65       876\n",
      "          10       0.38      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 3, Step 27100, Loss: 0.2893100380897522, F1: 0.5445489581233239, Accuracy: 0.5043011492670841, Time Elapsed: 7829.770669937134 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.51      0.85      0.64       877\n",
      "           3       0.59      0.72      0.65       897\n",
      "           4       0.59      0.51      0.55       892\n",
      "           5       0.53      0.24      0.34       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.57      0.87      0.69       889\n",
      "           8       0.59      0.71      0.65       892\n",
      "           9       0.56      0.79      0.66       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 3, Step 27200, Loss: 1.5215017795562744, F1: 0.5958650060285736, Accuracy: 0.5321725965177896, Time Elapsed: 7844.765860080719 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.62      0.46      0.53       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.60      0.56      0.58       897\n",
      "           4       0.62      0.42      0.50       892\n",
      "           5       0.53      0.22      0.31       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.57      0.66      0.61       892\n",
      "           9       0.56      0.69      0.62       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 27300, Loss: 0.8733530640602112, F1: 0.5600471302617724, Accuracy: 0.5156561833321863, Time Elapsed: 7859.661386966705 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.94      0.68       912\n",
      "           1       0.59      0.87      0.71       885\n",
      "           2       0.58      0.53      0.56       877\n",
      "           3       0.59      0.68      0.63       897\n",
      "           4       0.54      0.86      0.66       892\n",
      "           5       0.43      0.77      0.55       862\n",
      "           6       0.59      0.82      0.69       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.57      0.52      0.54       892\n",
      "           9       0.57      0.61      0.59       876\n",
      "          10       0.38      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.54      0.68      0.59     14531\n",
      "weighted avg       0.49      0.52      0.48     14531\n",
      "\n",
      "Epoch 3, Step 27400, Loss: 0.7895289063453674, F1: 0.5927987561556244, Accuracy: 0.5212304727823275, Time Elapsed: 7874.607509851456 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.62      0.44      0.51       885\n",
      "           2       0.58      0.60      0.59       877\n",
      "           3       0.52      0.87      0.65       897\n",
      "           4       0.57      0.74      0.64       892\n",
      "           5       0.46      0.69      0.55       862\n",
      "           6       0.62      0.51      0.56       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.58      0.57      0.57       892\n",
      "           9       0.59      0.42      0.49       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 3, Step 27500, Loss: 1.0394096374511719, F1: 0.5704167771243592, Accuracy: 0.5114582616475122, Time Elapsed: 7889.4773778915405 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.61      0.44      0.51       877\n",
      "           3       0.60      0.66      0.63       897\n",
      "           4       0.58      0.69      0.63       892\n",
      "           5       0.50      0.56      0.53       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.60      0.72      0.66       889\n",
      "           8       0.55      0.55      0.55       892\n",
      "           9       0.59      0.46      0.51       876\n",
      "          10       0.40      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 3, Step 27600, Loss: 1.0266072750091553, F1: 0.5855563886441152, Accuracy: 0.5247402105842681, Time Elapsed: 7904.551634788513 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.60      0.91      0.73       885\n",
      "           2       0.53      0.81      0.64       877\n",
      "           3       0.60      0.75      0.67       897\n",
      "           4       0.57      0.62      0.60       892\n",
      "           5       0.55      0.44      0.49       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.57      0.69      0.62       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.67      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 3, Step 27700, Loss: 1.8224196434020996, F1: 0.6058780770285853, Accuracy: 0.5353382423783635, Time Elapsed: 7919.595413923264 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.57      0.95      0.72       885\n",
      "           2       0.60      0.61      0.60       877\n",
      "           3       0.62      0.40      0.49       897\n",
      "           4       0.80      0.00      0.01       892\n",
      "           5       0.57      0.16      0.25       862\n",
      "           6       0.60      0.74      0.66       903\n",
      "           7       0.58      0.78      0.67       889\n",
      "           8       0.58      0.56      0.57       892\n",
      "           9       0.58      0.66      0.62       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.59      0.56      0.52     14531\n",
      "weighted avg       0.52      0.51      0.48     14531\n",
      "\n",
      "Epoch 3, Step 27800, Loss: 0.5666912794113159, F1: 0.5169601701347218, Accuracy: 0.5074667951276581, Time Elapsed: 7934.982028007507 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.09      0.16       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.67      0.01      0.01       897\n",
      "           4       0.56      0.73      0.64       892\n",
      "           5       0.52      0.04      0.07       862\n",
      "           6       0.61      0.71      0.66       903\n",
      "           7       0.54      0.84      0.66       889\n",
      "           8       0.59      0.62      0.61       892\n",
      "           9       0.59      0.51      0.54       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.46     14531\n",
      "weighted avg       0.50      0.49      0.45     14531\n",
      "\n",
      "Epoch 3, Step 27900, Loss: 0.35908931493759155, F1: 0.4643735102821902, Accuracy: 0.4907439267772349, Time Elapsed: 7951.10303902626 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       912\n",
      "           1       0.60      0.91      0.73       885\n",
      "           2       0.62      0.44      0.51       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.57      0.68      0.62       892\n",
      "           5       0.55      0.08      0.13       862\n",
      "           6       0.61      0.39      0.48       903\n",
      "           7       0.58      0.79      0.67       889\n",
      "           8       0.59      0.48      0.53       892\n",
      "           9       0.50      0.86      0.63       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 28000, Loss: 0.29209104180336, F1: 0.5422170940423204, Accuracy: 0.5089119812813984, Time Elapsed: 7967.377938985825 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.93      0.67       912\n",
      "           1       0.60      0.47      0.53       885\n",
      "           2       0.61      0.42      0.49       877\n",
      "           3       0.62      0.41      0.49       897\n",
      "           4       0.65      0.08      0.14       892\n",
      "           5       0.55      0.42      0.48       862\n",
      "           6       0.61      0.52      0.56       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.61      0.31      0.41       892\n",
      "           9       0.59      0.54      0.56       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 3, Step 28100, Loss: 0.7289214730262756, F1: 0.49573281056768564, Accuracy: 0.48854173835248776, Time Elapsed: 7983.357215881348 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.95      0.68       912\n",
      "           1       0.60      0.03      0.06       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.60      0.75      0.67       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.57      0.29      0.39       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.60      0.78      0.67       889\n",
      "           8       0.59      0.52      0.55       892\n",
      "           9       0.56      0.79      0.65       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.54      0.49     14531\n",
      "weighted avg       0.47      0.50      0.46     14531\n",
      "\n",
      "Epoch 3, Step 28200, Loss: 0.32810312509536743, F1: 0.4877589570631612, Accuracy: 0.49955268047622325, Time Elapsed: 7998.937278985977 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.65      0.17      0.27       877\n",
      "           3       0.50      0.90      0.64       897\n",
      "           4       0.57      0.61      0.59       892\n",
      "           5       0.60      0.21      0.31       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.61      0.70      0.65       889\n",
      "           8       0.59      0.30      0.40       892\n",
      "           9       0.57      0.61      0.59       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 3, Step 28300, Loss: 1.0624046325683594, F1: 0.5391710508509022, Accuracy: 0.5121464455302457, Time Elapsed: 8014.17125082016 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       912\n",
      "           1       0.61      0.91      0.73       885\n",
      "           2       0.60      0.50      0.54       877\n",
      "           3       0.60      0.75      0.67       897\n",
      "           4       0.59      0.51      0.55       892\n",
      "           5       0.55      0.63      0.59       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.59      0.70      0.64       892\n",
      "           9       0.53      0.86      0.65       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 3, Step 28400, Loss: 0.8941333889961243, F1: 0.6093676769133145, Accuracy: 0.5372651572500172, Time Elapsed: 8030.001098871231 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.65      0.08      0.14       877\n",
      "           3       0.63      0.44      0.52       897\n",
      "           4       0.52      0.90      0.66       892\n",
      "           5       0.57      0.37      0.44       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.59      0.74      0.66       889\n",
      "           8       0.58      0.65      0.61       892\n",
      "           9       0.60      0.64      0.62       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.61      0.56     14531\n",
      "weighted avg       0.52      0.52      0.49     14531\n",
      "\n",
      "Epoch 3, Step 28500, Loss: 0.4161592125892639, F1: 0.5562641612604206, Accuracy: 0.5204046521230473, Time Elapsed: 8046.24646115303 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.58      0.65      0.61       877\n",
      "           3       0.54      0.88      0.67       897\n",
      "           4       0.57      0.61      0.59       892\n",
      "           5       0.54      0.59      0.56       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.53      0.84      0.65       892\n",
      "           9       0.52      0.80      0.63       876\n",
      "          10       0.38      0.17      0.23      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.55      0.71      0.61     14531\n",
      "weighted avg       0.50      0.54      0.49     14531\n",
      "\n",
      "Epoch 3, Step 28600, Loss: 1.9040873050689697, F1: 0.6106775545504776, Accuracy: 0.5352006056018168, Time Elapsed: 8060.789516925812 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.55      0.96      0.70       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.62      0.65      0.63       897\n",
      "           4       0.59      0.57      0.58       892\n",
      "           5       0.51      0.69      0.58       862\n",
      "           6       0.63      0.32      0.42       903\n",
      "           7       0.60      0.55      0.58       889\n",
      "           8       0.56      0.83      0.67       892\n",
      "           9       0.55      0.74      0.63       876\n",
      "          10       0.38      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 3, Step 28700, Loss: 0.9628007411956787, F1: 0.5807113942535348, Accuracy: 0.5191659211341271, Time Elapsed: 8076.00866985321 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.71       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.53      0.75      0.62       877\n",
      "           3       0.61      0.63      0.62       897\n",
      "           4       0.58      0.67      0.62       892\n",
      "           5       0.52      0.69      0.59       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.58      0.61      0.60       892\n",
      "           9       0.62      0.32      0.42       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 3, Step 28800, Loss: 1.238804817199707, F1: 0.5944793228714187, Accuracy: 0.5290757690454889, Time Elapsed: 8092.0141270160675 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.67      0.08      0.14       897\n",
      "           4       0.61      0.43      0.50       892\n",
      "           5       0.58      0.17      0.26       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.62      0.24      0.34       892\n",
      "           9       0.62      0.53      0.57       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.59      0.50      0.50     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 3, Step 28900, Loss: 1.134016513824463, F1: 0.49941511502581426, Accuracy: 0.5003785011355034, Time Elapsed: 8107.67450594902 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.53      0.98      0.69       885\n",
      "           2       0.60      0.52      0.55       877\n",
      "           3       0.61      0.41      0.49       897\n",
      "           4       0.58      0.53      0.55       892\n",
      "           5       0.51      0.39      0.44       862\n",
      "           6       0.57      0.84      0.68       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.58      0.53      0.56       892\n",
      "           9       0.59      0.27      0.37       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.50      0.51      0.49     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 3, Step 29000, Loss: 0.585601806640625, F1: 0.48790321217782806, Accuracy: 0.4864771867042874, Time Elapsed: 8122.132302045822 seconds\n",
      "Epoch 3 completed. Time: 8122.552587985992\n",
      "Logger {'time': {0: 0.005532979965209961, 100: 18.030077934265137, 200: 36.5731520652771, 300: 53.25274586677551, 400: 67.87091183662415, 500: 83.82790803909302, 600: 102.96937489509583, 700: 120.0815269947052, 800: 137.98800897598267, 900: 155.46151280403137, 1000: 172.25893592834473, 1100: 189.8659429550171, 1200: 210.67707204818726, 1300: 228.4963779449463, 1400: 247.50066089630127, 1500: 266.798015832901, 1600: 283.0709090232849, 1700: 301.60244393348694, 1800: 323.2950830459595, 1900: 339.34089493751526, 2000: 357.6878020763397, 2100: 378.6669669151306, 2200: 397.02733302116394, 2300: 419.1526870727539, 2400: 436.3050220012665, 2500: 451.97218203544617, 2600: 467.9122591018677, 2700: 482.9631929397583, 2800: 499.18703413009644, 2900: 514.9300458431244, 3000: 530.1456098556519, 3100: 545.7430808544159, 3200: 560.8637180328369, 3300: 577.4969580173492, 3400: 592.8552739620209, 3500: 607.4871189594269, 3600: 623.9662599563599, 3700: 644.3956310749054, 3800: 661.8372452259064, 3900: 677.8684599399567, 4000: 693.2493560314178, 4100: 709.4254720211029, 4200: 737.0224061012268, 4300: 764.0957729816437, 4400: 792.3440639972687, 4500: 820.5170300006866, 4600: 849.424113035202, 4700: 872.2740380764008, 4800: 894.9758157730103, 4900: 916.3098130226135, 5000: 935.4925088882446, 5100: 951.7066340446472, 5200: 967.0720801353455, 5300: 983.0498421192169, 5400: 997.8484048843384, 5500: 1013.5466389656067, 5600: 1028.3039379119873, 5700: 1043.6198880672455, 5800: 1058.3811881542206, 5900: 1073.0533800125122, 6000: 1088.7770988941193, 6100: 1106.373118877411, 6200: 1122.234867811203, 6300: 1138.1186590194702, 6400: 1153.6139471530914, 6500: 1169.1171090602875, 6600: 1183.59010720253, 6700: 1199.264752149582, 6800: 1214.0263350009918, 6900: 1230.2131249904633, 7000: 1245.990045785904, 7100: 1262.330710887909, 7200: 1278.9776828289032, 7300: 1294.1253581047058, 7400: 1309.8126859664917, 7500: 1325.7521159648895, 7600: 1341.7699859142303, 7700: 1357.2178511619568, 7800: 1371.9251470565796, 7900: 1387.5388600826263, 8000: 1404.9126751422882, 8100: 1420.868588924408, 8200: 1437.6872608661652, 8300: 1456.0760078430176, 8400: 1474.7180578708649, 8500: 1492.4845628738403, 8600: 1508.79909491539, 8700: 1525.69447183609, 8800: 1541.3442029953003, 8900: 1557.7104470729828, 9000: 1574.937581062317, 9100: 1590.7541460990906, 9200: 1605.4475650787354, 9300: 1620.262246131897, 9400: 1635.3149070739746, 9500: 1653.5241498947144, 9600: 1670.3188898563385, 9700: 1686.8809897899628, 9800: 1703.1306109428406, 9900: 1719.3926088809967, 10000: 1734.9057409763336, 10100: 1750.5857830047607, 10200: 1766.541687965393, 10300: 1781.6210420131683, 10400: 1797.0235121250153, 10500: 1812.9440310001373, 10600: 1829.3247909545898, 10700: 1844.4988939762115, 10800: 1859.3039128780365, 10900: 1875.3414390087128, 11000: 1890.9439599514008, 11100: 1906.3632299900055, 11200: 1921.3419518470764, 11300: 1937.479590177536, 11400: 1953.7545340061188, 11500: 1968.5197517871857, 11600: 1984.258138179779, 11700: 1999.9875769615173, 11800: 2016.2110199928284, 11900: 2030.9726450443268, 12000: 2045.9300789833069, 12100: 2062.098571062088, 12200: 2077.4675459861755, 12300: 2092.10973405838, 12400: 2112.682862997055, 12500: 2133.924619913101, 12600: 2155.17231798172, 12700: 2172.2839601039886, 12800: 2187.7932851314545, 12900: 2202.287029027939, 13000: 2217.2956409454346, 13100: 2232.114993095398, 13200: 2247.439744949341, 13300: 2261.9137020111084, 13400: 2277.391273021698, 13500: 2293.0615170001984, 13600: 2308.697818040848, 13700: 2323.7104659080505, 13800: 2338.326346874237, 13900: 2353.374839067459, 14000: 2369.248227119446, 14100: 2384.094936132431, 14200: 2399.108157157898, 14300: 2710.257073163986, 14400: 2728.198513031006, 14500: 2749.675495862961, 14600: 2765.774535894394, 14700: 2782.063225030899, 14800: 2797.405420064926, 14900: 2812.0519320964813, 15000: 2827.366870880127, 15100: 2842.1022279262543, 15200: 2857.0774009227753, 15300: 2871.914183139801, 15400: 2886.6754519939423, 15500: 2902.007378101349, 15600: 2916.7466411590576, 15700: 2932.1628148555756, 15800: 2947.9739940166473, 15900: 2963.431717157364, 16000: 2978.095957994461, 16100: 2993.003242969513, 16200: 3009.057662010193, 16300: 3024.96381688118, 16400: 3040.498862028122, 16500: 3056.48774600029, 16600: 3071.630249977112, 16700: 3086.391708135605, 16800: 3102.96444106102, 16900: 3118.6006031036377, 17000: 3133.0969059467316, 17100: 3147.818248987198, 17200: 3163.0546889305115, 17300: 3178.895404100418, 17400: 3193.9799370765686, 17500: 3208.6271929740906, 17600: 3224.032936811447, 17700: 3239.1522691249847, 17800: 3254.9446790218353, 17900: 3270.88996386528, 18000: 3287.1944839954376, 18100: 3303.2355308532715, 18200: 3319.22429895401, 18300: 3334.363494157791, 18400: 4259.380707979202, 18500: 4277.621310949326, 18600: 4295.554928064346, 18700: 4310.646331071854, 18800: 4326.024462938309, 18900: 4340.817049980164, 19000: 4355.194593906403, 19100: 4370.401529073715, 19200: 4385.188506126404, 19300: 4399.446334838867, 19400: 4414.013432025909, 19500: 4430.385172843933, 19600: 4446.474107027054, 19700: 4461.484690904617, 19800: 4476.170056819916, 19900: 4493.886034965515, 20000: 5420.211266040802, 20100: 5436.677298069, 20200: 6500.814683198929, 20300: 6524.59713101387, 20400: 6542.132847070694, 20500: 6565.287203073502, 20600: 6585.353691101074, 20700: 6604.117464065552, 20800: 6627.071577072144, 20900: 6651.604910135269, 21000: 6666.148720026016, 21100: 6680.73602604866, 21200: 6695.642310142517, 21300: 6710.007236003876, 21400: 6725.211840867996, 21500: 6739.5119659900665, 21600: 6755.1307599544525, 21700: 6770.496498823166, 21800: 6785.320291996002, 21900: 6799.902092933655, 22000: 6815.288135051727, 22100: 6830.975967884064, 22200: 6846.375905036926, 22300: 6861.6962831020355, 22400: 6877.408975124359, 22500: 6891.817129850388, 22600: 6906.954117059708, 22700: 6921.54244184494, 22800: 6936.239356040955, 22900: 6950.95719909668, 23000: 6965.7432181835175, 23100: 6980.683897972107, 23200: 6996.965392112732, 23300: 7011.287659883499, 23400: 7026.371213912964, 23500: 7040.912503004074, 23600: 7055.964905977249, 23700: 7070.526523113251, 23800: 7085.401994943619, 23900: 7100.232891082764, 24000: 7115.9024250507355, 24100: 7130.319777011871, 24200: 7145.316190958023, 24300: 7159.6924700737, 24400: 7174.814910888672, 24500: 7189.351678848267, 24600: 7204.152166128159, 24700: 7218.524464130402, 24800: 7233.774653911591, 24900: 7248.3212559223175, 25000: 7263.260449886322, 25100: 7277.926650047302, 25200: 7293.331667900085, 25300: 7307.985172986984, 25400: 7322.816843032837, 25500: 7337.437907934189, 25600: 7353.011943101883, 25700: 7367.972967863083, 25800: 7382.470052957535, 25900: 7396.735516786575, 26000: 7412.798857927322, 26100: 7429.656221866608, 26200: 7666.057065963745, 26300: 7683.497543096542, 26400: 7706.419668912888, 26500: 7721.579591989517, 26600: 7736.499344110489, 26700: 7753.46831202507, 26800: 7768.602348089218, 26900: 7784.423458099365, 27000: 7800.383718013763, 27100: 7815.8654198646545, 27200: 7830.321969032288, 27300: 7845.341480970383, 27400: 7860.234181165695, 27500: 7875.132516145706, 27600: 7890.016216039658, 27700: 7905.107571840286, 27800: 7920.1185920238495, 27900: 7935.529792070389, 28000: 7951.708850860596, 28100: 7967.990221977234, 28200: 7983.985564947128, 28300: 7999.538402080536, 28400: 8014.7773768901825, 28500: 8030.553180932999, 28600: 8046.848711967468, 28700: 8061.320839166641, 28800: 8076.625267982483, 28900: 8092.573948144913, 29000: 8108.296653032303}, 'loss': {0: 2.3051939010620117, 100: 3.989603281021118, 200: 0.39107653498649597, 300: 1.0229110717773438, 400: 0.46313557028770447, 500: 1.3991789817810059, 600: 1.7029423713684082, 700: 0.48403382301330566, 800: 2.0307705402374268, 900: 1.2995331287384033, 1000: 2.160174608230591, 1100: 0.9979056715965271, 1200: 0.5871980786323547, 1300: 1.017005205154419, 1400: 0.43248283863067627, 1500: 0.8065310120582581, 1600: 1.46786367893219, 1700: 2.1024653911590576, 1800: 0.17947052419185638, 1900: 0.8789610266685486, 2000: 1.4791946411132812, 2100: 0.601864218711853, 2200: 1.743896245956421, 2300: 0.5872783660888672, 2400: 0.5708857178688049, 2500: 1.0015186071395874, 2600: 0.40014728903770447, 2700: 3.196885108947754, 2800: 0.1142575591802597, 2900: 1.133739709854126, 3000: 1.2223150730133057, 3100: 0.5486159324645996, 3200: 1.0524144172668457, 3300: 0.9275966882705688, 3400: 0.6217947602272034, 3500: 0.7378378510475159, 3600: 1.3263416290283203, 3700: 0.9482681751251221, 3800: 1.5620522499084473, 3900: 0.24886365234851837, 4000: 0.5486193299293518, 4100: 0.9452401995658875, 4200: 0.5287258625030518, 4300: 1.7784841060638428, 4400: 1.3229526281356812, 4500: 1.1152455806732178, 4600: 1.704445242881775, 4700: 1.5828299522399902, 4800: 0.7237018346786499, 4900: 2.3260550498962402, 5000: 0.9239354729652405, 5100: 0.10699130594730377, 5200: 1.1979455947875977, 5300: 1.077502727508545, 5400: 0.7661776542663574, 5500: 0.7787296772003174, 5600: 2.2343435287475586, 5700: 0.2966063618659973, 5800: 0.7696855068206787, 5900: 0.7663536071777344, 6000: 0.36249110102653503, 6100: 0.3623797595500946, 6200: 1.2192720174789429, 6300: 0.7957590818405151, 6400: 0.8203390836715698, 6500: 0.6183543801307678, 6600: 0.4317423701286316, 6700: 7.090464115142822, 6800: 1.1538145542144775, 6900: 0.5641670227050781, 7000: 0.92751544713974, 7100: 1.0296071767807007, 7200: 0.5872665047645569, 7300: 4.869577884674072, 7400: 0.7792521119117737, 7500: 1.0611329078674316, 7600: 1.1926907300949097, 7700: 0.1951131373643875, 7800: 0.8131570219993591, 7900: 0.883981466293335, 8000: 0.6326078772544861, 8100: 1.566864013671875, 8200: 0.6544318199157715, 8300: 1.0988614559173584, 8400: 0.2806614339351654, 8500: 0.3371838927268982, 8600: 0.909440279006958, 8700: 1.6721217632293701, 8800: 1.536877155303955, 8900: 1.2355690002441406, 9000: 1.0621178150177002, 9100: 0.457677960395813, 9200: 0.4025226831436157, 9300: 0.4032084047794342, 9400: 0.7479690909385681, 9500: 0.5014516711235046, 9600: 1.127721905708313, 9700: 0.1550794392824173, 9800: 0.6701760292053223, 9900: 1.1340914964675903, 10000: 1.9551894664764404, 10100: 1.3857285976409912, 10200: 1.6032382249832153, 10300: 1.2614867687225342, 10400: 1.6393486261367798, 10500: 0.5810733437538147, 10600: 0.7603214383125305, 10700: 2.4402525424957275, 10800: 2.7124814987182617, 10900: 0.20909130573272705, 11000: 1.3959529399871826, 11100: 1.0909596681594849, 11200: 1.6325223445892334, 11300: 0.218738853931427, 11400: 1.5457310676574707, 11500: 0.577633261680603, 11600: 0.5558343529701233, 11700: 4.388785362243652, 11800: 1.1065807342529297, 11900: 0.5579276084899902, 12000: 1.0206608772277832, 12100: 0.5765864253044128, 12200: 0.748683750629425, 12300: 0.7343854904174805, 12400: 0.9534815549850464, 12500: 1.6312772035598755, 12600: 1.778548002243042, 12700: 0.605501115322113, 12800: 0.8983965516090393, 12900: 1.7353123426437378, 13000: 1.7297009229660034, 13100: 1.1326991319656372, 13200: 0.5106571316719055, 13300: 0.21636413037776947, 13400: 1.164119005203247, 13500: 2.946742057800293, 13600: 0.5496973395347595, 13700: 1.1174652576446533, 13800: 0.42494142055511475, 13900: 1.1835496425628662, 14000: 0.2803606390953064, 14100: 1.4774439334869385, 14200: 0.31485024094581604, 14300: 0.7776796817779541, 14400: 7.9825310707092285, 14500: 0.5603703260421753, 14600: 5.294471740722656, 14700: 2.136337995529175, 14800: 1.19759202003479, 14900: 1.3942902088165283, 15000: 1.048850655555725, 15100: 0.8325331807136536, 15200: 0.6918210387229919, 15300: 0.632685124874115, 15400: 0.6708773970603943, 15500: 1.0360605716705322, 15600: 0.5172858834266663, 15700: 1.2227962017059326, 15800: 0.9792490005493164, 15900: 0.5463705658912659, 16000: 0.7245826125144958, 16100: 1.8041870594024658, 16200: 1.0725057125091553, 16300: 0.3830254375934601, 16400: 0.8732719421386719, 16500: 0.7436233162879944, 16600: 0.413596510887146, 16700: 0.8674027919769287, 16800: 0.6098858714103699, 16900: 0.8900026679039001, 17000: 0.2912898659706116, 17100: 0.7382040619850159, 17200: 1.4304922819137573, 17300: 0.5811054110527039, 17400: 0.8811078071594238, 17500: 0.4404444098472595, 17600: 0.4818248450756073, 17700: 2.3620033264160156, 17800: 2.2582485675811768, 17900: 0.8733226656913757, 18000: 1.4610944986343384, 18100: 0.5951346755027771, 18200: 0.978776216506958, 18300: 2.197563409805298, 18400: 1.0949002504348755, 18500: 0.8308669924736023, 18600: 0.7313578724861145, 18700: 0.8673983216285706, 18800: 4.551797389984131, 18900: 0.6246597170829773, 19000: 0.7272583842277527, 19100: 0.5297366380691528, 19200: 0.29636815190315247, 19300: 0.6835434436798096, 19400: 0.7764901518821716, 19500: 4.143259525299072, 19600: 0.6436047554016113, 19700: 0.7396442890167236, 19800: 0.426420658826828, 19900: 0.33505722880363464, 20000: 0.2881277799606323, 20100: 0.9330406785011292, 20200: 0.864387571811676, 20300: 1.6755421161651611, 20400: 0.9301566481590271, 20500: 1.284062147140503, 20600: 1.0796513557434082, 20700: 0.7912596464157104, 20800: 1.2304741144180298, 20900: 0.9351352453231812, 21000: 0.43350735306739807, 21100: 0.9237954616546631, 21200: 1.254602074623108, 21300: 0.523834228515625, 21400: 0.7178162932395935, 21500: 0.968723475933075, 21600: 1.645923376083374, 21700: 0.8964558243751526, 21800: 0.8853956460952759, 21900: 0.49531418085098267, 22000: 0.8265661001205444, 22100: 0.9535820484161377, 22200: 0.4486490488052368, 22300: 0.9181960225105286, 22400: 0.5894383788108826, 22500: 0.522270917892456, 22600: 0.23564735054969788, 22700: 0.7024903893470764, 22800: 0.32824796438217163, 22900: 0.1860615462064743, 23000: 0.39757251739501953, 23100: 0.46492624282836914, 23200: 1.3523638248443604, 23300: 0.3526262938976288, 23400: 1.1033642292022705, 23500: 0.4087134599685669, 23600: 2.3910417556762695, 23700: 0.42877745628356934, 23800: 0.49499842524528503, 23900: 0.9787629842758179, 24000: 0.20165862143039703, 24100: 0.7528786063194275, 24200: 1.8227043151855469, 24300: 0.6423332691192627, 24400: 1.9321801662445068, 24500: 0.6547260284423828, 24600: 3.22259259223938, 24700: 1.58344566822052, 24800: 1.6795337200164795, 24900: 0.2405516356229782, 25000: 1.4298652410507202, 25100: 0.620222270488739, 25200: 0.6894649267196655, 25300: 0.3175992965698242, 25400: 1.0845673084259033, 25500: 0.9492177367210388, 25600: 1.2187035083770752, 25700: 0.2975495755672455, 25800: 1.5657424926757812, 25900: 0.6503640413284302, 26000: 0.44444704055786133, 26100: 0.797187089920044, 26200: 1.6231496334075928, 26300: 0.8548079133033752, 26400: 0.6245496273040771, 26500: 1.0952048301696777, 26600: 0.46530336141586304, 26700: 1.131869912147522, 26800: 0.34059634804725647, 26900: 1.2098608016967773, 27000: 0.47753679752349854, 27100: 0.2893100380897522, 27200: 1.5215017795562744, 27300: 0.8733530640602112, 27400: 0.7895289063453674, 27500: 1.0394096374511719, 27600: 1.0266072750091553, 27700: 1.8224196434020996, 27800: 0.5666912794113159, 27900: 0.35908931493759155, 28000: 0.29209104180336, 28100: 0.7289214730262756, 28200: 0.32810312509536743, 28300: 1.0624046325683594, 28400: 0.8941333889961243, 28500: 0.4161592125892639, 28600: 1.9040873050689697, 28700: 0.9628007411956787, 28800: 1.238804817199707, 28900: 1.134016513824463, 29000: 0.585601806640625}, 'F1': {0: 0.5542318748111204, 100: 0.5357402721537755, 200: 0.5712434482395199, 300: 0.6014133288851773, 400: 0.5456097308527303, 500: 0.5727570119567089, 600: 0.5912517328736506, 700: 0.6012553274432287, 800: 0.5922797606711494, 900: 0.5504581399444329, 1000: 0.523858507523407, 1100: 0.5317076927518071, 1200: 0.4660937463299359, 1300: 0.5597390005092364, 1400: 0.5184565019539208, 1500: 0.5402540632302356, 1600: 0.5785387720316897, 1700: 0.5211201548093599, 1800: 0.5179392747272518, 1900: 0.5726635600700647, 2000: 0.599185451911745, 2100: 0.46316852208721665, 2200: 0.571726333760608, 2300: 0.544200980701787, 2400: 0.5768472202531199, 2500: 0.4451345245322029, 2600: 0.5415253469872213, 2700: 0.48204653921963964, 2800: 0.5090287620517608, 2900: 0.5702965853014832, 3000: 0.5738833470856235, 3100: 0.5795320959464016, 3200: 0.5822135057213209, 3300: 0.5624946001614849, 3400: 0.3981910991534493, 3500: 0.5299927471911954, 3600: 0.522664953918312, 3700: 0.4861696728382285, 3800: 0.5672377417008174, 3900: 0.6032079475841716, 4000: 0.5675476394647787, 4100: 0.5047649209306736, 4200: 0.5574223209070363, 4300: 0.5832913016166015, 4400: 0.52169716190113, 4500: 0.5541845684893223, 4600: 0.5732598781804878, 4700: 0.4925600879512649, 4800: 0.4978684683482289, 4900: 0.5249479212306326, 5000: 0.5237207405582784, 5100: 0.5687140968843634, 5200: 0.5302553291406645, 5300: 0.5912198650524811, 5400: 0.6004856163581017, 5500: 0.5262247944326763, 5600: 0.5750655159747025, 5700: 0.5435894018660631, 5800: 0.4886330591467163, 5900: 0.4753040207204473, 6000: 0.5611226802710712, 6100: 0.4908348660678028, 6200: 0.5161589881339709, 6300: 0.5725989971985609, 6400: 0.4898297211938567, 6500: 0.5010565378566731, 6600: 0.5827521654786904, 6700: 0.5960130234302992, 6800: 0.5189433445953667, 6900: 0.5792294057732544, 7000: 0.604219924458943, 7100: 0.5347106725375027, 7200: 0.55753669802881, 7300: 0.5999466352020338, 7400: 0.4583448210149182, 7500: 0.45051522138860567, 7600: 0.5075159035931432, 7700: 0.5018508276056819, 7800: 0.5855435114604721, 7900: 0.5601355647167993, 8000: 0.5474590164926073, 8100: 0.5657655176668022, 8200: 0.5481222238508087, 8300: 0.5641807847611506, 8400: 0.5073416176513892, 8500: 0.5265369020767071, 8600: 0.5273354980790423, 8700: 0.5809283629083271, 8800: 0.5887107671044336, 8900: 0.5905426635990745, 9000: 0.49744005921041407, 9100: 0.5002203780101935, 9200: 0.5834635783300832, 9300: 0.5725935381530566, 9400: 0.4752264830823212, 9500: 0.4458729918482765, 9600: 0.5455520814320146, 9700: 0.4683045048301551, 9800: 0.47164650443222733, 9900: 0.4707244105263989, 10000: 0.5337902782548328, 10100: 0.5436143626364659, 10200: 0.4983623076269193, 10300: 0.5970502078376172, 10400: 0.5735936946359161, 10500: 0.5151474465404179, 10600: 0.6097777869575195, 10700: 0.5023909541708124, 10800: 0.5485642279559239, 10900: 0.5944741459053569, 11000: 0.471992421085908, 11100: 0.48820987086030404, 11200: 0.5409337901684754, 11300: 0.5815533280372995, 11400: 0.49384622849028176, 11500: 0.5740887719445568, 11600: 0.5757931953758099, 11700: 0.572760589540502, 11800: 0.5843858670941359, 11900: 0.5671959372539436, 12000: 0.45717268023223206, 12100: 0.5847500728612203, 12200: 0.5806004746116165, 12300: 0.5868192526198756, 12400: 0.5773596162633777, 12500: 0.6077422697988173, 12600: 0.5651887300440674, 12700: 0.5303812884128055, 12800: 0.4690717306076266, 12900: 0.5720432975271609, 13000: 0.5102043234650413, 13100: 0.597968216144788, 13200: 0.5903928168787177, 13300: 0.5476368024468745, 13400: 0.5556066044373694, 13500: 0.49549773615165355, 13600: 0.4898275989350683, 13700: 0.5578749790987494, 13800: 0.5372539679834971, 13900: 0.5755830259462471, 14000: 0.45856249449903186, 14100: 0.6027660741606188, 14200: 0.5503178745735883, 14300: 0.5666638408084611, 14400: 0.5554632565471772, 14500: 0.5027904406337028, 14600: 0.579455138695674, 14700: 0.5503856523482803, 14800: 0.5861361299596468, 14900: 0.5826939929462855, 15000: 0.44044901060219316, 15100: 0.5517032335371823, 15200: 0.5614216165133903, 15300: 0.5043081126554748, 15400: 0.44456062438112975, 15500: 0.5042597089431665, 15600: 0.5304261409186307, 15700: 0.5800919122135798, 15800: 0.5873000444494386, 15900: 0.5796903781361441, 16000: 0.600657678074698, 16100: 0.5361671041252968, 16200: 0.5751821407363029, 16300: 0.5663029580313848, 16400: 0.527126984185397, 16500: 0.5264028742962675, 16600: 0.5818098172577607, 16700: 0.4940872385776759, 16800: 0.5044361098240661, 16900: 0.5552619768894947, 17000: 0.5365516346279221, 17100: 0.49990427854040986, 17200: 0.5042078952936614, 17300: 0.5502571828423061, 17400: 0.48353267076540407, 17500: 0.6085303885775383, 17600: 0.5738021231578778, 17700: 0.5260820372248621, 17800: 0.5475221927409207, 17900: 0.545132447763791, 18000: 0.4053162641261761, 18100: 0.4803938342498613, 18200: 0.5340201647097426, 18300: 0.5684463140715418, 18400: 0.5190240082374322, 18500: 0.5421549058677465, 18600: 0.529278644553066, 18700: 0.5441218384432309, 18800: 0.5629980499826986, 18900: 0.5753768425389667, 19000: 0.596678503503772, 19100: 0.5914070597203707, 19200: 0.4400426888912212, 19300: 0.5848620750618965, 19400: 0.5458230324894731, 19500: 0.5922970745614081, 19600: 0.6032290717875651, 19700: 0.5984282869832825, 19800: 0.5710990513449618, 19900: 0.5776244847656924, 20000: 0.5498364294547237, 20100: 0.4764121006681774, 20200: 0.5687856049000545, 20300: 0.533453161865774, 20400: 0.4619915006974923, 20500: 0.5761298439158079, 20600: 0.593956774898084, 20700: 0.5484919110959019, 20800: 0.4431024358873451, 20900: 0.5639680257311857, 21000: 0.5619720386964074, 21100: 0.5733920954656967, 21200: 0.5975928521950965, 21300: 0.5318585393561305, 21400: 0.5620867635116361, 21500: 0.5346456095727645, 21600: 0.4605074382026441, 21700: 0.5559375017256644, 21800: 0.5857959907994018, 21900: 0.5733713900791483, 22000: 0.5335745431659032, 22100: 0.4528416295276323, 22200: 0.48972045641862977, 22300: 0.4740118048459289, 22400: 0.5396770581772005, 22500: 0.5792505630356045, 22600: 0.5457850866993401, 22700: 0.5405719023807968, 22800: 0.5872229092149384, 22900: 0.5494370656894136, 23000: 0.5875883022868682, 23100: 0.5045655245847812, 23200: 0.5804499674783347, 23300: 0.5720537161703416, 23400: 0.5351185794682198, 23500: 0.5510880896758658, 23600: 0.48565216335226435, 23700: 0.5534902339758555, 23800: 0.590502142352154, 23900: 0.44551306176840755, 24000: 0.4886201556405083, 24100: 0.45574730347477943, 24200: 0.6001571852422516, 24300: 0.5670925625268516, 24400: 0.43082758784948805, 24500: 0.5294304850736494, 24600: 0.5408489978032596, 24700: 0.5515335604900905, 24800: 0.5765187866137346, 24900: 0.5739939631805052, 25000: 0.4553556326238711, 25100: 0.5712948728049299, 25200: 0.46944050154314054, 25300: 0.48856233418640377, 25400: 0.5472492910923132, 25500: 0.60891851623052, 25600: 0.5898071191800012, 25700: 0.5471782342811179, 25800: 0.5521407364638469, 25900: 0.4250799042262186, 26000: 0.488658336859716, 26100: 0.5197275971484961, 26200: 0.5335824027150066, 26300: 0.5581174633735192, 26400: 0.5856557369060386, 26500: 0.5475570327046855, 26600: 0.5562005603612539, 26700: 0.46703145696028847, 26800: 0.5063414206372185, 26900: 0.5500732006373634, 27000: 0.4594721101102287, 27100: 0.5445489581233239, 27200: 0.5958650060285736, 27300: 0.5600471302617724, 27400: 0.5927987561556244, 27500: 0.5704167771243592, 27600: 0.5855563886441152, 27700: 0.6058780770285853, 27800: 0.5169601701347218, 27900: 0.4643735102821902, 28000: 0.5422170940423204, 28100: 0.49573281056768564, 28200: 0.4877589570631612, 28300: 0.5391710508509022, 28400: 0.6093676769133145, 28500: 0.5562641612604206, 28600: 0.6106775545504776, 28700: 0.5807113942535348, 28800: 0.5944793228714187, 28900: 0.49941511502581426, 29000: 0.48790321217782806}, 'Accuracy': {0: 0.5094625283875852, 100: 0.5092560732227651, 200: 0.5210928360057807, 300: 0.5332736907301631, 400: 0.5062968825270112, 500: 0.5191659211341271, 600: 0.5237767531484413, 700: 0.5297639529282224, 800: 0.5273553093386553, 900: 0.5093937099993118, 1000: 0.4987268598169431, 1100: 0.503268873442984, 1200: 0.4853072741036405, 1300: 0.5169637327093799, 1400: 0.5033376918312573, 1500: 0.5025806895602505, 1600: 0.5261853967380083, 1700: 0.5055398802560044, 1800: 0.5049893331498176, 1900: 0.5168260959328332, 2000: 0.5329295987887964, 2100: 0.48358681439680684, 2200: 0.5190282843575803, 2300: 0.5099442571054986, 2400: 0.5160002752735531, 2500: 0.47766843300529904, 2600: 0.5111829880944189, 2700: 0.4870965521987475, 2800: 0.4908127451655082, 2900: 0.5172390062624733, 3000: 0.5200605601816806, 3100: 0.5163443672149198, 3200: 0.5236391163718945, 3300: 0.5224003853829743, 3400: 0.4694102264124974, 3500: 0.5095313467758585, 3600: 0.5082926157869383, 3700: 0.49301493359025533, 3800: 0.5179960085334802, 3900: 0.5300392264813159, 4000: 0.5299704080930424, 4100: 0.49748812882802285, 4200: 0.5052646067029111, 4300: 0.5226068405477944, 4400: 0.503268873442984, 4500: 0.508430252563485, 4600: 0.5204734705113206, 4700: 0.48998692450622805, 4800: 0.501479595347877, 4900: 0.5077420686807514, 5000: 0.5060904273621912, 5100: 0.5168260959328332, 5200: 0.5042323308788108, 5300: 0.5318285045764228, 5400: 0.532654325235703, 5500: 0.5026495079485238, 5600: 0.5220562934416076, 5700: 0.5141421787901728, 5800: 0.5014107769596036, 5900: 0.48861055674076115, 6000: 0.5131099029660725, 6100: 0.4962493978391026, 6200: 0.49803867593420964, 6300: 0.5133851765191659, 6400: 0.49397839102608215, 6500: 0.49294611520198195, 6600: 0.5277682196682953, 6700: 0.5323790516826096, 6800: 0.491363292271695, 6900: 0.5154497281673663, 7000: 0.5369210653086505, 7100: 0.5149679994494529, 7200: 0.5110453513178721, 7300: 0.5330672355653431, 7400: 0.4823480834078866, 7500: 0.47808134333493907, 7600: 0.5016172321244237, 7700: 0.4958364875094625, 7800: 0.5240520267015346, 7900: 0.5109765329295988, 8000: 0.507260339962838, 8100: 0.5131099029660725, 8200: 0.5040258757139908, 8300: 0.515587364943913, 8400: 0.4952859404032758, 8500: 0.5024430527837038, 8600: 0.5045764228201776, 8700: 0.5179960085334802, 8800: 0.5228132957126144, 8900: 0.5272176725621086, 9000: 0.49796985754593626, 9100: 0.4941848461909022, 9200: 0.5254283944670016, 9300: 0.5240520267015346, 9400: 0.4848255453857271, 9500: 0.46899731608285733, 9600: 0.5100818938820453, 9700: 0.49205147615442846, 9800: 0.4817975363016998, 9900: 0.4864771867042874, 10000: 0.5012731401830569, 10100: 0.5009978666299635, 10200: 0.48558254765673386, 10300: 0.5283875851627555, 10400: 0.5252907576904549, 10500: 0.4985892230403964, 10600: 0.5371275204734706, 10700: 0.494735393297089, 10800: 0.5091872548344918, 10900: 0.5295574977634023, 11000: 0.477461977840479, 11100: 0.48262335696097997, 11200: 0.5007914114651435, 11300: 0.5183401004748469, 11400: 0.49260202326061525, 11500: 0.5147615442846328, 11600: 0.5257724864083683, 11700: 0.5244649370311747, 11800: 0.5152432730025462, 11900: 0.5182024636983001, 12000: 0.48007707659486615, 12100: 0.5246025738077215, 12200: 0.5283187667744822, 12300: 0.5288693138806689, 12400: 0.5250154841373615, 12500: 0.5335489642832565, 12600: 0.5182712820865736, 12700: 0.5035441469960773, 12800: 0.4823480834078866, 12900: 0.5188218291927603, 13000: 0.49652467139219597, 13100: 0.5271488541738353, 13200: 0.5178583717569335, 13300: 0.5064345193035579, 13400: 0.5153120913908197, 13500: 0.4923267497075218, 13600: 0.49108801871860164, 13700: 0.5136604500722594, 13800: 0.5118711719771523, 13900: 0.521161654394054, 14000: 0.4783566168880325, 14100: 0.5351317872135435, 14200: 0.5180648269217535, 14300: 0.5150368178377263, 14400: 0.5125593558598858, 14500: 0.501686050512697, 14600: 0.5247402105842681, 14700: 0.5074667951276581, 14800: 0.5224692037712477, 14900: 0.5158626384970064, 15000: 0.47670497556947217, 15100: 0.508430252563485, 15200: 0.5154497281673663, 15300: 0.4934278439198954, 15400: 0.4797329846534994, 15500: 0.4956988507329158, 15600: 0.5083614341752116, 15700: 0.5180648269217535, 15800: 0.5212304727823275, 15900: 0.522538022159521, 16000: 0.5298327713164958, 16100: 0.503888238937444, 16200: 0.5182712820865736, 16300: 0.5176519165921134, 16400: 0.4958364875094625, 16500: 0.5051957883146376, 16600: 0.5208175624526874, 16700: 0.48964283256486135, 16800: 0.49012456128277476, 16900: 0.5129034478012525, 17000: 0.5019613240657904, 17100: 0.4921202945427018, 17200: 0.49349666230816874, 17300: 0.510632440988232, 17400: 0.48365563278508017, 17500: 0.536232881425917, 17600: 0.5173078246507467, 17700: 0.49659348978046935, 17800: 0.50010322758241, 17900: 0.5043699676553575, 18000: 0.46617576216365014, 18100: 0.4811781708072397, 18200: 0.4985892230403964, 18300: 0.5177895533686601, 18400: 0.5062280641387379, 18500: 0.5157938201087331, 18600: 0.5062968825270112, 18700: 0.505471061867731, 18800: 0.5119399903654256, 18900: 0.5133851765191659, 19000: 0.5321725965177896, 19100: 0.5287316771041222, 19200: 0.47505333425091184, 19300: 0.5237767531484413, 19400: 0.5093248916110384, 19500: 0.5295574977634023, 19600: 0.5371963388617439, 19700: 0.5232262060422544, 19800: 0.5157938201087331, 19900: 0.5224692037712477, 20000: 0.51737664303902, 20100: 0.4926708416488886, 20200: 0.5202670153465005, 20300: 0.48806000963457435, 20400: 0.4801458949831395, 20500: 0.5179271901452068, 20600: 0.5288693138806689, 20700: 0.5045076044319042, 20800: 0.48496318216227374, 20900: 0.5147615442846328, 21000: 0.5191659211341271, 21100: 0.5233638428188012, 21200: 0.5297639529282224, 21300: 0.503475328607804, 21400: 0.5175142798155667, 21500: 0.501686050512697, 21600: 0.4843438166678136, 21700: 0.513798086848806, 21800: 0.522331566994701, 21900: 0.5232262060422544, 22000: 0.49810749432248297, 22100: 0.4819351730782465, 22200: 0.48902346707040123, 22300: 0.4771867042873856, 22400: 0.5077420686807514, 22500: 0.5224003853829743, 22600: 0.5203358337347739, 22700: 0.5044387860436309, 22800: 0.5185465556396669, 22900: 0.5065033376918313, 23000: 0.524120845089808, 23100: 0.5044387860436309, 23200: 0.5235702979836212, 23300: 0.5180648269217535, 23400: 0.5034065102195306, 23500: 0.5183401004748469, 23600: 0.49198265776615513, 23700: 0.5151056362259996, 23800: 0.5292134058220357, 23900: 0.48152226274860643, 24000: 0.49335902553162203, 24100: 0.48262335696097997, 24200: 0.53444360333081, 24300: 0.5138669052370793, 24400: 0.47773725139357237, 24500: 0.5051269699263643, 24600: 0.5053334250911844, 24700: 0.5102195306585919, 24800: 0.524327300254628, 24900: 0.5230885692657078, 25000: 0.4843438166678136, 25100: 0.5161379120500997, 25200: 0.49466657490881566, 25300: 0.5014107769596036, 25400: 0.5073979767393848, 25500: 0.5357511527080036, 25600: 0.523707934760168, 25700: 0.5115270800357855, 25800: 0.511595898424059, 25900: 0.4729199642144381, 26000: 0.48750946252838756, 26100: 0.4968687633335627, 26200: 0.5051957883146376, 26300: 0.5175142798155667, 26400: 0.5281811299979354, 26500: 0.5073291583511114, 26600: 0.5102883490468654, 26700: 0.48599545798637395, 26800: 0.49852040465212305, 26900: 0.5147615442846328, 27000: 0.4820728098547932, 27100: 0.5043011492670841, 27200: 0.5321725965177896, 27300: 0.5156561833321863, 27400: 0.5212304727823275, 27500: 0.5114582616475122, 27600: 0.5247402105842681, 27700: 0.5353382423783635, 27800: 0.5074667951276581, 27900: 0.4907439267772349, 28000: 0.5089119812813984, 28100: 0.48854173835248776, 28200: 0.49955268047622325, 28300: 0.5121464455302457, 28400: 0.5372651572500172, 28500: 0.5204046521230473, 28600: 0.5352006056018168, 28700: 0.5191659211341271, 28800: 0.5290757690454889, 28900: 0.5003785011355034, 29000: 0.4864771867042874}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.61      0.61      0.61       897\n",
      "           4       0.53      0.75      0.62       892\n",
      "           5       0.53      0.66      0.59       862\n",
      "           6       0.59      0.75      0.66       903\n",
      "           7       0.57      0.80      0.67       889\n",
      "           8       0.59      0.32      0.41       892\n",
      "           9       0.51      0.79      0.62       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 0, Loss: 1.7563214302062988, F1: 0.5861559157401192, Accuracy: 0.5239832083132613, Time Elapsed: 14.794118165969849 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.63      0.09      0.16       885\n",
      "           2       0.63      0.27      0.38       877\n",
      "           3       0.61      0.60      0.61       897\n",
      "           4       0.59      0.56      0.57       892\n",
      "           5       0.53      0.65      0.58       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.57      0.75      0.65       892\n",
      "           9       0.55      0.82      0.66       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 100, Loss: 0.6639291048049927, F1: 0.5501918705234937, Accuracy: 0.5165508223797398, Time Elapsed: 30.37507724761963 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.62      0.22      0.33       885\n",
      "           2       0.58      0.60      0.59       877\n",
      "           3       0.59      0.71      0.64       897\n",
      "           4       0.67      0.17      0.27       892\n",
      "           5       0.56      0.46      0.50       862\n",
      "           6       0.57      0.91      0.70       903\n",
      "           7       0.60      0.79      0.68       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.61      0.52      0.56       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.57      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 200, Loss: 0.39853328466415405, F1: 0.5444675357099421, Accuracy: 0.5145550891198128, Time Elapsed: 50.00724816322327 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.58      0.91      0.71       885\n",
      "           2       0.59      0.52      0.55       877\n",
      "           3       0.61      0.52      0.56       897\n",
      "           4       0.55      0.65      0.60       892\n",
      "           5       0.50      0.71      0.59       862\n",
      "           6       0.61      0.53      0.57       903\n",
      "           7       0.61      0.66      0.63       889\n",
      "           8       0.59      0.64      0.62       892\n",
      "           9       0.61      0.38      0.47       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 300, Loss: 0.8684584498405457, F1: 0.577358934684089, Accuracy: 0.5177207349803867, Time Elapsed: 66.47790908813477 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.66       912\n",
      "           1       0.64      0.21      0.32       885\n",
      "           2       0.59      0.33      0.43       877\n",
      "           3       0.57      0.68      0.62       897\n",
      "           4       0.71      0.01      0.01       892\n",
      "           5       0.51      0.57      0.53       862\n",
      "           6       0.61      0.54      0.57       903\n",
      "           7       0.61      0.48      0.53       889\n",
      "           8       0.55      0.65      0.60       892\n",
      "           9       0.60      0.51      0.55       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.47      0.48     14531\n",
      "weighted avg       0.52      0.48      0.47     14531\n",
      "\n",
      "Epoch 4, Step 400, Loss: 0.5931786894798279, F1: 0.47841318913498515, Accuracy: 0.48365563278508017, Time Elapsed: 81.85515809059143 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.66      0.12      0.20       885\n",
      "           2       0.57      0.58      0.58       877\n",
      "           3       0.56      0.76      0.65       897\n",
      "           4       0.52      0.83      0.64       892\n",
      "           5       0.58      0.49      0.53       862\n",
      "           6       0.58      0.79      0.67       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.53      0.75      0.62       892\n",
      "           9       0.56      0.74      0.64       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 500, Loss: 1.6688618659973145, F1: 0.5658972782833915, Accuracy: 0.5173078246507467, Time Elapsed: 96.47998523712158 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.72       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.60      0.40      0.48       877\n",
      "           3       0.55      0.74      0.63       897\n",
      "           4       0.45      0.89      0.59       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.57      0.85      0.68       903\n",
      "           7       0.59      0.59      0.59       889\n",
      "           8       0.54      0.69      0.61       892\n",
      "           9       0.60      0.49      0.54       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 600, Loss: 1.1723490953445435, F1: 0.5841185639568546, Accuracy: 0.5195788314637672, Time Elapsed: 111.18162989616394 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68       912\n",
      "           1       0.61      0.73      0.66       885\n",
      "           2       0.59      0.42      0.49       877\n",
      "           3       0.59      0.62      0.61       897\n",
      "           4       0.53      0.66      0.59       892\n",
      "           5       0.54      0.69      0.61       862\n",
      "           6       0.57      0.89      0.69       903\n",
      "           7       0.60      0.82      0.69       889\n",
      "           8       0.59      0.52      0.55       892\n",
      "           9       0.58      0.59      0.59       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 700, Loss: 0.6088302731513977, F1: 0.5906277433166648, Accuracy: 0.5247402105842681, Time Elapsed: 126.79177904129028 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.60      0.38      0.47       877\n",
      "           3       0.60      0.69      0.64       897\n",
      "           4       0.49      0.92      0.64       892\n",
      "           5       0.49      0.78      0.60       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.56      0.44      0.49       892\n",
      "           9       0.56      0.69      0.62       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.66      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 800, Loss: 0.9528260827064514, F1: 0.5900294995153259, Accuracy: 0.5249466657490881, Time Elapsed: 142.14788007736206 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       912\n",
      "           1       0.65      0.17      0.26       885\n",
      "           2       0.46      0.86      0.60       877\n",
      "           3       0.62      0.40      0.49       897\n",
      "           4       0.60      0.42      0.49       892\n",
      "           5       0.54      0.27      0.36       862\n",
      "           6       0.60      0.72      0.65       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.60      0.30      0.40       892\n",
      "           9       0.57      0.73      0.64       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.53      0.51     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 900, Loss: 1.0327026844024658, F1: 0.5106692157790075, Accuracy: 0.4912944738834216, Time Elapsed: 158.35118508338928 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.59      0.43      0.50       877\n",
      "           3       0.61      0.31      0.41       897\n",
      "           4       0.60      0.46      0.52       892\n",
      "           5       0.55      0.47      0.51       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.60      0.68      0.63       889\n",
      "           8       0.59      0.39      0.47       892\n",
      "           9       0.49      0.85      0.62       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 1000, Loss: 0.5455027222633362, F1: 0.5534327767725109, Accuracy: 0.5091872548344918, Time Elapsed: 173.8139820098877 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       912\n",
      "           1       0.61      0.73      0.66       885\n",
      "           2       0.57      0.65      0.61       877\n",
      "           3       0.68      0.05      0.09       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.54      0.26      0.35       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.60      0.45      0.51       889\n",
      "           8       0.59      0.54      0.56       892\n",
      "           9       0.57      0.74      0.64       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 1100, Loss: 0.7943408489227295, F1: 0.5320560420852583, Accuracy: 0.5075356135159315, Time Elapsed: 188.8288881778717 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.85      0.70       912\n",
      "           1       0.62      0.35      0.45       885\n",
      "           2       0.59      0.41      0.48       877\n",
      "           3       0.61      0.47      0.53       897\n",
      "           4       0.57      0.74      0.65       892\n",
      "           5       0.56      0.41      0.48       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.59      0.69      0.64       889\n",
      "           8       0.60      0.33      0.42       892\n",
      "           9       0.58      0.61      0.59       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.54      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 1200, Loss: 0.4156230688095093, F1: 0.5451811660190025, Accuracy: 0.506847429633198, Time Elapsed: 204.513906955719 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.82      0.68       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.62      0.17      0.27       877\n",
      "           3       0.60      0.55      0.58       897\n",
      "           4       0.55      0.78      0.65       892\n",
      "           5       0.54      0.38      0.44       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.59      0.67      0.62       889\n",
      "           8       0.59      0.28      0.38       892\n",
      "           9       0.55      0.72      0.62       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 1300, Loss: 0.9983800649642944, F1: 0.5475122528318734, Accuracy: 0.5114582616475122, Time Elapsed: 220.1697371006012 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.57      0.48      0.52       877\n",
      "           3       0.62      0.39      0.48       897\n",
      "           4       0.61      0.44      0.51       892\n",
      "           5       0.56      0.11      0.18       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.57      0.86      0.69       889\n",
      "           8       0.57      0.29      0.38       892\n",
      "           9       0.58      0.08      0.14       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.50      0.48     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 1400, Loss: 0.4849376380443573, F1: 0.4842258096318567, Accuracy: 0.4943224829674489, Time Elapsed: 235.2509570121765 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.61      0.73      0.67       885\n",
      "           2       0.57      0.53      0.55       877\n",
      "           3       0.59      0.31      0.40       897\n",
      "           4       0.50      0.92      0.65       892\n",
      "           5       0.54      0.39      0.45       862\n",
      "           6       0.60      0.71      0.65       903\n",
      "           7       0.60      0.47      0.52       889\n",
      "           8       0.52      0.60      0.56       892\n",
      "           9       0.56      0.04      0.07       876\n",
      "          10       0.38      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.54      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 1500, Loss: 0.4675500690937042, F1: 0.5098943392697989, Accuracy: 0.4928772968137086, Time Elapsed: 249.89794206619263 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.56      0.97      0.71       885\n",
      "           2       0.57      0.47      0.52       877\n",
      "           3       0.61      0.35      0.44       897\n",
      "           4       0.59      0.64      0.61       892\n",
      "           5       0.52      0.71      0.60       862\n",
      "           6       0.60      0.64      0.62       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.54      0.74      0.62       892\n",
      "           9       0.58      0.19      0.28       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 1600, Loss: 1.4295170307159424, F1: 0.5561185037517229, Accuracy: 0.5120776271419724, Time Elapsed: 265.2878921031952 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.62      0.79      0.69       885\n",
      "           2       0.61      0.41      0.49       877\n",
      "           3       0.63      0.29      0.40       897\n",
      "           4       0.58      0.73      0.64       892\n",
      "           5       0.54      0.57      0.55       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.54      0.80      0.64       892\n",
      "           9       0.57      0.53      0.55       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 1700, Loss: 1.431908369064331, F1: 0.5767998886263668, Accuracy: 0.5224692037712477, Time Elapsed: 281.2790389060974 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.63      0.29      0.40       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.55      0.78      0.65       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.62      0.56      0.59       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.56      0.61      0.59       892\n",
      "           9       0.64      0.22      0.33       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.57      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 1800, Loss: 0.6139280796051025, F1: 0.5509028323607349, Accuracy: 0.5121464455302457, Time Elapsed: 296.9789619445801 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.70       912\n",
      "           1       0.56      0.79      0.65       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.60      0.35      0.44       897\n",
      "           4       0.56      0.81      0.66       892\n",
      "           5       0.55      0.23      0.32       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.61      0.41      0.49       889\n",
      "           8       0.57      0.63      0.60       892\n",
      "           9       0.57      0.45      0.50       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 1900, Loss: 0.9836366176605225, F1: 0.5480073021683601, Accuracy: 0.5069162480214713, Time Elapsed: 312.9785771369934 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.90      0.71       912\n",
      "           1       0.52      0.97      0.68       885\n",
      "           2       0.56      0.73      0.64       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.51      0.91      0.65       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.59      0.51      0.55       889\n",
      "           8       0.59      0.44      0.50       892\n",
      "           9       0.57      0.59      0.58       876\n",
      "          10       0.38      0.21      0.27      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.49      0.52      0.48     14531\n",
      "\n",
      "Epoch 4, Step 2000, Loss: 1.4969500303268433, F1: 0.5893468582504969, Accuracy: 0.5212992911706008, Time Elapsed: 329.0180401802063 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.89      0.70       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.61      0.68      0.64       897\n",
      "           4       0.61      0.18      0.28       892\n",
      "           5       0.62      0.06      0.11       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.59      0.65      0.62       889\n",
      "           8       0.57      0.02      0.03       892\n",
      "           9       0.57      0.72      0.64       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.50     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 2100, Loss: 0.36234042048454285, F1: 0.4961651635576559, Accuracy: 0.5045076044319042, Time Elapsed: 344.6657762527466 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.58      0.58      0.58       877\n",
      "           3       0.61      0.73      0.66       897\n",
      "           4       0.59      0.72      0.65       892\n",
      "           5       0.55      0.36      0.44       862\n",
      "           6       0.62      0.72      0.66       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.57      0.76      0.65       892\n",
      "           9       0.55      0.77      0.64       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 2200, Loss: 1.9185901880264282, F1: 0.6041319021559437, Accuracy: 0.53423714816599, Time Elapsed: 359.3445839881897 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.56      0.93      0.70       885\n",
      "           2       0.60      0.42      0.49       877\n",
      "           3       0.61      0.64      0.62       897\n",
      "           4       0.59      0.73      0.65       892\n",
      "           5       0.55      0.19      0.28       862\n",
      "           6       0.62      0.74      0.67       903\n",
      "           7       0.61      0.68      0.64       889\n",
      "           8       0.60      0.55      0.57       892\n",
      "           9       0.58      0.64      0.61       876\n",
      "          10       0.39      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 2300, Loss: 0.32472869753837585, F1: 0.5754905336365589, Accuracy: 0.5251531209139082, Time Elapsed: 374.5281550884247 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.60      0.43      0.50       877\n",
      "           3       0.61      0.72      0.66       897\n",
      "           4       0.58      0.76      0.66       892\n",
      "           5       0.54      0.63      0.58       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.58      0.76      0.66       892\n",
      "           9       0.54      0.54      0.54       876\n",
      "          10       0.40      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.67      0.60     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 4, Step 2400, Loss: 0.38425007462501526, F1: 0.6040771465709539, Accuracy: 0.5356135159314569, Time Elapsed: 389.75411105155945 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.61      0.51      0.56       897\n",
      "           4       0.63      0.13      0.22       892\n",
      "           5       0.50      0.67      0.57       862\n",
      "           6       0.60      0.23      0.34       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.60      0.44      0.50       892\n",
      "           9       0.61      0.44      0.52       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.49      0.47     14531\n",
      "weighted avg       0.48      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 2500, Loss: 1.9618251323699951, F1: 0.4696424973358766, Accuracy: 0.4869589154222008, Time Elapsed: 405.0145580768585 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.85      0.70       912\n",
      "           1       0.56      0.96      0.71       885\n",
      "           2       0.68      0.07      0.13       877\n",
      "           3       0.59      0.76      0.66       897\n",
      "           4       0.59      0.65      0.62       892\n",
      "           5       0.46      0.84      0.60       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.59      0.66      0.63       889\n",
      "           8       0.54      0.81      0.65       892\n",
      "           9       0.62      0.50      0.55       876\n",
      "          10       0.40      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.65      0.57     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 2600, Loss: 0.480833500623703, F1: 0.5681518147533486, Accuracy: 0.5243961186429014, Time Elapsed: 420.1027829647064 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.64      0.42      0.50       897\n",
      "           4       0.62      0.16      0.25       892\n",
      "           5       0.55      0.65      0.59       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.59      0.86      0.70       889\n",
      "           8       0.61      0.48      0.54       892\n",
      "           9       0.64      0.46      0.53       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.58      0.56     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 2700, Loss: 3.5584607124328613, F1: 0.5578449292077506, Accuracy: 0.5210928360057807, Time Elapsed: 435.2902660369873 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.59      0.73      0.66       885\n",
      "           2       0.60      0.37      0.46       877\n",
      "           3       0.66      0.22      0.33       897\n",
      "           4       0.55      0.75      0.64       892\n",
      "           5       0.56      0.51      0.54       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.59      0.79      0.67       889\n",
      "           8       0.57      0.71      0.63       892\n",
      "           9       0.56      0.59      0.58       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.54      0.51     14531\n",
      "weighted avg       0.47      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 2800, Loss: 0.3835756778717041, F1: 0.5089593307182763, Accuracy: 0.49941504369967654, Time Elapsed: 450.48042607307434 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58       912\n",
      "           1       0.59      0.75      0.66       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.62      0.47      0.53       897\n",
      "           4       0.54      0.80      0.65       892\n",
      "           5       0.54      0.26      0.36       862\n",
      "           6       0.62      0.75      0.68       903\n",
      "           7       0.59      0.63      0.61       889\n",
      "           8       0.48      0.88      0.62       892\n",
      "           9       0.52      0.70      0.60       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 2900, Loss: 1.2656710147857666, F1: 0.5685819078905338, Accuracy: 0.5124217190833391, Time Elapsed: 1299.75119805336 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.73       912\n",
      "           1       0.65      0.20      0.31       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.52      0.87      0.65       897\n",
      "           4       0.56      0.76      0.65       892\n",
      "           5       0.57      0.59      0.58       862\n",
      "           6       0.60      0.87      0.71       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.57      0.66      0.61       892\n",
      "           9       0.56      0.71      0.63       876\n",
      "          10       0.39      0.24      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.59     14531\n",
      "weighted avg       0.51      0.53      0.49     14531\n",
      "\n",
      "Epoch 4, Step 3000, Loss: 2.2506093978881836, F1: 0.5910227260335509, Accuracy: 0.531071502305416, Time Elapsed: 1315.9841589927673 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.61      0.62      0.62       885\n",
      "           2       0.59      0.40      0.48       877\n",
      "           3       0.61      0.66      0.63       897\n",
      "           4       0.58      0.27      0.37       892\n",
      "           5       0.48      0.82      0.60       862\n",
      "           6       0.58      0.87      0.69       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.58      0.62      0.60       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 3100, Loss: 0.8273458480834961, F1: 0.5696152946044909, Accuracy: 0.5147615442846328, Time Elapsed: 1333.33682513237 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.57      0.62      0.59       877\n",
      "           3       0.60      0.62      0.61       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.56      0.52      0.54       862\n",
      "           6       0.55      0.90      0.69       903\n",
      "           7       0.56      0.07      0.12       889\n",
      "           8       0.58      0.41      0.48       892\n",
      "           9       0.58      0.56      0.57       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.55     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 3200, Loss: 0.6940588355064392, F1: 0.5477947629206659, Accuracy: 0.5131099029660725, Time Elapsed: 1349.158525943756 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.55      0.96      0.70       885\n",
      "           2       0.66      0.09      0.16       877\n",
      "           3       0.56      0.82      0.66       897\n",
      "           4       0.61      0.21      0.31       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.56      0.92      0.70       903\n",
      "           7       0.61      0.74      0.66       889\n",
      "           8       0.59      0.38      0.47       892\n",
      "           9       0.59      0.60      0.60       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.54     14531\n",
      "weighted avg       0.51      0.52      0.48     14531\n",
      "\n",
      "Epoch 4, Step 3300, Loss: 0.6513051390647888, F1: 0.538452520349015, Accuracy: 0.5154497281673663, Time Elapsed: 1364.9117450714111 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.61      0.32      0.42       885\n",
      "           2       0.71      0.04      0.08       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.55      0.47      0.51       862\n",
      "           6       0.62      0.63      0.62       903\n",
      "           7       0.61      0.32      0.42       889\n",
      "           8       0.56      0.64      0.60       892\n",
      "           9       0.62      0.54      0.58       876\n",
      "          10       0.39      0.54      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.53      0.46      0.46     14531\n",
      "weighted avg       0.49      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 3400, Loss: 0.5051282048225403, F1: 0.45973986022115376, Accuracy: 0.4888170119055812, Time Elapsed: 1380.722608089447 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.62      0.29      0.40       877\n",
      "           3       0.61      0.63      0.62       897\n",
      "           4       0.60      0.43      0.50       892\n",
      "           5       0.55      0.40      0.46       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.60      0.64      0.62       889\n",
      "           8       0.53      0.83      0.65       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.52      0.51     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 3500, Loss: 0.6392044425010681, F1: 0.5066461987561042, Accuracy: 0.5006537746885968, Time Elapsed: 1396.461787223816 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.58      0.55      0.56       877\n",
      "           3       0.61      0.43      0.51       897\n",
      "           4       0.62      0.32      0.42       892\n",
      "           5       0.50      0.70      0.58       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.62      0.01      0.01       892\n",
      "           9       0.50      0.01      0.01       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.52      0.48     14531\n",
      "weighted avg       0.51      0.50      0.46     14531\n",
      "\n",
      "Epoch 4, Step 3600, Loss: 1.5867998600006104, F1: 0.4771930846574622, Accuracy: 0.4966623081687427, Time Elapsed: 1411.5135180950165 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.61      0.59      0.60       885\n",
      "           2       0.57      0.59      0.58       877\n",
      "           3       0.59      0.10      0.17       897\n",
      "           4       0.58      0.79      0.67       892\n",
      "           5       0.55      0.48      0.51       862\n",
      "           6       0.56      0.91      0.70       903\n",
      "           7       0.60      0.78      0.67       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.15      0.24       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.52      0.48     14531\n",
      "weighted avg       0.47      0.50      0.46     14531\n",
      "\n",
      "Epoch 4, Step 3700, Loss: 0.49406880140304565, F1: 0.4783511283145922, Accuracy: 0.49556121395636915, Time Elapsed: 1425.917073249817 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.58      0.57      0.58       877\n",
      "           3       0.58      0.73      0.64       897\n",
      "           4       0.58      0.77      0.66       892\n",
      "           5       0.54      0.59      0.56       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.59      0.74      0.66       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.60      0.39      0.48       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.52      0.60      0.55     14531\n",
      "weighted avg       0.47      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 3800, Loss: 1.902572512626648, F1: 0.5493871699920868, Accuracy: 0.5199917417934072, Time Elapsed: 1441.5433101654053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.55      0.92      0.69       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.53      0.80      0.64       897\n",
      "           4       0.57      0.79      0.66       892\n",
      "           5       0.54      0.62      0.58       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.58      0.73      0.65       892\n",
      "           9       0.57      0.78      0.66       876\n",
      "          10       0.39      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.71      0.62     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 4, Step 3900, Loss: 0.16744916141033173, F1: 0.6159975396504763, Accuracy: 0.5393297088982176, Time Elapsed: 1457.473098039627 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.93      0.63       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.60      0.50      0.55       897\n",
      "           4       0.60      0.51      0.55       892\n",
      "           5       0.50      0.53      0.52       862\n",
      "           6       0.60      0.77      0.68       903\n",
      "           7       0.55      0.83      0.66       889\n",
      "           8       0.60      0.58      0.59       892\n",
      "           9       0.60      0.13      0.21       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 4000, Loss: 1.2928342819213867, F1: 0.547612476980423, Accuracy: 0.5060904273621912, Time Elapsed: 1472.7430431842804 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.40      0.48       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.60      0.33      0.42       897\n",
      "           4       1.00      0.00      0.00       892\n",
      "           5       0.55      0.36      0.43       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.62      0.23      0.33       889\n",
      "           8       0.59      0.63      0.61       892\n",
      "           9       0.59      0.60      0.59       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.56      0.42      0.42     14531\n",
      "weighted avg       0.50      0.47      0.44     14531\n",
      "\n",
      "Epoch 4, Step 4100, Loss: 1.005047082901001, F1: 0.4223827648986119, Accuracy: 0.4714747780606978, Time Elapsed: 1488.5828659534454 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.00      0.01       912\n",
      "           1       0.61      0.31      0.41       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.61      0.40      0.48       897\n",
      "           4       0.43      0.94      0.59       892\n",
      "           5       0.57      0.31      0.40       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.59      0.47      0.52       889\n",
      "           8       0.59      0.52      0.55       892\n",
      "           9       0.58      0.42      0.49       876\n",
      "          10       0.38      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.56      0.48      0.47     14531\n",
      "weighted avg       0.50      0.47      0.45     14531\n",
      "\n",
      "Epoch 4, Step 4200, Loss: 0.6599504947662354, F1: 0.46976274489115233, Accuracy: 0.472507053884798, Time Elapsed: 1503.7407760620117 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.08      0.14       912\n",
      "           1       0.61      0.29      0.40       885\n",
      "           2       0.55      0.74      0.63       877\n",
      "           3       0.54      0.72      0.62       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.57      0.32      0.42       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.58      0.42      0.49       889\n",
      "           8       0.60      0.48      0.53       892\n",
      "           9       0.58      0.62      0.60       876\n",
      "          10       0.38      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.50     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 4300, Loss: 2.2369818687438965, F1: 0.5046101576079572, Accuracy: 0.48847291996421444, Time Elapsed: 1519.4972751140594 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.34      0.43       912\n",
      "           1       0.59      0.47      0.53       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.53      0.78      0.63       897\n",
      "           4       0.58      0.16      0.25       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.65      0.18      0.28       903\n",
      "           7       0.61      0.31      0.41       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.57      0.58      0.58       876\n",
      "          10       0.39      0.54      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.45      0.47     14531\n",
      "weighted avg       0.51      0.48      0.47     14531\n",
      "\n",
      "Epoch 4, Step 4400, Loss: 2.0393221378326416, F1: 0.4747203328732974, Accuracy: 0.4771867042873856, Time Elapsed: 1535.5821931362152 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       912\n",
      "           1       0.59      0.58      0.59       885\n",
      "           2       0.62      0.29      0.40       877\n",
      "           3       0.55      0.78      0.65       897\n",
      "           4       0.59      0.48      0.53       892\n",
      "           5       0.39      0.84      0.53       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.58      0.77      0.66       889\n",
      "           8       0.59      0.43      0.50       892\n",
      "           9       0.59      0.57      0.58       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.59      0.54      0.50     14531\n",
      "weighted avg       0.52      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 4500, Loss: 1.5636324882507324, F1: 0.5006784716237116, Accuracy: 0.4859266395981006, Time Elapsed: 1550.0595400333405 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.62      0.32      0.42       885\n",
      "           2       0.53      0.75      0.62       877\n",
      "           3       0.62      0.51      0.56       897\n",
      "           4       0.60      0.41      0.49       892\n",
      "           5       0.52      0.51      0.51       862\n",
      "           6       0.59      0.80      0.68       903\n",
      "           7       0.56      0.88      0.68       889\n",
      "           8       0.60      0.48      0.54       892\n",
      "           9       0.59      0.66      0.62       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.52      0.50     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 4600, Loss: 1.6826964616775513, F1: 0.5036482438149223, Accuracy: 0.49308375197852866, Time Elapsed: 1565.969661951065 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.58      0.87      0.70       885\n",
      "           2       0.55      0.72      0.62       877\n",
      "           3       0.60      0.71      0.65       897\n",
      "           4       0.60      0.48      0.53       892\n",
      "           5       0.53      0.42      0.46       862\n",
      "           6       0.62      0.49      0.54       903\n",
      "           7       0.59      0.45      0.51       889\n",
      "           8       0.60      0.55      0.57       892\n",
      "           9       0.59      0.62      0.61       876\n",
      "          10       0.38      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.52      0.51     14531\n",
      "weighted avg       0.47      0.49      0.48     14531\n",
      "\n",
      "Epoch 4, Step 4700, Loss: 1.3760157823562622, F1: 0.5092887180092626, Accuracy: 0.49260202326061525, Time Elapsed: 1581.7175641059875 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.53      0.90      0.67       885\n",
      "           2       0.60      0.45      0.51       877\n",
      "           3       0.57      0.75      0.65       897\n",
      "           4       0.57      0.71      0.63       892\n",
      "           5       0.54      0.17      0.26       862\n",
      "           6       0.62      0.47      0.53       903\n",
      "           7       0.59      0.82      0.69       889\n",
      "           8       0.59      0.39      0.47       892\n",
      "           9       0.59      0.42      0.49       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.50      0.48     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 4800, Loss: 0.5260170698165894, F1: 0.4837378718699988, Accuracy: 0.4884041015759411, Time Elapsed: 1597.4453308582306 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.57      0.42      0.49       885\n",
      "           2       0.57      0.60      0.59       877\n",
      "           3       0.59      0.33      0.43       897\n",
      "           4       0.56      0.87      0.68       892\n",
      "           5       0.54      0.24      0.33       862\n",
      "           6       0.59      0.79      0.68       903\n",
      "           7       0.59      0.28      0.38       889\n",
      "           8       0.56      0.68      0.61       892\n",
      "           9       0.59      0.61      0.60       876\n",
      "          10       0.38      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.50      0.48      0.47     14531\n",
      "weighted avg       0.46      0.48      0.46     14531\n",
      "\n",
      "Epoch 4, Step 4900, Loss: 0.42066439986228943, F1: 0.4729247818686045, Accuracy: 0.4813846259720597, Time Elapsed: 1613.5920372009277 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.91      0.66       912\n",
      "           1       0.56      0.79      0.66       885\n",
      "           2       0.57      0.60      0.58       877\n",
      "           3       0.60      0.59      0.59       897\n",
      "           4       0.58      0.52      0.55       892\n",
      "           5       0.48      0.13      0.20       862\n",
      "           6       0.61      0.18      0.28       903\n",
      "           7       0.59      0.62      0.61       889\n",
      "           8       0.60      0.53      0.56       892\n",
      "           9       0.60      0.55      0.57       876\n",
      "          10       0.38      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.53      0.51     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 4, Step 5000, Loss: 1.709050178527832, F1: 0.5148750669533011, Accuracy: 0.4921202945427018, Time Elapsed: 1629.2234480381012 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.53      0.27      0.36       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.56      0.49      0.52       897\n",
      "           4       0.52      0.92      0.66       892\n",
      "           5       0.52      0.58      0.55       862\n",
      "           6       0.63      0.21      0.32       903\n",
      "           7       0.58      0.79      0.67       889\n",
      "           8       0.56      0.76      0.65       892\n",
      "           9       0.59      0.70      0.64       876\n",
      "          10       0.38      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.59      0.54     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 5100, Loss: 0.2622610628604889, F1: 0.5448529066741465, Accuracy: 0.5032000550547107, Time Elapsed: 1645.6498758792877 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.12      0.20       912\n",
      "           1       0.40      0.07      0.12       885\n",
      "           2       0.59      0.50      0.54       877\n",
      "           3       0.57      0.29      0.38       897\n",
      "           4       0.59      0.45      0.51       892\n",
      "           5       0.53      0.56      0.54       862\n",
      "           6       0.59      0.79      0.67       903\n",
      "           7       0.59      0.29      0.39       889\n",
      "           8       0.55      0.77      0.64       892\n",
      "           9       0.63      0.32      0.42       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.55      0.43      0.44     14531\n",
      "weighted avg       0.49      0.47      0.45     14531\n",
      "\n",
      "Epoch 4, Step 5200, Loss: 1.470984935760498, F1: 0.4435709936034915, Accuracy: 0.46913495285940404, Time Elapsed: 1662.4625480175018 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       912\n",
      "           1       0.53      0.53      0.53       885\n",
      "           2       0.58      0.52      0.55       877\n",
      "           3       0.57      0.52      0.54       897\n",
      "           4       0.55      0.52      0.54       892\n",
      "           5       0.53      0.62      0.57       862\n",
      "           6       0.47      0.95      0.63       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.59      0.49      0.54       892\n",
      "           9       0.63      0.39      0.48       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.56      0.55     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 5300, Loss: 0.7263678908348083, F1: 0.5467543628042454, Accuracy: 0.49893331498176313, Time Elapsed: 1678.280368089676 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.35      0.09      0.14       885\n",
      "           2       0.58      0.53      0.55       877\n",
      "           3       0.56      0.45      0.50       897\n",
      "           4       0.51      0.82      0.63       892\n",
      "           5       0.57      0.53      0.55       862\n",
      "           6       0.60      0.72      0.65       903\n",
      "           7       0.60      0.67      0.64       889\n",
      "           8       0.53      0.76      0.62       892\n",
      "           9       0.57      0.66      0.61       876\n",
      "          10       0.40      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.53      0.59      0.54     14531\n",
      "weighted avg       0.49      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 5400, Loss: 0.2740863263607025, F1: 0.5431662157079375, Accuracy: 0.5060216089739178, Time Elapsed: 1694.4104619026184 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.42      0.30      0.35       885\n",
      "           2       0.57      0.63      0.60       877\n",
      "           3       0.55      0.60      0.58       897\n",
      "           4       0.55      0.74      0.63       892\n",
      "           5       0.57      0.34      0.43       862\n",
      "           6       0.61      0.49      0.54       903\n",
      "           7       0.62      0.09      0.15       889\n",
      "           8       0.59      0.47      0.52       892\n",
      "           9       0.44      0.89      0.59       876\n",
      "          10       0.38      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.52      0.50     14531\n",
      "weighted avg       0.49      0.48      0.46     14531\n",
      "\n",
      "Epoch 4, Step 5500, Loss: 0.7403979897499084, F1: 0.49874810831166666, Accuracy: 0.47993943981831944, Time Elapsed: 1710.8621871471405 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.70       912\n",
      "           1       0.47      0.18      0.26       885\n",
      "           2       0.59      0.60      0.59       877\n",
      "           3       0.57      0.44      0.50       897\n",
      "           4       0.46      0.93      0.62       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.56      0.89      0.69       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.64      0.17      0.27       892\n",
      "           9       0.62      0.48      0.54       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.55      0.52     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 5600, Loss: 1.749738335609436, F1: 0.517877283978707, Accuracy: 0.494735393297089, Time Elapsed: 1726.5281028747559 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66       912\n",
      "           1       0.56      0.87      0.68       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.54      0.78      0.64       897\n",
      "           4       0.54      0.90      0.67       892\n",
      "           5       0.56      0.45      0.50       862\n",
      "           6       0.58      0.87      0.70       903\n",
      "           7       0.58      0.87      0.69       889\n",
      "           8       0.60      0.51      0.55       892\n",
      "           9       0.60      0.52      0.56       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 5700, Loss: 0.2330537885427475, F1: 0.597529755767987, Accuracy: 0.5290069506572156, Time Elapsed: 1741.9582841396332 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       912\n",
      "           1       0.58      0.75      0.65       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.58      0.73      0.64       897\n",
      "           4       0.57      0.71      0.63       892\n",
      "           5       0.53      0.45      0.49       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.61      0.28      0.38       892\n",
      "           9       0.61      0.57      0.59       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 5800, Loss: 1.2297980785369873, F1: 0.578466479321936, Accuracy: 0.5214369279471475, Time Elapsed: 1757.4149072170258 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.12      0.21       912\n",
      "           1       0.53      0.88      0.66       885\n",
      "           2       0.59      0.58      0.59       877\n",
      "           3       0.59      0.71      0.64       897\n",
      "           4       0.56      0.61      0.58       892\n",
      "           5       0.56      0.43      0.49       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.61      0.69      0.64       889\n",
      "           8       0.52      0.06      0.10       892\n",
      "           9       0.60      0.66      0.63       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.54      0.51     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 5900, Loss: 0.6966424584388733, F1: 0.5112372586461871, Accuracy: 0.49838276787557634, Time Elapsed: 1772.561490058899 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.56      0.86      0.68       885\n",
      "           2       0.59      0.58      0.59       877\n",
      "           3       0.59      0.71      0.65       897\n",
      "           4       0.57      0.49      0.53       892\n",
      "           5       0.55      0.50      0.52       862\n",
      "           6       0.59      0.78      0.67       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.60      0.27      0.37       892\n",
      "           9       0.52      0.76      0.62       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 6000, Loss: 0.5669875144958496, F1: 0.5719970051827651, Accuracy: 0.515587364943913, Time Elapsed: 1788.1109549999237 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.57      0.63      0.60       885\n",
      "           2       0.60      0.38      0.47       877\n",
      "           3       0.61      0.61      0.61       897\n",
      "           4       0.59      0.12      0.20       892\n",
      "           5       0.53      0.16      0.24       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.59      0.26      0.36       892\n",
      "           9       0.59      0.31      0.41       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.50      0.49     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 6100, Loss: 0.25964394211769104, F1: 0.4919198864358348, Accuracy: 0.4958364875094625, Time Elapsed: 1803.645271062851 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.59      0.84      0.69       885\n",
      "           2       0.58      0.60      0.59       877\n",
      "           3       0.55      0.87      0.67       897\n",
      "           4       0.62      0.33      0.43       892\n",
      "           5       0.54      0.21      0.30       862\n",
      "           6       0.60      0.77      0.68       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.60      0.31      0.41       892\n",
      "           9       0.60      0.33      0.43       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 6200, Loss: 1.7745161056518555, F1: 0.5443077941020809, Accuracy: 0.5148303626729062, Time Elapsed: 1819.3493571281433 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.51      0.98      0.67       885\n",
      "           2       0.59      0.50      0.54       877\n",
      "           3       0.57      0.75      0.65       897\n",
      "           4       0.56      0.70      0.62       892\n",
      "           5       0.51      0.69      0.58       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.61      0.76      0.68       889\n",
      "           8       0.57      0.59      0.58       892\n",
      "           9       0.61      0.55      0.58       876\n",
      "          10       0.39      0.23      0.28      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 6300, Loss: 0.48384740948677063, F1: 0.5979714747616302, Accuracy: 0.5268047622324685, Time Elapsed: 1835.0770192146301 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.46      0.53       912\n",
      "           1       0.54      0.93      0.69       885\n",
      "           2       0.61      0.38      0.47       877\n",
      "           3       0.56      0.83      0.67       897\n",
      "           4       0.58      0.66      0.62       892\n",
      "           5       0.57      0.28      0.37       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.61      0.72      0.66       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.60      0.46      0.52       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 6400, Loss: 0.7658578157424927, F1: 0.5596061573677574, Accuracy: 0.5146239075080862, Time Elapsed: 1850.8491990566254 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.49      0.54       885\n",
      "           2       0.65      0.21      0.32       877\n",
      "           3       0.56      0.77      0.65       897\n",
      "           4       0.61      0.51      0.55       892\n",
      "           5       0.54      0.58      0.56       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.58      0.25      0.35       892\n",
      "           9       0.53      0.83      0.65       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 6500, Loss: 0.45433884859085083, F1: 0.5522508529685108, Accuracy: 0.5144862707315395, Time Elapsed: 1867.0874750614166 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.57      0.92      0.70       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.58      0.67      0.62       897\n",
      "           4       0.58      0.58      0.58       892\n",
      "           5       0.56      0.51      0.53       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.58      0.84      0.69       889\n",
      "           8       0.55      0.63      0.59       892\n",
      "           9       0.54      0.72      0.62       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 6600, Loss: 1.1109132766723633, F1: 0.5962919440777507, Accuracy: 0.5279058564448421, Time Elapsed: 1883.2989339828491 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.69       912\n",
      "           1       0.55      0.67      0.60       885\n",
      "           2       0.57      0.69      0.62       877\n",
      "           3       0.61      0.53      0.57       897\n",
      "           4       0.56      0.64      0.59       892\n",
      "           5       0.58      0.51      0.54       862\n",
      "           6       0.58      0.89      0.70       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.55      0.64      0.59       892\n",
      "           9       0.55      0.41      0.47       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 6700, Loss: 5.415869235992432, F1: 0.581988762674861, Accuracy: 0.5193035579106737, Time Elapsed: 1898.8778412342072 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.74      0.68       912\n",
      "           1       0.55      0.72      0.62       885\n",
      "           2       0.61      0.39      0.47       877\n",
      "           3       0.62      0.23      0.34       897\n",
      "           4       0.46      0.87      0.60       892\n",
      "           5       0.55      0.46      0.50       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.59      0.36      0.45       892\n",
      "           9       0.57      0.70      0.63       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 6800, Loss: 1.0493197441101074, F1: 0.5359037434098085, Accuracy: 0.4968687633335627, Time Elapsed: 1914.7630620002747 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.59      0.39      0.47       885\n",
      "           2       0.63      0.29      0.40       877\n",
      "           3       0.63      0.31      0.41       897\n",
      "           4       0.56      0.81      0.66       892\n",
      "           5       0.52      0.66      0.58       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.54      0.65      0.59       892\n",
      "           9       0.64      0.20      0.30       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 6900, Loss: 0.7220476865768433, F1: 0.5267594934574859, Accuracy: 0.5025118711719772, Time Elapsed: 1930.894877910614 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.59      0.69      0.64       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.59      0.69      0.64       897\n",
      "           4       0.56      0.49      0.52       892\n",
      "           5       0.54      0.60      0.57       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.55      0.66      0.60       892\n",
      "           9       0.50      0.46      0.48       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 7000, Loss: 1.1178579330444336, F1: 0.5873306783943529, Accuracy: 0.5214369279471475, Time Elapsed: 1946.275614976883 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.59      0.87      0.70       885\n",
      "           2       0.61      0.45      0.52       877\n",
      "           3       0.58      0.73      0.65       897\n",
      "           4       0.56      0.39      0.46       892\n",
      "           5       0.56      0.40      0.47       862\n",
      "           6       0.58      0.87      0.70       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.54      0.75      0.63       892\n",
      "           9       0.51      0.70      0.59       876\n",
      "          10       0.39      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 7100, Loss: 0.7999222278594971, F1: 0.5824197327623291, Accuracy: 0.5226756589360677, Time Elapsed: 1962.9232592582703 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.59      0.83      0.69       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.61      0.52      0.56       897\n",
      "           4       0.43      0.90      0.58       892\n",
      "           5       0.54      0.10      0.16       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.60      0.55      0.57       892\n",
      "           9       0.59      0.39      0.47       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 7200, Loss: 0.9618116021156311, F1: 0.5474002368803158, Accuracy: 0.5096689835524052, Time Elapsed: 1979.4490160942078 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.93      0.73       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.57      0.69      0.63       877\n",
      "           3       0.58      0.63      0.61       897\n",
      "           4       0.53      0.85      0.65       892\n",
      "           5       0.55      0.56      0.56       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.59      0.43      0.50       889\n",
      "           8       0.61      0.59      0.60       892\n",
      "           9       0.56      0.79      0.65       876\n",
      "          10       0.38      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 7300, Loss: 7.503030300140381, F1: 0.5978369114709736, Accuracy: 0.5276305828917487, Time Elapsed: 1995.3262321949005 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.72       912\n",
      "           1       0.62      0.74      0.67       885\n",
      "           2       0.62      0.31      0.41       877\n",
      "           3       0.59      0.64      0.61       897\n",
      "           4       0.54      0.79      0.65       892\n",
      "           5       0.56      0.45      0.50       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.61      0.64      0.62       889\n",
      "           8       0.59      0.48      0.53       892\n",
      "           9       0.62      0.32      0.42       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.52      0.50     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 7400, Loss: 1.0868268013000488, F1: 0.5044813742018093, Accuracy: 0.4991397701465832, Time Elapsed: 2011.0215039253235 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.61      0.47      0.53       877\n",
      "           3       0.62      0.50      0.56       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.53      0.16      0.24       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.57      0.89      0.69       889\n",
      "           8       0.61      0.40      0.48       892\n",
      "           9       0.57      0.73      0.64       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 7500, Loss: 1.6233985424041748, F1: 0.5694783908747151, Accuracy: 0.5246713921959948, Time Elapsed: 2026.7458171844482 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.61      0.22      0.33       877\n",
      "           3       0.59      0.79      0.68       897\n",
      "           4       0.57      0.31      0.40       892\n",
      "           5       0.56      0.08      0.13       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.59      0.65      0.62       892\n",
      "           9       0.56      0.40      0.47       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.53     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 7600, Loss: 0.37891480326652527, F1: 0.5288609380068526, Accuracy: 0.5128346294129792, Time Elapsed: 2043.1018669605255 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.62      0.43      0.51       885\n",
      "           2       0.60      0.38      0.46       877\n",
      "           3       0.44      0.93      0.59       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.55      0.12      0.20       862\n",
      "           6       0.60      0.88      0.71       903\n",
      "           7       0.61      0.67      0.64       889\n",
      "           8       0.56      0.64      0.60       892\n",
      "           9       0.61      0.29      0.40       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.58      0.53     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 7700, Loss: 0.09656435996294022, F1: 0.5308644296652706, Accuracy: 0.5047828779849975, Time Elapsed: 2060.6602461338043 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       912\n",
      "           1       0.62      0.79      0.70       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.54      0.86      0.66       897\n",
      "           4       0.58      0.63      0.61       892\n",
      "           5       0.56      0.61      0.58       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.55      0.90      0.68       889\n",
      "           8       0.58      0.55      0.56       892\n",
      "           9       0.59      0.51      0.55       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 4, Step 7800, Loss: 1.2172744274139404, F1: 0.6035343768303735, Accuracy: 0.5353382423783635, Time Elapsed: 2081.1348690986633 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.59      0.23      0.33       885\n",
      "           2       0.61      0.49      0.54       877\n",
      "           3       0.59      0.69      0.63       897\n",
      "           4       0.54      0.71      0.61       892\n",
      "           5       0.55      0.49      0.52       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.57      0.84      0.68       889\n",
      "           8       0.55      0.69      0.61       892\n",
      "           9       0.55      0.76      0.64       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 7900, Loss: 0.5806586742401123, F1: 0.5701910136481433, Accuracy: 0.5171013694859267, Time Elapsed: 2101.5714218616486 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.60      0.67      0.63       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.59      0.61      0.60       897\n",
      "           4       0.59      0.75      0.66       892\n",
      "           5       0.54      0.17      0.26       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.55      0.77      0.64       892\n",
      "           9       0.58      0.73      0.64       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 8000, Loss: 0.6797996759414673, F1: 0.5822541093777147, Accuracy: 0.5272864909503819, Time Elapsed: 2123.264412164688 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.61      0.82      0.70       885\n",
      "           2       0.55      0.77      0.64       877\n",
      "           3       0.60      0.76      0.67       897\n",
      "           4       0.59      0.69      0.63       892\n",
      "           5       0.56      0.25      0.35       862\n",
      "           6       0.64      0.45      0.52       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.54      0.82      0.65       892\n",
      "           9       0.58      0.61      0.59       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 8100, Loss: 0.2832084596157074, F1: 0.5844701373101772, Accuracy: 0.5265294886793751, Time Elapsed: 2142.5173721313477 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.61      0.46      0.52       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.57      0.76      0.65       892\n",
      "           5       0.54      0.31      0.39       862\n",
      "           6       0.63      0.40      0.49       903\n",
      "           7       0.59      0.69      0.64       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.56      0.49      0.52       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 8200, Loss: 0.6302945613861084, F1: 0.5643817707316224, Accuracy: 0.515380909779093, Time Elapsed: 2156.9409699440002 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61       912\n",
      "           1       0.57      0.96      0.71       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.59      0.73      0.66       897\n",
      "           4       0.55      0.85      0.67       892\n",
      "           5       0.58      0.47      0.52       862\n",
      "           6       0.62      0.77      0.68       903\n",
      "           7       0.59      0.49      0.54       889\n",
      "           8       0.57      0.69      0.63       892\n",
      "           9       0.60      0.05      0.10       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 8300, Loss: 0.9445392489433289, F1: 0.5470162352005791, Accuracy: 0.5153120913908197, Time Elapsed: 2171.7531220912933 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.57      0.61      0.59       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.53      0.90      0.67       892\n",
      "           5       0.54      0.37      0.44       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.60      0.59      0.60       889\n",
      "           8       0.58      0.62      0.60       892\n",
      "           9       0.59      0.06      0.10       876\n",
      "          10       0.38      0.37      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 8400, Loss: 0.4213234782218933, F1: 0.5343008455772936, Accuracy: 0.5053334250911844, Time Elapsed: 2186.897497177124 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.70       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.59      0.56      0.57       877\n",
      "           3       0.61      0.51      0.55       897\n",
      "           4       0.52      0.88      0.66       892\n",
      "           5       0.48      0.76      0.59       862\n",
      "           6       0.62      0.49      0.55       903\n",
      "           7       0.60      0.70      0.64       889\n",
      "           8       0.59      0.37      0.45       892\n",
      "           9       0.55      0.01      0.02       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.53     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 8500, Loss: 0.765396237373352, F1: 0.5301342116790774, Accuracy: 0.5059527905856445, Time Elapsed: 2201.424015045166 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69       912\n",
      "           1       0.58      0.19      0.28       885\n",
      "           2       0.62      0.42      0.50       877\n",
      "           3       0.58      0.78      0.67       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.55      0.50      0.53       862\n",
      "           6       0.61      0.46      0.52       903\n",
      "           7       0.51      0.93      0.65       889\n",
      "           8       0.58      0.56      0.57       892\n",
      "           9       0.60      0.21      0.31       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.52     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 8600, Loss: 0.645725429058075, F1: 0.5225750951152256, Accuracy: 0.49707521849838276, Time Elapsed: 2220.477760076523 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.69       912\n",
      "           1       0.58      0.75      0.66       885\n",
      "           2       0.59      0.54      0.57       877\n",
      "           3       0.62      0.44      0.52       897\n",
      "           4       0.55      0.80      0.65       892\n",
      "           5       0.55      0.59      0.57       862\n",
      "           6       0.59      0.88      0.71       903\n",
      "           7       0.58      0.79      0.67       889\n",
      "           8       0.58      0.70      0.64       892\n",
      "           9       0.57      0.71      0.63       876\n",
      "          10       0.38      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 8700, Loss: 1.1013621091842651, F1: 0.5990259468390188, Accuracy: 0.5286628587158488, Time Elapsed: 2241.229038000107 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.59      0.87      0.70       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.54      0.83      0.65       897\n",
      "           4       0.57      0.80      0.66       892\n",
      "           5       0.55      0.63      0.59       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.53      0.81      0.64       892\n",
      "           9       0.59      0.18      0.27       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.59     14531\n",
      "weighted avg       0.51      0.53      0.49     14531\n",
      "\n",
      "Epoch 4, Step 8800, Loss: 1.984691858291626, F1: 0.5899670399175646, Accuracy: 0.5312091390819627, Time Elapsed: 2258.297114133835 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.72       912\n",
      "           1       0.58      0.74      0.65       885\n",
      "           2       0.61      0.42      0.50       877\n",
      "           3       0.51      0.85      0.64       897\n",
      "           4       0.53      0.82      0.65       892\n",
      "           5       0.54      0.61      0.57       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.57      0.90      0.70       889\n",
      "           8       0.53      0.66      0.58       892\n",
      "           9       0.62      0.47      0.53       876\n",
      "          10       0.40      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 4, Step 8900, Loss: 1.0316189527511597, F1: 0.5916750969437916, Accuracy: 0.5263230335145551, Time Elapsed: 2411.4311470985413 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.62      0.43      0.51       885\n",
      "           2       0.64      0.24      0.35       877\n",
      "           3       0.58      0.71      0.64       897\n",
      "           4       0.52      0.90      0.66       892\n",
      "           5       0.57      0.21      0.31       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.59      0.49      0.53       889\n",
      "           8       0.57      0.64      0.60       892\n",
      "           9       0.60      0.04      0.08       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.52      0.50     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 9000, Loss: 0.4293197691440582, F1: 0.4970445016272333, Accuracy: 0.49803867593420964, Time Elapsed: 2431.002583026886 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.62      0.34      0.44       885\n",
      "           2       0.57      0.71      0.64       877\n",
      "           3       0.58      0.20      0.29       897\n",
      "           4       0.58      0.70      0.63       892\n",
      "           5       0.56      0.19      0.28       862\n",
      "           6       0.62      0.72      0.67       903\n",
      "           7       0.62      0.26      0.36       889\n",
      "           8       0.53      0.62      0.57       892\n",
      "           9       0.55      0.45      0.50       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.50     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 4, Step 9100, Loss: 0.7942588925361633, F1: 0.5025217207237757, Accuracy: 0.49335902553162203, Time Elapsed: 2446.614448070526 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.57      0.76      0.65       877\n",
      "           3       0.59      0.28      0.38       897\n",
      "           4       0.61      0.34      0.44       892\n",
      "           5       0.55      0.23      0.33       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.59      0.66      0.63       889\n",
      "           8       0.59      0.58      0.58       892\n",
      "           9       0.54      0.54      0.54       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 9200, Loss: 0.20659221708774567, F1: 0.5486698365081328, Accuracy: 0.5109077145413254, Time Elapsed: 2462.5546119213104 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.59      0.87      0.70       885\n",
      "           2       0.56      0.77      0.64       877\n",
      "           3       0.62      0.34      0.44       897\n",
      "           4       0.60      0.34      0.44       892\n",
      "           5       0.58      0.17      0.26       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.59      0.65      0.62       889\n",
      "           8       0.58      0.56      0.57       892\n",
      "           9       0.58      0.08      0.14       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 9300, Loss: 0.4182834327220917, F1: 0.5113945165210856, Accuracy: 0.5038194205491707, Time Elapsed: 2480.696090221405 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.91      0.70       912\n",
      "           1       0.60      0.46      0.52       885\n",
      "           2       0.57      0.67      0.62       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.57      0.37      0.45       892\n",
      "           5       0.58      0.08      0.14       862\n",
      "           6       0.62      0.46      0.53       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.56      0.71      0.63       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.47      0.47     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 9400, Loss: 0.9717301726341248, F1: 0.4681057115094991, Accuracy: 0.48558254765673386, Time Elapsed: 2496.7974750995636 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.13      0.21       912\n",
      "           1       0.60      0.51      0.55       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.59      0.24      0.34       897\n",
      "           4       0.60      0.33      0.43       892\n",
      "           5       0.56      0.47      0.51       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.58      0.46      0.51       889\n",
      "           8       0.59      0.39      0.47       892\n",
      "           9       0.49      0.86      0.62       876\n",
      "          10       0.38      0.45      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.49      0.49     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 4, Step 9500, Loss: 0.6349089741706848, F1: 0.49020112579132386, Accuracy: 0.4779437065583924, Time Elapsed: 2512.555946111679 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.71       912\n",
      "           1       0.60      0.30      0.40       885\n",
      "           2       0.54      0.73      0.62       877\n",
      "           3       0.61      0.51      0.55       897\n",
      "           4       0.62      0.13      0.21       892\n",
      "           5       0.55      0.56      0.55       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.59      0.79      0.67       889\n",
      "           8       0.57      0.57      0.57       892\n",
      "           9       0.52      0.72      0.60       876\n",
      "          10       0.39      0.35      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 9600, Loss: 1.0839706659317017, F1: 0.5413228807207426, Accuracy: 0.505471061867731, Time Elapsed: 2528.664673089981 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.96      0.66       912\n",
      "           1       0.61      0.54      0.58       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.57      0.47      0.51       897\n",
      "           4       0.54      0.06      0.11       892\n",
      "           5       0.59      0.32      0.41       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.57      0.86      0.68       889\n",
      "           8       0.57      0.48      0.52       892\n",
      "           9       0.56      0.68      0.61       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.55      0.52     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 9700, Loss: 0.34093835949897766, F1: 0.521748421134959, Accuracy: 0.49941504369967654, Time Elapsed: 2544.385256052017 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       912\n",
      "           1       0.61      0.02      0.05       885\n",
      "           2       0.62      0.30      0.40       877\n",
      "           3       0.60      0.56      0.58       897\n",
      "           4       0.56      0.81      0.66       892\n",
      "           5       0.55      0.42      0.48       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.55      0.53      0.54       892\n",
      "           9       0.55      0.83      0.66       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 9800, Loss: 0.6933864951133728, F1: 0.5162436316179572, Accuracy: 0.5003096827472301, Time Elapsed: 2559.328202009201 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.68       912\n",
      "           1       0.61      0.68      0.64       885\n",
      "           2       0.59      0.45      0.51       877\n",
      "           3       0.52      0.84      0.64       897\n",
      "           4       0.55      0.25      0.34       892\n",
      "           5       0.54      0.35      0.42       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.59      0.82      0.68       889\n",
      "           8       0.55      0.27      0.36       892\n",
      "           9       0.55      0.82      0.66       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.59      0.54     14531\n",
      "weighted avg       0.49      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 9900, Loss: 1.2584569454193115, F1: 0.5432963157749051, Accuracy: 0.5047140595967242, Time Elapsed: 2573.825129032135 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.84      0.70       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.56      0.67      0.61       877\n",
      "           3       0.53      0.84      0.65       897\n",
      "           4       0.48      0.88      0.63       892\n",
      "           5       0.53      0.16      0.24       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.60      0.79      0.68       889\n",
      "           8       0.54      0.60      0.57       892\n",
      "           9       0.60      0.54      0.57       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.58     14531\n",
      "weighted avg       0.50      0.52      0.48     14531\n",
      "\n",
      "Epoch 4, Step 10000, Loss: 2.7235984802246094, F1: 0.575673335557815, Accuracy: 0.5208863808409607, Time Elapsed: 2589.340518951416 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.03      0.05       912\n",
      "           1       0.60      0.27      0.37       885\n",
      "           2       0.55      0.69      0.61       877\n",
      "           3       0.59      0.72      0.65       897\n",
      "           4       0.53      0.94      0.68       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.61      0.66      0.63       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.53      0.48      0.50       892\n",
      "           9       0.54      0.81      0.65       876\n",
      "          10       0.38      0.35      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.58      0.52     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 10100, Loss: 0.5807647705078125, F1: 0.5222865392861793, Accuracy: 0.49907095175830984, Time Elapsed: 2605.145555973053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.53      0.84      0.65       877\n",
      "           3       0.55      0.80      0.65       897\n",
      "           4       0.51      0.93      0.66       892\n",
      "           5       0.57      0.47      0.51       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.57      0.50      0.53       892\n",
      "           9       0.57      0.71      0.64       876\n",
      "          10       0.39      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.69      0.60     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 4, Step 10200, Loss: 2.021566867828369, F1: 0.5976121381894801, Accuracy: 0.527492946115202, Time Elapsed: 2620.4242770671844 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       912\n",
      "           1       0.59      0.36      0.45       885\n",
      "           2       0.55      0.71      0.62       877\n",
      "           3       0.54      0.85      0.66       897\n",
      "           4       0.53      0.94      0.68       892\n",
      "           5       0.55      0.46      0.50       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.51      0.64      0.57       892\n",
      "           9       0.52      0.86      0.65       876\n",
      "          10       0.38      0.18      0.24      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.54      0.69      0.59     14531\n",
      "weighted avg       0.49      0.52      0.47     14531\n",
      "\n",
      "Epoch 4, Step 10300, Loss: 0.8906403183937073, F1: 0.5863609486700428, Accuracy: 0.5217810198885142, Time Elapsed: 2634.9340620040894 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.55      0.76      0.64       877\n",
      "           3       0.57      0.71      0.63       897\n",
      "           4       0.56      0.45      0.50       892\n",
      "           5       0.55      0.45      0.49       862\n",
      "           6       0.60      0.80      0.69       903\n",
      "           7       0.58      0.78      0.67       889\n",
      "           8       0.60      0.33      0.43       892\n",
      "           9       0.75      0.01      0.01       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 10400, Loss: 0.501291036605835, F1: 0.5318872637978707, Accuracy: 0.5112518064826922, Time Elapsed: 2650.810954093933 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.66       912\n",
      "           1       0.61      0.51      0.55       885\n",
      "           2       0.57      0.73      0.64       877\n",
      "           3       0.58      0.18      0.27       897\n",
      "           4       0.56      0.81      0.66       892\n",
      "           5       0.53      0.62      0.57       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.65      0.27      0.38       889\n",
      "           8       0.57      0.40      0.47       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.50      0.48     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 10500, Loss: 0.5672615170478821, F1: 0.48450359858475095, Accuracy: 0.49053747161241484, Time Elapsed: 2666.4452290534973 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.67       912\n",
      "           1       0.63      0.21      0.32       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.55      0.78      0.64       897\n",
      "           4       0.54      0.89      0.67       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.56      0.85      0.68       889\n",
      "           8       0.59      0.37      0.46       892\n",
      "           9       0.57      0.76      0.65       876\n",
      "          10       0.38      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 10600, Loss: 0.5030087232589722, F1: 0.5696227170796406, Accuracy: 0.5162067304383732, Time Elapsed: 2681.1111962795258 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62       912\n",
      "           1       0.33      0.00      0.01       885\n",
      "           2       0.53      0.76      0.63       877\n",
      "           3       0.56      0.49      0.52       897\n",
      "           4       0.60      0.46      0.52       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.60      0.72      0.66       903\n",
      "           7       0.57      0.86      0.69       889\n",
      "           8       0.59      0.37      0.45       892\n",
      "           9       0.58      0.68      0.63       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.54      0.52     14531\n",
      "weighted avg       0.49      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 10700, Loss: 0.9650564193725586, F1: 0.5151566706489937, Accuracy: 0.4974193104397495, Time Elapsed: 2696.2263531684875 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       912\n",
      "           1       0.61      0.44      0.51       885\n",
      "           2       0.62      0.44      0.52       877\n",
      "           3       0.60      0.43      0.50       897\n",
      "           4       0.50      0.92      0.65       892\n",
      "           5       0.56      0.25      0.35       862\n",
      "           6       0.60      0.63      0.61       903\n",
      "           7       0.59      0.67      0.63       889\n",
      "           8       0.58      0.69      0.63       892\n",
      "           9       0.60      0.68      0.64       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 10800, Loss: 1.8387322425842285, F1: 0.5536903092143531, Accuracy: 0.5093248916110384, Time Elapsed: 2711.5995399951935 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.57      0.91      0.70       885\n",
      "           2       0.54      0.75      0.63       877\n",
      "           3       0.57      0.73      0.64       897\n",
      "           4       0.53      0.82      0.65       892\n",
      "           5       0.54      0.60      0.57       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.59      0.40      0.48       892\n",
      "           9       0.60      0.70      0.65       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 10900, Loss: 0.41163474321365356, F1: 0.6016157930790325, Accuracy: 0.5311403206936893, Time Elapsed: 2727.2651920318604 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.18      0.28       912\n",
      "           1       0.61      0.31      0.41       885\n",
      "           2       0.57      0.56      0.57       877\n",
      "           3       0.53      0.80      0.64       897\n",
      "           4       0.59      0.52      0.56       892\n",
      "           5       0.57      0.51      0.54       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.61      0.62      0.61       889\n",
      "           8       0.55      0.72      0.62       892\n",
      "           9       0.57      0.71      0.64       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.49      0.48     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 11000, Loss: 1.7096818685531616, F1: 0.48124482781114336, Accuracy: 0.4850320005505471, Time Elapsed: 2743.5885450839996 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.31      0.41       912\n",
      "           1       0.56      0.85      0.68       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.51      0.89      0.64       897\n",
      "           4       0.61      0.38      0.47       892\n",
      "           5       0.54      0.66      0.59       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.47      0.53       889\n",
      "           8       0.61      0.49      0.54       892\n",
      "           9       0.58      0.71      0.64       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 11100, Loss: 1.2705026865005493, F1: 0.5528937331710125, Accuracy: 0.5071915215745647, Time Elapsed: 2759.2855291366577 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.54      0.73      0.62       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.58      0.55      0.56       897\n",
      "           4       0.55      0.88      0.67       892\n",
      "           5       0.52      0.65      0.58       862\n",
      "           6       0.61      0.66      0.63       903\n",
      "           7       0.61      0.50      0.55       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.57      0.79      0.66       876\n",
      "          10       0.39      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 11200, Loss: 0.5189648270606995, F1: 0.5899076404928483, Accuracy: 0.5214369279471475, Time Elapsed: 2776.0593569278717 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.70       912\n",
      "           1       0.58      0.42      0.49       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.61      0.52      0.56       897\n",
      "           4       0.57      0.66      0.61       892\n",
      "           5       0.54      0.55      0.55       862\n",
      "           6       0.62      0.63      0.62       903\n",
      "           7       0.57      0.82      0.67       889\n",
      "           8       0.59      0.49      0.54       892\n",
      "           9       0.56      0.72      0.63       876\n",
      "          10       0.39      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 11300, Loss: 0.8530269265174866, F1: 0.5777922493581503, Accuracy: 0.5188906475810336, Time Elapsed: 2791.642590045929 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.56      0.87      0.68       885\n",
      "           2       0.58      0.68      0.63       877\n",
      "           3       0.59      0.19      0.29       897\n",
      "           4       0.55      0.78      0.65       892\n",
      "           5       0.52      0.43      0.47       862\n",
      "           6       0.61      0.76      0.67       903\n",
      "           7       0.60      0.72      0.66       889\n",
      "           8       0.60      0.41      0.48       892\n",
      "           9       0.57      0.66      0.62       876\n",
      "          10       0.40      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 11400, Loss: 1.3675023317337036, F1: 0.5656052869940464, Accuracy: 0.5199229234051338, Time Elapsed: 2806.9448671340942 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       912\n",
      "           1       0.59      0.77      0.67       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.56      0.55      0.55       897\n",
      "           4       0.54      0.89      0.67       892\n",
      "           5       0.45      0.71      0.55       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.60      0.40      0.48       892\n",
      "           9       0.58      0.63      0.61       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 11500, Loss: 1.1320674419403076, F1: 0.5876768330365427, Accuracy: 0.5210240176175074, Time Elapsed: 2822.5999071598053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.59      0.87      0.70       885\n",
      "           2       0.56      0.68      0.61       877\n",
      "           3       0.60      0.53      0.56       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.51      0.31      0.38       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.78      0.01      0.02       892\n",
      "           9       0.57      0.72      0.64       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.61      0.55     14531\n",
      "weighted avg       0.51      0.52      0.48     14531\n",
      "\n",
      "Epoch 4, Step 11600, Loss: 0.36443251371383667, F1: 0.5463300376389144, Accuracy: 0.5180648269217535, Time Elapsed: 2838.274619102478 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       912\n",
      "           1       0.60      0.77      0.67       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.56      0.18      0.27       897\n",
      "           4       0.58      0.32      0.42       892\n",
      "           5       0.61      0.07      0.12       862\n",
      "           6       0.62      0.81      0.70       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.53      0.76      0.63       892\n",
      "           9       0.59      0.75      0.66       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.52     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 11700, Loss: 4.0707831382751465, F1: 0.5243098128173247, Accuracy: 0.5100818938820453, Time Elapsed: 2853.865254163742 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.58      0.91      0.71       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.54      0.82      0.65       892\n",
      "           5       0.53      0.45      0.49       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.55      0.82      0.65       876\n",
      "          10       0.39      0.22      0.29      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 4, Step 11800, Loss: 0.7958998084068298, F1: 0.6060532712770001, Accuracy: 0.5352006056018168, Time Elapsed: 2869.7959322929382 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.58      0.94      0.71       885\n",
      "           2       0.60      0.61      0.60       877\n",
      "           3       0.60      0.39      0.48       897\n",
      "           4       0.55      0.60      0.58       892\n",
      "           5       0.61      0.10      0.17       862\n",
      "           6       0.62      0.63      0.63       903\n",
      "           7       0.59      0.71      0.64       889\n",
      "           8       0.61      0.42      0.50       892\n",
      "           9       0.61      0.46      0.52       876\n",
      "          10       0.40      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 11900, Loss: 0.40701261162757874, F1: 0.540067836347045, Accuracy: 0.5133851765191659, Time Elapsed: 2884.9777431488037 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.39      0.49       912\n",
      "           1       0.59      0.71      0.65       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.67      0.01      0.02       897\n",
      "           4       0.56      0.25      0.34       892\n",
      "           5       0.46      0.67      0.54       862\n",
      "           6       0.64      0.32      0.43       903\n",
      "           7       0.57      0.81      0.67       889\n",
      "           8       0.60      0.29      0.39       892\n",
      "           9       0.61      0.34      0.44       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.44      0.45     14531\n",
      "weighted avg       0.52      0.48      0.45     14531\n",
      "\n",
      "Epoch 4, Step 12000, Loss: 0.9700300693511963, F1: 0.4520032302492219, Accuracy: 0.4753974261922786, Time Elapsed: 2901.2304031848907 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.59      0.82      0.69       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.61      0.45      0.51       897\n",
      "           4       0.43      0.92      0.59       892\n",
      "           5       0.55      0.41      0.47       862\n",
      "           6       0.61      0.81      0.70       903\n",
      "           7       0.61      0.59      0.60       889\n",
      "           8       0.61      0.35      0.44       892\n",
      "           9       0.61      0.47      0.53       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 12100, Loss: 0.8367870450019836, F1: 0.5662965264205034, Accuracy: 0.5136604500722594, Time Elapsed: 2916.2332990169525 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.69       912\n",
      "           1       0.61      0.47      0.53       885\n",
      "           2       0.49      0.72      0.58       877\n",
      "           3       0.54      0.82      0.65       897\n",
      "           4       0.59      0.53      0.56       892\n",
      "           5       0.57      0.07      0.12       862\n",
      "           6       0.59      0.81      0.69       903\n",
      "           7       0.62      0.48      0.55       889\n",
      "           8       0.59      0.46      0.52       892\n",
      "           9       0.56      0.71      0.63       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 12200, Loss: 1.2665021419525146, F1: 0.5354893082022606, Accuracy: 0.5054022434794577, Time Elapsed: 2930.765349149704 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.60      0.80      0.68       885\n",
      "           2       0.54      0.69      0.61       877\n",
      "           3       0.57      0.06      0.12       897\n",
      "           4       0.61      0.48      0.54       892\n",
      "           5       0.55      0.37      0.44       862\n",
      "           6       0.60      0.72      0.66       903\n",
      "           7       0.61      0.29      0.40       889\n",
      "           8       0.48      0.86      0.61       892\n",
      "           9       0.56      0.78      0.65       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.58      0.53     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 12300, Loss: 0.7282999157905579, F1: 0.5256312298748511, Accuracy: 0.5012043217947836, Time Elapsed: 2946.333062171936 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.58      0.88      0.70       885\n",
      "           2       0.51      0.80      0.62       877\n",
      "           3       0.59      0.73      0.65       897\n",
      "           4       0.58      0.63      0.60       892\n",
      "           5       0.57      0.29      0.38       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.62      0.43      0.51       892\n",
      "           9       0.59      0.48      0.53       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 12400, Loss: 0.993648111820221, F1: 0.5821090306256067, Accuracy: 0.5255660312435483, Time Elapsed: 2961.9598710536957 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.53      0.93      0.67       885\n",
      "           2       0.53      0.78      0.63       877\n",
      "           3       0.57      0.70      0.63       897\n",
      "           4       0.52      0.86      0.65       892\n",
      "           5       0.55      0.51      0.53       862\n",
      "           6       0.58      0.09      0.15       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.56      0.60      0.58       892\n",
      "           9       0.58      0.65      0.61       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.64      0.56     14531\n",
      "weighted avg       0.49      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 12500, Loss: 1.9174880981445312, F1: 0.5586363409922211, Accuracy: 0.5139357236253527, Time Elapsed: 2978.0554740428925 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.71       912\n",
      "           1       0.58      0.92      0.71       885\n",
      "           2       0.58      0.41      0.48       877\n",
      "           3       0.60      0.45      0.51       897\n",
      "           4       0.62      0.33      0.43       892\n",
      "           5       0.54      0.49      0.52       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.59      0.37      0.46       892\n",
      "           9       0.55      0.79      0.65       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 12600, Loss: 1.259006142616272, F1: 0.5622319094360891, Accuracy: 0.515587364943913, Time Elapsed: 2992.6219069957733 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.61      0.50      0.55       897\n",
      "           4       0.52      0.86      0.65       892\n",
      "           5       0.53      0.51      0.52       862\n",
      "           6       0.61      0.60      0.60       903\n",
      "           7       0.59      0.63      0.61       889\n",
      "           8       0.60      0.44      0.51       892\n",
      "           9       0.55      0.80      0.65       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 12700, Loss: 0.8920953869819641, F1: 0.580738861566699, Accuracy: 0.5183401004748469, Time Elapsed: 3008.630268096924 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.55      0.05      0.08       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.54      0.42      0.47       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.65      0.11      0.19       889\n",
      "           8       0.60      0.51      0.55       892\n",
      "           9       0.52      0.85      0.65       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.48      0.45     14531\n",
      "weighted avg       0.47      0.48      0.45     14531\n",
      "\n",
      "Epoch 4, Step 12800, Loss: 1.1605682373046875, F1: 0.4498296344523755, Accuracy: 0.4832427224554401, Time Elapsed: 3025.8068730831146 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.61      0.70      0.65       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.59      0.51      0.55       897\n",
      "           4       0.55      0.79      0.65       892\n",
      "           5       0.54      0.24      0.33       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.59      0.66      0.62       892\n",
      "           9       0.61      0.59      0.60       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 12900, Loss: 1.2191729545593262, F1: 0.5754375108339417, Accuracy: 0.523914389924988, Time Elapsed: 3041.475805044174 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.59      0.61      0.60       897\n",
      "           4       0.57      0.72      0.64       892\n",
      "           5       0.50      0.70      0.58       862\n",
      "           6       0.62      0.61      0.61       903\n",
      "           7       0.61      0.60      0.60       889\n",
      "           8       0.58      0.68      0.63       892\n",
      "           9       0.61      0.23      0.33       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.55      0.52     14531\n",
      "weighted avg       0.47      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 13000, Loss: 0.7967206835746765, F1: 0.5178143996859259, Accuracy: 0.5010666850182369, Time Elapsed: 3056.109304189682 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.71       912\n",
      "           1       0.58      0.85      0.69       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.60      0.64      0.62       897\n",
      "           4       0.57      0.63      0.60       892\n",
      "           5       0.50      0.67      0.57       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.61      0.62      0.61       889\n",
      "           8       0.59      0.46      0.52       892\n",
      "           9       0.60      0.44      0.51       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.55      0.52     14531\n",
      "weighted avg       0.47      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 13100, Loss: 0.8481056094169617, F1: 0.5227164651650801, Accuracy: 0.5022365976188837, Time Elapsed: 3071.296555042267 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.57      0.55      0.56       885\n",
      "           2       0.58      0.65      0.62       877\n",
      "           3       0.58      0.52      0.55       897\n",
      "           4       0.42      0.94      0.58       892\n",
      "           5       0.46      0.77      0.58       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.56      0.74      0.64       892\n",
      "           9       0.55      0.56      0.55       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.54      0.65      0.58     14531\n",
      "weighted avg       0.49      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 13200, Loss: 0.640956461429596, F1: 0.5752814872518832, Accuracy: 0.5080173422338449, Time Elapsed: 3087.100102186203 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.60      0.37      0.46       885\n",
      "           2       0.60      0.44      0.51       877\n",
      "           3       0.57      0.54      0.56       897\n",
      "           4       0.46      0.81      0.59       892\n",
      "           5       0.53      0.21      0.31       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.61      0.68      0.64       889\n",
      "           8       0.51      0.83      0.63       892\n",
      "           9       0.61      0.28      0.38       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.50      0.50      0.47     14531\n",
      "weighted avg       0.46      0.48      0.45     14531\n",
      "\n",
      "Epoch 4, Step 13300, Loss: 0.27409040927886963, F1: 0.4725293342087611, Accuracy: 0.48110935241896635, Time Elapsed: 3103.1132349967957 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.55      0.96      0.70       885\n",
      "           2       0.56      0.77      0.64       877\n",
      "           3       0.57      0.77      0.66       897\n",
      "           4       0.38      0.85      0.53       892\n",
      "           5       0.54      0.30      0.39       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.61      0.72      0.66       889\n",
      "           8       0.57      0.66      0.61       892\n",
      "           9       0.68      0.11      0.19       876\n",
      "          10       0.39      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.62      0.55     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 13400, Loss: 1.7571165561676025, F1: 0.5463104724418171, Accuracy: 0.503888238937444, Time Elapsed: 3119.0761411190033 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65       912\n",
      "           1       0.58      0.48      0.53       885\n",
      "           2       0.48      0.83      0.61       877\n",
      "           3       0.56      0.73      0.64       897\n",
      "           4       0.57      0.32      0.41       892\n",
      "           5       0.58      0.35      0.43       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.59      0.65      0.62       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.51      0.72      0.60       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.49      0.53      0.49     14531\n",
      "weighted avg       0.45      0.48      0.46     14531\n",
      "\n",
      "Epoch 4, Step 13500, Loss: 1.9610693454742432, F1: 0.4911802533496528, Accuracy: 0.4819351730782465, Time Elapsed: 3135.0621361732483 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.76      0.64       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.45      0.82      0.58       877\n",
      "           3       0.61      0.37      0.46       897\n",
      "           4       0.54      0.41      0.47       892\n",
      "           5       0.53      0.47      0.50       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.62      0.26      0.36       889\n",
      "           8       0.62      0.23      0.34       892\n",
      "           9       0.58      0.33      0.42       876\n",
      "          10       0.39      0.58      0.46      5646\n",
      "\n",
      "    accuracy                           0.45     14531\n",
      "   macro avg       0.44      0.38      0.38     14531\n",
      "weighted avg       0.42      0.45      0.41     14531\n",
      "\n",
      "Epoch 4, Step 13600, Loss: 0.6876226663589478, F1: 0.3843164123611992, Accuracy: 0.44766361571811986, Time Elapsed: 3150.5873510837555 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.86      0.69       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.58      0.54      0.56       897\n",
      "           4       0.48      0.78      0.59       892\n",
      "           5       0.55      0.39      0.45       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.62      0.27      0.37       889\n",
      "           8       0.60      0.51      0.55       892\n",
      "           9       0.57      0.29      0.39       876\n",
      "          10       0.39      0.45      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.50      0.50      0.48     14531\n",
      "weighted avg       0.47      0.48      0.46     14531\n",
      "\n",
      "Epoch 4, Step 13700, Loss: 2.937188148498535, F1: 0.4813151063971786, Accuracy: 0.4843438166678136, Time Elapsed: 3165.8513810634613 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.33      0.44       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.59      0.70      0.64       877\n",
      "           3       0.61      0.54      0.57       897\n",
      "           4       0.47      0.86      0.61       892\n",
      "           5       0.64      0.08      0.14       862\n",
      "           6       0.59      0.87      0.71       903\n",
      "           7       0.59      0.66      0.62       889\n",
      "           8       0.60      0.34      0.44       892\n",
      "           9       0.56      0.41      0.47       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 13800, Loss: 0.3608130216598511, F1: 0.5219930831442724, Accuracy: 0.5032000550547107, Time Elapsed: 3182.639755010605 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.61      0.57      0.59       885\n",
      "           2       0.61      0.39      0.48       877\n",
      "           3       0.57      0.68      0.62       897\n",
      "           4       0.56      0.56      0.56       892\n",
      "           5       0.56      0.34      0.42       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.60      0.48      0.53       889\n",
      "           8       0.55      0.67      0.60       892\n",
      "           9       0.55      0.36      0.43       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.55     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 4, Step 13900, Loss: 0.8675785660743713, F1: 0.5455296884992511, Accuracy: 0.503888238937444, Time Elapsed: 3198.899628162384 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.01      0.02       912\n",
      "           1       0.61      0.29      0.39       885\n",
      "           2       0.61      0.45      0.52       877\n",
      "           3       0.65      0.20      0.31       897\n",
      "           4       0.58      0.15      0.24       892\n",
      "           5       0.56      0.29      0.38       862\n",
      "           6       0.61      0.65      0.63       903\n",
      "           7       0.61      0.42      0.50       889\n",
      "           8       0.54      0.64      0.59       892\n",
      "           9       0.53      0.62      0.57       876\n",
      "          10       0.39      0.61      0.47      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.59      0.39      0.42     14531\n",
      "weighted avg       0.52      0.46      0.44     14531\n",
      "\n",
      "Epoch 4, Step 14000, Loss: 0.8618366718292236, F1: 0.4194266944676377, Accuracy: 0.46328538985616957, Time Elapsed: 3214.635894060135 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.56      0.77      0.65       877\n",
      "           3       0.55      0.64      0.59       897\n",
      "           4       0.49      0.87      0.63       892\n",
      "           5       0.56      0.37      0.45       862\n",
      "           6       0.63      0.70      0.66       903\n",
      "           7       0.59      0.74      0.66       889\n",
      "           8       0.57      0.55      0.56       892\n",
      "           9       0.54      0.63      0.58       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 14100, Loss: 1.437887191772461, F1: 0.5881350082425159, Accuracy: 0.5224692037712477, Time Elapsed: 3229.734791278839 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       912\n",
      "           1       0.59      0.77      0.67       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.56      0.54      0.55       897\n",
      "           4       0.51      0.82      0.63       892\n",
      "           5       0.61      0.11      0.19       862\n",
      "           6       0.62      0.49      0.55       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.53      0.66      0.59       892\n",
      "           9       0.60      0.21      0.31       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 14200, Loss: 0.35968026518821716, F1: 0.5326035546175635, Accuracy: 0.5062280641387379, Time Elapsed: 3244.896815061569 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.67       912\n",
      "           1       0.60      0.51      0.56       885\n",
      "           2       0.60      0.64      0.62       877\n",
      "           3       0.67      0.01      0.01       897\n",
      "           4       0.57      0.66      0.61       892\n",
      "           5       0.54      0.51      0.52       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.58      0.84      0.69       889\n",
      "           8       0.59      0.56      0.58       892\n",
      "           9       0.56      0.71      0.62       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.54     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 14300, Loss: 1.7595255374908447, F1: 0.5390257883573762, Accuracy: 0.5084990709517583, Time Elapsed: 3260.9003541469574 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.57      0.86      0.69       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.64      0.14      0.23       897\n",
      "           4       1.00      0.00      0.00       892\n",
      "           5       0.53      0.49      0.51       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.60      0.32      0.42       892\n",
      "           9       0.56      0.75      0.64       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.60      0.54      0.50     14531\n",
      "weighted avg       0.53      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 14400, Loss: 6.4050445556640625, F1: 0.5008906294513091, Accuracy: 0.49996559080586334, Time Elapsed: 3276.5908019542694 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.56      0.94      0.70       885\n",
      "           2       0.59      0.69      0.63       877\n",
      "           3       0.71      0.01      0.01       897\n",
      "           4       0.57      0.52      0.54       892\n",
      "           5       0.57      0.12      0.19       862\n",
      "           6       0.62      0.61      0.62       903\n",
      "           7       0.59      0.14      0.22       889\n",
      "           8       0.57      0.64      0.60       892\n",
      "           9       0.54      0.83      0.65       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.48     14531\n",
      "weighted avg       0.51      0.50      0.46     14531\n",
      "\n",
      "Epoch 4, Step 14500, Loss: 1.4669358730316162, F1: 0.4822009311203818, Accuracy: 0.4957676691211892, Time Elapsed: 3292.711718082428 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.94      0.71       912\n",
      "           1       0.56      0.91      0.70       885\n",
      "           2       0.63      0.49      0.55       877\n",
      "           3       0.60      0.41      0.49       897\n",
      "           4       0.57      0.21      0.30       892\n",
      "           5       0.52      0.36      0.43       862\n",
      "           6       0.61      0.59      0.60       903\n",
      "           7       0.58      0.47      0.52       889\n",
      "           8       0.60      0.37      0.46       892\n",
      "           9       0.57      0.78      0.66       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 14600, Loss: 3.4700093269348145, F1: 0.5286475467129473, Accuracy: 0.49989677241759, Time Elapsed: 3308.5827519893646 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.56      0.90      0.69       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.57      0.67      0.62       897\n",
      "           4       0.51      0.84      0.64       892\n",
      "           5       0.54      0.39      0.45       862\n",
      "           6       0.60      0.51      0.55       903\n",
      "           7       0.60      0.60      0.60       889\n",
      "           8       0.62      0.40      0.49       892\n",
      "           9       0.53      0.85      0.65       876\n",
      "          10       0.38      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.63      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 14700, Loss: 2.6652603149414062, F1: 0.5747450180670305, Accuracy: 0.5151056362259996, Time Elapsed: 3324.4428491592407 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.72       912\n",
      "           1       0.58      0.90      0.71       885\n",
      "           2       0.61      0.54      0.57       877\n",
      "           3       0.61      0.48      0.54       897\n",
      "           4       0.57      0.27      0.37       892\n",
      "           5       0.51      0.68      0.58       862\n",
      "           6       0.61      0.63      0.62       903\n",
      "           7       0.61      0.72      0.66       889\n",
      "           8       0.54      0.64      0.59       892\n",
      "           9       0.58      0.76      0.66       876\n",
      "          10       0.40      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 14800, Loss: 1.226460576057434, F1: 0.577935998033249, Accuracy: 0.5226068405477944, Time Elapsed: 3339.9854509830475 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.72       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.53      0.77      0.62       877\n",
      "           3       0.55      0.82      0.66       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.56      0.43      0.49       862\n",
      "           6       0.61      0.81      0.70       903\n",
      "           7       0.60      0.45      0.51       889\n",
      "           8       0.52      0.72      0.60       892\n",
      "           9       0.50      0.85      0.63       876\n",
      "          10       0.39      0.20      0.26      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.69      0.59     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 4, Step 14900, Loss: 1.3040494918823242, F1: 0.5949721751440012, Accuracy: 0.5271488541738353, Time Elapsed: 3354.8834891319275 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.02      0.04       912\n",
      "           1       0.64      0.06      0.10       885\n",
      "           2       0.63      0.36      0.46       877\n",
      "           3       0.63      0.35      0.45       897\n",
      "           4       0.57      0.71      0.63       892\n",
      "           5       0.57      0.01      0.03       862\n",
      "           6       0.61      0.30      0.40       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.47      0.80      0.59       892\n",
      "           9       0.60      0.37      0.45       876\n",
      "          10       0.39      0.61      0.48      5646\n",
      "\n",
      "    accuracy                           0.46     14531\n",
      "   macro avg       0.57      0.38      0.39     14531\n",
      "weighted avg       0.51      0.46      0.42     14531\n",
      "\n",
      "Epoch 4, Step 15000, Loss: 0.8430034518241882, F1: 0.387389074873223, Accuracy: 0.4597756520542289, Time Elapsed: 3371.0667152404785 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.31      0.42       912\n",
      "           1       0.59      0.43      0.50       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.59      0.56      0.57       897\n",
      "           4       0.55      0.82      0.66       892\n",
      "           5       0.56      0.43      0.49       862\n",
      "           6       0.62      0.65      0.63       903\n",
      "           7       0.61      0.60      0.61       889\n",
      "           8       0.59      0.62      0.60       892\n",
      "           9       0.63      0.15      0.24       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.52     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 15100, Loss: 0.7931970357894897, F1: 0.5214584918246136, Accuracy: 0.498313949487303, Time Elapsed: 3386.9194202423096 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.58       912\n",
      "           1       0.50      0.30      0.37       885\n",
      "           2       0.59      0.66      0.63       877\n",
      "           3       0.53      0.76      0.63       897\n",
      "           4       0.54      0.86      0.67       892\n",
      "           5       0.57      0.35      0.43       862\n",
      "           6       0.62      0.52      0.57       903\n",
      "           7       0.60      0.53      0.56       889\n",
      "           8       0.60      0.37      0.46       892\n",
      "           9       0.54      0.80      0.65       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 15200, Loss: 0.7747135758399963, F1: 0.5398172149792849, Accuracy: 0.5012043217947836, Time Elapsed: 3402.912894964218 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.28      0.38       912\n",
      "           1       0.60      0.72      0.65       885\n",
      "           2       0.61      0.51      0.55       877\n",
      "           3       0.68      0.08      0.15       897\n",
      "           4       0.56      0.86      0.68       892\n",
      "           5       0.52      0.70      0.60       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.61      0.57      0.59       889\n",
      "           8       0.61      0.11      0.18       892\n",
      "           9       0.60      0.65      0.63       876\n",
      "          10       0.40      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.50     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 15300, Loss: 0.4796949625015259, F1: 0.49906859116128294, Accuracy: 0.4982451310990297, Time Elapsed: 3721.321939945221 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.61      0.27      0.38       885\n",
      "           2       0.61      0.56      0.58       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.52      0.92      0.66       892\n",
      "           5       0.51      0.55      0.53       862\n",
      "           6       0.63      0.55      0.59       903\n",
      "           7       0.61      0.66      0.63       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.61      0.53      0.56       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.54      0.51     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 15400, Loss: 0.8876734972000122, F1: 0.5130822004214064, Accuracy: 0.5019613240657904, Time Elapsed: 3738.6622672080994 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.61      0.63      0.62       885\n",
      "           2       0.60      0.63      0.62       877\n",
      "           3       0.65      0.11      0.19       897\n",
      "           4       0.50      0.93      0.65       892\n",
      "           5       0.50      0.61      0.55       862\n",
      "           6       0.61      0.81      0.70       903\n",
      "           7       0.59      0.40      0.48       889\n",
      "           8       0.61      0.33      0.42       892\n",
      "           9       0.62      0.34      0.44       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 15500, Loss: 1.3625283241271973, F1: 0.5222362235385406, Accuracy: 0.4992774069231299, Time Elapsed: 3754.627038002014 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.61      0.75      0.68       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.61      0.34      0.43       897\n",
      "           4       0.56      0.82      0.66       892\n",
      "           5       0.50      0.65      0.56       862\n",
      "           6       0.59      0.87      0.71       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.67      0.00      0.00       892\n",
      "           9       0.60      0.59      0.60       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.59      0.54     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 15600, Loss: 0.6576058864593506, F1: 0.5390849903079235, Accuracy: 0.5144174523432661, Time Elapsed: 4070.567379951477 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.71       912\n",
      "           1       0.63      0.06      0.11       885\n",
      "           2       0.62      0.54      0.58       877\n",
      "           3       0.56      0.71      0.63       897\n",
      "           4       0.55      0.83      0.66       892\n",
      "           5       0.53      0.59      0.56       862\n",
      "           6       0.63      0.63      0.63       903\n",
      "           7       0.59      0.16      0.25       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.59      0.65      0.62       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 15700, Loss: 0.5356922745704651, F1: 0.5192069944370844, Accuracy: 0.503475328607804, Time Elapsed: 4087.057599067688 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.59      0.45      0.51       885\n",
      "           2       0.61      0.54      0.57       877\n",
      "           3       0.62      0.41      0.49       897\n",
      "           4       0.57      0.72      0.64       892\n",
      "           5       0.48      0.74      0.58       862\n",
      "           6       0.62      0.63      0.63       903\n",
      "           7       0.60      0.18      0.28       889\n",
      "           8       0.52      0.68      0.59       892\n",
      "           9       0.52      0.86      0.65       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 15800, Loss: 1.2212591171264648, F1: 0.5470073417282053, Accuracy: 0.5044387860436309, Time Elapsed: 4102.516472101212 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.61      0.19      0.29       885\n",
      "           2       0.62      0.51      0.56       877\n",
      "           3       0.60      0.68      0.64       897\n",
      "           4       0.54      0.89      0.67       892\n",
      "           5       0.54      0.38      0.44       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.61      0.61      0.61       889\n",
      "           8       0.61      0.55      0.58       892\n",
      "           9       0.59      0.69      0.64       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 15900, Loss: 0.425253301858902, F1: 0.5646222069119481, Accuracy: 0.5198541050168605, Time Elapsed: 4116.972738981247 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.61      0.69      0.65       885\n",
      "           2       0.56      0.66      0.61       877\n",
      "           3       0.58      0.73      0.64       897\n",
      "           4       0.56      0.79      0.66       892\n",
      "           5       0.54      0.52      0.53       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.61      0.74      0.67       889\n",
      "           8       0.61      0.52      0.56       892\n",
      "           9       0.58      0.74      0.65       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.61     14531\n",
      "weighted avg       0.51      0.53      0.52     14531\n",
      "\n",
      "Epoch 4, Step 16000, Loss: 0.5559320449829102, F1: 0.6051666890821599, Accuracy: 0.5336866010598031, Time Elapsed: 4131.879554033279 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.96      0.71       912\n",
      "           1       0.63      0.21      0.32       885\n",
      "           2       0.55      0.71      0.62       877\n",
      "           3       0.58      0.70      0.64       897\n",
      "           4       0.56      0.77      0.65       892\n",
      "           5       0.56      0.22      0.31       862\n",
      "           6       0.61      0.57      0.59       903\n",
      "           7       0.59      0.13      0.22       889\n",
      "           8       0.60      0.00      0.01       892\n",
      "           9       0.59      0.75      0.66       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.50      0.47     14531\n",
      "weighted avg       0.51      0.49      0.45     14531\n",
      "\n",
      "Epoch 4, Step 16100, Loss: 1.9652414321899414, F1: 0.467371869494, Accuracy: 0.4884041015759411, Time Elapsed: 4148.644565105438 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.61      0.66      0.64       885\n",
      "           2       0.51      0.78      0.62       877\n",
      "           3       0.54      0.86      0.66       897\n",
      "           4       0.59      0.60      0.59       892\n",
      "           5       0.55      0.58      0.56       862\n",
      "           6       0.62      0.74      0.67       903\n",
      "           7       0.61      0.63      0.62       889\n",
      "           8       0.60      0.52      0.56       892\n",
      "           9       0.60      0.69      0.64       876\n",
      "          10       0.39      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 16200, Loss: 0.578267514705658, F1: 0.6003367245666656, Accuracy: 0.5301768632578625, Time Elapsed: 4164.023578166962 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.61      0.22      0.33       885\n",
      "           2       0.52      0.70      0.60       877\n",
      "           3       0.56      0.82      0.67       897\n",
      "           4       0.58      0.34      0.43       892\n",
      "           5       0.58      0.16      0.25       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.61      0.73      0.66       889\n",
      "           8       0.59      0.59      0.59       892\n",
      "           9       0.53      0.78      0.63       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 16300, Loss: 0.5532174706459045, F1: 0.5393167346677651, Accuracy: 0.5091872548344918, Time Elapsed: 4178.892614126205 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.60      0.72      0.65       885\n",
      "           2       0.62      0.31      0.41       877\n",
      "           3       0.50      0.86      0.63       897\n",
      "           4       0.57      0.63      0.60       892\n",
      "           5       0.56      0.23      0.33       862\n",
      "           6       0.62      0.72      0.66       903\n",
      "           7       0.60      0.74      0.67       889\n",
      "           8       0.55      0.70      0.62       892\n",
      "           9       0.60      0.54      0.57       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 16400, Loss: 0.4513853192329407, F1: 0.5637411147830111, Accuracy: 0.5175830982038401, Time Elapsed: 4193.425276994705 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.66      0.17      0.27       897\n",
      "           4       0.57      0.71      0.63       892\n",
      "           5       0.55      0.34      0.42       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.61      0.70      0.65       889\n",
      "           8       0.60      0.53      0.57       892\n",
      "           9       0.59      0.66      0.62       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.55      0.51     14531\n",
      "weighted avg       0.48      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 16500, Loss: 0.5261918902397156, F1: 0.5125768081221378, Accuracy: 0.5081549790103915, Time Elapsed: 4208.776690006256 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.53      0.75      0.62       877\n",
      "           3       0.66      0.23      0.34       897\n",
      "           4       0.51      0.92      0.66       892\n",
      "           5       0.53      0.59      0.56       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.59      0.71      0.64       892\n",
      "           9       0.50      0.87      0.64       876\n",
      "          10       0.39      0.21      0.28      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.59     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 4, Step 16600, Loss: 0.518526017665863, F1: 0.5868499356989719, Accuracy: 0.5259789415731884, Time Elapsed: 4224.092892885208 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.73       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.61      0.44      0.51       897\n",
      "           4       0.56      0.77      0.65       892\n",
      "           5       0.54      0.61      0.57       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.62      0.31      0.42       889\n",
      "           8       0.60      0.45      0.51       892\n",
      "           9       0.57      0.71      0.64       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 16700, Loss: 0.4992469251155853, F1: 0.5751687256126256, Accuracy: 0.5216433831119676, Time Elapsed: 4238.620156288147 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.72       912\n",
      "           1       0.61      0.72      0.66       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.63      0.38      0.47       897\n",
      "           4       0.56      0.84      0.68       892\n",
      "           5       0.54      0.56      0.55       862\n",
      "           6       0.62      0.50      0.56       903\n",
      "           7       0.63      0.39      0.48       889\n",
      "           8       0.61      0.23      0.33       892\n",
      "           9       0.61      0.49      0.54       876\n",
      "          10       0.40      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 16800, Loss: 0.39506471157073975, F1: 0.5470955911990492, Accuracy: 0.5114582616475122, Time Elapsed: 5167.631012201309 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.57      0.90      0.70       885\n",
      "           2       0.61      0.33      0.43       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.54      0.89      0.67       892\n",
      "           5       0.56      0.39      0.46       862\n",
      "           6       0.62      0.74      0.68       903\n",
      "           7       0.61      0.59      0.60       889\n",
      "           8       0.55      0.75      0.63       892\n",
      "           9       0.56      0.82      0.67       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.58     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 16900, Loss: 1.0569508075714111, F1: 0.5824819680617751, Accuracy: 0.5259789415731884, Time Elapsed: 5184.323665857315 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.60      0.24      0.34       877\n",
      "           3       0.62      0.41      0.50       897\n",
      "           4       0.57      0.19      0.29       892\n",
      "           5       0.55      0.42      0.47       862\n",
      "           6       0.53      0.94      0.68       903\n",
      "           7       0.60      0.63      0.62       889\n",
      "           8       0.48      0.87      0.62       892\n",
      "           9       0.53      0.87      0.65       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.59      0.53     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 17000, Loss: 0.30797791481018066, F1: 0.5343048750010497, Accuracy: 0.5009978666299635, Time Elapsed: 5199.830844163895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.00      0.01       912\n",
      "           1       0.59      0.87      0.70       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.60      0.46      0.52       897\n",
      "           4       0.57      0.44      0.50       892\n",
      "           5       0.55      0.60      0.57       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.55      0.76      0.64       892\n",
      "           9       0.50      0.88      0.64       876\n",
      "          10       0.38      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.60      0.53     14531\n",
      "weighted avg       0.51      0.51      0.47     14531\n",
      "\n",
      "Epoch 4, Step 17100, Loss: 0.8173568844795227, F1: 0.534666824137081, Accuracy: 0.5062280641387379, Time Elapsed: 6220.839866161346 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.04      0.07       912\n",
      "           1       0.61      0.60      0.61       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.56      0.60      0.58       897\n",
      "           4       0.57      0.74      0.64       892\n",
      "           5       0.56      0.52      0.54       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.58      0.65      0.61       889\n",
      "           8       0.61      0.37      0.46       892\n",
      "           9       0.59      0.60      0.60       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.54      0.53     14531\n",
      "weighted avg       0.52      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 17200, Loss: 2.129666805267334, F1: 0.5268913584156658, Accuracy: 0.5012043217947836, Time Elapsed: 6238.324553012848 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.34      0.42       912\n",
      "           1       0.57      0.17      0.27       885\n",
      "           2       0.55      0.70      0.62       877\n",
      "           3       0.52      0.54      0.53       897\n",
      "           4       0.59      0.53      0.56       892\n",
      "           5       0.54      0.57      0.56       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.57      0.83      0.67       889\n",
      "           8       0.60      0.33      0.42       892\n",
      "           9       0.54      0.68      0.60       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.53      0.52     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 4, Step 17300, Loss: 0.7165865302085876, F1: 0.5190340279595959, Accuracy: 0.49060629000068817, Time Elapsed: 7232.350731134415 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.21      0.31       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.61      0.35      0.44       877\n",
      "           3       0.59      0.44      0.51       897\n",
      "           4       0.55      0.85      0.67       892\n",
      "           5       0.55      0.33      0.41       862\n",
      "           6       0.61      0.68      0.65       903\n",
      "           7       0.60      0.03      0.06       889\n",
      "           8       0.58      0.68      0.63       892\n",
      "           9       0.50      0.89      0.64       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.52      0.49     14531\n",
      "weighted avg       0.50      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 17400, Loss: 0.7446964383125305, F1: 0.4917053390277884, Accuracy: 0.4898492877296814, Time Elapsed: 7250.400375127792 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.88      0.69       912\n",
      "           1       0.56      0.95      0.71       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.55      0.80      0.65       897\n",
      "           4       0.56      0.86      0.68       892\n",
      "           5       0.55      0.63      0.59       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.47      0.81      0.59       892\n",
      "           9       0.59      0.72      0.65       876\n",
      "          10       0.39      0.14      0.20      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.55      0.73      0.61     14531\n",
      "weighted avg       0.50      0.54      0.48     14531\n",
      "\n",
      "Epoch 4, Step 17500, Loss: 0.3982609808444977, F1: 0.6111092630219124, Accuracy: 0.5363016998141904, Time Elapsed: 7270.313266038895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.44      0.50       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.63      0.06      0.11       889\n",
      "           8       0.61      0.43      0.50       892\n",
      "           9       0.58      0.77      0.66       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.54     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 17600, Loss: 0.4050319790840149, F1: 0.5372151199019177, Accuracy: 0.5091184364462185, Time Elapsed: 8225.258180141449 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.62      0.88      0.73       885\n",
      "           2       0.56      0.72      0.63       877\n",
      "           3       0.63      0.46      0.53       897\n",
      "           4       0.56      0.75      0.64       892\n",
      "           5       0.48      0.76      0.59       862\n",
      "           6       0.62      0.57      0.59       903\n",
      "           7       0.62      0.52      0.57       889\n",
      "           8       0.59      0.73      0.65       892\n",
      "           9       0.60      0.48      0.53       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.57      0.53     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 17700, Loss: 2.3967323303222656, F1: 0.5318551862722173, Accuracy: 0.5062968825270112, Time Elapsed: 8241.734138250351 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.08      0.14       912\n",
      "           1       0.62      0.47      0.53       885\n",
      "           2       0.52      0.66      0.58       877\n",
      "           3       0.62      0.23      0.34       897\n",
      "           4       0.55      0.74      0.63       892\n",
      "           5       0.46      0.58      0.52       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.61      0.60      0.60       889\n",
      "           8       0.56      0.77      0.65       892\n",
      "           9       0.48      0.85      0.61       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.55      0.56      0.51     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 17800, Loss: 1.278291940689087, F1: 0.5136626728669742, Accuracy: 0.4897116509531347, Time Elapsed: 8258.813828229904 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.60      0.78      0.68       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.62      0.32      0.42       897\n",
      "           4       0.60      0.41      0.49       892\n",
      "           5       0.56      0.49      0.52       862\n",
      "           6       0.59      0.85      0.69       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.61      0.56      0.58       892\n",
      "           9       0.57      0.74      0.64       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.59      0.57     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 17900, Loss: 1.13145911693573, F1: 0.5705352272718826, Accuracy: 0.5182712820865736, Time Elapsed: 9180.250889062881 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.11      0.18       912\n",
      "           1       0.62      0.69      0.65       885\n",
      "           2       0.59      0.32      0.42       877\n",
      "           3       0.61      0.56      0.58       897\n",
      "           4       0.57      0.43      0.49       892\n",
      "           5       0.55      0.46      0.50       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.60      0.57      0.59       892\n",
      "           9       0.57      0.41      0.48       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.50      0.51     14531\n",
      "weighted avg       0.51      0.49      0.49     14531\n",
      "\n",
      "Epoch 4, Step 18000, Loss: 1.5192646980285645, F1: 0.5129334751611853, Accuracy: 0.49466657490881566, Time Elapsed: 9197.686838150024 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.05      0.10       912\n",
      "           1       0.62      0.63      0.62       885\n",
      "           2       0.51      0.77      0.62       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.57      0.82      0.67       892\n",
      "           5       0.54      0.59      0.56       862\n",
      "           6       0.58      0.85      0.69       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.61      0.52      0.56       892\n",
      "           9       0.58      0.33      0.42       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.57      0.53     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 18100, Loss: 0.5066543817520142, F1: 0.5336130283370668, Accuracy: 0.5042323308788108, Time Elapsed: 9214.031630039215 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.69       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.55      0.73      0.63       877\n",
      "           3       0.61      0.35      0.44       897\n",
      "           4       0.56      0.89      0.69       892\n",
      "           5       0.54      0.30      0.39       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.61      0.39      0.47       892\n",
      "           9       0.59      0.51      0.55       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 18200, Loss: 1.4009742736816406, F1: 0.566442667162195, Accuracy: 0.5176519165921134, Time Elapsed: 10286.999788999557 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       912\n",
      "           1       0.62      0.73      0.67       885\n",
      "           2       0.58      0.59      0.59       877\n",
      "           3       0.62      0.37      0.47       897\n",
      "           4       0.60      0.35      0.44       892\n",
      "           5       0.54      0.60      0.57       862\n",
      "           6       0.60      0.59      0.60       903\n",
      "           7       0.61      0.51      0.56       889\n",
      "           8       0.60      0.52      0.56       892\n",
      "           9       0.61      0.64      0.62       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.55     14531\n",
      "weighted avg       0.52      0.51      0.51     14531\n",
      "\n",
      "Epoch 4, Step 18300, Loss: 2.3989179134368896, F1: 0.5544109276203948, Accuracy: 0.5096689835524052, Time Elapsed: 10303.308588981628 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.61      0.75      0.67       885\n",
      "           2       0.52      0.74      0.61       877\n",
      "           3       0.66      0.20      0.30       897\n",
      "           4       0.52      0.76      0.62       892\n",
      "           5       0.56      0.30      0.39       862\n",
      "           6       0.58      0.86      0.69       903\n",
      "           7       0.59      0.06      0.12       889\n",
      "           8       0.55      0.58      0.56       892\n",
      "           9       0.60      0.62      0.61       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.52     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 18400, Loss: 0.6911464929580688, F1: 0.5159653967240245, Accuracy: 0.5004473195237767, Time Elapsed: 11234.709856033325 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       912\n",
      "           1       0.61      0.56      0.58       885\n",
      "           2       0.55      0.78      0.64       877\n",
      "           3       0.58      0.72      0.64       897\n",
      "           4       0.57      0.37      0.45       892\n",
      "           5       0.57      0.53      0.55       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.61      0.24      0.35       892\n",
      "           9       0.60      0.64      0.62       876\n",
      "          10       0.39      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 18500, Loss: 0.8242214322090149, F1: 0.5655752919085366, Accuracy: 0.5168260959328332, Time Elapsed: 11256.482413053513 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68       912\n",
      "           1       0.65      0.11      0.19       885\n",
      "           2       0.61      0.36      0.46       877\n",
      "           3       0.61      0.46      0.53       897\n",
      "           4       0.56      0.81      0.66       892\n",
      "           5       0.57      0.27      0.37       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.58      0.79      0.67       889\n",
      "           8       0.60      0.46      0.52       892\n",
      "           9       0.56      0.80      0.66       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 18600, Loss: 0.8722474575042725, F1: 0.5266133303545373, Accuracy: 0.5060216089739178, Time Elapsed: 11273.420261144638 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.55      0.80      0.65       897\n",
      "           4       0.59      0.45      0.51       892\n",
      "           5       0.56      0.39      0.46       862\n",
      "           6       0.63      0.57      0.60       903\n",
      "           7       0.60      0.45      0.51       889\n",
      "           8       0.60      0.51      0.55       892\n",
      "           9       0.57      0.39      0.46       876\n",
      "          10       0.40      0.48      0.44      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.50      0.50     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 18700, Loss: 1.1279642581939697, F1: 0.4970896482853075, Accuracy: 0.4958364875094625, Time Elapsed: 11288.87950706482 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.61      0.48      0.54       885\n",
      "           2       0.62      0.31      0.41       877\n",
      "           3       0.56      0.74      0.63       897\n",
      "           4       0.55      0.74      0.63       892\n",
      "           5       0.51      0.69      0.59       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.61      0.44      0.51       889\n",
      "           8       0.52      0.61      0.56       892\n",
      "           9       0.59      0.54      0.57       876\n",
      "          10       0.40      0.35      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 18800, Loss: 4.308712005615234, F1: 0.5641874585495422, Accuracy: 0.5147615442846328, Time Elapsed: 11303.467200994492 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.50      0.55       912\n",
      "           1       0.59      0.53      0.56       885\n",
      "           2       0.56      0.70      0.62       877\n",
      "           3       0.55      0.45      0.50       897\n",
      "           4       0.56      0.85      0.67       892\n",
      "           5       0.56      0.41      0.48       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.61      0.69      0.64       889\n",
      "           8       0.45      0.75      0.56       892\n",
      "           9       0.58      0.68      0.63       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.59      0.56     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 18900, Loss: 0.5378175973892212, F1: 0.5631561950138256, Accuracy: 0.5058839721973711, Time Elapsed: 12259.443614959717 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       912\n",
      "           1       0.54      0.94      0.69       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.56      0.63      0.59       897\n",
      "           4       0.59      0.57      0.58       892\n",
      "           5       0.54      0.67      0.60       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.51      0.71      0.59       892\n",
      "           9       0.58      0.71      0.64       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 19000, Loss: 0.5519830584526062, F1: 0.6037438023314409, Accuracy: 0.5296263161516758, Time Elapsed: 12278.983386039734 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.58      0.92      0.71       885\n",
      "           2       0.57      0.64      0.61       877\n",
      "           3       0.55      0.76      0.63       897\n",
      "           4       0.49      0.91      0.64       892\n",
      "           5       0.53      0.61      0.57       862\n",
      "           6       0.58      0.85      0.69       903\n",
      "           7       0.60      0.51      0.55       889\n",
      "           8       0.60      0.46      0.52       892\n",
      "           9       0.59      0.61      0.60       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 19100, Loss: 0.5911374092102051, F1: 0.5940942942372797, Accuracy: 0.5285252219393022, Time Elapsed: 13241.324985027313 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60       912\n",
      "           1       0.61      0.50      0.55       885\n",
      "           2       0.54      0.74      0.63       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.51      0.13      0.21       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.60      0.51      0.55       889\n",
      "           8       0.53      0.01      0.02       892\n",
      "           9       0.57      0.36      0.44       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.47      0.48     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 19200, Loss: 0.256317675113678, F1: 0.4769164811847872, Accuracy: 0.4859266395981006, Time Elapsed: 13262.587944984436 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.57      0.89      0.70       885\n",
      "           2       0.54      0.80      0.65       877\n",
      "           3       0.55      0.77      0.64       897\n",
      "           4       0.55      0.78      0.65       892\n",
      "           5       0.56      0.21      0.31       862\n",
      "           6       0.62      0.55      0.58       903\n",
      "           7       0.54      0.87      0.67       889\n",
      "           8       0.60      0.45      0.51       892\n",
      "           9       0.51      0.75      0.61       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.66      0.58     14531\n",
      "weighted avg       0.50      0.52      0.48     14531\n",
      "\n",
      "Epoch 4, Step 19300, Loss: 0.42163583636283875, F1: 0.5751217771693397, Accuracy: 0.5201981969582272, Time Elapsed: 13282.929655075073 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.58      0.66      0.61       877\n",
      "           3       0.59      0.55      0.57       897\n",
      "           4       0.44      0.97      0.61       892\n",
      "           5       0.56      0.43      0.49       862\n",
      "           6       0.60      0.58      0.59       903\n",
      "           7       0.54      0.87      0.66       889\n",
      "           8       0.60      0.38      0.47       892\n",
      "           9       0.60      0.30      0.40       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.63      0.56     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 19400, Loss: 0.7752846479415894, F1: 0.5601147091768381, Accuracy: 0.5090496180579451, Time Elapsed: 14271.739928007126 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.58      0.93      0.72       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.62      0.35      0.45       897\n",
      "           4       0.56      0.71      0.62       892\n",
      "           5       0.55      0.43      0.48       862\n",
      "           6       0.59      0.81      0.69       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.56      0.75      0.64       892\n",
      "           9       0.60      0.49      0.54       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 19500, Loss: 3.763535976409912, F1: 0.5832673390295068, Accuracy: 0.5262542151262818, Time Elapsed: 14298.776901245117 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.60      0.89      0.71       885\n",
      "           2       0.61      0.46      0.52       877\n",
      "           3       0.56      0.82      0.66       897\n",
      "           4       0.52      0.92      0.67       892\n",
      "           5       0.53      0.62      0.57       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.58      0.73      0.65       892\n",
      "           9       0.60      0.51      0.55       876\n",
      "          10       0.40      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 4, Step 19600, Loss: 0.6243100762367249, F1: 0.6089083222057352, Accuracy: 0.5394673456747643, Time Elapsed: 14313.859207868576 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       912\n",
      "           1       0.58      0.87      0.70       885\n",
      "           2       0.50      0.86      0.63       877\n",
      "           3       0.55      0.83      0.66       897\n",
      "           4       0.58      0.52      0.55       892\n",
      "           5       0.51      0.52      0.51       862\n",
      "           6       0.56      0.90      0.69       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.60      0.58      0.59       892\n",
      "           9       0.55      0.83      0.66       876\n",
      "          10       0.39      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 4, Step 19700, Loss: 0.6478330492973328, F1: 0.5956117194555391, Accuracy: 0.5262542151262818, Time Elapsed: 14328.695900917053 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.60      0.83      0.69       885\n",
      "           2       0.59      0.65      0.62       877\n",
      "           3       0.58      0.66      0.62       897\n",
      "           4       0.58      0.36      0.44       892\n",
      "           5       0.55      0.47      0.51       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.53      0.90      0.67       889\n",
      "           8       0.61      0.32      0.42       892\n",
      "           9       0.50      0.83      0.62       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 19800, Loss: 0.38320887088775635, F1: 0.5734975157005935, Accuracy: 0.5184777372513936, Time Elapsed: 14344.780756950378 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.59      0.84      0.69       885\n",
      "           2       0.60      0.55      0.58       877\n",
      "           3       0.45      0.90      0.60       897\n",
      "           4       0.57      0.74      0.64       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.57      0.88      0.69       889\n",
      "           8       0.61      0.35      0.44       892\n",
      "           9       0.60      0.51      0.55       876\n",
      "          10       0.40      0.22      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.59     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 19900, Loss: 0.33854568004608154, F1: 0.5856586985612581, Accuracy: 0.5239832083132613, Time Elapsed: 14360.482776165009 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.84      0.68       912\n",
      "           1       0.58      0.93      0.72       885\n",
      "           2       0.54      0.69      0.60       877\n",
      "           3       0.55      0.73      0.63       897\n",
      "           4       0.58      0.39      0.46       892\n",
      "           5       0.54      0.29      0.38       862\n",
      "           6       0.60      0.67      0.64       903\n",
      "           7       0.59      0.67      0.63       889\n",
      "           8       0.45      0.71      0.55       892\n",
      "           9       0.67      0.01      0.02       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.57      0.52     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 20000, Loss: 0.25777626037597656, F1: 0.5151242269550595, Accuracy: 0.49659348978046935, Time Elapsed: 14376.01718711853 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.86      0.68       912\n",
      "           1       0.61      0.84      0.70       885\n",
      "           2       0.57      0.56      0.56       877\n",
      "           3       0.58      0.69      0.63       897\n",
      "           4       0.54      0.41      0.46       892\n",
      "           5       0.56      0.15      0.23       862\n",
      "           6       0.61      0.53      0.57       903\n",
      "           7       0.60      0.22      0.32       889\n",
      "           8       0.60      0.00      0.01       892\n",
      "           9       0.48      0.64      0.55       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.49      0.47     14531\n",
      "weighted avg       0.50      0.48      0.45     14531\n",
      "\n",
      "Epoch 4, Step 20100, Loss: 0.9372344017028809, F1: 0.46670013860666776, Accuracy: 0.4819351730782465, Time Elapsed: 14390.754732131958 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.82      0.68       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.50      0.81      0.62       897\n",
      "           4       0.45      0.89      0.60       892\n",
      "           5       0.55      0.09      0.15       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.61      0.34      0.44       889\n",
      "           8       0.49      0.66      0.56       892\n",
      "           9       0.52      0.15      0.23       876\n",
      "          10       0.38      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.53      0.58      0.51     14531\n",
      "weighted avg       0.48      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 20200, Loss: 0.8020259737968445, F1: 0.5121603879302312, Accuracy: 0.4923267497075218, Time Elapsed: 14405.614664077759 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.47      0.97      0.64       885\n",
      "           2       0.61      0.46      0.52       877\n",
      "           3       0.58      0.73      0.64       897\n",
      "           4       0.51      0.96      0.66       892\n",
      "           5       0.51      0.58      0.54       862\n",
      "           6       0.59      0.84      0.70       903\n",
      "           7       0.59      0.17      0.26       889\n",
      "           8       0.58      0.45      0.51       892\n",
      "           9       0.52      0.80      0.63       876\n",
      "          10       0.38      0.24      0.29      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.54      0.64      0.55     14531\n",
      "weighted avg       0.49      0.51      0.47     14531\n",
      "\n",
      "Epoch 4, Step 20300, Loss: 2.029724597930908, F1: 0.5542189429263401, Accuracy: 0.5058151538090978, Time Elapsed: 14421.355875015259 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.22      0.32       912\n",
      "           1       0.59      0.78      0.67       885\n",
      "           2       0.61      0.49      0.54       877\n",
      "           3       0.61      0.60      0.60       897\n",
      "           4       0.56      0.73      0.64       892\n",
      "           5       0.52      0.43      0.47       862\n",
      "           6       0.62      0.65      0.63       903\n",
      "           7       0.69      0.04      0.08       889\n",
      "           8       0.43      0.86      0.57       892\n",
      "           9       0.60      0.28      0.38       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.50      0.48     14531\n",
      "weighted avg       0.51      0.48      0.46     14531\n",
      "\n",
      "Epoch 4, Step 20400, Loss: 0.9715690612792969, F1: 0.48410592701308325, Accuracy: 0.4817287179134265, Time Elapsed: 14437.235552072525 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.00       912\n",
      "           1       0.57      0.92      0.71       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.56      0.76      0.64       897\n",
      "           4       0.57      0.62      0.59       892\n",
      "           5       0.50      0.41      0.45       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.61      0.30      0.40       889\n",
      "           8       0.60      0.43      0.50       892\n",
      "           9       0.54      0.76      0.63       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.53      0.55      0.51     14531\n",
      "weighted avg       0.48      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 20500, Loss: 0.8201338052749634, F1: 0.5130900983930119, Accuracy: 0.49803867593420964, Time Elapsed: 15457.237643957138 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68       912\n",
      "           1       0.50      0.86      0.63       885\n",
      "           2       0.64      0.25      0.36       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.54      0.80      0.65       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.61      0.61      0.61       903\n",
      "           7       0.59      0.71      0.64       889\n",
      "           8       0.49      0.80      0.61       892\n",
      "           9       0.56      0.78      0.65       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.63      0.57     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 20600, Loss: 0.5931198596954346, F1: 0.5713498908915741, Accuracy: 0.5137292684605327, Time Elapsed: 15474.270488023758 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.27      0.38       912\n",
      "           1       0.60      0.38      0.47       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.57      0.72      0.63       897\n",
      "           4       0.53      0.90      0.66       892\n",
      "           5       0.56      0.59      0.57       862\n",
      "           6       0.62      0.49      0.55       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.59      0.68      0.63       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 20700, Loss: 1.8137736320495605, F1: 0.554460481991191, Accuracy: 0.5080173422338449, Time Elapsed: 16408.68313407898 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.00       912\n",
      "           1       0.57      0.63      0.60       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.48      0.86      0.61       897\n",
      "           4       0.57      0.80      0.66       892\n",
      "           5       0.57      0.33      0.42       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.82      0.69       889\n",
      "           8       0.50      0.00      0.00       892\n",
      "           9       0.75      0.00      0.01       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.54      0.48      0.42     14531\n",
      "weighted avg       0.49      0.48      0.43     14531\n",
      "\n",
      "Epoch 4, Step 20800, Loss: 1.2004094123840332, F1: 0.42491590593302037, Accuracy: 0.4784254352763058, Time Elapsed: 16427.434634923935 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.61      0.38      0.47       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.57      0.73      0.64       897\n",
      "           4       0.57      0.67      0.61       892\n",
      "           5       0.52      0.17      0.26       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.59      0.48      0.53       892\n",
      "           9       0.56      0.78      0.65       876\n",
      "          10       0.38      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 20900, Loss: 0.5462542772293091, F1: 0.5583947994838387, Accuracy: 0.5124217190833391, Time Elapsed: 17407.1891040802 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69       912\n",
      "           1       0.59      0.91      0.71       885\n",
      "           2       0.54      0.78      0.63       877\n",
      "           3       0.58      0.75      0.65       897\n",
      "           4       0.57      0.65      0.61       892\n",
      "           5       0.54      0.22      0.31       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.61      0.35      0.44       892\n",
      "           9       0.58      0.75      0.66       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.58     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 21000, Loss: 0.47581619024276733, F1: 0.5834192880419137, Accuracy: 0.527699401280022, Time Elapsed: 17427.137540102005 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.19      0.29       912\n",
      "           1       0.60      0.70      0.65       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.63      0.35      0.45       897\n",
      "           4       0.56      0.79      0.66       892\n",
      "           5       0.55      0.22      0.32       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.58      0.74      0.65       889\n",
      "           8       0.61      0.64      0.63       892\n",
      "           9       0.57      0.77      0.66       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 21100, Loss: 0.9067689776420593, F1: 0.5448693140490776, Accuracy: 0.5112518064826922, Time Elapsed: 17444.692217111588 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68       912\n",
      "           1       0.60      0.89      0.71       885\n",
      "           2       0.60      0.54      0.57       877\n",
      "           3       0.60      0.64      0.62       897\n",
      "           4       0.56      0.86      0.68       892\n",
      "           5       0.54      0.58      0.56       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.59      0.71      0.65       889\n",
      "           8       0.61      0.55      0.58       892\n",
      "           9       0.58      0.77      0.66       876\n",
      "          10       0.40      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.67      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 4, Step 21200, Loss: 0.7573502063751221, F1: 0.6093548940538315, Accuracy: 0.537815704356204, Time Elapsed: 18309.86208796501 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.18      0.28       912\n",
      "           1       0.55      0.95      0.70       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.53      0.85      0.65       897\n",
      "           4       0.58      0.42      0.48       892\n",
      "           5       0.52      0.61      0.57       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.60      0.79      0.68       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.60      0.65      0.62       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.56      0.51     14531\n",
      "weighted avg       0.47      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 21300, Loss: 0.7068644762039185, F1: 0.5125767014657276, Accuracy: 0.5029247815016172, Time Elapsed: 18327.10528612137 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.01      0.02       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.59      0.48      0.53       877\n",
      "           3       0.59      0.72      0.65       897\n",
      "           4       0.59      0.51      0.55       892\n",
      "           5       0.54      0.63      0.58       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.59      0.73      0.65       892\n",
      "           9       0.57      0.77      0.66       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 21400, Loss: 0.7248704433441162, F1: 0.5530446988981235, Accuracy: 0.5201293785699539, Time Elapsed: 18344.33913207054 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.02      0.03       912\n",
      "           1       0.61      0.81      0.69       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.60      0.71      0.65       897\n",
      "           4       0.54      0.93      0.68       892\n",
      "           5       0.57      0.53      0.55       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.58      0.74      0.65       889\n",
      "           8       0.57      0.72      0.64       892\n",
      "           9       0.57      0.74      0.65       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 21500, Loss: 1.568312406539917, F1: 0.5495233471923642, Accuracy: 0.5156561833321863, Time Elapsed: 18360.517517089844 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       912\n",
      "           1       0.61      0.66      0.64       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.60      0.58      0.59       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.57      0.45      0.50       862\n",
      "           6       0.62      0.25      0.36       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.57      0.77      0.65       892\n",
      "           9       0.60      0.46      0.52       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 21600, Loss: 1.522355556488037, F1: 0.568661136118655, Accuracy: 0.5168949143211066, Time Elapsed: 18376.28247499466 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.61      0.76      0.68       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.54      0.84      0.65       897\n",
      "           4       0.57      0.70      0.63       892\n",
      "           5       0.56      0.44      0.49       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.60      0.57      0.58       892\n",
      "           9       0.57      0.68      0.62       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 21700, Loss: 0.5512927174568176, F1: 0.6044847210585543, Accuracy: 0.5330672355653431, Time Elapsed: 18392.124935865402 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       912\n",
      "           1       0.60      0.71      0.65       885\n",
      "           2       0.60      0.47      0.52       877\n",
      "           3       0.57      0.74      0.65       897\n",
      "           4       0.59      0.63      0.61       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.60      0.70      0.64       889\n",
      "           8       0.51      0.84      0.63       892\n",
      "           9       0.51      0.70      0.59       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 21800, Loss: 0.5407347083091736, F1: 0.5951779619166019, Accuracy: 0.5254283944670016, Time Elapsed: 18407.7920691967 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.60      0.86      0.70       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.55      0.82      0.66       897\n",
      "           4       0.57      0.50      0.53       892\n",
      "           5       0.56      0.39      0.46       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.57      0.59      0.58       892\n",
      "           9       0.60      0.59      0.59       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 21900, Loss: 0.50521320104599, F1: 0.5892905178387647, Accuracy: 0.5268735806207419, Time Elapsed: 18423.452035188675 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.40      0.48       912\n",
      "           1       0.65      0.38      0.48       885\n",
      "           2       0.59      0.41      0.49       877\n",
      "           3       0.60      0.68      0.63       897\n",
      "           4       0.56      0.73      0.64       892\n",
      "           5       0.55      0.60      0.57       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.64      0.25      0.36       889\n",
      "           8       0.57      0.70      0.63       892\n",
      "           9       0.58      0.54      0.56       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.54      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 22000, Loss: 1.3680124282836914, F1: 0.5401071645256788, Accuracy: 0.5051269699263643, Time Elapsed: 18438.5914311409 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.02      0.03       912\n",
      "           1       0.62      0.73      0.67       885\n",
      "           2       0.59      0.47      0.53       877\n",
      "           3       0.61      0.41      0.49       897\n",
      "           4       0.60      0.33      0.42       892\n",
      "           5       0.55      0.48      0.51       862\n",
      "           6       0.64      0.38      0.48       903\n",
      "           7       0.61      0.67      0.63       889\n",
      "           8       0.62      0.54      0.58       892\n",
      "           9       0.58      0.20      0.30       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.58      0.44      0.46     14531\n",
      "weighted avg       0.52      0.48      0.46     14531\n",
      "\n",
      "Epoch 4, Step 22100, Loss: 1.48912513256073, F1: 0.4643752184604626, Accuracy: 0.48097171564241964, Time Elapsed: 18453.10067296028 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       912\n",
      "           1       0.59      0.90      0.72       885\n",
      "           2       0.59      0.46      0.51       877\n",
      "           3       0.55      0.09      0.16       897\n",
      "           4       0.59      0.45      0.51       892\n",
      "           5       0.50      0.39      0.44       862\n",
      "           6       0.65      0.10      0.17       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.60      0.63      0.61       892\n",
      "           9       0.54      0.73      0.62       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 22200, Loss: 0.5067235231399536, F1: 0.49552023877216766, Accuracy: 0.49108801871860164, Time Elapsed: 18467.56684422493 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61       912\n",
      "           1       0.59      0.82      0.69       885\n",
      "           2       0.51      0.77      0.61       877\n",
      "           3       0.59      0.58      0.59       897\n",
      "           4       0.53      0.13      0.21       892\n",
      "           5       0.52      0.19      0.28       862\n",
      "           6       0.61      0.51      0.56       903\n",
      "           7       0.61      0.63      0.62       889\n",
      "           8       0.58      0.71      0.64       892\n",
      "           9       0.56      0.67      0.61       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.53     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 22300, Loss: 1.0036605596542358, F1: 0.5283110505078349, Accuracy: 0.501686050512697, Time Elapsed: 18483.02020716667 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.90      0.72       912\n",
      "           1       0.60      0.74      0.66       885\n",
      "           2       0.60      0.39      0.48       877\n",
      "           3       0.56      0.81      0.66       897\n",
      "           4       0.55      0.87      0.68       892\n",
      "           5       0.56      0.61      0.58       862\n",
      "           6       0.62      0.69      0.65       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.58      0.70      0.64       892\n",
      "           9       0.58      0.78      0.66       876\n",
      "          10       0.40      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.68      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 4, Step 22400, Loss: 1.635932445526123, F1: 0.6085029325364747, Accuracy: 0.5383662514623907, Time Elapsed: 18498.603333234787 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.59      0.81      0.69       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.58      0.79      0.67       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.57      0.50      0.53       862\n",
      "           6       0.61      0.62      0.61       903\n",
      "           7       0.56      0.89      0.69       889\n",
      "           8       0.60      0.54      0.57       892\n",
      "           9       0.59      0.70      0.64       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 22500, Loss: 0.12132157385349274, F1: 0.600513608008136, Accuracy: 0.5332736907301631, Time Elapsed: 18513.33714723587 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.85      0.70       912\n",
      "           1       0.62      0.52      0.56       885\n",
      "           2       0.60      0.25      0.35       877\n",
      "           3       0.57      0.82      0.68       897\n",
      "           4       0.57      0.69      0.63       892\n",
      "           5       0.57      0.43      0.49       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.58      0.86      0.69       889\n",
      "           8       0.60      0.41      0.49       892\n",
      "           9       0.58      0.65      0.61       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 22600, Loss: 0.4912663698196411, F1: 0.5668753236793908, Accuracy: 0.5196476498520405, Time Elapsed: 18528.734108924866 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       912\n",
      "           1       0.59      0.70      0.64       885\n",
      "           2       0.62      0.32      0.42       877\n",
      "           3       0.58      0.46      0.51       897\n",
      "           4       0.52      0.92      0.67       892\n",
      "           5       0.42      0.82      0.55       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.60      0.72      0.66       889\n",
      "           8       0.60      0.45      0.52       892\n",
      "           9       0.59      0.59      0.59       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 22700, Loss: 0.697559118270874, F1: 0.5681498030783023, Accuracy: 0.5114582616475122, Time Elapsed: 18544.31006217003 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.61      0.68      0.64       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.55      0.18      0.27       897\n",
      "           4       0.58      0.61      0.60       892\n",
      "           5       0.43      0.84      0.57       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.82      0.69       889\n",
      "           8       0.59      0.56      0.58       892\n",
      "           9       0.53      0.85      0.66       876\n",
      "          10       0.39      0.24      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.58     14531\n",
      "weighted avg       0.50      0.52      0.48     14531\n",
      "\n",
      "Epoch 4, Step 22800, Loss: 0.4027608036994934, F1: 0.5751202230920462, Accuracy: 0.5173078246507467, Time Elapsed: 18559.81509923935 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70       912\n",
      "           1       0.67      0.04      0.07       885\n",
      "           2       0.55      0.77      0.64       877\n",
      "           3       0.57      0.42      0.48       897\n",
      "           4       0.58      0.54      0.56       892\n",
      "           5       0.54      0.58      0.56       862\n",
      "           6       0.62      0.55      0.59       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.59      0.58      0.58       892\n",
      "           9       0.57      0.72      0.64       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.53     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 22900, Loss: 0.18418945372104645, F1: 0.534591889923721, Accuracy: 0.5056775170325511, Time Elapsed: 18574.792246103287 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69       912\n",
      "           1       0.58      0.20      0.29       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.54      0.68      0.60       897\n",
      "           4       0.57      0.65      0.61       892\n",
      "           5       0.52      0.60      0.55       862\n",
      "           6       0.60      0.78      0.67       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.62      0.53      0.57       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 23000, Loss: 1.0027108192443848, F1: 0.5600804974321129, Accuracy: 0.5117335352006056, Time Elapsed: 18589.45833492279 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.57      0.00      0.01       885\n",
      "           2       0.60      0.25      0.36       877\n",
      "           3       0.57      0.78      0.66       897\n",
      "           4       0.59      0.54      0.56       892\n",
      "           5       0.53      0.10      0.17       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.56      0.57      0.57       892\n",
      "           9       0.58      0.61      0.59       876\n",
      "          10       0.40      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.51      0.49     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 23100, Loss: 0.3523164987564087, F1: 0.48732953217490865, Accuracy: 0.49893331498176313, Time Elapsed: 18604.925242185593 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.97      0.70       912\n",
      "           1       0.61      0.43      0.50       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.56      0.82      0.67       897\n",
      "           4       0.59      0.57      0.58       892\n",
      "           5       0.54      0.52      0.53       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.53      0.78      0.63       892\n",
      "           9       0.55      0.83      0.66       876\n",
      "          10       0.40      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.59     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 23200, Loss: 1.7196574211120605, F1: 0.5933238808195399, Accuracy: 0.5277682196682953, Time Elapsed: 18620.33877801895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.71       912\n",
      "           1       0.57      0.90      0.70       885\n",
      "           2       0.61      0.50      0.55       877\n",
      "           3       0.58      0.78      0.66       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.54      0.27      0.37       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.61      0.74      0.66       889\n",
      "           8       0.53      0.83      0.65       892\n",
      "           9       0.57      0.85      0.68       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 4, Step 23300, Loss: 0.3670804798603058, F1: 0.5976140019178809, Accuracy: 0.5353382423783635, Time Elapsed: 18635.985692977905 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.59      0.13      0.22       885\n",
      "           2       0.60      0.45      0.51       877\n",
      "           3       0.58      0.61      0.60       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.53      0.37      0.44       862\n",
      "           6       0.62      0.41      0.49       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.59      0.70      0.64       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.48      0.48     14531\n",
      "weighted avg       0.48      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 23400, Loss: 0.8696884512901306, F1: 0.47682738960466936, Accuracy: 0.48922992223522127, Time Elapsed: 18651.918332099915 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.60      0.70      0.64       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.56      0.74      0.64       897\n",
      "           4       0.56      0.15      0.24       892\n",
      "           5       0.46      0.75      0.57       862\n",
      "           6       0.59      0.82      0.69       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.58      0.30      0.39       892\n",
      "           9       0.57      0.38      0.45       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.59      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 4, Step 23500, Loss: 1.1040689945220947, F1: 0.5429246136654146, Accuracy: 0.5071915215745647, Time Elapsed: 18668.11673593521 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.71       912\n",
      "           1       0.58      0.93      0.71       885\n",
      "           2       0.62      0.26      0.37       877\n",
      "           3       0.60      0.46      0.53       897\n",
      "           4       0.60      0.48      0.53       892\n",
      "           5       0.46      0.10      0.17       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.58      0.26      0.36       889\n",
      "           8       0.60      0.28      0.38       892\n",
      "           9       0.57      0.38      0.46       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.49      0.48     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 23600, Loss: 4.810237884521484, F1: 0.48269417906329976, Accuracy: 0.4870965521987475, Time Elapsed: 18683.69838809967 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.58       912\n",
      "           1       0.60      0.76      0.67       885\n",
      "           2       0.60      0.59      0.59       877\n",
      "           3       0.58      0.68      0.62       897\n",
      "           4       0.52      0.88      0.65       892\n",
      "           5       0.57      0.04      0.08       862\n",
      "           6       0.60      0.69      0.64       903\n",
      "           7       0.58      0.42      0.49       889\n",
      "           8       0.60      0.33      0.43       892\n",
      "           9       0.49      0.87      0.62       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.52     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 23700, Loss: 0.5236174464225769, F1: 0.5229173216313184, Accuracy: 0.4992774069231299, Time Elapsed: 18699.175981998444 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       912\n",
      "           1       0.60      0.79      0.68       885\n",
      "           2       0.61      0.34      0.44       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.53      0.80      0.64       892\n",
      "           5       0.52      0.55      0.53       862\n",
      "           6       0.59      0.87      0.71       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.59      0.49      0.53       892\n",
      "           9       0.58      0.69      0.63       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 23800, Loss: 0.63050377368927, F1: 0.5725154844845061, Accuracy: 0.5156561833321863, Time Elapsed: 18714.62082004547 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.02      0.04       912\n",
      "           1       0.60      0.61      0.61       885\n",
      "           2       0.61      0.34      0.43       877\n",
      "           3       0.61      0.52      0.56       897\n",
      "           4       0.54      0.54      0.54       892\n",
      "           5       0.54      0.24      0.34       862\n",
      "           6       0.61      0.58      0.59       903\n",
      "           7       0.59      0.51      0.55       889\n",
      "           8       0.59      0.22      0.32       892\n",
      "           9       0.62      0.45      0.52       876\n",
      "          10       0.39      0.58      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.58      0.42      0.45     14531\n",
      "weighted avg       0.52      0.47      0.46     14531\n",
      "\n",
      "Epoch 4, Step 23900, Loss: 1.3001670837402344, F1: 0.45176625031995477, Accuracy: 0.4738146032619916, Time Elapsed: 18730.67163324356 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.02      0.05       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.60      0.40      0.48       877\n",
      "           3       0.56      0.75      0.64       897\n",
      "           4       0.50      0.95      0.65       892\n",
      "           5       0.53      0.70      0.60       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.59      0.47      0.52       889\n",
      "           8       0.59      0.04      0.07       892\n",
      "           9       0.60      0.68      0.64       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.49     14531\n",
      "weighted avg       0.51      0.50      0.46     14531\n",
      "\n",
      "Epoch 4, Step 24000, Loss: 0.24339596927165985, F1: 0.4921430241785671, Accuracy: 0.4958364875094625, Time Elapsed: 18746.4404668808 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.02      0.03       912\n",
      "           1       0.50      0.98      0.66       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.55      0.75      0.63       897\n",
      "           4       0.53      0.79      0.64       892\n",
      "           5       0.54      0.56      0.55       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.67      0.04      0.07       889\n",
      "           8       0.56      0.16      0.25       892\n",
      "           9       0.57      0.73      0.64       876\n",
      "          10       0.38      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.52      0.46     14531\n",
      "weighted avg       0.50      0.48      0.44     14531\n",
      "\n",
      "Epoch 4, Step 24100, Loss: 1.1240451335906982, F1: 0.4632219825629988, Accuracy: 0.4814534443603331, Time Elapsed: 18761.610049962997 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58       912\n",
      "           1       0.59      0.90      0.71       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.52      0.82      0.63       897\n",
      "           4       0.56      0.85      0.67       892\n",
      "           5       0.56      0.55      0.55       862\n",
      "           6       0.62      0.67      0.65       903\n",
      "           7       0.58      0.87      0.69       889\n",
      "           8       0.56      0.80      0.66       892\n",
      "           9       0.62      0.47      0.53       876\n",
      "          10       0.40      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 24200, Loss: 1.7060253620147705, F1: 0.6021210410503651, Accuracy: 0.5341683297777166, Time Elapsed: 18777.713088989258 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       912\n",
      "           1       0.61      0.63      0.62       885\n",
      "           2       0.57      0.73      0.64       877\n",
      "           3       0.59      0.62      0.61       897\n",
      "           4       0.55      0.77      0.64       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.60      0.49      0.54       889\n",
      "           8       0.55      0.75      0.64       892\n",
      "           9       0.63      0.50      0.56       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 24300, Loss: 0.3754208981990814, F1: 0.5904229077684829, Accuracy: 0.5256348496318216, Time Elapsed: 18793.432202100754 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69       912\n",
      "           1       0.63      0.13      0.22       885\n",
      "           2       0.60      0.48      0.54       877\n",
      "           3       0.61      0.57      0.59       897\n",
      "           4       0.58      0.56      0.57       892\n",
      "           5       0.54      0.70      0.61       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.62      0.10      0.18       889\n",
      "           8       0.58      0.71      0.64       892\n",
      "           9       0.76      0.04      0.08       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.59      0.49      0.48     14531\n",
      "weighted avg       0.53      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 24400, Loss: 2.1868860721588135, F1: 0.4762914564457649, Accuracy: 0.4934278439198954, Time Elapsed: 18809.162257909775 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       912\n",
      "           1       0.59      0.85      0.70       885\n",
      "           2       0.61      0.59      0.60       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.54      0.88      0.67       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.58      0.69      0.63       889\n",
      "           8       0.59      0.62      0.60       892\n",
      "           9       0.65      0.05      0.09       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 24500, Loss: 0.4990701377391815, F1: 0.5587022974728844, Accuracy: 0.5200605601816806, Time Elapsed: 18823.870512247086 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.56      0.75      0.64       897\n",
      "           4       0.57      0.80      0.66       892\n",
      "           5       0.53      0.77      0.63       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.59      0.55      0.57       876\n",
      "          10       0.40      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 4, Step 24600, Loss: 4.047590255737305, F1: 0.6102877164919728, Accuracy: 0.5369898836969238, Time Elapsed: 18838.83263516426 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.62      0.44      0.51       877\n",
      "           3       0.53      0.87      0.66       897\n",
      "           4       0.52      0.93      0.67       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.63      0.44      0.51       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.47      0.84      0.60       892\n",
      "           9       0.61      0.25      0.36       876\n",
      "          10       0.40      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 24700, Loss: 1.4211633205413818, F1: 0.5659531722578905, Accuracy: 0.5162755488266465, Time Elapsed: 18853.923909187317 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.70       912\n",
      "           1       0.57      0.90      0.70       885\n",
      "           2       0.60      0.62      0.61       877\n",
      "           3       0.57      0.68      0.62       897\n",
      "           4       0.56      0.77      0.65       892\n",
      "           5       0.57      0.49      0.53       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.58      0.75      0.65       889\n",
      "           8       0.61      0.38      0.46       892\n",
      "           9       0.63      0.39      0.48       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 4, Step 24800, Loss: 0.8917612433433533, F1: 0.5861507635623693, Accuracy: 0.5284564035510289, Time Elapsed: 18869.054918050766 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.55      0.96      0.70       885\n",
      "           2       0.63      0.39      0.48       877\n",
      "           3       0.58      0.68      0.63       897\n",
      "           4       0.51      0.88      0.65       892\n",
      "           5       0.52      0.21      0.30       862\n",
      "           6       0.61      0.65      0.63       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.51      0.79      0.62       892\n",
      "           9       0.59      0.67      0.63       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.57     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 24900, Loss: 0.257692813873291, F1: 0.5730307654001217, Accuracy: 0.520542288899594, Time Elapsed: 18883.404430150986 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.01      0.02       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.62      0.41      0.49       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.51      0.11      0.18       862\n",
      "           6       0.63      0.49      0.55       903\n",
      "           7       0.59      0.71      0.64       889\n",
      "           8       0.60      0.36      0.45       892\n",
      "           9       0.63      0.36      0.46       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.49      0.48     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 25000, Loss: 1.1555694341659546, F1: 0.4765411066021485, Accuracy: 0.4927396600371619, Time Elapsed: 18899.306119918823 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.62      0.41      0.50       877\n",
      "           3       0.60      0.39      0.47       897\n",
      "           4       0.56      0.87      0.68       892\n",
      "           5       0.53      0.32      0.40       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.61      0.48      0.54       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.55      0.85      0.67       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 25100, Loss: 0.6099223494529724, F1: 0.5658893749303303, Accuracy: 0.5171701878742, Time Elapsed: 18915.082098960876 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.57      0.92      0.70       885\n",
      "           2       0.62      0.40      0.48       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.56      0.59      0.57       892\n",
      "           5       0.54      0.61      0.57       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.75      0.00      0.01       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.53      0.84      0.65       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.54      0.49     14531\n",
      "weighted avg       0.48      0.50      0.46     14531\n",
      "\n",
      "Epoch 4, Step 25200, Loss: 0.829976499080658, F1: 0.48707307662862287, Accuracy: 0.4987268598169431, Time Elapsed: 18930.673279047012 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.57      0.47      0.52       885\n",
      "           2       0.62      0.54      0.58       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.56      0.74      0.64       892\n",
      "           5       0.50      0.11      0.18       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.59      0.10      0.17       889\n",
      "           8       0.50      0.00      0.00       892\n",
      "           9       0.60      0.45      0.52       876\n",
      "          10       0.40      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.47      0.46     14531\n",
      "weighted avg       0.51      0.49      0.46     14531\n",
      "\n",
      "Epoch 4, Step 25300, Loss: 0.4290468394756317, F1: 0.4606665338233535, Accuracy: 0.4921202945427018, Time Elapsed: 18946.282579898834 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       912\n",
      "           1       0.53      0.97      0.69       885\n",
      "           2       0.63      0.47      0.54       877\n",
      "           3       0.62      0.45      0.52       897\n",
      "           4       0.48      0.93      0.64       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.62      0.63      0.63       903\n",
      "           7       0.63      0.14      0.23       889\n",
      "           8       0.60      0.29      0.39       892\n",
      "           9       0.59      0.66      0.62       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.56      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 25400, Loss: 1.0818006992340088, F1: 0.531463622445671, Accuracy: 0.5032000550547107, Time Elapsed: 18961.912843942642 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.84      0.69       912\n",
      "           1       0.59      0.94      0.72       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.60      0.24      0.34       897\n",
      "           4       0.55      0.71      0.62       892\n",
      "           5       0.52      0.70      0.60       862\n",
      "           6       0.59      0.89      0.71       903\n",
      "           7       0.58      0.68      0.63       889\n",
      "           8       0.57      0.09      0.15       892\n",
      "           9       0.61      0.55      0.58       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.55     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 25500, Loss: 0.7420980334281921, F1: 0.550147014281273, Accuracy: 0.5154497281673663, Time Elapsed: 18977.610554218292 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69       912\n",
      "           1       0.60      0.62      0.61       885\n",
      "           2       0.52      0.76      0.62       877\n",
      "           3       0.63      0.40      0.49       897\n",
      "           4       0.57      0.47      0.52       892\n",
      "           5       0.55      0.43      0.48       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.59      0.66      0.62       889\n",
      "           8       0.60      0.26      0.37       892\n",
      "           9       0.57      0.78      0.66       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 25600, Loss: 1.9091508388519287, F1: 0.5566742739976749, Accuracy: 0.5099442571054986, Time Elapsed: 18993.33818912506 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.90      0.70       912\n",
      "           1       0.58      0.90      0.70       885\n",
      "           2       0.61      0.45      0.52       877\n",
      "           3       0.62      0.40      0.49       897\n",
      "           4       0.56      0.47      0.51       892\n",
      "           5       0.55      0.46      0.50       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.59      0.68      0.63       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 25700, Loss: 0.2177879959344864, F1: 0.579796810298228, Accuracy: 0.5228821141008878, Time Elapsed: 19279.428166151047 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55       912\n",
      "           1       0.60      0.92      0.72       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.60      0.53      0.56       897\n",
      "           4       0.58      0.30      0.39       892\n",
      "           5       0.50      0.72      0.59       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.63      0.21      0.31       889\n",
      "           8       0.61      0.37      0.46       892\n",
      "           9       0.54      0.81      0.65       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 25800, Loss: 1.45551335811615, F1: 0.5399506299858163, Accuracy: 0.5058839721973711, Time Elapsed: 19415.234050035477 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.15      0.24       912\n",
      "           1       0.55      0.96      0.70       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.61      0.59      0.60       897\n",
      "           4       0.58      0.52      0.55       892\n",
      "           5       0.56      0.55      0.55       862\n",
      "           6       0.62      0.22      0.33       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.60      0.29      0.39       892\n",
      "           9       0.57      0.80      0.67       876\n",
      "          10       0.38      0.45      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.51     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 4, Step 25900, Loss: 0.5574813485145569, F1: 0.507639043923246, Accuracy: 0.49067510838896156, Time Elapsed: 19436.452535152435 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.01      0.02       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.61      0.58      0.60       897\n",
      "           4       0.58      0.53      0.56       892\n",
      "           5       0.55      0.39      0.46       862\n",
      "           6       0.63      0.58      0.60       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.59      0.56      0.58       892\n",
      "           9       0.59      0.50      0.54       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 26000, Loss: 0.5461308360099792, F1: 0.5217251170304724, Accuracy: 0.5014107769596036, Time Elapsed: 20431.441899061203 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.26      0.36       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.61      0.48      0.54       897\n",
      "           4       0.57      0.15      0.24       892\n",
      "           5       0.48      0.71      0.57       862\n",
      "           6       0.63      0.35      0.45       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.54      0.75      0.63       892\n",
      "           9       0.61      0.39      0.48       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.52      0.51     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 4, Step 26100, Loss: 1.4562568664550781, F1: 0.5098392425962469, Accuracy: 0.4908815635537816, Time Elapsed: 20454.74938225746 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.02      0.04       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.44      0.87      0.59       877\n",
      "           3       0.60      0.72      0.65       897\n",
      "           4       0.58      0.40      0.47       892\n",
      "           5       0.50      0.49      0.50       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.56      0.87      0.68       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.58      0.49      0.53       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.56      0.52     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 26200, Loss: 1.6013877391815186, F1: 0.5186719596743822, Accuracy: 0.4943224829674489, Time Elapsed: 20472.730727910995 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.27      0.38       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.51      0.79      0.62       877\n",
      "           3       0.60      0.48      0.53       897\n",
      "           4       0.56      0.84      0.67       892\n",
      "           5       0.56      0.18      0.27       862\n",
      "           6       0.59      0.79      0.67       903\n",
      "           7       0.59      0.76      0.66       889\n",
      "           8       0.58      0.63      0.61       892\n",
      "           9       0.57      0.76      0.65       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 26300, Loss: 0.4434420168399811, F1: 0.5579299585087243, Accuracy: 0.515380909779093, Time Elapsed: 20772.304824113846 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64       912\n",
      "           1       0.57      0.20      0.30       885\n",
      "           2       0.57      0.43      0.49       877\n",
      "           3       0.59      0.56      0.58       897\n",
      "           4       0.57      0.57      0.57       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.54      0.85      0.66       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.61      0.60      0.60       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 4, Step 26400, Loss: 0.5466803908348083, F1: 0.5435664830113469, Accuracy: 0.5029247815016172, Time Elapsed: 20788.91464805603 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       912\n",
      "           1       0.50      0.08      0.14       885\n",
      "           2       0.59      0.51      0.54       877\n",
      "           3       0.57      0.77      0.65       897\n",
      "           4       0.57      0.58      0.57       892\n",
      "           5       0.56      0.37      0.44       862\n",
      "           6       0.63      0.47      0.54       903\n",
      "           7       0.59      0.65      0.62       889\n",
      "           8       0.58      0.71      0.64       892\n",
      "           9       0.59      0.64      0.62       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 4, Step 26500, Loss: 0.7898910641670227, F1: 0.5291641552720594, Accuracy: 0.5029935998898906, Time Elapsed: 20804.228226184845 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.71       912\n",
      "           1       0.58      0.93      0.71       885\n",
      "           2       0.58      0.62      0.60       877\n",
      "           3       0.60      0.68      0.64       897\n",
      "           4       0.52      0.89      0.66       892\n",
      "           5       0.55      0.53      0.54       862\n",
      "           6       0.62      0.63      0.63       903\n",
      "           7       0.62      0.20      0.30       889\n",
      "           8       0.54      0.81      0.65       892\n",
      "           9       0.61      0.40      0.49       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.57     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 26600, Loss: 0.45401179790496826, F1: 0.5693137893699836, Accuracy: 0.5202670153465005, Time Elapsed: 20819.458306074142 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.57      0.55      0.56       885\n",
      "           2       0.63      0.26      0.37       877\n",
      "           3       0.60      0.52      0.56       897\n",
      "           4       0.54      0.49      0.52       892\n",
      "           5       0.52      0.51      0.51       862\n",
      "           6       0.62      0.32      0.42       903\n",
      "           7       0.61      0.34      0.44       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.61      0.32      0.42       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.47      0.50     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 4, Step 26700, Loss: 0.9420235753059387, F1: 0.5024144020810366, Accuracy: 0.48613309476292066, Time Elapsed: 20834.43246102333 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.54      0.58      0.56       885\n",
      "           2       0.63      0.27      0.38       877\n",
      "           3       0.56      0.63      0.60       897\n",
      "           4       0.50      0.87      0.63       892\n",
      "           5       0.50      0.77      0.61       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.66      0.06      0.11       889\n",
      "           8       0.58      0.30      0.40       892\n",
      "           9       0.63      0.36      0.46       876\n",
      "          10       0.40      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.53      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 4, Step 26800, Loss: 0.39137721061706543, F1: 0.5014832058167795, Accuracy: 0.4942536645791756, Time Elapsed: 20849.63114285469 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.67       912\n",
      "           1       0.59      0.88      0.71       885\n",
      "           2       0.58      0.65      0.61       877\n",
      "           3       0.57      0.79      0.66       897\n",
      "           4       0.54      0.85      0.66       892\n",
      "           5       0.51      0.76      0.61       862\n",
      "           6       0.62      0.60      0.61       903\n",
      "           7       0.56      0.02      0.05       889\n",
      "           8       0.60      0.67      0.63       892\n",
      "           9       0.61      0.52      0.56       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 26900, Loss: 1.189231276512146, F1: 0.5565174209007289, Accuracy: 0.5182712820865736, Time Elapsed: 20866.74434709549 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.84      0.70       912\n",
      "           1       0.60      0.18      0.28       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.62      0.44      0.51       897\n",
      "           4       0.56      0.76      0.65       892\n",
      "           5       0.50      0.65      0.57       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.61      0.22      0.32       889\n",
      "           8       0.54      0.78      0.64       892\n",
      "           9       0.61      0.12      0.20       876\n",
      "          10       0.39      0.52      0.44      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.51      0.45      0.44     14531\n",
      "weighted avg       0.47      0.47      0.44     14531\n",
      "\n",
      "Epoch 4, Step 27000, Loss: 0.776713490486145, F1: 0.4388623367004261, Accuracy: 0.47408987681508497, Time Elapsed: 20881.937746047974 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       912\n",
      "           1       0.59      0.80      0.68       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.60      0.61      0.61       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.52      0.31      0.38       862\n",
      "           6       0.61      0.63      0.62       903\n",
      "           7       0.60      0.58      0.59       889\n",
      "           8       0.55      0.68      0.61       892\n",
      "           9       0.55      0.83      0.66       876\n",
      "          10       0.38      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 27100, Loss: 0.362975150346756, F1: 0.5784973268727766, Accuracy: 0.5166196407680133, Time Elapsed: 20896.725255966187 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.55      0.73      0.63       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.58      0.10      0.18       892\n",
      "           5       0.52      0.34      0.41       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.56      0.88      0.68       889\n",
      "           8       0.60      0.58      0.59       892\n",
      "           9       0.56      0.83      0.67       876\n",
      "          10       0.38      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 27200, Loss: 1.2582988739013672, F1: 0.5602657508244918, Accuracy: 0.5171701878742, Time Elapsed: 20911.27138400078 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.60      0.51      0.55       885\n",
      "           2       0.57      0.64      0.60       877\n",
      "           3       0.59      0.69      0.64       897\n",
      "           4       0.58      0.08      0.14       892\n",
      "           5       0.56      0.28      0.37       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.56      0.78      0.65       892\n",
      "           9       0.54      0.78      0.64       876\n",
      "          10       0.38      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 27300, Loss: 0.7103649973869324, F1: 0.5457773193593078, Accuracy: 0.5109765329295988, Time Elapsed: 20926.626409053802 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.60      0.77      0.67       885\n",
      "           2       0.60      0.57      0.59       877\n",
      "           3       0.58      0.80      0.67       897\n",
      "           4       0.57      0.63      0.60       892\n",
      "           5       0.48      0.83      0.61       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.54      0.68      0.60       892\n",
      "           9       0.47      0.79      0.59       876\n",
      "          10       0.38      0.17      0.23      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.70      0.60     14531\n",
      "weighted avg       0.49      0.53      0.48     14531\n",
      "\n",
      "Epoch 4, Step 27400, Loss: 0.40333446860313416, F1: 0.6010311719713828, Accuracy: 0.525497212855275, Time Elapsed: 20941.1796541214 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64       912\n",
      "           1       0.61      0.19      0.29       885\n",
      "           2       0.60      0.59      0.60       877\n",
      "           3       0.55      0.88      0.67       897\n",
      "           4       0.57      0.72      0.64       892\n",
      "           5       0.49      0.78      0.60       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.59      0.82      0.69       889\n",
      "           8       0.49      0.79      0.61       892\n",
      "           9       0.58      0.44      0.50       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.62      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 27500, Loss: 1.2310166358947754, F1: 0.5637140933855262, Accuracy: 0.5134539949074393, Time Elapsed: 20956.43591117859 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       912\n",
      "           1       0.59      0.90      0.71       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.58      0.63      0.61       897\n",
      "           4       0.58      0.79      0.67       892\n",
      "           5       0.53      0.68      0.60       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.58      0.71      0.64       892\n",
      "           9       0.60      0.19      0.29       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 4, Step 27600, Loss: 0.6336642503738403, F1: 0.5753056381366402, Accuracy: 0.5229509324891611, Time Elapsed: 20970.892482042313 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.67       912\n",
      "           1       0.57      0.92      0.70       885\n",
      "           2       0.52      0.81      0.64       877\n",
      "           3       0.57      0.74      0.64       897\n",
      "           4       0.58      0.60      0.59       892\n",
      "           5       0.55      0.48      0.51       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.60      0.58      0.59       892\n",
      "           9       0.59      0.73      0.65       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 4, Step 27700, Loss: 1.7278536558151245, F1: 0.603011257553356, Accuracy: 0.5314155942467828, Time Elapsed: 20986.35353398323 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.69       912\n",
      "           1       0.51      0.97      0.67       885\n",
      "           2       0.60      0.64      0.62       877\n",
      "           3       0.57      0.40      0.47       897\n",
      "           4       0.56      0.10      0.17       892\n",
      "           5       0.58      0.47      0.52       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.58      0.80      0.67       889\n",
      "           8       0.64      0.23      0.34       892\n",
      "           9       0.59      0.70      0.64       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.53     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 27800, Loss: 0.574122428894043, F1: 0.5320675040643509, Accuracy: 0.5078797054572982, Time Elapsed: 21005.87474298477 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.62      0.01      0.02       897\n",
      "           4       0.53      0.84      0.65       892\n",
      "           5       0.55      0.32      0.41       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.57      0.66      0.61       892\n",
      "           9       0.60      0.73      0.66       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 4, Step 27900, Loss: 0.6053513884544373, F1: 0.5461721142545969, Accuracy: 0.5168949143211066, Time Elapsed: 21025.26442694664 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.69       912\n",
      "           1       0.61      0.71      0.65       885\n",
      "           2       0.59      0.50      0.54       877\n",
      "           3       0.56      0.74      0.63       897\n",
      "           4       0.57      0.50      0.53       892\n",
      "           5       0.56      0.30      0.39       862\n",
      "           6       0.63      0.32      0.42       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.59      0.50      0.54       892\n",
      "           9       0.53      0.82      0.64       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 28000, Loss: 0.8953458070755005, F1: 0.5531083399488445, Accuracy: 0.5071915215745647, Time Elapsed: 21044.13086795807 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.63      0.45      0.52       885\n",
      "           2       0.60      0.40      0.48       877\n",
      "           3       0.59      0.46      0.52       897\n",
      "           4       0.58      0.10      0.17       892\n",
      "           5       0.56      0.60      0.58       862\n",
      "           6       0.61      0.48      0.54       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.61      0.19      0.28       892\n",
      "           9       0.59      0.76      0.66       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.51      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 28100, Loss: 0.6099357604980469, F1: 0.5063414783883647, Accuracy: 0.49707521849838276, Time Elapsed: 21061.885281085968 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.71       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.57      0.64      0.61       877\n",
      "           3       0.55      0.80      0.65       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.56      0.35      0.43       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.60      0.80      0.69       889\n",
      "           8       0.60      0.45      0.51       892\n",
      "           9       0.58      0.78      0.67       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.46      0.55      0.49     14531\n",
      "weighted avg       0.44      0.50      0.46     14531\n",
      "\n",
      "Epoch 4, Step 28200, Loss: 0.2920841872692108, F1: 0.4882574771433657, Accuracy: 0.503475328607804, Time Elapsed: 21080.831884145737 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.61      0.89      0.72       885\n",
      "           2       0.58      0.31      0.40       877\n",
      "           3       0.52      0.89      0.65       897\n",
      "           4       0.53      0.59      0.56       892\n",
      "           5       0.56      0.26      0.35       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.62      0.64      0.63       889\n",
      "           8       0.57      0.57      0.57       892\n",
      "           9       0.59      0.62      0.60       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 4, Step 28300, Loss: 1.0821127891540527, F1: 0.5694218014007606, Accuracy: 0.5212304727823275, Time Elapsed: 21100.469372987747 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.58      0.54      0.56       877\n",
      "           3       0.58      0.79      0.67       897\n",
      "           4       0.57      0.49      0.53       892\n",
      "           5       0.54      0.66      0.59       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.56      0.79      0.66       892\n",
      "           9       0.58      0.76      0.66       876\n",
      "          10       0.40      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 4, Step 28400, Loss: 0.8943542838096619, F1: 0.6119847980276775, Accuracy: 0.5396738008395844, Time Elapsed: 21119.723900079727 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.59      0.23      0.33       877\n",
      "           3       0.60      0.39      0.47       897\n",
      "           4       0.52      0.85      0.65       892\n",
      "           5       0.50      0.26      0.35       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.55      0.80      0.65       892\n",
      "           9       0.59      0.64      0.61       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 28500, Loss: 0.6293861865997314, F1: 0.5561141698486872, Accuracy: 0.5135916316839859, Time Elapsed: 21140.817936182022 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69       912\n",
      "           1       0.55      0.96      0.70       885\n",
      "           2       0.58      0.59      0.59       877\n",
      "           3       0.54      0.87      0.67       897\n",
      "           4       0.57      0.71      0.63       892\n",
      "           5       0.54      0.50      0.52       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.53      0.82      0.65       892\n",
      "           9       0.58      0.79      0.67       876\n",
      "          10       0.40      0.19      0.26      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 4, Step 28600, Loss: 2.0914645195007324, F1: 0.6103695395181874, Accuracy: 0.5374716124148372, Time Elapsed: 21157.3217420578 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.56      0.73      0.63       885\n",
      "           2       0.59      0.49      0.54       877\n",
      "           3       0.60      0.65      0.62       897\n",
      "           4       0.54      0.19      0.28       892\n",
      "           5       0.48      0.62      0.54       862\n",
      "           6       0.61      0.09      0.16       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.54      0.76      0.63       892\n",
      "           9       0.58      0.72      0.65       876\n",
      "          10       0.38      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.55      0.52     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 4, Step 28700, Loss: 1.2057746648788452, F1: 0.5232769543576195, Accuracy: 0.4974193104397495, Time Elapsed: 21177.527979135513 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.70       912\n",
      "           1       0.53      0.10      0.17       885\n",
      "           2       0.57      0.74      0.64       877\n",
      "           3       0.61      0.32      0.42       897\n",
      "           4       0.56      0.58      0.57       892\n",
      "           5       0.50      0.71      0.59       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.60      0.79      0.68       889\n",
      "           8       0.59      0.54      0.56       892\n",
      "           9       0.60      0.56      0.58       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.54     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 4, Step 28800, Loss: 1.269240379333496, F1: 0.5440483790599381, Accuracy: 0.5083614341752116, Time Elapsed: 21196.135068893433 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       912\n",
      "           1       0.58      0.91      0.71       885\n",
      "           2       0.59      0.56      0.57       877\n",
      "           3       0.60      0.31      0.41       897\n",
      "           4       0.58      0.43      0.49       892\n",
      "           5       0.53      0.19      0.28       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.60      0.60      0.60       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.61      0.60      0.60       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.54      0.54     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 4, Step 28900, Loss: 1.6646860837936401, F1: 0.5391408044097521, Accuracy: 0.5065033376918313, Time Elapsed: 21217.207005023956 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.00      0.00       912\n",
      "           1       0.48      0.98      0.64       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.56      0.62      0.59       897\n",
      "           4       0.57      0.64      0.60       892\n",
      "           5       0.56      0.42      0.48       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.59      0.74      0.66       889\n",
      "           8       0.55      0.65      0.60       892\n",
      "           9       0.61      0.43      0.51       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.56      0.52     14531\n",
      "weighted avg       0.48      0.50      0.47     14531\n",
      "\n",
      "Epoch 4, Step 29000, Loss: 0.9151040315628052, F1: 0.5175051217928903, Accuracy: 0.4967999449452894, Time Elapsed: 21236.159126996994 seconds\n",
      "Epoch 4 completed. Time: 21236.883835077286\n",
      "Logger {'time': {0: 0.008226156234741211, 100: 15.41076397895813, 200: 31.22092604637146, 300: 50.683725118637085, 400: 67.08399701118469, 500: 82.42717218399048, 600: 97.03833293914795, 700: 111.74396586418152, 800: 127.35899209976196, 900: 142.7363510131836, 1000: 158.94676303863525, 1100: 174.34265613555908, 1200: 189.4165120124817, 1300: 205.10280013084412, 1400: 220.78863310813904, 1500: 235.78312182426453, 1600: 250.47465109825134, 1700: 265.8806562423706, 1800: 281.9050521850586, 1900: 297.55622720718384, 2000: 313.58471393585205, 2100: 329.60306215286255, 2200: 345.25642704963684, 2300: 359.85913920402527, 2400: 375.1409468650818, 2500: 390.31243205070496, 2600: 405.60913705825806, 2700: 420.7870662212372, 2800: 435.87411999702454, 2900: 451.10155391693115, 3000: 1300.4095151424408, 3100: 1316.5851020812988, 3200: 1333.9370601177216, 3300: 1349.7405931949615, 3400: 1365.4786450862885, 3500: 1381.2896661758423, 3600: 1397.0346932411194, 3700: 1412.071645975113, 3800: 1426.4445180892944, 3900: 1442.2275409698486, 4000: 1458.0583112239838, 4100: 1473.2845981121063, 4200: 1489.1775691509247, 4300: 1504.3096330165863, 4400: 1520.0877089500427, 4500: 1536.1133570671082, 4600: 1550.6145899295807, 4700: 1566.5363221168518, 4800: 1582.3791930675507, 4900: 1598.000009059906, 5000: 1614.173594236374, 5100: 1629.8796548843384, 5200: 1646.3334081172943, 5300: 1663.1088519096375, 5400: 1678.8703339099884, 5500: 1694.997777223587, 5600: 1711.4388880729675, 5700: 1727.088674068451, 5800: 1742.5027599334717, 5900: 1757.9964010715485, 6000: 1773.1177699565887, 6100: 1788.7079169750214, 6200: 1804.2528021335602, 6300: 1819.9404780864716, 6400: 1835.6677570343018, 6500: 1851.4374022483826, 6600: 1867.6996531486511, 6700: 1883.9011719226837, 6800: 1899.4814462661743, 6900: 1915.3558058738708, 7000: 1931.4901239871979, 7100: 1946.8264870643616, 7200: 1963.5833530426025, 7300: 1980.0529000759125, 7400: 1995.9301550388336, 7500: 2011.5933151245117, 7600: 2027.339042186737, 7700: 2043.7119340896606, 7800: 2061.4227340221405, 7900: 2081.8432450294495, 8000: 2102.7440440654755, 8100: 2123.929894208908, 8200: 2143.0403740406036, 8300: 2157.467297077179, 8400: 2172.337481021881, 8500: 2187.4284160137177, 8600: 2201.978065252304, 8700: 2221.1137132644653, 8800: 2241.941181898117, 8900: 2258.8374919891357, 9000: 2412.017711162567, 9100: 2431.5878479480743, 9200: 2447.1578500270844, 9300: 2463.2295260429382, 9400: 2481.331665992737, 9500: 2497.4432711601257, 9600: 2513.130818128586, 9700: 2529.2786948680878, 9800: 2544.951901912689, 9900: 2559.8612520694733, 10000: 2574.3711400032043, 10100: 2589.9643881320953, 10200: 2605.7575879096985, 10300: 2620.9571261405945, 10400: 2635.5039072036743, 10500: 2651.3963420391083, 10600: 2667.004868030548, 10700: 2681.619560956955, 10800: 2696.78697013855, 10900: 2712.1400530338287, 11000: 2727.858318090439, 11100: 2744.174353837967, 11200: 2759.8632068634033, 11300: 2776.6157100200653, 11400: 2792.2276611328125, 11500: 2807.528401851654, 11600: 2823.2049100399017, 11700: 2838.8900668621063, 11800: 2854.4350929260254, 11900: 2870.3282330036163, 12000: 2885.567983150482, 12100: 2901.8653559684753, 12200: 2916.775428056717, 12300: 2931.3158440589905, 12400: 2946.950565099716, 12500: 2962.563796043396, 12600: 2978.6171741485596, 12700: 2993.153002977371, 12800: 3009.238872051239, 12900: 3026.401640892029, 13000: 3042.060362100601, 13100: 3056.6698820590973, 13200: 3071.8735690116882, 13300: 3087.7279422283173, 13400: 3103.764839887619, 13500: 3119.6633331775665, 13600: 3135.6553671360016, 13700: 3151.1330449581146, 13800: 3166.4018502235413, 13900: 3183.2358191013336, 14000: 3199.5074129104614, 14100: 3215.2435960769653, 14200: 3230.2764711380005, 14300: 3245.4955220222473, 14400: 3261.498428106308, 14500: 3277.151253938675, 14600: 3293.3172659873962, 14700: 3309.2325801849365, 14800: 3325.0697631835938, 14900: 3340.5324890613556, 15000: 3355.4463942050934, 15100: 3371.6214690208435, 15200: 3387.512531042099, 15300: 3403.5406289100647, 15400: 3721.965204000473, 15500: 3739.2504901885986, 15600: 3755.3765711784363, 15700: 4071.274266242981, 15800: 4087.618196964264, 15900: 4103.128114938736, 16000: 4117.4922461509705, 16100: 4132.46361207962, 16200: 4149.19168305397, 16300: 4164.581162929535, 16400: 4179.431029081345, 16500: 4194.017538070679, 16600: 4209.345668077469, 16700: 4224.662478208542, 16800: 4239.115223169327, 16900: 5168.273201227188, 17000: 5184.917551040649, 17100: 5200.4040150642395, 17200: 6221.618515014648, 17300: 6239.108443260193, 17400: 7232.985958099365, 17500: 7251.031145095825, 17600: 7270.989132165909, 17700: 8225.83387207985, 17800: 8242.285803079605, 17900: 8259.416419029236, 18000: 9180.836437940598, 18100: 9198.22501206398, 18200: 9214.779755115509, 18300: 10287.717914104462, 18400: 10303.888235092163, 18500: 11235.425797224045, 18600: 11257.440422058105, 18700: 11273.972699165344, 18800: 11289.409477233887, 18900: 11303.999571084976, 19000: 12260.066059112549, 19100: 12279.78994512558, 19200: 13243.013803005219, 19300: 13263.242608070374, 19400: 13283.578619241714, 19500: 14272.312423944473, 19600: 14299.410533189774, 19700: 14314.373524904251, 19800: 14329.4307949543, 19900: 14345.34820818901, 20000: 14361.028487920761, 20100: 14376.583331108093, 20200: 14391.28488111496, 20300: 14406.19439792633, 20400: 14421.937552213669, 20500: 14437.927138090134, 20600: 15457.912145137787, 20700: 15474.814289093018, 20800: 16409.47494506836, 20900: 16428.002614974976, 21000: 17408.435897111893, 21100: 17427.758384227753, 21200: 17445.448651075363, 21300: 18310.549463033676, 21400: 18327.68988418579, 21500: 18345.227847099304, 21600: 18361.119849920273, 21700: 18376.901713848114, 21800: 18392.712589025497, 21900: 18408.454977989197, 22000: 18424.04208421707, 22100: 18439.173473119736, 22200: 18453.63906621933, 22300: 18468.14716219902, 22400: 18483.587836265564, 22500: 18499.285186052322, 22600: 18513.895703077316, 22700: 18529.33127593994, 22800: 18544.885459899902, 22900: 18560.398359060287, 23000: 18575.314648151398, 23100: 18590.008896112442, 23200: 18605.52354502678, 23300: 18620.92964410782, 23400: 18636.605447292328, 23500: 18652.49751806259, 23600: 18668.7034842968, 23700: 18684.292594909668, 23800: 18699.759292840958, 23900: 18715.223495960236, 24000: 18731.275727033615, 24100: 18747.033024072647, 24200: 18762.181670188904, 24300: 18778.29258799553, 24400: 18794.063443899155, 24500: 18809.76614713669, 24600: 18824.468832969666, 24700: 18839.349825143814, 24800: 18854.699316978455, 24900: 18869.636199951172, 25000: 18883.924398183823, 25100: 18899.903064012527, 25200: 18915.658393144608, 25300: 18931.286342144012, 25400: 18946.888683080673, 25500: 18962.492776870728, 25600: 18978.192342996597, 25700: 18996.01043200493, 25800: 19280.120729207993, 25900: 19415.967142105103, 26000: 19437.16236591339, 26100: 20432.615193128586, 26200: 20455.368166923523, 26300: 20473.400282144547, 26400: 20773.02184820175, 26500: 20789.52473306656, 26600: 20804.79223394394, 26700: 20820.040421247482, 26800: 20834.969335079193, 26900: 20850.214522123337, 27000: 20867.32840013504, 27100: 20882.485280036926, 27200: 20897.28116416931, 27300: 20911.8594789505, 27400: 20927.17723608017, 27500: 20941.701920986176, 27600: 20957.0505259037, 27700: 20971.506051063538, 27800: 20986.94428706169, 27900: 21006.46924304962, 28000: 21025.901361227036, 28100: 21044.746657133102, 28200: 21062.47741484642, 28300: 21081.491396188736, 28400: 21101.21208190918, 28500: 21120.366980075836, 28600: 21141.508953094482, 28700: 21157.884208202362, 28800: 21178.17798614502, 28900: 21196.88583803177, 29000: 21217.944315195084}, 'loss': {0: 1.7563214302062988, 100: 0.6639291048049927, 200: 0.39853328466415405, 300: 0.8684584498405457, 400: 0.5931786894798279, 500: 1.6688618659973145, 600: 1.1723490953445435, 700: 0.6088302731513977, 800: 0.9528260827064514, 900: 1.0327026844024658, 1000: 0.5455027222633362, 1100: 0.7943408489227295, 1200: 0.4156230688095093, 1300: 0.9983800649642944, 1400: 0.4849376380443573, 1500: 0.4675500690937042, 1600: 1.4295170307159424, 1700: 1.431908369064331, 1800: 0.6139280796051025, 1900: 0.9836366176605225, 2000: 1.4969500303268433, 2100: 0.36234042048454285, 2200: 1.9185901880264282, 2300: 0.32472869753837585, 2400: 0.38425007462501526, 2500: 1.9618251323699951, 2600: 0.480833500623703, 2700: 3.5584607124328613, 2800: 0.3835756778717041, 2900: 1.2656710147857666, 3000: 2.2506093978881836, 3100: 0.8273458480834961, 3200: 0.6940588355064392, 3300: 0.6513051390647888, 3400: 0.5051282048225403, 3500: 0.6392044425010681, 3600: 1.5867998600006104, 3700: 0.49406880140304565, 3800: 1.902572512626648, 3900: 0.16744916141033173, 4000: 1.2928342819213867, 4100: 1.005047082901001, 4200: 0.6599504947662354, 4300: 2.2369818687438965, 4400: 2.0393221378326416, 4500: 1.5636324882507324, 4600: 1.6826964616775513, 4700: 1.3760157823562622, 4800: 0.5260170698165894, 4900: 0.42066439986228943, 5000: 1.709050178527832, 5100: 0.2622610628604889, 5200: 1.470984935760498, 5300: 0.7263678908348083, 5400: 0.2740863263607025, 5500: 0.7403979897499084, 5600: 1.749738335609436, 5700: 0.2330537885427475, 5800: 1.2297980785369873, 5900: 0.6966424584388733, 6000: 0.5669875144958496, 6100: 0.25964394211769104, 6200: 1.7745161056518555, 6300: 0.48384740948677063, 6400: 0.7658578157424927, 6500: 0.45433884859085083, 6600: 1.1109132766723633, 6700: 5.415869235992432, 6800: 1.0493197441101074, 6900: 0.7220476865768433, 7000: 1.1178579330444336, 7100: 0.7999222278594971, 7200: 0.9618116021156311, 7300: 7.503030300140381, 7400: 1.0868268013000488, 7500: 1.6233985424041748, 7600: 0.37891480326652527, 7700: 0.09656435996294022, 7800: 1.2172744274139404, 7900: 0.5806586742401123, 8000: 0.6797996759414673, 8100: 0.2832084596157074, 8200: 0.6302945613861084, 8300: 0.9445392489433289, 8400: 0.4213234782218933, 8500: 0.765396237373352, 8600: 0.645725429058075, 8700: 1.1013621091842651, 8800: 1.984691858291626, 8900: 1.0316189527511597, 9000: 0.4293197691440582, 9100: 0.7942588925361633, 9200: 0.20659221708774567, 9300: 0.4182834327220917, 9400: 0.9717301726341248, 9500: 0.6349089741706848, 9600: 1.0839706659317017, 9700: 0.34093835949897766, 9800: 0.6933864951133728, 9900: 1.2584569454193115, 10000: 2.7235984802246094, 10100: 0.5807647705078125, 10200: 2.021566867828369, 10300: 0.8906403183937073, 10400: 0.501291036605835, 10500: 0.5672615170478821, 10600: 0.5030087232589722, 10700: 0.9650564193725586, 10800: 1.8387322425842285, 10900: 0.41163474321365356, 11000: 1.7096818685531616, 11100: 1.2705026865005493, 11200: 0.5189648270606995, 11300: 0.8530269265174866, 11400: 1.3675023317337036, 11500: 1.1320674419403076, 11600: 0.36443251371383667, 11700: 4.0707831382751465, 11800: 0.7958998084068298, 11900: 0.40701261162757874, 12000: 0.9700300693511963, 12100: 0.8367870450019836, 12200: 1.2665021419525146, 12300: 0.7282999157905579, 12400: 0.993648111820221, 12500: 1.9174880981445312, 12600: 1.259006142616272, 12700: 0.8920953869819641, 12800: 1.1605682373046875, 12900: 1.2191729545593262, 13000: 0.7967206835746765, 13100: 0.8481056094169617, 13200: 0.640956461429596, 13300: 0.27409040927886963, 13400: 1.7571165561676025, 13500: 1.9610693454742432, 13600: 0.6876226663589478, 13700: 2.937188148498535, 13800: 0.3608130216598511, 13900: 0.8675785660743713, 14000: 0.8618366718292236, 14100: 1.437887191772461, 14200: 0.35968026518821716, 14300: 1.7595255374908447, 14400: 6.4050445556640625, 14500: 1.4669358730316162, 14600: 3.4700093269348145, 14700: 2.6652603149414062, 14800: 1.226460576057434, 14900: 1.3040494918823242, 15000: 0.8430034518241882, 15100: 0.7931970357894897, 15200: 0.7747135758399963, 15300: 0.4796949625015259, 15400: 0.8876734972000122, 15500: 1.3625283241271973, 15600: 0.6576058864593506, 15700: 0.5356922745704651, 15800: 1.2212591171264648, 15900: 0.425253301858902, 16000: 0.5559320449829102, 16100: 1.9652414321899414, 16200: 0.578267514705658, 16300: 0.5532174706459045, 16400: 0.4513853192329407, 16500: 0.5261918902397156, 16600: 0.518526017665863, 16700: 0.4992469251155853, 16800: 0.39506471157073975, 16900: 1.0569508075714111, 17000: 0.30797791481018066, 17100: 0.8173568844795227, 17200: 2.129666805267334, 17300: 0.7165865302085876, 17400: 0.7446964383125305, 17500: 0.3982609808444977, 17600: 0.4050319790840149, 17700: 2.3967323303222656, 17800: 1.278291940689087, 17900: 1.13145911693573, 18000: 1.5192646980285645, 18100: 0.5066543817520142, 18200: 1.4009742736816406, 18300: 2.3989179134368896, 18400: 0.6911464929580688, 18500: 0.8242214322090149, 18600: 0.8722474575042725, 18700: 1.1279642581939697, 18800: 4.308712005615234, 18900: 0.5378175973892212, 19000: 0.5519830584526062, 19100: 0.5911374092102051, 19200: 0.256317675113678, 19300: 0.42163583636283875, 19400: 0.7752846479415894, 19500: 3.763535976409912, 19600: 0.6243100762367249, 19700: 0.6478330492973328, 19800: 0.38320887088775635, 19900: 0.33854568004608154, 20000: 0.25777626037597656, 20100: 0.9372344017028809, 20200: 0.8020259737968445, 20300: 2.029724597930908, 20400: 0.9715690612792969, 20500: 0.8201338052749634, 20600: 0.5931198596954346, 20700: 1.8137736320495605, 20800: 1.2004094123840332, 20900: 0.5462542772293091, 21000: 0.47581619024276733, 21100: 0.9067689776420593, 21200: 0.7573502063751221, 21300: 0.7068644762039185, 21400: 0.7248704433441162, 21500: 1.568312406539917, 21600: 1.522355556488037, 21700: 0.5512927174568176, 21800: 0.5407347083091736, 21900: 0.50521320104599, 22000: 1.3680124282836914, 22100: 1.48912513256073, 22200: 0.5067235231399536, 22300: 1.0036605596542358, 22400: 1.635932445526123, 22500: 0.12132157385349274, 22600: 0.4912663698196411, 22700: 0.697559118270874, 22800: 0.4027608036994934, 22900: 0.18418945372104645, 23000: 1.0027108192443848, 23100: 0.3523164987564087, 23200: 1.7196574211120605, 23300: 0.3670804798603058, 23400: 0.8696884512901306, 23500: 1.1040689945220947, 23600: 4.810237884521484, 23700: 0.5236174464225769, 23800: 0.63050377368927, 23900: 1.3001670837402344, 24000: 0.24339596927165985, 24100: 1.1240451335906982, 24200: 1.7060253620147705, 24300: 0.3754208981990814, 24400: 2.1868860721588135, 24500: 0.4990701377391815, 24600: 4.047590255737305, 24700: 1.4211633205413818, 24800: 0.8917612433433533, 24900: 0.257692813873291, 25000: 1.1555694341659546, 25100: 0.6099223494529724, 25200: 0.829976499080658, 25300: 0.4290468394756317, 25400: 1.0818006992340088, 25500: 0.7420980334281921, 25600: 1.9091508388519287, 25700: 0.2177879959344864, 25800: 1.45551335811615, 25900: 0.5574813485145569, 26000: 0.5461308360099792, 26100: 1.4562568664550781, 26200: 1.6013877391815186, 26300: 0.4434420168399811, 26400: 0.5466803908348083, 26500: 0.7898910641670227, 26600: 0.45401179790496826, 26700: 0.9420235753059387, 26800: 0.39137721061706543, 26900: 1.189231276512146, 27000: 0.776713490486145, 27100: 0.362975150346756, 27200: 1.2582988739013672, 27300: 0.7103649973869324, 27400: 0.40333446860313416, 27500: 1.2310166358947754, 27600: 0.6336642503738403, 27700: 1.7278536558151245, 27800: 0.574122428894043, 27900: 0.6053513884544373, 28000: 0.8953458070755005, 28100: 0.6099357604980469, 28200: 0.2920841872692108, 28300: 1.0821127891540527, 28400: 0.8943542838096619, 28500: 0.6293861865997314, 28600: 2.0914645195007324, 28700: 1.2057746648788452, 28800: 1.269240379333496, 28900: 1.6646860837936401, 29000: 0.9151040315628052}, 'F1': {0: 0.5861559157401192, 100: 0.5501918705234937, 200: 0.5444675357099421, 300: 0.577358934684089, 400: 0.47841318913498515, 500: 0.5658972782833915, 600: 0.5841185639568546, 700: 0.5906277433166648, 800: 0.5900294995153259, 900: 0.5106692157790075, 1000: 0.5534327767725109, 1100: 0.5320560420852583, 1200: 0.5451811660190025, 1300: 0.5475122528318734, 1400: 0.4842258096318567, 1500: 0.5098943392697989, 1600: 0.5561185037517229, 1700: 0.5767998886263668, 1800: 0.5509028323607349, 1900: 0.5480073021683601, 2000: 0.5893468582504969, 2100: 0.4961651635576559, 2200: 0.6041319021559437, 2300: 0.5754905336365589, 2400: 0.6040771465709539, 2500: 0.4696424973358766, 2600: 0.5681518147533486, 2700: 0.5578449292077506, 2800: 0.5089593307182763, 2900: 0.5685819078905338, 3000: 0.5910227260335509, 3100: 0.5696152946044909, 3200: 0.5477947629206659, 3300: 0.538452520349015, 3400: 0.45973986022115376, 3500: 0.5066461987561042, 3600: 0.4771930846574622, 3700: 0.4783511283145922, 3800: 0.5493871699920868, 3900: 0.6159975396504763, 4000: 0.547612476980423, 4100: 0.4223827648986119, 4200: 0.46976274489115233, 4300: 0.5046101576079572, 4400: 0.4747203328732974, 4500: 0.5006784716237116, 4600: 0.5036482438149223, 4700: 0.5092887180092626, 4800: 0.4837378718699988, 4900: 0.4729247818686045, 5000: 0.5148750669533011, 5100: 0.5448529066741465, 5200: 0.4435709936034915, 5300: 0.5467543628042454, 5400: 0.5431662157079375, 5500: 0.49874810831166666, 5600: 0.517877283978707, 5700: 0.597529755767987, 5800: 0.578466479321936, 5900: 0.5112372586461871, 6000: 0.5719970051827651, 6100: 0.4919198864358348, 6200: 0.5443077941020809, 6300: 0.5979714747616302, 6400: 0.5596061573677574, 6500: 0.5522508529685108, 6600: 0.5962919440777507, 6700: 0.581988762674861, 6800: 0.5359037434098085, 6900: 0.5267594934574859, 7000: 0.5873306783943529, 7100: 0.5824197327623291, 7200: 0.5474002368803158, 7300: 0.5978369114709736, 7400: 0.5044813742018093, 7500: 0.5694783908747151, 7600: 0.5288609380068526, 7700: 0.5308644296652706, 7800: 0.6035343768303735, 7900: 0.5701910136481433, 8000: 0.5822541093777147, 8100: 0.5844701373101772, 8200: 0.5643817707316224, 8300: 0.5470162352005791, 8400: 0.5343008455772936, 8500: 0.5301342116790774, 8600: 0.5225750951152256, 8700: 0.5990259468390188, 8800: 0.5899670399175646, 8900: 0.5916750969437916, 9000: 0.4970445016272333, 9100: 0.5025217207237757, 9200: 0.5486698365081328, 9300: 0.5113945165210856, 9400: 0.4681057115094991, 9500: 0.49020112579132386, 9600: 0.5413228807207426, 9700: 0.521748421134959, 9800: 0.5162436316179572, 9900: 0.5432963157749051, 10000: 0.575673335557815, 10100: 0.5222865392861793, 10200: 0.5976121381894801, 10300: 0.5863609486700428, 10400: 0.5318872637978707, 10500: 0.48450359858475095, 10600: 0.5696227170796406, 10700: 0.5151566706489937, 10800: 0.5536903092143531, 10900: 0.6016157930790325, 11000: 0.48124482781114336, 11100: 0.5528937331710125, 11200: 0.5899076404928483, 11300: 0.5777922493581503, 11400: 0.5656052869940464, 11500: 0.5876768330365427, 11600: 0.5463300376389144, 11700: 0.5243098128173247, 11800: 0.6060532712770001, 11900: 0.540067836347045, 12000: 0.4520032302492219, 12100: 0.5662965264205034, 12200: 0.5354893082022606, 12300: 0.5256312298748511, 12400: 0.5821090306256067, 12500: 0.5586363409922211, 12600: 0.5622319094360891, 12700: 0.580738861566699, 12800: 0.4498296344523755, 12900: 0.5754375108339417, 13000: 0.5178143996859259, 13100: 0.5227164651650801, 13200: 0.5752814872518832, 13300: 0.4725293342087611, 13400: 0.5463104724418171, 13500: 0.4911802533496528, 13600: 0.3843164123611992, 13700: 0.4813151063971786, 13800: 0.5219930831442724, 13900: 0.5455296884992511, 14000: 0.4194266944676377, 14100: 0.5881350082425159, 14200: 0.5326035546175635, 14300: 0.5390257883573762, 14400: 0.5008906294513091, 14500: 0.4822009311203818, 14600: 0.5286475467129473, 14700: 0.5747450180670305, 14800: 0.577935998033249, 14900: 0.5949721751440012, 15000: 0.387389074873223, 15100: 0.5214584918246136, 15200: 0.5398172149792849, 15300: 0.49906859116128294, 15400: 0.5130822004214064, 15500: 0.5222362235385406, 15600: 0.5390849903079235, 15700: 0.5192069944370844, 15800: 0.5470073417282053, 15900: 0.5646222069119481, 16000: 0.6051666890821599, 16100: 0.467371869494, 16200: 0.6003367245666656, 16300: 0.5393167346677651, 16400: 0.5637411147830111, 16500: 0.5125768081221378, 16600: 0.5868499356989719, 16700: 0.5751687256126256, 16800: 0.5470955911990492, 16900: 0.5824819680617751, 17000: 0.5343048750010497, 17100: 0.534666824137081, 17200: 0.5268913584156658, 17300: 0.5190340279595959, 17400: 0.4917053390277884, 17500: 0.6111092630219124, 17600: 0.5372151199019177, 17700: 0.5318551862722173, 17800: 0.5136626728669742, 17900: 0.5705352272718826, 18000: 0.5129334751611853, 18100: 0.5336130283370668, 18200: 0.566442667162195, 18300: 0.5544109276203948, 18400: 0.5159653967240245, 18500: 0.5655752919085366, 18600: 0.5266133303545373, 18700: 0.4970896482853075, 18800: 0.5641874585495422, 18900: 0.5631561950138256, 19000: 0.6037438023314409, 19100: 0.5940942942372797, 19200: 0.4769164811847872, 19300: 0.5751217771693397, 19400: 0.5601147091768381, 19500: 0.5832673390295068, 19600: 0.6089083222057352, 19700: 0.5956117194555391, 19800: 0.5734975157005935, 19900: 0.5856586985612581, 20000: 0.5151242269550595, 20100: 0.46670013860666776, 20200: 0.5121603879302312, 20300: 0.5542189429263401, 20400: 0.48410592701308325, 20500: 0.5130900983930119, 20600: 0.5713498908915741, 20700: 0.554460481991191, 20800: 0.42491590593302037, 20900: 0.5583947994838387, 21000: 0.5834192880419137, 21100: 0.5448693140490776, 21200: 0.6093548940538315, 21300: 0.5125767014657276, 21400: 0.5530446988981235, 21500: 0.5495233471923642, 21600: 0.568661136118655, 21700: 0.6044847210585543, 21800: 0.5951779619166019, 21900: 0.5892905178387647, 22000: 0.5401071645256788, 22100: 0.4643752184604626, 22200: 0.49552023877216766, 22300: 0.5283110505078349, 22400: 0.6085029325364747, 22500: 0.600513608008136, 22600: 0.5668753236793908, 22700: 0.5681498030783023, 22800: 0.5751202230920462, 22900: 0.534591889923721, 23000: 0.5600804974321129, 23100: 0.48732953217490865, 23200: 0.5933238808195399, 23300: 0.5976140019178809, 23400: 0.47682738960466936, 23500: 0.5429246136654146, 23600: 0.48269417906329976, 23700: 0.5229173216313184, 23800: 0.5725154844845061, 23900: 0.45176625031995477, 24000: 0.4921430241785671, 24100: 0.4632219825629988, 24200: 0.6021210410503651, 24300: 0.5904229077684829, 24400: 0.4762914564457649, 24500: 0.5587022974728844, 24600: 0.6102877164919728, 24700: 0.5659531722578905, 24800: 0.5861507635623693, 24900: 0.5730307654001217, 25000: 0.4765411066021485, 25100: 0.5658893749303303, 25200: 0.48707307662862287, 25300: 0.4606665338233535, 25400: 0.531463622445671, 25500: 0.550147014281273, 25600: 0.5566742739976749, 25700: 0.579796810298228, 25800: 0.5399506299858163, 25900: 0.507639043923246, 26000: 0.5217251170304724, 26100: 0.5098392425962469, 26200: 0.5186719596743822, 26300: 0.5579299585087243, 26400: 0.5435664830113469, 26500: 0.5291641552720594, 26600: 0.5693137893699836, 26700: 0.5024144020810366, 26800: 0.5014832058167795, 26900: 0.5565174209007289, 27000: 0.4388623367004261, 27100: 0.5784973268727766, 27200: 0.5602657508244918, 27300: 0.5457773193593078, 27400: 0.6010311719713828, 27500: 0.5637140933855262, 27600: 0.5753056381366402, 27700: 0.603011257553356, 27800: 0.5320675040643509, 27900: 0.5461721142545969, 28000: 0.5531083399488445, 28100: 0.5063414783883647, 28200: 0.4882574771433657, 28300: 0.5694218014007606, 28400: 0.6119847980276775, 28500: 0.5561141698486872, 28600: 0.6103695395181874, 28700: 0.5232769543576195, 28800: 0.5440483790599381, 28900: 0.5391408044097521, 29000: 0.5175051217928903}, 'Accuracy': {0: 0.5239832083132613, 100: 0.5165508223797398, 200: 0.5145550891198128, 300: 0.5177207349803867, 400: 0.48365563278508017, 500: 0.5173078246507467, 600: 0.5195788314637672, 700: 0.5247402105842681, 800: 0.5249466657490881, 900: 0.4912944738834216, 1000: 0.5091872548344918, 1100: 0.5075356135159315, 1200: 0.506847429633198, 1300: 0.5114582616475122, 1400: 0.4943224829674489, 1500: 0.4928772968137086, 1600: 0.5120776271419724, 1700: 0.5224692037712477, 1800: 0.5121464455302457, 1900: 0.5069162480214713, 2000: 0.5212992911706008, 2100: 0.5045076044319042, 2200: 0.53423714816599, 2300: 0.5251531209139082, 2400: 0.5356135159314569, 2500: 0.4869589154222008, 2600: 0.5243961186429014, 2700: 0.5210928360057807, 2800: 0.49941504369967654, 2900: 0.5124217190833391, 3000: 0.531071502305416, 3100: 0.5147615442846328, 3200: 0.5131099029660725, 3300: 0.5154497281673663, 3400: 0.4888170119055812, 3500: 0.5006537746885968, 3600: 0.4966623081687427, 3700: 0.49556121395636915, 3800: 0.5199917417934072, 3900: 0.5393297088982176, 4000: 0.5060904273621912, 4100: 0.4714747780606978, 4200: 0.472507053884798, 4300: 0.48847291996421444, 4400: 0.4771867042873856, 4500: 0.4859266395981006, 4600: 0.49308375197852866, 4700: 0.49260202326061525, 4800: 0.4884041015759411, 4900: 0.4813846259720597, 5000: 0.4921202945427018, 5100: 0.5032000550547107, 5200: 0.46913495285940404, 5300: 0.49893331498176313, 5400: 0.5060216089739178, 5500: 0.47993943981831944, 5600: 0.494735393297089, 5700: 0.5290069506572156, 5800: 0.5214369279471475, 5900: 0.49838276787557634, 6000: 0.515587364943913, 6100: 0.4958364875094625, 6200: 0.5148303626729062, 6300: 0.5268047622324685, 6400: 0.5146239075080862, 6500: 0.5144862707315395, 6600: 0.5279058564448421, 6700: 0.5193035579106737, 6800: 0.4968687633335627, 6900: 0.5025118711719772, 7000: 0.5214369279471475, 7100: 0.5226756589360677, 7200: 0.5096689835524052, 7300: 0.5276305828917487, 7400: 0.4991397701465832, 7500: 0.5246713921959948, 7600: 0.5128346294129792, 7700: 0.5047828779849975, 7800: 0.5353382423783635, 7900: 0.5171013694859267, 8000: 0.5272864909503819, 8100: 0.5265294886793751, 8200: 0.515380909779093, 8300: 0.5153120913908197, 8400: 0.5053334250911844, 8500: 0.5059527905856445, 8600: 0.49707521849838276, 8700: 0.5286628587158488, 8800: 0.5312091390819627, 8900: 0.5263230335145551, 9000: 0.49803867593420964, 9100: 0.49335902553162203, 9200: 0.5109077145413254, 9300: 0.5038194205491707, 9400: 0.48558254765673386, 9500: 0.4779437065583924, 9600: 0.505471061867731, 9700: 0.49941504369967654, 9800: 0.5003096827472301, 9900: 0.5047140595967242, 10000: 0.5208863808409607, 10100: 0.49907095175830984, 10200: 0.527492946115202, 10300: 0.5217810198885142, 10400: 0.5112518064826922, 10500: 0.49053747161241484, 10600: 0.5162067304383732, 10700: 0.4974193104397495, 10800: 0.5093248916110384, 10900: 0.5311403206936893, 11000: 0.4850320005505471, 11100: 0.5071915215745647, 11200: 0.5214369279471475, 11300: 0.5188906475810336, 11400: 0.5199229234051338, 11500: 0.5210240176175074, 11600: 0.5180648269217535, 11700: 0.5100818938820453, 11800: 0.5352006056018168, 11900: 0.5133851765191659, 12000: 0.4753974261922786, 12100: 0.5136604500722594, 12200: 0.5054022434794577, 12300: 0.5012043217947836, 12400: 0.5255660312435483, 12500: 0.5139357236253527, 12600: 0.515587364943913, 12700: 0.5183401004748469, 12800: 0.4832427224554401, 12900: 0.523914389924988, 13000: 0.5010666850182369, 13100: 0.5022365976188837, 13200: 0.5080173422338449, 13300: 0.48110935241896635, 13400: 0.503888238937444, 13500: 0.4819351730782465, 13600: 0.44766361571811986, 13700: 0.4843438166678136, 13800: 0.5032000550547107, 13900: 0.503888238937444, 14000: 0.46328538985616957, 14100: 0.5224692037712477, 14200: 0.5062280641387379, 14300: 0.5084990709517583, 14400: 0.49996559080586334, 14500: 0.4957676691211892, 14600: 0.49989677241759, 14700: 0.5151056362259996, 14800: 0.5226068405477944, 14900: 0.5271488541738353, 15000: 0.4597756520542289, 15100: 0.498313949487303, 15200: 0.5012043217947836, 15300: 0.4982451310990297, 15400: 0.5019613240657904, 15500: 0.4992774069231299, 15600: 0.5144174523432661, 15700: 0.503475328607804, 15800: 0.5044387860436309, 15900: 0.5198541050168605, 16000: 0.5336866010598031, 16100: 0.4884041015759411, 16200: 0.5301768632578625, 16300: 0.5091872548344918, 16400: 0.5175830982038401, 16500: 0.5081549790103915, 16600: 0.5259789415731884, 16700: 0.5216433831119676, 16800: 0.5114582616475122, 16900: 0.5259789415731884, 17000: 0.5009978666299635, 17100: 0.5062280641387379, 17200: 0.5012043217947836, 17300: 0.49060629000068817, 17400: 0.4898492877296814, 17500: 0.5363016998141904, 17600: 0.5091184364462185, 17700: 0.5062968825270112, 17800: 0.4897116509531347, 17900: 0.5182712820865736, 18000: 0.49466657490881566, 18100: 0.5042323308788108, 18200: 0.5176519165921134, 18300: 0.5096689835524052, 18400: 0.5004473195237767, 18500: 0.5168260959328332, 18600: 0.5060216089739178, 18700: 0.4958364875094625, 18800: 0.5147615442846328, 18900: 0.5058839721973711, 19000: 0.5296263161516758, 19100: 0.5285252219393022, 19200: 0.4859266395981006, 19300: 0.5201981969582272, 19400: 0.5090496180579451, 19500: 0.5262542151262818, 19600: 0.5394673456747643, 19700: 0.5262542151262818, 19800: 0.5184777372513936, 19900: 0.5239832083132613, 20000: 0.49659348978046935, 20100: 0.4819351730782465, 20200: 0.4923267497075218, 20300: 0.5058151538090978, 20400: 0.4817287179134265, 20500: 0.49803867593420964, 20600: 0.5137292684605327, 20700: 0.5080173422338449, 20800: 0.4784254352763058, 20900: 0.5124217190833391, 21000: 0.527699401280022, 21100: 0.5112518064826922, 21200: 0.537815704356204, 21300: 0.5029247815016172, 21400: 0.5201293785699539, 21500: 0.5156561833321863, 21600: 0.5168949143211066, 21700: 0.5330672355653431, 21800: 0.5254283944670016, 21900: 0.5268735806207419, 22000: 0.5051269699263643, 22100: 0.48097171564241964, 22200: 0.49108801871860164, 22300: 0.501686050512697, 22400: 0.5383662514623907, 22500: 0.5332736907301631, 22600: 0.5196476498520405, 22700: 0.5114582616475122, 22800: 0.5173078246507467, 22900: 0.5056775170325511, 23000: 0.5117335352006056, 23100: 0.49893331498176313, 23200: 0.5277682196682953, 23300: 0.5353382423783635, 23400: 0.48922992223522127, 23500: 0.5071915215745647, 23600: 0.4870965521987475, 23700: 0.4992774069231299, 23800: 0.5156561833321863, 23900: 0.4738146032619916, 24000: 0.4958364875094625, 24100: 0.4814534443603331, 24200: 0.5341683297777166, 24300: 0.5256348496318216, 24400: 0.4934278439198954, 24500: 0.5200605601816806, 24600: 0.5369898836969238, 24700: 0.5162755488266465, 24800: 0.5284564035510289, 24900: 0.520542288899594, 25000: 0.4927396600371619, 25100: 0.5171701878742, 25200: 0.4987268598169431, 25300: 0.4921202945427018, 25400: 0.5032000550547107, 25500: 0.5154497281673663, 25600: 0.5099442571054986, 25700: 0.5228821141008878, 25800: 0.5058839721973711, 25900: 0.49067510838896156, 26000: 0.5014107769596036, 26100: 0.4908815635537816, 26200: 0.4943224829674489, 26300: 0.515380909779093, 26400: 0.5029247815016172, 26500: 0.5029935998898906, 26600: 0.5202670153465005, 26700: 0.48613309476292066, 26800: 0.4942536645791756, 26900: 0.5182712820865736, 27000: 0.47408987681508497, 27100: 0.5166196407680133, 27200: 0.5171701878742, 27300: 0.5109765329295988, 27400: 0.525497212855275, 27500: 0.5134539949074393, 27600: 0.5229509324891611, 27700: 0.5314155942467828, 27800: 0.5078797054572982, 27900: 0.5168949143211066, 28000: 0.5071915215745647, 28100: 0.49707521849838276, 28200: 0.503475328607804, 28300: 0.5212304727823275, 28400: 0.5396738008395844, 28500: 0.5135916316839859, 28600: 0.5374716124148372, 28700: 0.4974193104397495, 28800: 0.5083614341752116, 28900: 0.5065033376918313, 29000: 0.4967999449452894}}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.57      0.95      0.71       885\n",
      "           2       0.60      0.50      0.54       877\n",
      "           3       0.59      0.50      0.54       897\n",
      "           4       0.52      0.77      0.62       892\n",
      "           5       0.52      0.57      0.54       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.57      0.83      0.68       889\n",
      "           8       0.59      0.42      0.49       892\n",
      "           9       0.58      0.64      0.61       876\n",
      "          10       0.38      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 0, Loss: 1.0368952751159668, F1: 0.5825962228505421, Accuracy: 0.5188218291927603, Time Elapsed: 17.153621912002563 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.75      0.03      0.05       885\n",
      "           2       0.60      0.24      0.35       877\n",
      "           3       0.59      0.59      0.59       897\n",
      "           4       0.59      0.72      0.65       892\n",
      "           5       0.49      0.74      0.59       862\n",
      "           6       0.60      0.67      0.63       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.51      0.76      0.61       892\n",
      "           9       0.57      0.83      0.68       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.60      0.54     14531\n",
      "weighted avg       0.51      0.51      0.47     14531\n",
      "\n",
      "Epoch 5, Step 100, Loss: 3.6870079040527344, F1: 0.5358765746770495, Accuracy: 0.5085678893400316, Time Elapsed: 35.842499017715454 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70       912\n",
      "           1       0.70      0.02      0.05       885\n",
      "           2       0.61      0.55      0.57       877\n",
      "           3       0.58      0.70      0.63       897\n",
      "           4       0.44      0.04      0.07       892\n",
      "           5       0.56      0.28      0.37       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.59      0.60      0.60       892\n",
      "           9       0.59      0.67      0.63       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.52      0.49     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 200, Loss: 1.1470634937286377, F1: 0.49031723473849986, Accuracy: 0.49907095175830984, Time Elapsed: 58.92287516593933 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.59      0.77      0.67       885\n",
      "           2       0.58      0.66      0.61       877\n",
      "           3       0.58      0.58      0.58       897\n",
      "           4       0.59      0.61      0.60       892\n",
      "           5       0.47      0.65      0.55       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.58      0.60      0.59       892\n",
      "           9       0.62      0.27      0.38       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 300, Loss: 0.8406378030776978, F1: 0.5777743089607511, Accuracy: 0.5181336453100268, Time Elapsed: 80.57766389846802 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.46      0.52       885\n",
      "           2       0.59      0.45      0.51       877\n",
      "           3       0.55      0.88      0.67       897\n",
      "           4       0.58      0.28      0.38       892\n",
      "           5       0.54      0.72      0.61       862\n",
      "           6       0.60      0.73      0.66       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.50      0.72      0.59       892\n",
      "           9       0.54      0.59      0.56       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 400, Loss: 0.7211953997612, F1: 0.5600340514145794, Accuracy: 0.5093248916110384, Time Elapsed: 99.66802310943604 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70       912\n",
      "           1       0.61      0.09      0.16       885\n",
      "           2       0.59      0.56      0.57       877\n",
      "           3       0.55      0.78      0.64       897\n",
      "           4       0.55      0.79      0.65       892\n",
      "           5       0.56      0.47      0.51       862\n",
      "           6       0.60      0.74      0.66       903\n",
      "           7       0.61      0.60      0.60       889\n",
      "           8       0.51      0.76      0.61       892\n",
      "           9       0.50      0.84      0.63       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.61      0.55     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 500, Loss: 3.424351692199707, F1: 0.552759593114655, Accuracy: 0.5094625283875852, Time Elapsed: 116.92978620529175 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.53      0.95      0.68       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.54      0.80      0.64       897\n",
      "           4       0.55      0.89      0.68       892\n",
      "           5       0.55      0.61      0.58       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.61      0.50      0.55       889\n",
      "           8       0.50      0.74      0.60       892\n",
      "           9       0.57      0.71      0.63       876\n",
      "          10       0.38      0.20      0.26      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.68      0.59     14531\n",
      "weighted avg       0.49      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 600, Loss: 1.1816633939743042, F1: 0.5930111750654806, Accuracy: 0.5231573876539811, Time Elapsed: 133.90494894981384 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.59      0.47      0.53       877\n",
      "           3       0.59      0.73      0.65       897\n",
      "           4       0.55      0.88      0.68       892\n",
      "           5       0.51      0.75      0.61       862\n",
      "           6       0.60      0.77      0.68       903\n",
      "           7       0.61      0.73      0.66       889\n",
      "           8       0.59      0.51      0.55       892\n",
      "           9       0.57      0.79      0.66       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.68      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 5, Step 700, Loss: 0.47504228353500366, F1: 0.6098598402825379, Accuracy: 0.5380909779092974, Time Elapsed: 151.03531002998352 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.45      0.52       912\n",
      "           1       0.60      0.51      0.55       885\n",
      "           2       0.60      0.38      0.47       877\n",
      "           3       0.59      0.70      0.64       897\n",
      "           4       0.53      0.86      0.66       892\n",
      "           5       0.47      0.76      0.58       862\n",
      "           6       0.60      0.75      0.67       903\n",
      "           7       0.61      0.50      0.55       889\n",
      "           8       0.60      0.34      0.43       892\n",
      "           9       0.57      0.79      0.66       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 800, Loss: 1.9441183805465698, F1: 0.5543658573402791, Accuracy: 0.5049205147615443, Time Elapsed: 170.05551624298096 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68       912\n",
      "           1       0.62      0.49      0.55       885\n",
      "           2       0.46      0.82      0.59       877\n",
      "           3       0.61      0.47      0.53       897\n",
      "           4       0.59      0.37      0.45       892\n",
      "           5       0.55      0.27      0.37       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.61      0.70      0.65       889\n",
      "           8       0.00      0.00      0.00       892\n",
      "           9       0.59      0.47      0.52       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.51      0.50     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 900, Loss: 1.2991607189178467, F1: 0.4966320473304725, Accuracy: 0.49335902553162203, Time Elapsed: 190.31378412246704 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.60      0.79      0.68       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.59      0.17      0.26       897\n",
      "           4       0.60      0.34      0.44       892\n",
      "           5       0.56      0.64      0.60       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.58      0.56      0.57       892\n",
      "           9       0.48      0.87      0.62       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 1000, Loss: 0.38353824615478516, F1: 0.5583059470324984, Accuracy: 0.5122840823067923, Time Elapsed: 209.21857929229736 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.50      0.73      0.59       877\n",
      "           3       0.58      0.03      0.06       897\n",
      "           4       0.57      0.74      0.65       892\n",
      "           5       0.54      0.20      0.29       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.60      0.65      0.62       892\n",
      "           9       0.58      0.74      0.65       876\n",
      "          10       0.39      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 1100, Loss: 0.6168524622917175, F1: 0.53606539805782, Accuracy: 0.5127658110247058, Time Elapsed: 229.89427208900452 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.71       912\n",
      "           1       0.62      0.66      0.63       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.61      0.37      0.46       897\n",
      "           4       0.54      0.88      0.67       892\n",
      "           5       0.55      0.26      0.36       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.59      0.69      0.64       889\n",
      "           8       0.60      0.39      0.47       892\n",
      "           9       0.60      0.67      0.64       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 1200, Loss: 0.6410737037658691, F1: 0.5599337827494753, Accuracy: 0.5166196407680133, Time Elapsed: 248.96744012832642 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.60      0.38      0.46       877\n",
      "           3       0.57      0.63      0.60       897\n",
      "           4       0.50      0.88      0.64       892\n",
      "           5       0.56      0.41      0.47       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.59      0.54      0.56       892\n",
      "           9       0.58      0.73      0.65       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 1300, Loss: 1.220293402671814, F1: 0.5832801388151505, Accuracy: 0.5217810198885142, Time Elapsed: 272.293270111084 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.66       912\n",
      "           1       0.61      0.90      0.73       885\n",
      "           2       0.58      0.46      0.51       877\n",
      "           3       0.61      0.36      0.45       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.56      0.20      0.30       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.59      0.84      0.70       889\n",
      "           8       0.60      0.45      0.51       892\n",
      "           9       0.61      0.50      0.55       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.53      0.52      0.50     14531\n",
      "weighted avg       0.48      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 1400, Loss: 0.47996440529823303, F1: 0.5026784663555443, Accuracy: 0.504851696373271, Time Elapsed: 290.39527797698975 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.62      0.32      0.43       885\n",
      "           2       0.59      0.50      0.54       877\n",
      "           3       0.63      0.31      0.41       897\n",
      "           4       0.52      0.83      0.64       892\n",
      "           5       0.57      0.45      0.50       862\n",
      "           6       0.62      0.78      0.69       903\n",
      "           7       0.59      0.63      0.61       889\n",
      "           8       0.58      0.43      0.49       892\n",
      "           9       0.63      0.49      0.55       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.55      0.54     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 1500, Loss: 0.5934423208236694, F1: 0.5440962252576269, Accuracy: 0.5069850664097447, Time Elapsed: 313.710825920105 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.57      0.89      0.69       885\n",
      "           2       0.60      0.63      0.61       877\n",
      "           3       0.61      0.21      0.31       897\n",
      "           4       0.55      0.81      0.65       892\n",
      "           5       0.53      0.70      0.60       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.57      0.67      0.61       892\n",
      "           9       0.60      0.60      0.60       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 1600, Loss: 1.2062389850616455, F1: 0.5850572880670976, Accuracy: 0.5262542151262818, Time Elapsed: 340.97358798980713 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.62      0.43      0.51       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.61      0.07      0.12       897\n",
      "           4       0.60      0.53      0.56       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.59      0.67      0.63       889\n",
      "           8       0.53      0.81      0.64       892\n",
      "           9       0.56      0.51      0.53       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 1700, Loss: 1.871381402015686, F1: 0.5366224717929269, Accuracy: 0.5065721560801046, Time Elapsed: 363.99398398399353 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69       912\n",
      "           1       0.57      0.87      0.69       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.55      0.56      0.55       897\n",
      "           4       0.57      0.70      0.63       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.60      0.54      0.57       892\n",
      "           9       0.64      0.36      0.46       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.56      0.53     14531\n",
      "weighted avg       0.48      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 1800, Loss: 0.46367090940475464, F1: 0.5304848911549975, Accuracy: 0.5105636225999587, Time Elapsed: 382.95721793174744 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.54      0.92      0.68       885\n",
      "           2       0.59      0.67      0.62       877\n",
      "           3       0.56      0.44      0.49       897\n",
      "           4       0.54      0.84      0.66       892\n",
      "           5       0.57      0.37      0.45       862\n",
      "           6       0.62      0.74      0.68       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.59      0.54      0.56       892\n",
      "           9       0.59      0.55      0.57       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 1900, Loss: 0.8206316828727722, F1: 0.5798078090751063, Accuracy: 0.5204046521230473, Time Elapsed: 404.2113461494446 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.59      0.68      0.63       877\n",
      "           3       0.54      0.71      0.61       897\n",
      "           4       0.47      0.90      0.62       892\n",
      "           5       0.53      0.73      0.61       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.62      0.48      0.54       889\n",
      "           8       0.59      0.59      0.59       892\n",
      "           9       0.58      0.63      0.60       876\n",
      "          10       0.39      0.20      0.26      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.69      0.60     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 5, Step 2000, Loss: 1.395002841949463, F1: 0.6011706931118763, Accuracy: 0.5299015897047691, Time Elapsed: 424.60439705848694 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.60      0.66      0.63       885\n",
      "           2       0.60      0.64      0.62       877\n",
      "           3       0.57      0.40      0.47       897\n",
      "           4       0.57      0.27      0.36       892\n",
      "           5       0.54      0.23      0.32       862\n",
      "           6       0.60      0.83      0.70       903\n",
      "           7       0.61      0.60      0.60       889\n",
      "           8       0.53      0.05      0.09       892\n",
      "           9       0.57      0.58      0.57       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.51      0.50     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 2100, Loss: 0.5611076354980469, F1: 0.5008762252523046, Accuracy: 0.4954923955680958, Time Elapsed: 447.3994212150574 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.72       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.61      0.48      0.53       897\n",
      "           4       0.58      0.38      0.46       892\n",
      "           5       0.55      0.49      0.52       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.61      0.68      0.64       889\n",
      "           8       0.55      0.63      0.59       892\n",
      "           9       0.58      0.72      0.64       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 2200, Loss: 1.9787209033966064, F1: 0.5874378722987245, Accuracy: 0.5268735806207419, Time Elapsed: 468.7885320186615 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.60      0.87      0.71       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.61      0.42      0.50       897\n",
      "           4       0.58      0.46      0.51       892\n",
      "           5       0.55      0.31      0.40       862\n",
      "           6       0.62      0.79      0.69       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.59      0.66      0.63       892\n",
      "           9       0.61      0.68      0.64       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.58      0.61      0.58     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 2300, Loss: 0.5920916199684143, F1: 0.5793957831129192, Accuracy: 0.5259789415731884, Time Elapsed: 487.07675409317017 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67       912\n",
      "           1       0.54      0.96      0.69       885\n",
      "           2       0.59      0.45      0.51       877\n",
      "           3       0.58      0.60      0.59       897\n",
      "           4       0.55      0.82      0.66       892\n",
      "           5       0.57      0.60      0.58       862\n",
      "           6       0.61      0.68      0.64       903\n",
      "           7       0.61      0.71      0.65       889\n",
      "           8       0.57      0.78      0.66       892\n",
      "           9       0.60      0.61      0.60       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 2400, Loss: 0.4414803385734558, F1: 0.5981103784133589, Accuracy: 0.5281123116096621, Time Elapsed: 505.27001428604126 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69       912\n",
      "           1       0.61      0.50      0.55       885\n",
      "           2       0.66      0.10      0.17       877\n",
      "           3       0.59      0.58      0.58       897\n",
      "           4       0.58      0.35      0.43       892\n",
      "           5       0.53      0.78      0.63       862\n",
      "           6       0.63      0.09      0.16       903\n",
      "           7       0.59      0.76      0.67       889\n",
      "           8       0.61      0.51      0.56       892\n",
      "           9       0.62      0.45      0.52       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.50      0.49     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 2500, Loss: 0.946103036403656, F1: 0.48930265195272077, Accuracy: 0.49108801871860164, Time Elapsed: 520.9962842464447 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.57      0.94      0.71       885\n",
      "           2       0.61      0.19      0.29       877\n",
      "           3       0.59      0.75      0.66       897\n",
      "           4       0.56      0.65      0.60       892\n",
      "           5       0.45      0.89      0.60       862\n",
      "           6       0.60      0.80      0.68       903\n",
      "           7       0.61      0.64      0.62       889\n",
      "           8       0.53      0.78      0.63       892\n",
      "           9       0.60      0.61      0.61       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.58     14531\n",
      "weighted avg       0.50      0.52      0.48     14531\n",
      "\n",
      "Epoch 5, Step 2600, Loss: 0.5533731579780579, F1: 0.5822176232026867, Accuracy: 0.5242584818663547, Time Elapsed: 537.3979561328888 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.64      0.18      0.29       897\n",
      "           4       0.59      0.39      0.47       892\n",
      "           5       0.48      0.71      0.57       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.60      0.58      0.59       892\n",
      "           9       0.63      0.43      0.51       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.57      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 2700, Loss: 5.567961692810059, F1: 0.5542812904448634, Accuracy: 0.514004542013626, Time Elapsed: 555.9736838340759 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.03      0.06       912\n",
      "           1       0.62      0.56      0.59       885\n",
      "           2       0.60      0.43      0.50       877\n",
      "           3       0.60      0.04      0.08       897\n",
      "           4       0.56      0.82      0.67       892\n",
      "           5       0.53      0.46      0.50       862\n",
      "           6       0.60      0.85      0.70       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.54      0.80      0.65       892\n",
      "           9       0.56      0.84      0.67       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.50     14531\n",
      "weighted avg       0.51      0.50      0.46     14531\n",
      "\n",
      "Epoch 5, Step 2800, Loss: 0.23192286491394043, F1: 0.49642674972683415, Accuracy: 0.4987956782052164, Time Elapsed: 572.2729232311249 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.57      0.67      0.61       877\n",
      "           3       0.60      0.37      0.46       897\n",
      "           4       0.56      0.72      0.63       892\n",
      "           5       0.56      0.37      0.44       862\n",
      "           6       0.60      0.83      0.69       903\n",
      "           7       0.60      0.56      0.58       889\n",
      "           8       0.48      0.89      0.62       892\n",
      "           9       0.51      0.86      0.64       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 2900, Loss: 1.0858993530273438, F1: 0.5774197668777715, Accuracy: 0.5175142798155667, Time Elapsed: 588.5076551437378 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       912\n",
      "           1       0.61      0.67      0.64       885\n",
      "           2       0.55      0.73      0.62       877\n",
      "           3       0.51      0.86      0.64       897\n",
      "           4       0.55      0.68      0.61       892\n",
      "           5       0.54      0.66      0.60       862\n",
      "           6       0.57      0.88      0.69       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.58      0.66      0.62       892\n",
      "           9       0.59      0.72      0.65       876\n",
      "          10       0.39      0.21      0.27      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 3000, Loss: 3.3887457847595215, F1: 0.6087725791980974, Accuracy: 0.5332048723418897, Time Elapsed: 603.510176897049 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.61      0.30      0.40       877\n",
      "           3       0.59      0.69      0.64       897\n",
      "           4       0.55      0.16      0.25       892\n",
      "           5       0.50      0.77      0.61       862\n",
      "           6       0.56      0.90      0.69       903\n",
      "           7       0.61      0.68      0.64       889\n",
      "           8       0.58      0.63      0.61       892\n",
      "           9       0.58      0.70      0.63       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 3100, Loss: 0.5547018051147461, F1: 0.5634357996206734, Accuracy: 0.5193035579106737, Time Elapsed: 618.7518961429596 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       912\n",
      "           1       0.58      0.96      0.73       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.58      0.70      0.64       897\n",
      "           4       0.54      0.76      0.63       892\n",
      "           5       0.58      0.54      0.56       862\n",
      "           6       0.59      0.87      0.70       903\n",
      "           7       0.62      0.12      0.20       889\n",
      "           8       0.59      0.58      0.59       892\n",
      "           9       0.58      0.73      0.65       876\n",
      "          10       0.39      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.58     14531\n",
      "weighted avg       0.51      0.53      0.49     14531\n",
      "\n",
      "Epoch 5, Step 3200, Loss: 0.4036276638507843, F1: 0.5757315701309729, Accuracy: 0.5260477599614617, Time Elapsed: 633.789971113205 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.71       912\n",
      "           1       0.54      0.97      0.70       885\n",
      "           2       0.58      0.28      0.38       877\n",
      "           3       0.56      0.81      0.66       897\n",
      "           4       0.50      0.00      0.00       892\n",
      "           5       0.58      0.63      0.60       862\n",
      "           6       0.56      0.93      0.70       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.59      0.59      0.59       892\n",
      "           9       0.62      0.57      0.59       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.54     14531\n",
      "weighted avg       0.50      0.52      0.48     14531\n",
      "\n",
      "Epoch 5, Step 3300, Loss: 1.082625150680542, F1: 0.5408953960340243, Accuracy: 0.5179271901452068, Time Elapsed: 649.0870351791382 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.84      0.70       912\n",
      "           1       0.61      0.63      0.62       885\n",
      "           2       0.61      0.07      0.12       877\n",
      "           3       0.59      0.72      0.65       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.55      0.50      0.52       862\n",
      "           6       0.62      0.74      0.67       903\n",
      "           7       0.63      0.34      0.44       889\n",
      "           8       0.59      0.59      0.59       892\n",
      "           9       0.64      0.38      0.47       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.53      0.48      0.48     14531\n",
      "weighted avg       0.48      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 3400, Loss: 0.6694774031639099, F1: 0.4754641154322295, Accuracy: 0.49411602780262887, Time Elapsed: 665.9505362510681 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.60      0.23      0.33       877\n",
      "           3       0.57      0.75      0.65       897\n",
      "           4       0.49      0.05      0.10       892\n",
      "           5       0.54      0.64      0.58       862\n",
      "           6       0.63      0.25      0.36       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.52      0.82      0.64       892\n",
      "           9       0.63      0.40      0.49       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.51     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 3500, Loss: 0.9016716480255127, F1: 0.5115239929785167, Accuracy: 0.5018925056775171, Time Elapsed: 682.2413890361786 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64       912\n",
      "           1       0.60      0.82      0.69       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.59      0.60      0.59       897\n",
      "           4       0.00      0.00      0.00       892\n",
      "           5       0.51      0.73      0.60       862\n",
      "           6       0.59      0.82      0.69       903\n",
      "           7       0.60      0.75      0.67       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.62      0.57      0.59       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.58      0.54     14531\n",
      "weighted avg       0.48      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 3600, Loss: 1.658439040184021, F1: 0.5427254890065508, Accuracy: 0.5145550891198128, Time Elapsed: 697.3320372104645 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.69       912\n",
      "           1       0.60      0.49      0.54       885\n",
      "           2       0.57      0.63      0.60       877\n",
      "           3       0.62      0.41      0.49       897\n",
      "           4       0.53      0.87      0.66       892\n",
      "           5       0.55      0.52      0.54       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.59      0.37      0.45       892\n",
      "           9       0.61      0.61      0.61       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 3700, Loss: 0.5210442543029785, F1: 0.5742216410795365, Accuracy: 0.5194411946872204, Time Elapsed: 712.9543061256409 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.61      0.63      0.62       897\n",
      "           4       0.52      0.87      0.65       892\n",
      "           5       0.54      0.64      0.59       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.59      0.40      0.47       892\n",
      "           9       0.61      0.57      0.59       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 3800, Loss: 2.6102046966552734, F1: 0.598952558548678, Accuracy: 0.5314155942467828, Time Elapsed: 728.2084121704102 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.70       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.51      0.84      0.64       897\n",
      "           4       0.53      0.85      0.65       892\n",
      "           5       0.53      0.71      0.61       862\n",
      "           6       0.62      0.78      0.69       903\n",
      "           7       0.60      0.60      0.60       889\n",
      "           8       0.56      0.76      0.65       892\n",
      "           9       0.58      0.67      0.62       876\n",
      "          10       0.39      0.17      0.24      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.71      0.61     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 5, Step 3900, Loss: 0.363847941160202, F1: 0.6107363255740309, Accuracy: 0.5345124217190833, Time Elapsed: 743.5147321224213 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.59      0.60      0.59       877\n",
      "           3       0.62      0.57      0.59       897\n",
      "           4       0.55      0.59      0.57       892\n",
      "           5       0.52      0.66      0.58       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.56      0.85      0.68       889\n",
      "           8       0.57      0.62      0.59       892\n",
      "           9       0.59      0.06      0.11       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 4000, Loss: 0.34069910645484924, F1: 0.5598954656460751, Accuracy: 0.5185465556396669, Time Elapsed: 758.9240889549255 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01       912\n",
      "           1       0.60      0.39      0.47       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.61      0.43      0.50       897\n",
      "           4       0.58      0.48      0.53       892\n",
      "           5       0.55      0.26      0.36       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.61      0.49      0.54       889\n",
      "           8       0.59      0.51      0.54       892\n",
      "           9       0.53      0.74      0.62       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.49      0.48     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 5, Step 4100, Loss: 1.8406660556793213, F1: 0.4839917065410828, Accuracy: 0.48448145344436033, Time Elapsed: 775.1035771369934 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       912\n",
      "           1       0.57      0.19      0.29       885\n",
      "           2       0.57      0.74      0.65       877\n",
      "           3       0.60      0.51      0.55       897\n",
      "           4       0.49      0.93      0.64       892\n",
      "           5       0.58      0.34      0.43       862\n",
      "           6       0.61      0.83      0.70       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.60      0.55      0.57       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 4200, Loss: 0.5102787017822266, F1: 0.5475820856220275, Accuracy: 0.5079485238455715, Time Elapsed: 789.891077041626 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63       912\n",
      "           1       0.58      0.58      0.58       885\n",
      "           2       0.57      0.72      0.63       877\n",
      "           3       0.60      0.71      0.65       897\n",
      "           4       0.53      0.77      0.63       892\n",
      "           5       0.57      0.50      0.53       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.58      0.65      0.61       892\n",
      "           9       0.61      0.41      0.49       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 4300, Loss: 1.445205569267273, F1: 0.5801639568548193, Accuracy: 0.5186153740279402, Time Elapsed: 805.0225579738617 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.55       912\n",
      "           1       0.60      0.91      0.73       885\n",
      "           2       0.60      0.43      0.50       877\n",
      "           3       0.59      0.74      0.66       897\n",
      "           4       0.58      0.53      0.55       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.59      0.25      0.35       889\n",
      "           8       0.57      0.55      0.56       892\n",
      "           9       0.60      0.49      0.54       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.49      0.49     14531\n",
      "weighted avg       0.48      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 4400, Loss: 1.72833251953125, F1: 0.4935534001866721, Accuracy: 0.4923955680957952, Time Elapsed: 821.286327123642 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.09      0.15       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.59      0.36      0.44       877\n",
      "           3       0.52      0.75      0.62       897\n",
      "           4       0.57      0.58      0.58       892\n",
      "           5       0.43      0.90      0.58       862\n",
      "           6       0.59      0.80      0.68       903\n",
      "           7       0.61      0.72      0.66       889\n",
      "           8       0.60      0.55      0.57       892\n",
      "           9       0.61      0.60      0.60       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.55      0.59      0.54     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 4500, Loss: 3.2000298500061035, F1: 0.5399668520021546, Accuracy: 0.5018925056775171, Time Elapsed: 837.0857520103455 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01       912\n",
      "           1       0.61      0.65      0.63       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.58      0.78      0.66       897\n",
      "           4       0.58      0.48      0.52       892\n",
      "           5       0.56      0.58      0.57       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.57      0.54      0.55       892\n",
      "           9       0.60      0.58      0.59       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.56      0.53     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 4600, Loss: 1.5683125257492065, F1: 0.532755636417154, Accuracy: 0.506640974468378, Time Elapsed: 852.9400601387024 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.00      0.00       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.57      0.63      0.60       877\n",
      "           3       0.60      0.74      0.66       897\n",
      "           4       0.58      0.51      0.54       892\n",
      "           5       0.55      0.47      0.51       862\n",
      "           6       0.62      0.63      0.63       903\n",
      "           7       0.60      0.63      0.62       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.53      0.69      0.60       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.55      0.53     14531\n",
      "weighted avg       0.49      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 4700, Loss: 1.5725423097610474, F1: 0.5269037640995439, Accuracy: 0.5031312366664372, Time Elapsed: 869.0326750278473 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.19      0.29       912\n",
      "           1       0.59      0.67      0.62       885\n",
      "           2       0.61      0.41      0.49       877\n",
      "           3       0.60      0.59      0.60       897\n",
      "           4       0.56      0.75      0.64       892\n",
      "           5       0.54      0.18      0.27       862\n",
      "           6       0.63      0.65      0.64       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.59      0.28      0.38       892\n",
      "           9       0.70      0.09      0.16       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.46      0.47     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 4800, Loss: 0.5776350498199463, F1: 0.4736322610813666, Accuracy: 0.48757828091666094, Time Elapsed: 885.2660789489746 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65       912\n",
      "           1       0.57      0.11      0.18       885\n",
      "           2       0.60      0.63      0.61       877\n",
      "           3       0.55      0.27      0.36       897\n",
      "           4       0.59      0.71      0.64       892\n",
      "           5       0.54      0.44      0.48       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.59      0.82      0.69       889\n",
      "           8       0.53      0.76      0.63       892\n",
      "           9       0.58      0.32      0.42       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.54      0.52     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 4900, Loss: 1.11741304397583, F1: 0.522042673401189, Accuracy: 0.4998279540293166, Time Elapsed: 900.8069748878479 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.70       912\n",
      "           1       0.56      0.40      0.47       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.56      0.60      0.58       892\n",
      "           5       0.53      0.14      0.23       862\n",
      "           6       0.61      0.49      0.54       903\n",
      "           7       0.59      0.74      0.66       889\n",
      "           8       0.58      0.65      0.61       892\n",
      "           9       0.57      0.70      0.63       876\n",
      "          10       0.38      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 5000, Loss: 1.437002182006836, F1: 0.536984811273398, Accuracy: 0.5015484137361503, Time Elapsed: 916.1270930767059 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.58      0.19      0.28       885\n",
      "           2       0.61      0.57      0.59       877\n",
      "           3       0.57      0.38      0.45       897\n",
      "           4       0.55      0.88      0.68       892\n",
      "           5       0.54      0.65      0.59       862\n",
      "           6       0.61      0.61      0.61       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.56      0.71      0.63       892\n",
      "           9       0.59      0.67      0.62       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 5100, Loss: 0.18123550713062286, F1: 0.5615788486690104, Accuracy: 0.5132475397426193, Time Elapsed: 931.6521170139313 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.16      0.26       912\n",
      "           1       0.45      0.03      0.06       885\n",
      "           2       0.59      0.44      0.50       877\n",
      "           3       0.58      0.30      0.39       897\n",
      "           4       0.58      0.77      0.66       892\n",
      "           5       0.53      0.61      0.57       862\n",
      "           6       0.60      0.74      0.66       903\n",
      "           7       0.62      0.30      0.40       889\n",
      "           8       0.55      0.71      0.62       892\n",
      "           9       0.59      0.60      0.60       876\n",
      "          10       0.39      0.51      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.47      0.47     14531\n",
      "weighted avg       0.50      0.48      0.46     14531\n",
      "\n",
      "Epoch 5, Step 5200, Loss: 1.421303391456604, F1: 0.47021424486903646, Accuracy: 0.4814534443603331, Time Elapsed: 947.815416097641 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       912\n",
      "           1       0.58      0.80      0.67       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.55      0.63      0.59       897\n",
      "           4       0.55      0.83      0.66       892\n",
      "           5       0.54      0.65      0.59       862\n",
      "           6       0.51      0.94      0.66       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.58      0.49      0.53       892\n",
      "           9       0.57      0.64      0.60       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 5300, Loss: 0.777720034122467, F1: 0.5882491245245721, Accuracy: 0.5208175624526874, Time Elapsed: 963.923574924469 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.89      0.70       912\n",
      "           1       0.61      0.45      0.52       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.59      0.43      0.50       897\n",
      "           4       0.58      0.67      0.62       892\n",
      "           5       0.51      0.66      0.58       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.60      0.60      0.60       889\n",
      "           8       0.52      0.80      0.63       892\n",
      "           9       0.59      0.77      0.67       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 5400, Loss: 0.37481772899627686, F1: 0.5831372611857198, Accuracy: 0.5212304727823275, Time Elapsed: 979.5704119205475 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.57      0.27      0.36       885\n",
      "           2       0.58      0.73      0.65       877\n",
      "           3       0.59      0.42      0.49       897\n",
      "           4       0.58      0.32      0.41       892\n",
      "           5       0.51      0.27      0.35       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.38      0.01      0.01       889\n",
      "           8       0.58      0.70      0.63       892\n",
      "           9       0.45      0.90      0.60       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.53      0.50      0.48     14531\n",
      "weighted avg       0.49      0.48      0.46     14531\n",
      "\n",
      "Epoch 5, Step 5500, Loss: 0.690096914768219, F1: 0.4757109898739188, Accuracy: 0.4827609937375267, Time Elapsed: 994.872239112854 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.50      0.19      0.28       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.59      0.41      0.49       897\n",
      "           4       0.51      0.89      0.64       892\n",
      "           5       0.46      0.55      0.50       862\n",
      "           6       0.52      0.92      0.67       903\n",
      "           7       0.62      0.39      0.48       889\n",
      "           8       0.58      0.34      0.43       892\n",
      "           9       0.59      0.71      0.64       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.55      0.52     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 5, Step 5600, Loss: 0.8513081073760986, F1: 0.5206278413067311, Accuracy: 0.4923955680957952, Time Elapsed: 1011.5591289997101 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.01       912\n",
      "           1       0.49      0.08      0.14       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.54      0.71      0.61       897\n",
      "           4       0.51      0.93      0.66       892\n",
      "           5       0.50      0.45      0.47       862\n",
      "           6       0.53      0.92      0.68       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.61      0.64      0.62       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.53      0.55      0.49     14531\n",
      "weighted avg       0.49      0.50      0.46     14531\n",
      "\n",
      "Epoch 5, Step 5700, Loss: 0.18665508925914764, F1: 0.4935851028655431, Accuracy: 0.49514830362672907, Time Elapsed: 1027.378216266632 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.01      0.01       912\n",
      "           1       0.60      0.74      0.66       885\n",
      "           2       0.60      0.64      0.62       877\n",
      "           3       0.56      0.65      0.60       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.51      0.47      0.49       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.59      0.85      0.69       889\n",
      "           8       0.59      0.51      0.54       892\n",
      "           9       0.60      0.68      0.64       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 5800, Loss: 1.3353782892227173, F1: 0.5421250776966858, Accuracy: 0.512008808753699, Time Elapsed: 1043.3363921642303 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.00      0.01       912\n",
      "           1       0.57      0.76      0.65       885\n",
      "           2       0.57      0.36      0.44       877\n",
      "           3       0.56      0.61      0.58       897\n",
      "           4       0.55      0.76      0.63       892\n",
      "           5       0.52      0.45      0.48       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.56      0.36      0.44       892\n",
      "           9       0.61      0.66      0.63       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.53      0.51     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 5900, Loss: 0.5830173492431641, F1: 0.509431695801083, Accuracy: 0.4961805794508293, Time Elapsed: 1061.2156159877777 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.59      0.67      0.63       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.56      0.83      0.67       892\n",
      "           5       0.52      0.58      0.55       862\n",
      "           6       0.60      0.80      0.68       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.56      0.57      0.56       892\n",
      "           9       0.56      0.82      0.66       876\n",
      "          10       0.40      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 6000, Loss: 0.8350494503974915, F1: 0.5995324844907935, Accuracy: 0.5305897735875026, Time Elapsed: 1076.6238062381744 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       912\n",
      "           1       0.43      0.01      0.03       885\n",
      "           2       0.62      0.32      0.42       877\n",
      "           3       0.53      0.12      0.20       897\n",
      "           4       0.59      0.22      0.32       892\n",
      "           5       0.56      0.18      0.28       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.55      0.90      0.68       889\n",
      "           8       0.59      0.40      0.48       892\n",
      "           9       0.60      0.51      0.55       876\n",
      "          10       0.39      0.54      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.55      0.45      0.44     14531\n",
      "weighted avg       0.50      0.48      0.44     14531\n",
      "\n",
      "Epoch 5, Step 6100, Loss: 0.2476332187652588, F1: 0.4351003256597593, Accuracy: 0.47918243754731266, Time Elapsed: 1091.018632888794 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.57      0.51      0.54       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.49      0.76      0.59       897\n",
      "           4       0.59      0.41      0.48       892\n",
      "           5       0.54      0.31      0.39       862\n",
      "           6       0.59      0.80      0.68       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.55      0.30      0.39       892\n",
      "           9       0.59      0.49      0.53       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.54     14531\n",
      "weighted avg       0.50      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 6200, Loss: 2.612703323364258, F1: 0.5361076738172117, Accuracy: 0.49996559080586334, Time Elapsed: 1106.4901700019836 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71       912\n",
      "           1       0.54      0.97      0.69       885\n",
      "           2       0.60      0.43      0.50       877\n",
      "           3       0.58      0.44      0.50       897\n",
      "           4       0.57      0.74      0.64       892\n",
      "           5       0.51      0.79      0.62       862\n",
      "           6       0.59      0.65      0.62       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.57      0.56      0.57       892\n",
      "           9       0.60      0.63      0.61       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.58     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 6300, Loss: 0.7907764315605164, F1: 0.5835252554448216, Accuracy: 0.5197852866285871, Time Elapsed: 1120.795084953308 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.26      0.36       912\n",
      "           1       0.63      0.12      0.20       885\n",
      "           2       0.58      0.11      0.19       877\n",
      "           3       0.49      0.74      0.59       897\n",
      "           4       0.57      0.67      0.62       892\n",
      "           5       0.55      0.43      0.48       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.59      0.71      0.65       889\n",
      "           8       0.58      0.52      0.55       892\n",
      "           9       0.62      0.35      0.45       876\n",
      "          10       0.39      0.49      0.44      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.48      0.47     14531\n",
      "weighted avg       0.51      0.48      0.46     14531\n",
      "\n",
      "Epoch 5, Step 6400, Loss: 0.7493202686309814, F1: 0.47414081137087916, Accuracy: 0.48289863051407333, Time Elapsed: 1347.348140001297 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.71       912\n",
      "           1       0.65      0.18      0.28       885\n",
      "           2       0.63      0.08      0.15       877\n",
      "           3       0.53      0.69      0.60       897\n",
      "           4       0.58      0.66      0.62       892\n",
      "           5       0.55      0.68      0.61       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.58      0.53      0.56       892\n",
      "           9       0.55      0.83      0.66       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 6500, Loss: 0.4228021204471588, F1: 0.537421303346059, Accuracy: 0.5121464455302457, Time Elapsed: 1363.477807044983 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.62      0.27      0.38       885\n",
      "           2       0.63      0.31      0.41       877\n",
      "           3       0.54      0.71      0.62       897\n",
      "           4       0.59      0.53      0.56       892\n",
      "           5       0.55      0.71      0.62       862\n",
      "           6       0.61      0.78      0.69       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.53      0.68      0.59       892\n",
      "           9       0.59      0.72      0.65       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 6600, Loss: 1.104318618774414, F1: 0.567408808622985, Accuracy: 0.5188218291927603, Time Elapsed: 1379.845535993576 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.54      0.91      0.67       892\n",
      "           5       0.51      0.60      0.55       862\n",
      "           6       0.55      0.90      0.68       903\n",
      "           7       0.61      0.70      0.65       889\n",
      "           8       0.51      0.78      0.62       892\n",
      "           9       0.60      0.28      0.38       876\n",
      "          10       0.40      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.50      0.57      0.51     14531\n",
      "weighted avg       0.46      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 6700, Loss: 6.899417877197266, F1: 0.514591062758409, Accuracy: 0.5021677792306104, Time Elapsed: 1395.5634591579437 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66       912\n",
      "           1       0.64      0.19      0.29       885\n",
      "           2       0.59      0.49      0.54       877\n",
      "           3       0.59      0.19      0.29       897\n",
      "           4       0.51      0.94      0.66       892\n",
      "           5       0.49      0.54      0.52       862\n",
      "           6       0.61      0.24      0.34       903\n",
      "           7       0.61      0.38      0.47       889\n",
      "           8       0.53      0.68      0.60       892\n",
      "           9       0.61      0.57      0.59       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.56      0.49      0.49     14531\n",
      "weighted avg       0.51      0.48      0.47     14531\n",
      "\n",
      "Epoch 5, Step 6800, Loss: 0.9174237251281738, F1: 0.4882234306923689, Accuracy: 0.48248572018443325, Time Elapsed: 1411.1748900413513 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.61      0.82      0.70       885\n",
      "           2       0.61      0.31      0.41       877\n",
      "           3       0.60      0.20      0.30       897\n",
      "           4       0.55      0.88      0.67       892\n",
      "           5       0.48      0.67      0.56       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.61      0.33      0.42       889\n",
      "           8       0.52      0.75      0.61       892\n",
      "           9       0.57      0.17      0.26       876\n",
      "          10       0.40      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 6900, Loss: 0.7650384306907654, F1: 0.5207604137617817, Accuracy: 0.5028559631133439, Time Elapsed: 1426.3532421588898 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.92      0.70       912\n",
      "           1       0.62      0.38      0.47       885\n",
      "           2       0.60      0.44      0.51       877\n",
      "           3       0.59      0.49      0.53       897\n",
      "           4       0.54      0.60      0.57       892\n",
      "           5       0.55      0.45      0.49       862\n",
      "           6       0.55      0.91      0.69       903\n",
      "           7       0.60      0.56      0.58       889\n",
      "           8       0.59      0.45      0.51       892\n",
      "           9       0.62      0.22      0.33       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.53      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 7000, Loss: 1.5144730806350708, F1: 0.5257769285951026, Accuracy: 0.4967999449452894, Time Elapsed: 1442.0267980098724 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.60      0.66      0.63       885\n",
      "           2       0.57      0.10      0.17       877\n",
      "           3       0.52      0.75      0.61       897\n",
      "           4       0.56      0.47      0.51       892\n",
      "           5       0.57      0.37      0.45       862\n",
      "           6       0.57      0.88      0.69       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.56      0.69      0.62       892\n",
      "           9       0.58      0.71      0.64       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.60      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 7100, Loss: 1.1927369832992554, F1: 0.5492938730889084, Accuracy: 0.5113206248709655, Time Elapsed: 1457.3900270462036 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.64      0.42      0.51       877\n",
      "           3       0.57      0.62      0.59       897\n",
      "           4       0.50      0.87      0.64       892\n",
      "           5       0.56      0.36      0.44       862\n",
      "           6       0.58      0.87      0.70       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.58      0.61      0.59       892\n",
      "           9       0.59      0.49      0.53       876\n",
      "          10       0.40      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.64      0.58     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 7200, Loss: 0.8986095786094666, F1: 0.5835356815598552, Accuracy: 0.526116578349735, Time Elapsed: 1473.6183350086212 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.59      0.65      0.62       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.53      0.91      0.67       892\n",
      "           5       0.54      0.59      0.56       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.64      0.39      0.49       889\n",
      "           8       0.58      0.45      0.51       892\n",
      "           9       0.59      0.68      0.63       876\n",
      "          10       0.40      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 7300, Loss: 5.242473602294922, F1: 0.5796956871808596, Accuracy: 0.5250843025256349, Time Elapsed: 1491.218158006668 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70       912\n",
      "           1       0.61      0.54      0.57       885\n",
      "           2       0.60      0.11      0.19       877\n",
      "           3       0.60      0.36      0.45       897\n",
      "           4       0.54      0.86      0.66       892\n",
      "           5       0.54      0.37      0.44       862\n",
      "           6       0.00      0.00      0.00       903\n",
      "           7       0.61      0.68      0.64       889\n",
      "           8       0.58      0.44      0.50       892\n",
      "           9       0.64      0.24      0.35       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.45      0.45     14531\n",
      "weighted avg       0.48      0.48      0.45     14531\n",
      "\n",
      "Epoch 5, Step 7400, Loss: 1.0815258026123047, F1: 0.4514510420358958, Accuracy: 0.4809028972541463, Time Elapsed: 1507.2648618221283 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.60      0.89      0.72       885\n",
      "           2       0.63      0.14      0.24       877\n",
      "           3       0.59      0.42      0.49       897\n",
      "           4       0.58      0.57      0.58       892\n",
      "           5       0.57      0.17      0.26       862\n",
      "           6       0.58      0.85      0.69       903\n",
      "           7       0.51      0.89      0.65       889\n",
      "           8       0.55      0.09      0.16       892\n",
      "           9       0.58      0.80      0.67       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.54      0.50     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 7500, Loss: 1.3565815687179565, F1: 0.5012763136213282, Accuracy: 0.501686050512697, Time Elapsed: 1522.986290216446 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.62      0.49      0.55       885\n",
      "           2       0.60      0.14      0.22       877\n",
      "           3       0.54      0.72      0.62       897\n",
      "           4       0.59      0.43      0.50       892\n",
      "           5       0.53      0.12      0.19       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.58      0.81      0.68       889\n",
      "           8       0.57      0.53      0.55       892\n",
      "           9       0.60      0.57      0.59       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 7600, Loss: 0.6502033472061157, F1: 0.5170074753432764, Accuracy: 0.5025118711719772, Time Elapsed: 1538.8908231258392 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.61      0.84      0.70       885\n",
      "           2       0.62      0.45      0.52       877\n",
      "           3       0.37      0.90      0.52       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.54      0.06      0.11       862\n",
      "           6       0.55      0.85      0.67       903\n",
      "           7       0.59      0.61      0.60       889\n",
      "           8       0.56      0.62      0.59       892\n",
      "           9       0.57      0.04      0.07       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.57      0.50     14531\n",
      "weighted avg       0.49      0.49      0.45     14531\n",
      "\n",
      "Epoch 5, Step 7700, Loss: 0.14038649201393127, F1: 0.49866365437220855, Accuracy: 0.4898492877296814, Time Elapsed: 1554.3761992454529 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.59      0.82      0.69       885\n",
      "           2       0.61      0.47      0.53       877\n",
      "           3       0.55      0.74      0.63       897\n",
      "           4       0.58      0.65      0.61       892\n",
      "           5       0.56      0.62      0.59       862\n",
      "           6       0.55      0.88      0.68       903\n",
      "           7       0.54      0.91      0.68       889\n",
      "           8       0.58      0.55      0.57       892\n",
      "           9       0.59      0.67      0.63       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 7800, Loss: 1.387485146522522, F1: 0.6002497796696008, Accuracy: 0.5313467758585094, Time Elapsed: 1570.064054965973 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.90      0.72       912\n",
      "           1       0.60      0.62      0.61       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.56      0.79      0.66       892\n",
      "           5       0.55      0.48      0.51       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.53      0.75      0.62       892\n",
      "           9       0.60      0.70      0.65       876\n",
      "          10       0.39      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 7900, Loss: 0.3814930021762848, F1: 0.5986482982928788, Accuracy: 0.5309338655288693, Time Elapsed: 1585.7003262043 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66       912\n",
      "           1       0.60      0.21      0.32       885\n",
      "           2       0.59      0.60      0.60       877\n",
      "           3       0.59      0.59      0.59       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.55      0.19      0.29       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.59      0.78      0.67       889\n",
      "           8       0.55      0.67      0.60       892\n",
      "           9       0.57      0.79      0.66       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 8000, Loss: 0.8046720623970032, F1: 0.5522089916869248, Accuracy: 0.5140733604018994, Time Elapsed: 1601.4645931720734 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72       912\n",
      "           1       0.61      0.78      0.68       885\n",
      "           2       0.57      0.72      0.64       877\n",
      "           3       0.56      0.73      0.63       897\n",
      "           4       0.58      0.64      0.61       892\n",
      "           5       0.55      0.28      0.37       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.61      0.66      0.63       889\n",
      "           8       0.49      0.86      0.62       892\n",
      "           9       0.59      0.70      0.64       876\n",
      "          10       0.41      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 8100, Loss: 0.4883030951023102, F1: 0.5966280463954777, Accuracy: 0.5338242378363499, Time Elapsed: 1617.5680000782013 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       912\n",
      "           1       0.62      0.80      0.70       885\n",
      "           2       0.64      0.37      0.47       877\n",
      "           3       0.62      0.34      0.44       897\n",
      "           4       0.58      0.77      0.66       892\n",
      "           5       0.57      0.31      0.40       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.59      0.58      0.58       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.58      0.78      0.67       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.58      0.57     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 8200, Loss: 1.276788592338562, F1: 0.5661668506902298, Accuracy: 0.5219186566650609, Time Elapsed: 1633.2431030273438 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.61      0.42      0.49       877\n",
      "           3       0.62      0.39      0.48       897\n",
      "           4       0.57      0.86      0.68       892\n",
      "           5       0.56      0.61      0.58       862\n",
      "           6       0.62      0.75      0.68       903\n",
      "           7       0.60      0.53      0.56       889\n",
      "           8       0.54      0.75      0.63       892\n",
      "           9       0.63      0.08      0.14       876\n",
      "          10       0.40      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.58      0.55     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 8300, Loss: 1.6128880977630615, F1: 0.5482728251897625, Accuracy: 0.5183401004748469, Time Elapsed: 1648.9795498847961 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.61      0.88      0.73       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.60      0.01      0.02       897\n",
      "           4       0.56      0.89      0.68       892\n",
      "           5       0.54      0.45      0.49       862\n",
      "           6       0.60      0.74      0.66       903\n",
      "           7       0.61      0.64      0.62       889\n",
      "           8       0.54      0.65      0.59       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.54      0.49     14531\n",
      "weighted avg       0.48      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 8400, Loss: 0.3225213587284088, F1: 0.49262256977651214, Accuracy: 0.5027871447250706, Time Elapsed: 1664.3945488929749 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       912\n",
      "           1       0.62      0.88      0.73       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.67      0.11      0.19       897\n",
      "           4       0.55      0.90      0.68       892\n",
      "           5       0.49      0.80      0.61       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.58      0.20      0.30       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.40      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.55      0.50     14531\n",
      "weighted avg       0.48      0.51      0.47     14531\n",
      "\n",
      "Epoch 5, Step 8500, Loss: 0.6232283711433411, F1: 0.49730333191683196, Accuracy: 0.5058151538090978, Time Elapsed: 1681.0018858909607 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.62      0.43      0.51       885\n",
      "           2       0.63      0.36      0.46       877\n",
      "           3       0.56      0.75      0.64       897\n",
      "           4       0.57      0.77      0.65       892\n",
      "           5       0.55      0.51      0.52       862\n",
      "           6       0.63      0.59      0.61       903\n",
      "           7       0.50      0.91      0.65       889\n",
      "           8       0.57      0.67      0.61       892\n",
      "           9       0.61      0.24      0.34       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 8600, Loss: 0.8485133051872253, F1: 0.5521536773186131, Accuracy: 0.5100818938820453, Time Elapsed: 1697.0329740047455 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.58      0.10      0.17       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.61      0.43      0.51       897\n",
      "           4       0.54      0.93      0.68       892\n",
      "           5       0.56      0.55      0.55       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.58      0.87      0.70       889\n",
      "           8       0.55      0.70      0.62       892\n",
      "           9       0.59      0.75      0.66       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 8700, Loss: 1.331979513168335, F1: 0.563503558202984, Accuracy: 0.5217122015002409, Time Elapsed: 1712.6378769874573 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.53      0.77      0.62       897\n",
      "           4       0.56      0.84      0.67       892\n",
      "           5       0.52      0.76      0.62       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.47      0.80      0.59       892\n",
      "           9       0.59      0.70      0.64       876\n",
      "          10       0.40      0.16      0.23      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.55      0.72      0.61     14531\n",
      "weighted avg       0.50      0.54      0.49     14531\n",
      "\n",
      "Epoch 5, Step 8800, Loss: 1.75845468044281, F1: 0.61422071329087, Accuracy: 0.5375404308031105, Time Elapsed: 1727.299357175827 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.60      0.84      0.70       885\n",
      "           2       0.64      0.37      0.46       877\n",
      "           3       0.54      0.72      0.62       897\n",
      "           4       0.57      0.83      0.68       892\n",
      "           5       0.50      0.74      0.60       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.58      0.87      0.69       889\n",
      "           8       0.52      0.72      0.60       892\n",
      "           9       0.59      0.71      0.65       876\n",
      "          10       0.41      0.21      0.28      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 8900, Loss: 1.314175009727478, F1: 0.6058498829266952, Accuracy: 0.5371963388617439, Time Elapsed: 1743.2384428977966 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.72       912\n",
      "           1       0.62      0.53      0.57       885\n",
      "           2       0.59      0.04      0.07       877\n",
      "           3       0.56      0.70      0.62       897\n",
      "           4       0.55      0.90      0.68       892\n",
      "           5       0.50      0.35      0.41       862\n",
      "           6       0.61      0.71      0.65       903\n",
      "           7       0.60      0.59      0.60       889\n",
      "           8       0.53      0.54      0.53       892\n",
      "           9       0.58      0.07      0.13       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.52      0.49     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 9000, Loss: 0.472421795129776, F1: 0.4904843362422238, Accuracy: 0.4952171220150024, Time Elapsed: 1758.8886771202087 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.62      0.36      0.46       885\n",
      "           2       0.60      0.63      0.61       877\n",
      "           3       0.59      0.27      0.37       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.52      0.23      0.32       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.64      0.32      0.43       889\n",
      "           8       0.53      0.52      0.53       892\n",
      "           9       0.59      0.37      0.46       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.51      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 9100, Loss: 0.8540314435958862, F1: 0.5127401733333201, Accuracy: 0.4958364875094625, Time Elapsed: 1774.5204861164093 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.86      0.70       912\n",
      "           1       0.58      0.96      0.72       885\n",
      "           2       0.57      0.78      0.66       877\n",
      "           3       0.60      0.38      0.46       897\n",
      "           4       0.57      0.57      0.57       892\n",
      "           5       0.51      0.28      0.36       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.61      0.75      0.67       889\n",
      "           8       0.58      0.43      0.50       892\n",
      "           9       0.58      0.67      0.62       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 9200, Loss: 0.35527315735816956, F1: 0.5731116263455107, Accuracy: 0.521161654394054, Time Elapsed: 1791.0096220970154 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.61      0.88      0.72       885\n",
      "           2       0.57      0.75      0.65       877\n",
      "           3       0.60      0.40      0.48       897\n",
      "           4       0.57      0.54      0.55       892\n",
      "           5       0.51      0.19      0.27       862\n",
      "           6       0.60      0.80      0.68       903\n",
      "           7       0.61      0.77      0.68       889\n",
      "           8       0.57      0.70      0.63       892\n",
      "           9       0.61      0.27      0.38       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.59      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 9300, Loss: 1.4312448501586914, F1: 0.556181309636425, Accuracy: 0.5172390062624733, Time Elapsed: 1806.6701080799103 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.67      0.30      0.41       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.59      0.48      0.53       897\n",
      "           4       0.57      0.50      0.53       892\n",
      "           5       0.53      0.06      0.10       862\n",
      "           6       0.62      0.48      0.54       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.46      0.87      0.60       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.49      0.46     14531\n",
      "weighted avg       0.47      0.49      0.45     14531\n",
      "\n",
      "Epoch 5, Step 9400, Loss: 0.8768149018287659, F1: 0.4645788055682319, Accuracy: 0.48523845571536717, Time Elapsed: 1822.0077080726624 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.10      0.17       912\n",
      "           1       0.62      0.69      0.65       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.59      0.43      0.50       897\n",
      "           4       0.56      0.65      0.60       892\n",
      "           5       0.56      0.36      0.44       862\n",
      "           6       0.58      0.86      0.69       903\n",
      "           7       0.60      0.43      0.50       889\n",
      "           8       0.55      0.43      0.48       892\n",
      "           9       0.49      0.88      0.63       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.54      0.52     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 5, Step 9500, Loss: 0.6541728377342224, F1: 0.5168294074743289, Accuracy: 0.4926708416488886, Time Elapsed: 1837.6773009300232 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.63      0.76      0.69       885\n",
      "           2       0.57      0.69      0.62       877\n",
      "           3       0.60      0.51      0.55       897\n",
      "           4       0.60      0.60      0.60       892\n",
      "           5       0.53      0.40      0.46       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.57      0.83      0.67       889\n",
      "           8       0.56      0.55      0.55       892\n",
      "           9       0.61      0.34      0.44       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 9600, Loss: 2.1929943561553955, F1: 0.574552238353401, Accuracy: 0.5215745647236941, Time Elapsed: 1853.680890083313 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71       912\n",
      "           1       0.60      0.53      0.56       885\n",
      "           2       0.60      0.49      0.54       877\n",
      "           3       0.60      0.35      0.44       897\n",
      "           4       0.59      0.68      0.63       892\n",
      "           5       0.52      0.40      0.45       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.57      0.88      0.69       889\n",
      "           8       0.53      0.73      0.62       892\n",
      "           9       0.59      0.64      0.61       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.60      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 9700, Loss: 0.16850338876247406, F1: 0.5690221388917193, Accuracy: 0.5151744546142729, Time Elapsed: 1869.5154612064362 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.61      0.19      0.29       885\n",
      "           2       0.58      0.07      0.13       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.54      0.88      0.67       892\n",
      "           5       0.55      0.46      0.50       862\n",
      "           6       0.61      0.60      0.60       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.55      0.58      0.56       892\n",
      "           9       0.56      0.68      0.62       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 9800, Loss: 0.37992286682128906, F1: 0.5156551070317608, Accuracy: 0.5001720459706833, Time Elapsed: 1885.1570422649384 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.60      0.46      0.52       885\n",
      "           2       0.63      0.10      0.17       877\n",
      "           3       0.54      0.77      0.63       897\n",
      "           4       0.58      0.42      0.48       892\n",
      "           5       0.56      0.44      0.50       862\n",
      "           6       0.60      0.73      0.66       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.59      0.43      0.50       892\n",
      "           9       0.45      0.91      0.60       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.57      0.53     14531\n",
      "weighted avg       0.50      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 9900, Loss: 1.479903221130371, F1: 0.5281906010200227, Accuracy: 0.49838276787557634, Time Elapsed: 1901.2891671657562 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66       912\n",
      "           1       0.59      0.13      0.22       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.52      0.72      0.60       897\n",
      "           4       0.51      0.88      0.65       892\n",
      "           5       0.57      0.23      0.33       862\n",
      "           6       0.58      0.86      0.69       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.58      0.62      0.60       892\n",
      "           9       0.58      0.52      0.55       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.54     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 10000, Loss: 1.9728188514709473, F1: 0.5440202694468289, Accuracy: 0.5110453513178721, Time Elapsed: 1916.9402360916138 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       912\n",
      "           1       0.57      0.38      0.46       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.54      0.71      0.61       897\n",
      "           4       0.55      0.78      0.65       892\n",
      "           5       0.56      0.54      0.55       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.58      0.84      0.69       889\n",
      "           8       0.59      0.58      0.59       892\n",
      "           9       0.50      0.90      0.65       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.65      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 10100, Loss: 0.8039968609809875, F1: 0.5883034147417384, Accuracy: 0.5221939302181543, Time Elapsed: 1932.5740330219269 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.50      0.85      0.63       877\n",
      "           3       0.57      0.69      0.62       897\n",
      "           4       0.52      0.89      0.66       892\n",
      "           5       0.57      0.48      0.52       862\n",
      "           6       0.52      0.92      0.66       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.57      0.60      0.59       892\n",
      "           9       0.59      0.47      0.52       876\n",
      "          10       0.40      0.21      0.27      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.55      0.68      0.59     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 5, Step 10200, Loss: 1.184473991394043, F1: 0.5936688096493717, Accuracy: 0.526116578349735, Time Elapsed: 1948.719253063202 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.60      0.93      0.73       885\n",
      "           2       0.58      0.73      0.64       877\n",
      "           3       0.56      0.74      0.63       897\n",
      "           4       0.56      0.81      0.67       892\n",
      "           5       0.57      0.45      0.50       862\n",
      "           6       0.54      0.92      0.68       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.54      0.74      0.63       892\n",
      "           9       0.55      0.78      0.65       876\n",
      "          10       0.39      0.15      0.22      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.55      0.73      0.61     14531\n",
      "weighted avg       0.50      0.54      0.48     14531\n",
      "\n",
      "Epoch 5, Step 10300, Loss: 1.3687525987625122, F1: 0.6134930264478791, Accuracy: 0.5404996214988645, Time Elapsed: 2144.330950021744 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.59      0.79      0.68       885\n",
      "           2       0.59      0.69      0.63       877\n",
      "           3       0.58      0.68      0.63       897\n",
      "           4       0.57      0.79      0.66       892\n",
      "           5       0.56      0.51      0.53       862\n",
      "           6       0.61      0.72      0.66       903\n",
      "           7       0.58      0.86      0.69       889\n",
      "           8       0.57      0.28      0.38       892\n",
      "           9       0.63      0.02      0.04       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.60      0.54     14531\n",
      "weighted avg       0.51      0.52      0.48     14531\n",
      "\n",
      "Epoch 5, Step 10400, Loss: 1.3726774454116821, F1: 0.5437281798161324, Accuracy: 0.5160690936618264, Time Elapsed: 2161.8006262779236 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.61      0.59      0.60       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.60      0.52      0.56       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.54      0.70      0.61       862\n",
      "           6       0.58      0.77      0.66       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.57      0.35      0.44       892\n",
      "           9       0.80      0.02      0.04       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.59      0.57      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 10500, Loss: 0.41525402665138245, F1: 0.533500171679865, Accuracy: 0.5085678893400316, Time Elapsed: 2177.537344932556 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.63      0.48      0.54       885\n",
      "           2       0.59      0.68      0.63       877\n",
      "           3       0.51      0.84      0.64       897\n",
      "           4       0.58      0.68      0.63       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.56      0.52      0.54       892\n",
      "           9       0.54      0.64      0.58       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.59     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 10600, Loss: 1.1544907093048096, F1: 0.5899366478390259, Accuracy: 0.523914389924988, Time Elapsed: 3105.483857154846 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       912\n",
      "           1       0.68      0.16      0.26       885\n",
      "           2       0.56      0.73      0.63       877\n",
      "           3       0.59      0.54      0.56       897\n",
      "           4       0.61      0.45      0.52       892\n",
      "           5       0.56      0.48      0.51       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.57      0.88      0.69       889\n",
      "           8       0.57      0.61      0.59       892\n",
      "           9       0.52      0.27      0.35       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 10700, Loss: 2.3600118160247803, F1: 0.5374291184931466, Accuracy: 0.5076044319042048, Time Elapsed: 3123.276309967041 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.70       912\n",
      "           1       0.61      0.78      0.69       885\n",
      "           2       0.60      0.50      0.54       877\n",
      "           3       0.59      0.43      0.50       897\n",
      "           4       0.54      0.93      0.68       892\n",
      "           5       0.55      0.41      0.47       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.57      0.61      0.59       892\n",
      "           9       0.59      0.76      0.67       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 10800, Loss: 6.015312671661377, F1: 0.591800120234952, Accuracy: 0.5295574977634023, Time Elapsed: 3138.8473830223083 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       912\n",
      "           1       0.59      0.93      0.73       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.59      0.63      0.61       897\n",
      "           4       0.56      0.85      0.68       892\n",
      "           5       0.52      0.56      0.54       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.56      0.88      0.68       889\n",
      "           8       0.59      0.31      0.41       892\n",
      "           9       0.59      0.77      0.67       876\n",
      "          10       0.40      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 10900, Loss: 0.5570440888404846, F1: 0.6007936442971815, Accuracy: 0.5354070607666368, Time Elapsed: 3154.4999380111694 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.20      0.30       912\n",
      "           1       0.62      0.78      0.69       885\n",
      "           2       0.60      0.47      0.53       877\n",
      "           3       0.57      0.66      0.62       897\n",
      "           4       0.58      0.69      0.63       892\n",
      "           5       0.51      0.48      0.49       862\n",
      "           6       0.71      0.01      0.03       903\n",
      "           7       0.61      0.65      0.63       889\n",
      "           8       0.54      0.74      0.63       892\n",
      "           9       0.59      0.72      0.65       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.53      0.51     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 11000, Loss: 0.6584569811820984, F1: 0.5089382277524135, Accuracy: 0.49852040465212305, Time Elapsed: 3169.771327972412 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.18      0.28       912\n",
      "           1       0.60      0.74      0.66       885\n",
      "           2       0.60      0.57      0.59       877\n",
      "           3       0.46      0.86      0.60       897\n",
      "           4       0.58      0.41      0.48       892\n",
      "           5       0.52      0.54      0.53       862\n",
      "           6       0.62      0.65      0.64       903\n",
      "           7       0.60      0.45      0.51       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.57      0.78      0.66       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 11100, Loss: 1.0865057706832886, F1: 0.5343499305072661, Accuracy: 0.4991397701465832, Time Elapsed: 3185.351364135742 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.44      0.52       912\n",
      "           1       0.58      0.87      0.70       885\n",
      "           2       0.58      0.62      0.60       877\n",
      "           3       0.59      0.46      0.52       897\n",
      "           4       0.56      0.91      0.69       892\n",
      "           5       0.49      0.77      0.60       862\n",
      "           6       0.62      0.65      0.63       903\n",
      "           7       0.59      0.58      0.58       889\n",
      "           8       0.58      0.52      0.55       892\n",
      "           9       0.56      0.77      0.65       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 11200, Loss: 0.8339076042175293, F1: 0.581299701267096, Accuracy: 0.520542288899594, Time Elapsed: 3200.226662158966 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.60      0.42      0.50       885\n",
      "           2       0.57      0.67      0.61       877\n",
      "           3       0.60      0.21      0.31       897\n",
      "           4       0.58      0.68      0.63       892\n",
      "           5       0.52      0.44      0.47       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.56      0.87      0.68       889\n",
      "           8       0.56      0.63      0.59       892\n",
      "           9       0.55      0.83      0.66       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 11300, Loss: 0.7888607978820801, F1: 0.5627220430048839, Accuracy: 0.5135228132957126, Time Elapsed: 3214.609631061554 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.78      0.68       885\n",
      "           2       0.58      0.66      0.62       877\n",
      "           3       0.60      0.12      0.19       897\n",
      "           4       0.58      0.73      0.65       892\n",
      "           5       0.50      0.58      0.53       862\n",
      "           6       0.61      0.81      0.69       903\n",
      "           7       0.58      0.76      0.66       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.59      0.78      0.67       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.63      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 11400, Loss: 1.5776338577270508, F1: 0.5743579750566842, Accuracy: 0.5246025738077215, Time Elapsed: 3229.6987040042877 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69       912\n",
      "           1       0.60      0.55      0.58       885\n",
      "           2       0.57      0.69      0.62       877\n",
      "           3       0.59      0.50      0.54       897\n",
      "           4       0.56      0.89      0.69       892\n",
      "           5       0.51      0.77      0.61       862\n",
      "           6       0.62      0.75      0.68       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.57      0.61      0.59       892\n",
      "           9       0.59      0.65      0.62       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 11500, Loss: 0.7226693630218506, F1: 0.6006725797961386, Accuracy: 0.5321725965177896, Time Elapsed: 3243.997678041458 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.87      0.70       912\n",
      "           1       0.60      0.65      0.63       885\n",
      "           2       0.59      0.69      0.64       877\n",
      "           3       0.61      0.44      0.51       897\n",
      "           4       0.59      0.58      0.58       892\n",
      "           5       0.52      0.56      0.54       862\n",
      "           6       0.56      0.89      0.69       903\n",
      "           7       0.55      0.87      0.68       889\n",
      "           8       0.63      0.25      0.35       892\n",
      "           9       0.59      0.71      0.64       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 11600, Loss: 0.15827009081840515, F1: 0.5734809977409229, Accuracy: 0.5200605601816806, Time Elapsed: 3258.6393761634827 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.71       912\n",
      "           1       0.59      0.90      0.71       885\n",
      "           2       0.59      0.21      0.31       877\n",
      "           3       0.61      0.29      0.39       897\n",
      "           4       0.59      0.39      0.47       892\n",
      "           5       0.56      0.27      0.37       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.55      0.68      0.61       892\n",
      "           9       0.58      0.75      0.65       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 11700, Loss: 5.085559368133545, F1: 0.5386926226926002, Accuracy: 0.5091872548344918, Time Elapsed: 3273.426775932312 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.59      0.70      0.64       877\n",
      "           3       0.61      0.46      0.52       897\n",
      "           4       0.57      0.86      0.68       892\n",
      "           5       0.53      0.68      0.59       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.59      0.79      0.68       889\n",
      "           8       0.54      0.74      0.62       892\n",
      "           9       0.56      0.82      0.67       876\n",
      "          10       0.40      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.71      0.62     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 11800, Loss: 1.147032380104065, F1: 0.6166376324971535, Accuracy: 0.5428394467001583, Time Elapsed: 3863.0862262248993 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.57      0.51      0.54       862\n",
      "           6       0.61      0.73      0.66       903\n",
      "           7       0.59      0.82      0.68       889\n",
      "           8       0.60      0.59      0.59       892\n",
      "           9       0.60      0.46      0.52       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.62      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 11900, Loss: 0.6663716435432434, F1: 0.5856687653341748, Accuracy: 0.5278370380565687, Time Elapsed: 3880.7901842594147 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.13      0.22       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.61      0.43      0.51       877\n",
      "           3       1.00      0.00      0.00       897\n",
      "           4       0.57      0.53      0.55       892\n",
      "           5       0.50      0.71      0.59       862\n",
      "           6       0.57      0.04      0.07       903\n",
      "           7       0.59      0.85      0.69       889\n",
      "           8       0.60      0.50      0.55       892\n",
      "           9       0.61      0.36      0.46       876\n",
      "          10       0.39      0.54      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.61      0.45      0.44     14531\n",
      "weighted avg       0.54      0.48      0.44     14531\n",
      "\n",
      "Epoch 5, Step 12000, Loss: 1.1199686527252197, F1: 0.436085976950452, Accuracy: 0.4787007088293992, Time Elapsed: 3899.335681915283 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.59      0.65      0.62       877\n",
      "           3       0.58      0.44      0.50       897\n",
      "           4       0.49      0.95      0.65       892\n",
      "           5       0.56      0.59      0.58       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.59      0.63      0.61       889\n",
      "           8       0.58      0.57      0.58       892\n",
      "           9       0.61      0.61      0.61       876\n",
      "          10       0.40      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 12100, Loss: 0.6920863389968872, F1: 0.5964101029395033, Accuracy: 0.5296263161516758, Time Elapsed: 4129.250768184662 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.62      0.64      0.63       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.57      0.73      0.64       897\n",
      "           4       0.59      0.59      0.59       892\n",
      "           5       0.57      0.30      0.39       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.62      0.39      0.48       889\n",
      "           8       0.56      0.73      0.63       892\n",
      "           9       0.59      0.74      0.65       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 12200, Loss: 0.8968850374221802, F1: 0.582646402370544, Accuracy: 0.5268735806207419, Time Elapsed: 4147.185993909836 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.58      0.65      0.61       877\n",
      "           3       0.60      0.42      0.50       897\n",
      "           4       0.62      0.45      0.52       892\n",
      "           5       0.57      0.49      0.53       862\n",
      "           6       0.62      0.73      0.67       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.54      0.80      0.65       892\n",
      "           9       0.58      0.69      0.63       876\n",
      "          10       0.40      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 12300, Loss: 0.7438679933547974, F1: 0.5894860217773178, Accuracy: 0.5293510425985823, Time Elapsed: 4163.737712144852 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.59      0.72      0.65       885\n",
      "           2       0.59      0.68      0.63       877\n",
      "           3       0.57      0.75      0.65       897\n",
      "           4       0.61      0.31      0.41       892\n",
      "           5       0.56      0.63      0.59       862\n",
      "           6       0.62      0.70      0.66       903\n",
      "           7       0.59      0.73      0.65       889\n",
      "           8       0.57      0.68      0.62       892\n",
      "           9       0.61      0.64      0.62       876\n",
      "          10       0.40      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.60     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 12400, Loss: 0.9191492795944214, F1: 0.595139127885849, Accuracy: 0.5317596861881495, Time Elapsed: 5208.454176902771 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.51      0.99      0.67       885\n",
      "           2       0.57      0.76      0.65       877\n",
      "           3       0.58      0.58      0.58       897\n",
      "           4       0.60      0.50      0.54       892\n",
      "           5       0.54      0.72      0.62       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.59      0.61      0.60       889\n",
      "           8       0.56      0.73      0.63       892\n",
      "           9       0.58      0.73      0.65       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 12500, Loss: 1.867614507675171, F1: 0.5978023325905981, Accuracy: 0.5285940403275755, Time Elapsed: 5227.024332046509 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.67      0.07      0.12       885\n",
      "           2       0.60      0.41      0.49       877\n",
      "           3       0.59      0.36      0.44       897\n",
      "           4       0.56      0.35      0.43       892\n",
      "           5       0.54      0.70      0.61       862\n",
      "           6       0.60      0.73      0.66       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.57      0.67      0.61       892\n",
      "           9       0.47      0.88      0.61       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.56      0.52     14531\n",
      "weighted avg       0.50      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 12600, Loss: 0.6911733150482178, F1: 0.5213415336371222, Accuracy: 0.49796985754593626, Time Elapsed: 5243.8034880161285 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       912\n",
      "           1       0.65      0.15      0.24       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.59      0.42      0.49       897\n",
      "           4       0.53      0.68      0.60       892\n",
      "           5       0.52      0.70      0.59       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.60      0.65      0.63       889\n",
      "           8       0.58      0.59      0.58       892\n",
      "           9       0.56      0.73      0.63       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 12700, Loss: 1.290739893913269, F1: 0.5478387071081777, Accuracy: 0.507053884798018, Time Elapsed: 6238.073531150818 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       912\n",
      "           1       0.62      0.66      0.63       885\n",
      "           2       0.60      0.59      0.59       877\n",
      "           3       0.53      0.11      0.19       897\n",
      "           4       0.53      0.60      0.56       892\n",
      "           5       0.56      0.42      0.48       862\n",
      "           6       0.61      0.58      0.60       903\n",
      "           7       0.61      0.24      0.35       889\n",
      "           8       0.57      0.41      0.48       892\n",
      "           9       0.52      0.81      0.64       876\n",
      "          10       0.38      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.52      0.51     14531\n",
      "weighted avg       0.50      0.49      0.48     14531\n",
      "\n",
      "Epoch 5, Step 12800, Loss: 2.359943151473999, F1: 0.5114404402954933, Accuracy: 0.4908815635537816, Time Elapsed: 6257.110907077789 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.73       912\n",
      "           1       0.61      0.03      0.06       885\n",
      "           2       0.62      0.49      0.55       877\n",
      "           3       0.59      0.56      0.57       897\n",
      "           4       0.54      0.40      0.46       892\n",
      "           5       0.58      0.44      0.50       862\n",
      "           6       0.61      0.63      0.62       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.56      0.61      0.58       892\n",
      "           9       0.60      0.33      0.42       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.51      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 12900, Loss: 1.0062291622161865, F1: 0.5054672248689195, Accuracy: 0.4968687633335627, Time Elapsed: 7261.088134050369 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.71       912\n",
      "           1       0.38      0.01      0.01       885\n",
      "           2       0.59      0.60      0.59       877\n",
      "           3       0.59      0.54      0.56       897\n",
      "           4       0.54      0.56      0.55       892\n",
      "           5       0.55      0.68      0.61       862\n",
      "           6       0.63      0.51      0.57       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.53      0.68      0.60       892\n",
      "           9       0.54      0.02      0.05       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.52      0.49     14531\n",
      "weighted avg       0.49      0.50      0.46     14531\n",
      "\n",
      "Epoch 5, Step 13000, Loss: 1.808629035949707, F1: 0.4857847398254695, Accuracy: 0.49507948523845574, Time Elapsed: 7279.356576919556 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73       912\n",
      "           1       0.57      0.96      0.72       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.57      0.72      0.63       897\n",
      "           4       0.55      0.71      0.62       892\n",
      "           5       0.52      0.77      0.62       862\n",
      "           6       0.63      0.58      0.60       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.56      0.61      0.58       892\n",
      "           9       0.59      0.56      0.58       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 13100, Loss: 0.5464949011802673, F1: 0.6039612746099217, Accuracy: 0.5327919620122497, Time Elapsed: 7296.162301063538 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.91      0.73       912\n",
      "           1       0.59      0.68      0.63       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.59      0.61      0.60       897\n",
      "           4       0.56      0.76      0.64       892\n",
      "           5       0.54      0.74      0.62       862\n",
      "           6       0.61      0.61      0.61       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.56      0.64      0.60       892\n",
      "           9       0.48      0.84      0.61       876\n",
      "          10       0.38      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.55      0.67      0.60     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 13200, Loss: 0.2937338650226593, F1: 0.5989518331021284, Accuracy: 0.5246025738077215, Time Elapsed: 7379.224707126617 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.47      0.01      0.02       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.57      0.66      0.61       897\n",
      "           4       0.57      0.67      0.61       892\n",
      "           5       0.57      0.41      0.48       862\n",
      "           6       0.62      0.59      0.61       903\n",
      "           7       0.59      0.72      0.65       889\n",
      "           8       0.52      0.78      0.62       892\n",
      "           9       0.60      0.58      0.59       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.56      0.53     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 13300, Loss: 0.27143386006355286, F1: 0.5291014167928908, Accuracy: 0.5062968825270112, Time Elapsed: 7394.2572321891785 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.61      0.59      0.60       885\n",
      "           2       0.58      0.68      0.62       877\n",
      "           3       0.60      0.47      0.53       897\n",
      "           4       0.51      0.90      0.65       892\n",
      "           5       0.56      0.47      0.51       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.58      0.72      0.64       889\n",
      "           8       0.54      0.68      0.60       892\n",
      "           9       0.61      0.02      0.04       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.54     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 13400, Loss: 1.6280521154403687, F1: 0.5381473703436307, Accuracy: 0.5085678893400316, Time Elapsed: 8336.917279958725 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       912\n",
      "           1       0.57      0.27      0.37       885\n",
      "           2       0.57      0.71      0.63       877\n",
      "           3       0.51      0.74      0.60       897\n",
      "           4       0.55      0.61      0.58       892\n",
      "           5       0.57      0.42      0.48       862\n",
      "           6       0.62      0.55      0.58       903\n",
      "           7       0.59      0.68      0.63       889\n",
      "           8       0.52      0.70      0.59       892\n",
      "           9       0.55      0.67      0.60       876\n",
      "          10       0.38      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.60      0.56     14531\n",
      "weighted avg       0.49      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 13500, Loss: 1.0992226600646973, F1: 0.5586013857472546, Accuracy: 0.5053334250911844, Time Elapsed: 8353.903895139694 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.60      0.28      0.38       897\n",
      "           4       0.57      0.56      0.57       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.60      0.57      0.59       889\n",
      "           8       0.56      0.43      0.49       892\n",
      "           9       0.57      0.57      0.57       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.51      0.50     14531\n",
      "weighted avg       0.47      0.49      0.48     14531\n",
      "\n",
      "Epoch 5, Step 13600, Loss: 0.5461771488189697, F1: 0.5034582455999632, Accuracy: 0.49452893813226895, Time Elapsed: 8370.38151216507 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.59      0.67      0.62       877\n",
      "           3       0.60      0.35      0.44       897\n",
      "           4       0.56      0.73      0.63       892\n",
      "           5       0.57      0.48      0.52       862\n",
      "           6       0.61      0.43      0.50       903\n",
      "           7       0.62      0.46      0.53       889\n",
      "           8       0.59      0.40      0.48       892\n",
      "           9       0.63      0.44      0.52       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 13700, Loss: 0.6564450860023499, F1: 0.5533139619457165, Accuracy: 0.5113206248709655, Time Elapsed: 8640.871711015701 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.60      0.80      0.68       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.59      0.39      0.47       897\n",
      "           4       0.58      0.72      0.64       892\n",
      "           5       0.63      0.06      0.11       862\n",
      "           6       0.57      0.88      0.69       903\n",
      "           7       0.60      0.79      0.69       889\n",
      "           8       0.58      0.28      0.38       892\n",
      "           9       0.58      0.83      0.68       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.60      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 13800, Loss: 0.2529378831386566, F1: 0.5496601653718394, Accuracy: 0.5199229234051338, Time Elapsed: 8660.139085054398 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.61      0.72      0.66       885\n",
      "           2       0.62      0.45      0.52       877\n",
      "           3       0.58      0.50      0.53       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.58      0.34      0.43       862\n",
      "           6       0.59      0.74      0.66       903\n",
      "           7       0.58      0.61      0.59       889\n",
      "           8       0.57      0.62      0.60       892\n",
      "           9       0.58      0.73      0.65       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 13900, Loss: 0.4940299689769745, F1: 0.5791282358496264, Accuracy: 0.5212304727823275, Time Elapsed: 8677.117630243301 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.67      0.04      0.07       885\n",
      "           2       0.60      0.44      0.51       877\n",
      "           3       0.60      0.27      0.37       897\n",
      "           4       0.61      0.40      0.49       892\n",
      "           5       0.58      0.45      0.51       862\n",
      "           6       0.63      0.50      0.56       903\n",
      "           7       0.60      0.50      0.54       889\n",
      "           8       0.56      0.66      0.61       892\n",
      "           9       0.58      0.74      0.65       876\n",
      "          10       0.39      0.59      0.47      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.53      0.42      0.43     14531\n",
      "weighted avg       0.48      0.47      0.44     14531\n",
      "\n",
      "Epoch 5, Step 14000, Loss: 0.3447560667991638, F1: 0.4333470722017944, Accuracy: 0.4724382354965247, Time Elapsed: 8692.845880031586 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.72       912\n",
      "           1       0.61      0.87      0.71       885\n",
      "           2       0.57      0.70      0.63       877\n",
      "           3       0.54      0.62      0.58       897\n",
      "           4       0.57      0.86      0.69       892\n",
      "           5       0.57      0.58      0.57       862\n",
      "           6       0.63      0.66      0.64       903\n",
      "           7       0.57      0.76      0.65       889\n",
      "           8       0.57      0.65      0.61       892\n",
      "           9       0.54      0.81      0.64       876\n",
      "          10       0.39      0.21      0.27      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 14100, Loss: 1.7241116762161255, F1: 0.6108951745405595, Accuracy: 0.5363016998141904, Time Elapsed: 8708.590646028519 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.59      0.76      0.67       885\n",
      "           2       0.56      0.68      0.61       877\n",
      "           3       0.58      0.58      0.58       897\n",
      "           4       0.60      0.75      0.67       892\n",
      "           5       0.57      0.22      0.32       862\n",
      "           6       0.61      0.46      0.53       903\n",
      "           7       0.57      0.80      0.66       889\n",
      "           8       0.54      0.65      0.59       892\n",
      "           9       0.57      0.28      0.38       876\n",
      "          10       0.39      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 14200, Loss: 0.41570982336997986, F1: 0.5535221669832633, Accuracy: 0.511595898424059, Time Elapsed: 8724.619774103165 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.58      0.47      0.52       885\n",
      "           2       0.60      0.52      0.55       877\n",
      "           3       0.60      0.34      0.43       897\n",
      "           4       0.58      0.81      0.67       892\n",
      "           5       0.53      0.57      0.55       862\n",
      "           6       0.56      0.81      0.66       903\n",
      "           7       0.58      0.74      0.65       889\n",
      "           8       0.55      0.61      0.58       892\n",
      "           9       0.55      0.74      0.63       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.62      0.57     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 14300, Loss: 3.1307332515716553, F1: 0.5720365527353318, Accuracy: 0.5140733604018994, Time Elapsed: 8741.918168067932 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.93      0.71       912\n",
      "           1       0.57      0.93      0.71       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.60      0.32      0.42       897\n",
      "           4       0.59      0.45      0.51       892\n",
      "           5       0.54      0.52      0.53       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.56      0.75      0.64       889\n",
      "           8       0.59      0.44      0.50       892\n",
      "           9       0.48      0.90      0.63       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.63      0.57     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 14400, Loss: 5.35407829284668, F1: 0.5675044589668402, Accuracy: 0.5124217190833391, Time Elapsed: 8758.878841161728 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71       912\n",
      "           1       0.58      0.71      0.64       885\n",
      "           2       0.60      0.59      0.59       877\n",
      "           3       0.63      0.21      0.31       897\n",
      "           4       0.57      0.64      0.60       892\n",
      "           5       0.56      0.46      0.50       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.65      0.20      0.30       889\n",
      "           8       0.55      0.56      0.55       892\n",
      "           9       0.50      0.78      0.61       876\n",
      "          10       0.39      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 14500, Loss: 1.1933486461639404, F1: 0.5303579399015598, Accuracy: 0.5001720459706833, Time Elapsed: 8773.77340221405 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.70       912\n",
      "           1       0.58      0.86      0.69       885\n",
      "           2       0.60      0.55      0.57       877\n",
      "           3       0.60      0.31      0.41       897\n",
      "           4       0.60      0.46      0.52       892\n",
      "           5       0.53      0.56      0.54       862\n",
      "           6       0.59      0.75      0.66       903\n",
      "           7       0.60      0.45      0.52       889\n",
      "           8       0.56      0.58      0.57       892\n",
      "           9       0.55      0.84      0.67       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 14600, Loss: 6.0112996101379395, F1: 0.5648797083783955, Accuracy: 0.5126969926364324, Time Elapsed: 8789.90055012703 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.59      0.87      0.70       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.59      0.61      0.60       897\n",
      "           4       0.57      0.82      0.67       892\n",
      "           5       0.58      0.60      0.59       862\n",
      "           6       0.61      0.71      0.66       903\n",
      "           7       0.60      0.47      0.53       889\n",
      "           8       0.59      0.44      0.51       892\n",
      "           9       0.52      0.86      0.65       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 14700, Loss: 4.522172451019287, F1: 0.5929052070496303, Accuracy: 0.5268735806207419, Time Elapsed: 8805.265600919724 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.72       912\n",
      "           1       0.58      0.67      0.62       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.60      0.53      0.56       897\n",
      "           4       0.60      0.46      0.52       892\n",
      "           5       0.55      0.70      0.61       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.60      0.75      0.66       889\n",
      "           8       0.56      0.73      0.63       892\n",
      "           9       0.60      0.68      0.64       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 14800, Loss: 1.3245186805725098, F1: 0.5950016446955121, Accuracy: 0.5290069506572156, Time Elapsed: 8822.594017028809 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.56      0.78      0.65       885\n",
      "           2       0.58      0.72      0.65       877\n",
      "           3       0.58      0.75      0.65       897\n",
      "           4       0.58      0.78      0.66       892\n",
      "           5       0.56      0.67      0.61       862\n",
      "           6       0.59      0.85      0.69       903\n",
      "           7       0.62      0.43      0.51       889\n",
      "           8       0.54      0.80      0.64       892\n",
      "           9       0.55      0.80      0.65       876\n",
      "          10       0.39      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 14900, Loss: 1.8952088356018066, F1: 0.6096903927078254, Accuracy: 0.5365081549790104, Time Elapsed: 8838.035304069519 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.46      0.52       885\n",
      "           2       0.60      0.47      0.53       877\n",
      "           3       0.61      0.48      0.54       897\n",
      "           4       0.59      0.69      0.64       892\n",
      "           5       0.55      0.11      0.19       862\n",
      "           6       0.56      0.03      0.05       903\n",
      "           7       0.61      0.75      0.67       889\n",
      "           8       0.55      0.75      0.63       892\n",
      "           9       0.61      0.64      0.62       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.51      0.45      0.44     14531\n",
      "weighted avg       0.47      0.48      0.45     14531\n",
      "\n",
      "Epoch 5, Step 15000, Loss: 1.1898478269577026, F1: 0.4405526815836472, Accuracy: 0.4811781708072397, Time Elapsed: 8853.676421165466 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.64      0.23      0.34       885\n",
      "           2       0.58      0.61      0.60       877\n",
      "           3       0.59      0.32      0.41       897\n",
      "           4       0.58      0.67      0.62       892\n",
      "           5       0.57      0.51      0.54       862\n",
      "           6       0.61      0.68      0.65       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.59      0.56      0.58       892\n",
      "           9       0.61      0.35      0.44       876\n",
      "          10       0.39      0.53      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.53      0.47      0.48     14531\n",
      "weighted avg       0.48      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 15100, Loss: 0.9679230451583862, F1: 0.478654747208609, Accuracy: 0.4864771867042874, Time Elapsed: 8868.778615951538 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.83      0.69       885\n",
      "           2       0.58      0.70      0.63       877\n",
      "           3       0.58      0.24      0.34       897\n",
      "           4       0.57      0.84      0.68       892\n",
      "           5       0.54      0.29      0.38       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.60      0.59      0.60       889\n",
      "           8       0.60      0.54      0.57       892\n",
      "           9       0.53      0.88      0.66       876\n",
      "          10       0.38      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.55      0.51     14531\n",
      "weighted avg       0.47      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 15200, Loss: 0.6519365906715393, F1: 0.5101418270246865, Accuracy: 0.49907095175830984, Time Elapsed: 8884.49589920044 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.69      0.65       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.55      0.13      0.21       897\n",
      "           4       0.57      0.75      0.65       892\n",
      "           5       0.52      0.55      0.53       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.63      0.41      0.50       889\n",
      "           8       0.61      0.24      0.34       892\n",
      "           9       0.59      0.77      0.67       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.48      0.47     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 5, Step 15300, Loss: 0.519737184047699, F1: 0.4740538777591546, Accuracy: 0.4873718257518409, Time Elapsed: 8900.460785150528 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.58      0.24      0.34       885\n",
      "           2       0.62      0.38      0.47       877\n",
      "           3       0.56      0.14      0.23       897\n",
      "           4       0.53      0.82      0.64       892\n",
      "           5       0.52      0.64      0.57       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.61      0.58      0.60       889\n",
      "           8       0.58      0.48      0.53       892\n",
      "           9       0.62      0.61      0.61       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.52     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 15400, Loss: 0.716248095035553, F1: 0.523385176592298, Accuracy: 0.4992085885348565, Time Elapsed: 8916.345856904984 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.55      0.11      0.18       885\n",
      "           2       0.60      0.53      0.56       877\n",
      "           3       0.56      0.16      0.25       897\n",
      "           4       0.52      0.88      0.65       892\n",
      "           5       0.51      0.56      0.53       862\n",
      "           6       0.58      0.84      0.68       903\n",
      "           7       0.62      0.64      0.63       889\n",
      "           8       0.60      0.36      0.45       892\n",
      "           9       0.62      0.30      0.41       876\n",
      "          10       0.39      0.45      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.56      0.51      0.49     14531\n",
      "weighted avg       0.50      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 15500, Loss: 1.6922093629837036, F1: 0.49470448511804926, Accuracy: 0.48909228545867456, Time Elapsed: 8931.316718101501 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.72       912\n",
      "           1       0.61      0.66      0.63       885\n",
      "           2       0.61      0.40      0.48       877\n",
      "           3       0.59      0.39      0.47       897\n",
      "           4       0.58      0.51      0.54       892\n",
      "           5       0.50      0.74      0.60       862\n",
      "           6       0.55      0.86      0.67       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.56      0.09      0.16       892\n",
      "           9       0.62      0.51      0.56       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 15600, Loss: 0.4775589108467102, F1: 0.5355351552049539, Accuracy: 0.5055398802560044, Time Elapsed: 8946.983402013779 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.65      0.03      0.06       885\n",
      "           2       0.59      0.58      0.58       877\n",
      "           3       0.58      0.70      0.63       897\n",
      "           4       0.56      0.51      0.53       892\n",
      "           5       0.54      0.65      0.59       862\n",
      "           6       0.61      0.58      0.60       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.58      0.59      0.59       892\n",
      "           9       0.56      0.81      0.66       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 15700, Loss: 1.361366868019104, F1: 0.538504368019989, Accuracy: 0.5069162480214713, Time Elapsed: 8962.835379123688 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.96      0.70       912\n",
      "           1       0.58      0.31      0.41       885\n",
      "           2       0.59      0.61      0.60       877\n",
      "           3       0.55      0.12      0.20       897\n",
      "           4       0.56      0.54      0.55       892\n",
      "           5       0.49      0.82      0.61       862\n",
      "           6       0.61      0.59      0.60       903\n",
      "           7       0.61      0.38      0.47       889\n",
      "           8       0.53      0.77      0.63       892\n",
      "           9       0.54      0.82      0.65       876\n",
      "          10       0.38      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.54      0.57      0.52     14531\n",
      "weighted avg       0.49      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 15800, Loss: 1.172099232673645, F1: 0.5244232843106629, Accuracy: 0.49218911293097517, Time Elapsed: 8978.379870891571 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.57      0.05      0.09       885\n",
      "           2       0.61      0.50      0.55       877\n",
      "           3       0.59      0.51      0.55       897\n",
      "           4       0.55      0.74      0.63       892\n",
      "           5       0.53      0.43      0.47       862\n",
      "           6       0.55      0.91      0.69       903\n",
      "           7       0.61      0.60      0.61       889\n",
      "           8       0.59      0.51      0.55       892\n",
      "           9       0.56      0.80      0.66       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.57      0.54     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 15900, Loss: 0.797914445400238, F1: 0.5351134568760691, Accuracy: 0.507260339962838, Time Elapsed: 8992.985306024551 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       912\n",
      "           1       0.62      0.51      0.56       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.59      0.58      0.59       897\n",
      "           4       0.56      0.58      0.57       892\n",
      "           5       0.53      0.63      0.58       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.56      0.65      0.60       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 16000, Loss: 0.47485142946243286, F1: 0.584047707154641, Accuracy: 0.5177207349803867, Time Elapsed: 9007.61929011345 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.95      0.72       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.57      0.67      0.61       877\n",
      "           3       0.58      0.69      0.63       897\n",
      "           4       0.58      0.70      0.63       892\n",
      "           5       0.52      0.09      0.16       862\n",
      "           6       0.63      0.60      0.61       903\n",
      "           7       0.62      0.37      0.47       889\n",
      "           8       0.58      0.28      0.38       892\n",
      "           9       0.58      0.62      0.60       876\n",
      "          10       0.39      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.50      0.48     14531\n",
      "weighted avg       0.47      0.49      0.46     14531\n",
      "\n",
      "Epoch 5, Step 16100, Loss: 2.014955997467041, F1: 0.47598527150629794, Accuracy: 0.4908127451655082, Time Elapsed: 9023.599661111832 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.72       912\n",
      "           1       0.62      0.55      0.59       885\n",
      "           2       0.58      0.74      0.65       877\n",
      "           3       0.53      0.85      0.65       897\n",
      "           4       0.57      0.59      0.58       892\n",
      "           5       0.57      0.59      0.58       862\n",
      "           6       0.62      0.72      0.67       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.58      0.62      0.60       892\n",
      "           9       0.57      0.80      0.66       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.67      0.61     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 16200, Loss: 0.667679488658905, F1: 0.6057619707265955, Accuracy: 0.5339618746128966, Time Elapsed: 9038.84591794014 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73       912\n",
      "           1       0.64      0.20      0.30       885\n",
      "           2       0.60      0.66      0.63       877\n",
      "           3       0.58      0.66      0.62       897\n",
      "           4       0.58      0.72      0.64       892\n",
      "           5       0.56      0.18      0.27       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.60      0.70      0.65       889\n",
      "           8       0.59      0.58      0.58       892\n",
      "           9       0.56      0.84      0.67       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.60      0.56     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 16300, Loss: 0.38745200634002686, F1: 0.5594745069386534, Accuracy: 0.5218498382767875, Time Elapsed: 9053.731077194214 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.69       912\n",
      "           1       0.60      0.90      0.72       885\n",
      "           2       0.63      0.17      0.27       877\n",
      "           3       0.59      0.74      0.66       897\n",
      "           4       0.58      0.65      0.61       892\n",
      "           5       0.55      0.55      0.55       862\n",
      "           6       0.60      0.80      0.68       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.55      0.80      0.65       892\n",
      "           9       0.58      0.78      0.66       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.66      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 16400, Loss: 0.3359898030757904, F1: 0.5908867512758469, Accuracy: 0.5323102332943362, Time Elapsed: 9069.159063100815 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.71       912\n",
      "           1       0.60      0.86      0.70       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.58      0.15      0.24       897\n",
      "           4       0.58      0.71      0.63       892\n",
      "           5       0.53      0.43      0.47       862\n",
      "           6       0.61      0.14      0.23       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.59      0.46      0.52       892\n",
      "           9       0.60      0.57      0.58       876\n",
      "          10       0.39      0.50      0.44      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.49      0.47     14531\n",
      "weighted avg       0.48      0.49      0.46     14531\n",
      "\n",
      "Epoch 5, Step 16500, Loss: 0.6281230449676514, F1: 0.4696115890265318, Accuracy: 0.489780469341408, Time Elapsed: 9084.703320026398 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.60      0.76      0.67       885\n",
      "           2       0.58      0.73      0.65       877\n",
      "           3       0.64      0.06      0.11       897\n",
      "           4       0.56      0.85      0.67       892\n",
      "           5       0.56      0.65      0.60       862\n",
      "           6       0.61      0.71      0.66       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.59      0.58      0.59       892\n",
      "           9       0.53      0.88      0.66       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.57     14531\n",
      "weighted avg       0.51      0.53      0.49     14531\n",
      "\n",
      "Epoch 5, Step 16600, Loss: 0.26650741696357727, F1: 0.5733371301727694, Accuracy: 0.5268735806207419, Time Elapsed: 9100.060147285461 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.60      0.65      0.63       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.65      0.04      0.08       897\n",
      "           4       0.55      0.65      0.60       892\n",
      "           5       0.55      0.57      0.56       862\n",
      "           6       0.62      0.51      0.56       903\n",
      "           7       0.62      0.48      0.54       889\n",
      "           8       0.60      0.61      0.61       892\n",
      "           9       0.56      0.77      0.65       876\n",
      "          10       0.39      0.38      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 16700, Loss: 0.7336447834968567, F1: 0.5426583520505371, Accuracy: 0.5107012593765055, Time Elapsed: 9114.532008886337 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69       912\n",
      "           1       0.61      0.80      0.69       885\n",
      "           2       0.59      0.46      0.52       877\n",
      "           3       0.59      0.32      0.41       897\n",
      "           4       0.55      0.87      0.67       892\n",
      "           5       0.50      0.73      0.59       862\n",
      "           6       0.61      0.59      0.60       903\n",
      "           7       0.63      0.36      0.46       889\n",
      "           8       0.58      0.30      0.40       892\n",
      "           9       0.61      0.31      0.41       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 16800, Loss: 0.7468069791793823, F1: 0.5314857095428679, Accuracy: 0.5006537746885968, Time Elapsed: 9129.945671081543 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.58      0.93      0.71       885\n",
      "           2       0.60      0.35      0.44       877\n",
      "           3       0.62      0.26      0.36       897\n",
      "           4       0.54      0.88      0.67       892\n",
      "           5       0.61      0.13      0.21       862\n",
      "           6       0.59      0.78      0.67       903\n",
      "           7       0.62      0.37      0.46       889\n",
      "           8       0.53      0.82      0.65       892\n",
      "           9       0.55      0.83      0.66       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.59      0.54     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 16900, Loss: 1.0770998001098633, F1: 0.5355017341779962, Accuracy: 0.5111141697061454, Time Elapsed: 9145.609948158264 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.61      0.40      0.48       877\n",
      "           3       0.58      0.49      0.53       897\n",
      "           4       0.59      0.55      0.57       892\n",
      "           5       0.53      0.43      0.47       862\n",
      "           6       0.55      0.85      0.67       903\n",
      "           7       0.61      0.62      0.61       889\n",
      "           8       0.48      0.86      0.61       892\n",
      "           9       0.50      0.86      0.63       876\n",
      "          10       0.38      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.64      0.57     14531\n",
      "weighted avg       0.49      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 17000, Loss: 0.6095338463783264, F1: 0.5729788065121132, Accuracy: 0.5124905374716124, Time Elapsed: 9161.204520225525 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.59      0.93      0.72       885\n",
      "           2       0.60      0.44      0.51       877\n",
      "           3       0.59      0.59      0.59       897\n",
      "           4       0.58      0.47      0.52       892\n",
      "           5       0.49      0.80      0.61       862\n",
      "           6       0.54      0.89      0.67       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.52      0.81      0.63       892\n",
      "           9       0.48      0.86      0.62       876\n",
      "          10       0.38      0.27      0.31      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.49      0.61      0.53     14531\n",
      "weighted avg       0.45      0.50      0.46     14531\n",
      "\n",
      "Epoch 5, Step 17100, Loss: 0.7696090936660767, F1: 0.5297656843983867, Accuracy: 0.4991397701465832, Time Elapsed: 9175.815976142883 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.04      0.07       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.58      0.53      0.55       892\n",
      "           5       0.56      0.54      0.55       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.57      0.79      0.66       889\n",
      "           8       0.60      0.48      0.53       892\n",
      "           9       0.61      0.43      0.50       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 17200, Loss: 2.788649082183838, F1: 0.53596944919982, Accuracy: 0.5074667951276581, Time Elapsed: 9191.104095935822 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.81      0.69       912\n",
      "           1       0.58      0.22      0.32       885\n",
      "           2       0.59      0.68      0.63       877\n",
      "           3       0.60      0.67      0.63       897\n",
      "           4       0.58      0.46      0.51       892\n",
      "           5       0.54      0.60      0.57       862\n",
      "           6       0.55      0.89      0.68       903\n",
      "           7       0.57      0.87      0.69       889\n",
      "           8       0.60      0.38      0.46       892\n",
      "           9       0.60      0.76      0.67       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 17300, Loss: 0.5916420817375183, F1: 0.5648418842232829, Accuracy: 0.5165508223797398, Time Elapsed: 9206.348732233047 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       912\n",
      "           1       0.54      0.02      0.03       885\n",
      "           2       0.61      0.55      0.58       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.58      0.74      0.65       892\n",
      "           5       0.55      0.33      0.42       862\n",
      "           6       0.61      0.80      0.69       903\n",
      "           7       0.62      0.38      0.48       889\n",
      "           8       0.59      0.69      0.64       892\n",
      "           9       0.51      0.87      0.65       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 17400, Loss: 0.7665290236473083, F1: 0.5162931778775053, Accuracy: 0.5021677792306104, Time Elapsed: 9221.759792089462 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       912\n",
      "           1       0.58      0.96      0.72       885\n",
      "           2       0.60      0.62      0.61       877\n",
      "           3       0.58      0.76      0.66       897\n",
      "           4       0.57      0.89      0.69       892\n",
      "           5       0.54      0.71      0.61       862\n",
      "           6       0.56      0.87      0.68       903\n",
      "           7       0.58      0.85      0.69       889\n",
      "           8       0.53      0.83      0.65       892\n",
      "           9       0.59      0.76      0.66       876\n",
      "          10       0.40      0.13      0.20      5646\n",
      "\n",
      "    accuracy                           0.55     14531\n",
      "   macro avg       0.56      0.75      0.63     14531\n",
      "weighted avg       0.50      0.55      0.49     14531\n",
      "\n",
      "Epoch 5, Step 17500, Loss: 0.2993957996368408, F1: 0.6265644686445518, Accuracy: 0.5494460119743996, Time Elapsed: 9237.122112035751 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66       912\n",
      "           1       0.62      0.77      0.69       885\n",
      "           2       0.60      0.65      0.62       877\n",
      "           3       0.60      0.68      0.64       897\n",
      "           4       0.56      0.63      0.59       892\n",
      "           5       0.55      0.53      0.54       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.61      0.36      0.45       889\n",
      "           8       0.60      0.58      0.59       892\n",
      "           9       0.49      0.84      0.62       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 17600, Loss: 0.6948312520980835, F1: 0.5820240725044482, Accuracy: 0.5193723762989471, Time Elapsed: 9252.804643154144 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.91      0.73       885\n",
      "           2       0.55      0.81      0.65       877\n",
      "           3       0.61      0.59      0.60       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.50      0.74      0.60       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.60      0.56      0.58       889\n",
      "           8       0.56      0.73      0.63       892\n",
      "           9       0.60      0.43      0.50       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.51      0.60      0.54     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 17700, Loss: 2.5088906288146973, F1: 0.5405623042683901, Accuracy: 0.5100818938820453, Time Elapsed: 9269.217948198318 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.35      0.45       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.58      0.52      0.55       877\n",
      "           3       0.62      0.23      0.34       897\n",
      "           4       0.55      0.84      0.67       892\n",
      "           5       0.49      0.62      0.55       862\n",
      "           6       0.61      0.71      0.66       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.55      0.74      0.63       892\n",
      "           9       0.55      0.81      0.65       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.60      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 17800, Loss: 0.6785063743591309, F1: 0.5578839614633883, Accuracy: 0.508430252563485, Time Elapsed: 9383.607163190842 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       912\n",
      "           1       0.60      0.68      0.64       885\n",
      "           2       0.60      0.55      0.58       877\n",
      "           3       0.60      0.37      0.46       897\n",
      "           4       0.59      0.70      0.64       892\n",
      "           5       0.56      0.48      0.52       862\n",
      "           6       0.58      0.87      0.69       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.60      0.53      0.56       892\n",
      "           9       0.59      0.78      0.67       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.62      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 17900, Loss: 1.1116477251052856, F1: 0.5896064932005093, Accuracy: 0.5276305828917487, Time Elapsed: 9399.789280891418 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65       912\n",
      "           1       0.60      0.72      0.65       885\n",
      "           2       0.61      0.44      0.51       877\n",
      "           3       0.58      0.55      0.56       897\n",
      "           4       0.58      0.66      0.62       892\n",
      "           5       0.57      0.46      0.51       862\n",
      "           6       0.57      0.88      0.69       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.58      0.39      0.47       892\n",
      "           9       0.60      0.37      0.46       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.56     14531\n",
      "weighted avg       0.51      0.51      0.51     14531\n",
      "\n",
      "Epoch 5, Step 18000, Loss: 0.7987124919891357, F1: 0.5587851046861864, Accuracy: 0.5109765329295988, Time Elapsed: 9415.527331113815 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.10      0.17       912\n",
      "           1       0.60      0.64      0.62       885\n",
      "           2       0.55      0.81      0.65       877\n",
      "           3       0.59      0.58      0.58       897\n",
      "           4       0.57      0.78      0.66       892\n",
      "           5       0.58      0.55      0.56       862\n",
      "           6       0.58      0.87      0.69       903\n",
      "           7       0.61      0.72      0.66       889\n",
      "           8       0.61      0.44      0.51       892\n",
      "           9       0.61      0.37      0.46       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.57      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 18100, Loss: 0.6117941737174988, F1: 0.5425390906291858, Accuracy: 0.5089119812813984, Time Elapsed: 9476.353266239166 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72       912\n",
      "           1       0.60      0.69      0.64       885\n",
      "           2       0.57      0.69      0.63       877\n",
      "           3       0.57      0.00      0.01       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.57      0.31      0.40       862\n",
      "           6       0.60      0.86      0.70       903\n",
      "           7       0.62      0.61      0.62       889\n",
      "           8       0.56      0.18      0.27       892\n",
      "           9       0.62      0.42      0.50       876\n",
      "          10       0.39      0.44      0.42      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.53      0.51     14531\n",
      "weighted avg       0.51      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 18200, Loss: 0.43763813376426697, F1: 0.5063236338039637, Accuracy: 0.5054022434794577, Time Elapsed: 9494.129554271698 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66       912\n",
      "           1       0.62      0.15      0.25       885\n",
      "           2       0.61      0.50      0.55       877\n",
      "           3       0.54      0.04      0.07       897\n",
      "           4       0.58      0.62      0.60       892\n",
      "           5       0.54      0.76      0.63       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.60      0.70      0.64       889\n",
      "           8       0.60      0.47      0.53       892\n",
      "           9       0.60      0.57      0.59       876\n",
      "          10       0.39      0.45      0.42      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.52      0.51     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 18300, Loss: 1.5625200271606445, F1: 0.5113786528865524, Accuracy: 0.5008602298534168, Time Elapsed: 9510.656231164932 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       912\n",
      "           1       0.61      0.63      0.62       885\n",
      "           2       0.51      0.73      0.60       877\n",
      "           3       0.50      0.01      0.01       897\n",
      "           4       0.55      0.89      0.68       892\n",
      "           5       0.58      0.53      0.55       862\n",
      "           6       0.62      0.74      0.67       903\n",
      "           7       0.63      0.48      0.55       889\n",
      "           8       0.56      0.67      0.61       892\n",
      "           9       0.58      0.65      0.62       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.54     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 18400, Loss: 0.9442688226699829, F1: 0.5438793657449424, Accuracy: 0.5133851765191659, Time Elapsed: 9526.580534934998 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       912\n",
      "           1       0.61      0.64      0.63       885\n",
      "           2       0.55      0.70      0.62       877\n",
      "           3       0.54      0.54      0.54       897\n",
      "           4       0.59      0.45      0.51       892\n",
      "           5       0.58      0.65      0.61       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.61      0.61      0.61       889\n",
      "           8       0.58      0.50      0.54       892\n",
      "           9       0.58      0.63      0.60       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 18500, Loss: 0.6262587308883667, F1: 0.5827948854522647, Accuracy: 0.5215745647236941, Time Elapsed: 9542.502121925354 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.60      0.42      0.49       877\n",
      "           3       0.57      0.25      0.35       897\n",
      "           4       0.56      0.80      0.66       892\n",
      "           5       0.59      0.33      0.43       862\n",
      "           6       0.59      0.75      0.66       903\n",
      "           7       0.55      0.86      0.67       889\n",
      "           8       0.54      0.39      0.45       892\n",
      "           9       0.56      0.73      0.63       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.50      0.53      0.50     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 18600, Loss: 2.019392251968384, F1: 0.4959330245855872, Accuracy: 0.4943224829674489, Time Elapsed: 9558.344501972198 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.61      0.31      0.41       877\n",
      "           3       0.56      0.42      0.48       897\n",
      "           4       0.58      0.70      0.63       892\n",
      "           5       0.57      0.32      0.41       862\n",
      "           6       0.61      0.54      0.57       903\n",
      "           7       0.57      0.81      0.67       889\n",
      "           8       0.56      0.32      0.41       892\n",
      "           9       0.57      0.65      0.61       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.51      0.49      0.48     14531\n",
      "weighted avg       0.47      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 18700, Loss: 0.5769649744033813, F1: 0.4843549453191533, Accuracy: 0.48950519578831464, Time Elapsed: 9574.183101177216 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       912\n",
      "           1       0.61      0.59      0.60       885\n",
      "           2       0.62      0.29      0.39       877\n",
      "           3       0.53      0.72      0.61       897\n",
      "           4       0.55      0.92      0.69       892\n",
      "           5       0.54      0.65      0.59       862\n",
      "           6       0.58      0.81      0.68       903\n",
      "           7       0.62      0.50      0.56       889\n",
      "           8       0.54      0.66      0.59       892\n",
      "           9       0.58      0.57      0.58       876\n",
      "          10       0.40      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 18800, Loss: 3.6904122829437256, F1: 0.5762537794257431, Accuracy: 0.5212304727823275, Time Elapsed: 9590.326737165451 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68       912\n",
      "           1       0.59      0.16      0.25       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.58      0.46      0.51       897\n",
      "           4       0.58      0.81      0.68       892\n",
      "           5       0.56      0.61      0.58       862\n",
      "           6       0.62      0.59      0.61       903\n",
      "           7       0.58      0.77      0.66       889\n",
      "           8       0.47      0.74      0.58       892\n",
      "           9       0.58      0.80      0.67       876\n",
      "          10       0.39      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.61      0.56     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 18900, Loss: 0.5110968351364136, F1: 0.5611595669564284, Accuracy: 0.5134539949074393, Time Elapsed: 9606.560423135757 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       912\n",
      "           1       0.59      0.88      0.70       885\n",
      "           2       0.59      0.69      0.64       877\n",
      "           3       0.55      0.65      0.60       897\n",
      "           4       0.60      0.22      0.32       892\n",
      "           5       0.53      0.67      0.59       862\n",
      "           6       0.61      0.75      0.68       903\n",
      "           7       0.60      0.68      0.64       889\n",
      "           8       0.55      0.61      0.58       892\n",
      "           9       0.53      0.75      0.62       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.64      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 19000, Loss: 0.7500594854354858, F1: 0.5824233425570718, Accuracy: 0.5236391163718945, Time Elapsed: 9622.520229101181 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       912\n",
      "           1       0.60      0.83      0.70       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.57      0.84      0.68       892\n",
      "           5       0.54      0.65      0.59       862\n",
      "           6       0.56      0.84      0.68       903\n",
      "           7       0.59      0.76      0.66       889\n",
      "           8       0.60      0.42      0.49       892\n",
      "           9       0.58      0.57      0.57       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 19100, Loss: 1.022345781326294, F1: 0.5973753634253274, Accuracy: 0.5291445874337622, Time Elapsed: 9638.729201078415 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.16      0.26       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.57      0.25      0.34       897\n",
      "           4       0.58      0.84      0.69       892\n",
      "           5       0.54      0.13      0.22       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.58      0.64      0.61       889\n",
      "           8       0.61      0.33      0.43       892\n",
      "           9       0.60      0.44      0.51       876\n",
      "          10       0.39      0.57      0.46      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.52      0.43      0.43     14531\n",
      "weighted avg       0.47      0.47      0.44     14531\n",
      "\n",
      "Epoch 5, Step 19200, Loss: 0.20762912929058075, F1: 0.433611571199636, Accuracy: 0.4743651503681784, Time Elapsed: 9654.703468084335 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.59      0.86      0.70       885\n",
      "           2       0.56      0.76      0.65       877\n",
      "           3       0.58      0.57      0.58       897\n",
      "           4       0.58      0.79      0.67       892\n",
      "           5       0.57      0.34      0.42       862\n",
      "           6       0.61      0.78      0.69       903\n",
      "           7       0.59      0.82      0.68       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.55      0.76      0.64       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 19300, Loss: 0.3737369179725647, F1: 0.603091752907027, Accuracy: 0.5343059665542633, Time Elapsed: 9670.618157148361 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.72       912\n",
      "           1       0.62      0.77      0.68       885\n",
      "           2       0.58      0.69      0.63       877\n",
      "           3       0.58      0.44      0.51       897\n",
      "           4       0.54      0.92      0.68       892\n",
      "           5       0.58      0.58      0.58       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.55      0.87      0.67       889\n",
      "           8       0.60      0.43      0.50       892\n",
      "           9       0.59      0.74      0.65       876\n",
      "          10       0.40      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 19400, Loss: 0.3248905539512634, F1: 0.5997016294230685, Accuracy: 0.5338242378363499, Time Elapsed: 9686.38688993454 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.84      0.72       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.59      0.45      0.51       877\n",
      "           3       0.64      0.26      0.37       897\n",
      "           4       0.59      0.70      0.64       892\n",
      "           5       0.54      0.70      0.61       862\n",
      "           6       0.58      0.86      0.70       903\n",
      "           7       0.61      0.62      0.62       889\n",
      "           8       0.54      0.79      0.64       892\n",
      "           9       0.61      0.47      0.53       876\n",
      "          10       0.40      0.32      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.58     14531\n",
      "weighted avg       0.52      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 19500, Loss: 4.7795281410217285, F1: 0.5819288407416633, Accuracy: 0.5286628587158488, Time Elapsed: 9702.244943141937 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.61      0.43      0.50       877\n",
      "           3       0.56      0.77      0.65       897\n",
      "           4       0.54      0.92      0.68       892\n",
      "           5       0.56      0.73      0.63       862\n",
      "           6       0.60      0.81      0.69       903\n",
      "           7       0.58      0.82      0.68       889\n",
      "           8       0.58      0.68      0.62       892\n",
      "           9       0.60      0.46      0.52       876\n",
      "          10       0.39      0.22      0.28      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 19600, Loss: 0.9391541481018066, F1: 0.6079443200209697, Accuracy: 0.5381597962975707, Time Elapsed: 9717.936922073364 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.52      0.86      0.65       877\n",
      "           3       0.56      0.75      0.64       897\n",
      "           4       0.56      0.78      0.65       892\n",
      "           5       0.53      0.69      0.60       862\n",
      "           6       0.57      0.89      0.69       903\n",
      "           7       0.59      0.81      0.68       889\n",
      "           8       0.59      0.65      0.62       892\n",
      "           9       0.58      0.80      0.67       876\n",
      "          10       0.39      0.14      0.21      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.55      0.74      0.62     14531\n",
      "weighted avg       0.50      0.54      0.49     14531\n",
      "\n",
      "Epoch 5, Step 19700, Loss: 1.0233826637268066, F1: 0.620801008823721, Accuracy: 0.5424265363705182, Time Elapsed: 9733.832521915436 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       912\n",
      "           1       0.60      0.78      0.68       885\n",
      "           2       0.59      0.52      0.55       877\n",
      "           3       0.54      0.76      0.63       897\n",
      "           4       0.58      0.63      0.60       892\n",
      "           5       0.56      0.62      0.59       862\n",
      "           6       0.60      0.82      0.70       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.58      0.32      0.41       892\n",
      "           9       0.59      0.76      0.66       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 19800, Loss: 0.3934474587440491, F1: 0.594150929502484, Accuracy: 0.529282224210309, Time Elapsed: 9750.10235118866 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.61      0.69      0.65       885\n",
      "           2       0.61      0.43      0.51       877\n",
      "           3       0.51      0.87      0.65       897\n",
      "           4       0.58      0.78      0.67       892\n",
      "           5       0.57      0.62      0.59       862\n",
      "           6       0.56      0.84      0.67       903\n",
      "           7       0.56      0.86      0.68       889\n",
      "           8       0.59      0.63      0.61       892\n",
      "           9       0.63      0.30      0.40       876\n",
      "          10       0.40      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 19900, Loss: 0.29786360263824463, F1: 0.5882037687631689, Accuracy: 0.5297639529282224, Time Elapsed: 9765.749696969986 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.61      0.79      0.69       885\n",
      "           2       0.58      0.56      0.57       877\n",
      "           3       0.59      0.75      0.66       897\n",
      "           4       0.59      0.63      0.61       892\n",
      "           5       0.57      0.43      0.49       862\n",
      "           6       0.62      0.78      0.69       903\n",
      "           7       0.60      0.78      0.68       889\n",
      "           8       0.55      0.78      0.64       892\n",
      "           9       0.61      0.15      0.24       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 20000, Loss: 0.2721075415611267, F1: 0.5763074060034533, Accuracy: 0.5273553093386553, Time Elapsed: 9781.736700057983 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.64      0.62       885\n",
      "           2       0.56      0.68      0.62       877\n",
      "           3       0.59      0.52      0.55       897\n",
      "           4       0.62      0.37      0.46       892\n",
      "           5       0.58      0.19      0.29       862\n",
      "           6       0.60      0.73      0.66       903\n",
      "           7       0.62      0.39      0.48       889\n",
      "           8       0.60      0.37      0.46       892\n",
      "           9       0.51      0.82      0.63       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 20100, Loss: 1.072468876838684, F1: 0.5346923222321182, Accuracy: 0.5040258757139908, Time Elapsed: 9797.503439188004 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.72       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.55      0.80      0.66       897\n",
      "           4       0.54      0.85      0.66       892\n",
      "           5       0.58      0.25      0.35       862\n",
      "           6       0.57      0.87      0.69       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.56      0.77      0.65       892\n",
      "           9       0.58      0.49      0.53       876\n",
      "          10       0.40      0.26      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 20200, Loss: 1.2391016483306885, F1: 0.5886255538402151, Accuracy: 0.5309338655288693, Time Elapsed: 9813.414988994598 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.78      0.69       912\n",
      "           1       0.49      0.97      0.65       885\n",
      "           2       0.59      0.47      0.52       877\n",
      "           3       0.60      0.65      0.63       897\n",
      "           4       0.50      0.95      0.66       892\n",
      "           5       0.54      0.61      0.58       862\n",
      "           6       0.55      0.89      0.68       903\n",
      "           7       0.60      0.50      0.55       889\n",
      "           8       0.55      0.80      0.65       892\n",
      "           9       0.54      0.82      0.65       876\n",
      "          10       0.39      0.17      0.24      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.54      0.69      0.59     14531\n",
      "weighted avg       0.49      0.52      0.47     14531\n",
      "\n",
      "Epoch 5, Step 20300, Loss: 0.9203720688819885, F1: 0.589434653416654, Accuracy: 0.5217122015002409, Time Elapsed: 9829.102634906769 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63       912\n",
      "           1       0.62      0.68      0.65       885\n",
      "           2       0.57      0.65      0.61       877\n",
      "           3       0.60      0.52      0.56       897\n",
      "           4       0.58      0.72      0.64       892\n",
      "           5       0.54      0.54      0.54       862\n",
      "           6       0.61      0.73      0.67       903\n",
      "           7       0.72      0.14      0.23       889\n",
      "           8       0.48      0.90      0.62       892\n",
      "           9       0.54      0.20      0.29       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 20400, Loss: 0.6270086765289307, F1: 0.5305218997507208, Accuracy: 0.503475328607804, Time Elapsed: 9844.90409898758 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.57      0.74      0.65       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.62      0.49      0.55       892\n",
      "           5       0.52      0.71      0.60       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.60      0.50      0.54       889\n",
      "           8       0.57      0.65      0.61       892\n",
      "           9       0.56      0.80      0.66       876\n",
      "          10       0.40      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 20500, Loss: 1.0144122838974, F1: 0.5927876944539232, Accuracy: 0.5279058564448421, Time Elapsed: 9860.55582523346 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.59      0.45      0.51       885\n",
      "           2       0.59      0.41      0.49       877\n",
      "           3       0.60      0.54      0.57       897\n",
      "           4       0.59      0.68      0.64       892\n",
      "           5       0.51      0.76      0.61       862\n",
      "           6       0.62      0.64      0.63       903\n",
      "           7       0.59      0.81      0.69       889\n",
      "           8       0.51      0.77      0.62       892\n",
      "           9       0.61      0.70      0.65       876\n",
      "          10       0.40      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.63      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 20600, Loss: 0.5411919951438904, F1: 0.5869219301713862, Accuracy: 0.524327300254628, Time Elapsed: 9877.425333976746 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.43      0.50       912\n",
      "           1       0.58      0.16      0.25       885\n",
      "           2       0.60      0.58      0.59       877\n",
      "           3       0.60      0.50      0.55       897\n",
      "           4       0.57      0.90      0.70       892\n",
      "           5       0.52      0.71      0.60       862\n",
      "           6       0.63      0.33      0.43       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.55      0.55      0.55       892\n",
      "           9       0.59      0.68      0.63       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 20700, Loss: 0.6743003726005554, F1: 0.5342683775971016, Accuracy: 0.5018925056775171, Time Elapsed: 9893.067590236664 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.81      0.69       885\n",
      "           2       0.62      0.25      0.35       877\n",
      "           3       0.60      0.70      0.65       897\n",
      "           4       0.57      0.88      0.69       892\n",
      "           5       0.56      0.36      0.44       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.59      0.84      0.69       889\n",
      "           8       0.58      0.38      0.46       892\n",
      "           9       0.59      0.09      0.16       876\n",
      "          10       0.39      0.47      0.43      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.50      0.48     14531\n",
      "weighted avg       0.48      0.50      0.46     14531\n",
      "\n",
      "Epoch 5, Step 20800, Loss: 1.2614498138427734, F1: 0.4761422544306692, Accuracy: 0.49501066685018236, Time Elapsed: 9908.832289934158 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       912\n",
      "           1       0.62      0.53      0.57       885\n",
      "           2       0.60      0.51      0.55       877\n",
      "           3       0.60      0.61      0.60       897\n",
      "           4       0.58      0.78      0.67       892\n",
      "           5       0.55      0.17      0.26       862\n",
      "           6       0.63      0.66      0.64       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.56      0.73      0.63       892\n",
      "           9       0.57      0.83      0.68       876\n",
      "          10       0.40      0.36      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.60      0.57     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 20900, Loss: 0.438768595457077, F1: 0.5727145032507782, Accuracy: 0.5247402105842681, Time Elapsed: 9924.479277133942 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.70       912\n",
      "           1       0.61      0.87      0.72       885\n",
      "           2       0.59      0.73      0.65       877\n",
      "           3       0.60      0.63      0.62       897\n",
      "           4       0.58      0.69      0.63       892\n",
      "           5       0.51      0.26      0.35       862\n",
      "           6       0.61      0.77      0.68       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.60      0.52      0.56       892\n",
      "           9       0.59      0.77      0.67       876\n",
      "          10       0.38      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.66      0.60     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 21000, Loss: 0.6154788136482239, F1: 0.5958598717071859, Accuracy: 0.5305897735875026, Time Elapsed: 9940.496732234955 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.61      0.48      0.54       897\n",
      "           4       0.56      0.73      0.63       892\n",
      "           5       0.55      0.22      0.32       862\n",
      "           6       0.59      0.85      0.69       903\n",
      "           7       0.59      0.61      0.60       889\n",
      "           8       0.61      0.67      0.64       892\n",
      "           9       0.56      0.83      0.67       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 21100, Loss: 1.3447275161743164, F1: 0.5773127968659147, Accuracy: 0.5215057463354208, Time Elapsed: 9956.432015180588 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.60      0.59      0.60       877\n",
      "           3       0.61      0.59      0.60       897\n",
      "           4       0.54      0.75      0.63       892\n",
      "           5       0.57      0.46      0.51       862\n",
      "           6       0.61      0.81      0.70       903\n",
      "           7       0.59      0.68      0.63       889\n",
      "           8       0.61      0.55      0.58       892\n",
      "           9       0.55      0.80      0.65       876\n",
      "          10       0.39      0.28      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 21200, Loss: 1.1958045959472656, F1: 0.6015709277721286, Accuracy: 0.5316908677998762, Time Elapsed: 9972.2534430027 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65       912\n",
      "           1       0.59      0.89      0.71       885\n",
      "           2       0.56      0.74      0.64       877\n",
      "           3       0.60      0.65      0.63       897\n",
      "           4       0.57      0.45      0.51       892\n",
      "           5       0.51      0.68      0.59       862\n",
      "           6       0.61      0.68      0.65       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.60      0.00      0.01       892\n",
      "           9       0.53      0.81      0.64       876\n",
      "          10       0.40      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.55     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 21300, Loss: 0.7686699628829956, F1: 0.5509397927656257, Accuracy: 0.5188218291927603, Time Elapsed: 9988.434667110443 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.81      0.69       885\n",
      "           2       0.61      0.55      0.58       877\n",
      "           3       0.60      0.56      0.58       897\n",
      "           4       0.59      0.37      0.45       892\n",
      "           5       0.56      0.61      0.59       862\n",
      "           6       0.61      0.75      0.68       903\n",
      "           7       0.60      0.55      0.57       889\n",
      "           8       0.59      0.62      0.60       892\n",
      "           9       0.57      0.78      0.66       876\n",
      "          10       0.39      0.42      0.41      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.55      0.53     14531\n",
      "weighted avg       0.48      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 21400, Loss: 0.8342468738555908, F1: 0.52816101884389, Accuracy: 0.5064345193035579, Time Elapsed: 10004.246562957764 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.61      0.75      0.67       885\n",
      "           2       0.63      0.25      0.35       877\n",
      "           3       0.60      0.59      0.59       897\n",
      "           4       0.54      0.80      0.64       892\n",
      "           5       0.56      0.56      0.56       862\n",
      "           6       0.61      0.67      0.64       903\n",
      "           7       0.60      0.82      0.69       889\n",
      "           8       0.57      0.70      0.63       892\n",
      "           9       0.59      0.34      0.43       876\n",
      "          10       0.39      0.43      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.54      0.51     14531\n",
      "weighted avg       0.47      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 21500, Loss: 0.8159475922584534, F1: 0.5105444224718488, Accuracy: 0.4994838620879499, Time Elapsed: 10020.263107061386 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       912\n",
      "           1       0.63      0.44      0.52       885\n",
      "           2       0.60      0.64      0.62       877\n",
      "           3       0.59      0.56      0.58       897\n",
      "           4       0.57      0.73      0.64       892\n",
      "           5       0.56      0.54      0.55       862\n",
      "           6       0.65      0.14      0.23       903\n",
      "           7       0.60      0.74      0.66       889\n",
      "           8       0.55      0.80      0.65       892\n",
      "           9       0.57      0.44      0.49       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.56      0.55     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 21600, Loss: 1.3327064514160156, F1: 0.5450083786785097, Accuracy: 0.5067786112449246, Time Elapsed: 10037.316972970963 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70       912\n",
      "           1       0.60      0.59      0.59       885\n",
      "           2       0.57      0.68      0.62       877\n",
      "           3       0.54      0.83      0.66       897\n",
      "           4       0.54      0.56      0.55       892\n",
      "           5       0.55      0.44      0.49       862\n",
      "           6       0.61      0.79      0.69       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.58      0.65      0.61       892\n",
      "           9       0.59      0.52      0.55       876\n",
      "          10       0.38      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.59     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 21700, Loss: 0.7334817051887512, F1: 0.5879945543209995, Accuracy: 0.5210240176175074, Time Elapsed: 10053.593096256256 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       912\n",
      "           1       0.62      0.35      0.44       885\n",
      "           2       0.60      0.47      0.52       877\n",
      "           3       0.60      0.62      0.61       897\n",
      "           4       0.54      0.40      0.46       892\n",
      "           5       0.55      0.69      0.61       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.60      0.63      0.61       889\n",
      "           8       0.54      0.81      0.65       892\n",
      "           9       0.55      0.79      0.65       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.61      0.57     14531\n",
      "weighted avg       0.50      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 21800, Loss: 0.9063625335693359, F1: 0.5729781680847222, Accuracy: 0.5159314568852797, Time Elapsed: 10069.467519044876 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.56      0.59      0.57       892\n",
      "           5       0.57      0.35      0.43       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.59      0.74      0.66       889\n",
      "           8       0.57      0.63      0.60       892\n",
      "           9       0.59      0.51      0.54       876\n",
      "          10       0.39      0.33      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 21900, Loss: 0.5336271524429321, F1: 0.5863169923676795, Accuracy: 0.5239832083132613, Time Elapsed: 10151.936120986938 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64       912\n",
      "           1       0.60      0.30      0.40       885\n",
      "           2       0.60      0.48      0.53       877\n",
      "           3       0.61      0.52      0.56       897\n",
      "           4       0.54      0.72      0.62       892\n",
      "           5       0.55      0.61      0.58       862\n",
      "           6       0.61      0.79      0.68       903\n",
      "           7       0.62      0.32      0.42       889\n",
      "           8       0.57      0.75      0.65       892\n",
      "           9       0.57      0.40      0.47       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.54     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 5, Step 22000, Loss: 0.973915696144104, F1: 0.5413973604219072, Accuracy: 0.5021677792306104, Time Elapsed: 10169.701937198639 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.58      0.40      0.48       885\n",
      "           2       0.59      0.41      0.49       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.56      0.39      0.46       892\n",
      "           5       0.54      0.60      0.57       862\n",
      "           6       0.61      0.52      0.56       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.58      0.76      0.66       892\n",
      "           9       0.67      0.00      0.00       876\n",
      "          10       0.38      0.54      0.45      5646\n",
      "\n",
      "    accuracy                           0.47     14531\n",
      "   macro avg       0.52      0.44      0.44     14531\n",
      "weighted avg       0.48      0.47      0.44     14531\n",
      "\n",
      "Epoch 5, Step 22100, Loss: 0.9603506922721863, F1: 0.44164455609914205, Accuracy: 0.4743651503681784, Time Elapsed: 10185.635381937027 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       912\n",
      "           1       0.58      0.94      0.72       885\n",
      "           2       0.62      0.31      0.41       877\n",
      "           3       0.67      0.00      0.00       897\n",
      "           4       0.57      0.63      0.60       892\n",
      "           5       0.51      0.59      0.55       862\n",
      "           6       0.65      0.36      0.46       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.58      0.61      0.59       892\n",
      "           9       0.57      0.71      0.63       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.58      0.55      0.52     14531\n",
      "weighted avg       0.52      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 22200, Loss: 0.5988246202468872, F1: 0.517047808351722, Accuracy: 0.5028559631133439, Time Elapsed: 10917.044412136078 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       912\n",
      "           1       0.60      0.55      0.57       885\n",
      "           2       0.58      0.71      0.64       877\n",
      "           3       0.61      0.31      0.41       897\n",
      "           4       0.56      0.21      0.31       892\n",
      "           5       0.51      0.25      0.34       862\n",
      "           6       0.63      0.59      0.61       903\n",
      "           7       0.61      0.73      0.66       889\n",
      "           8       0.58      0.65      0.61       892\n",
      "           9       0.59      0.68      0.63       876\n",
      "          10       0.39      0.44      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.53      0.53     14531\n",
      "weighted avg       0.51      0.50      0.49     14531\n",
      "\n",
      "Epoch 5, Step 22300, Loss: 0.8892248868942261, F1: 0.5323013043084647, Accuracy: 0.5020989608423371, Time Elapsed: 10934.508394956589 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.60      0.53      0.57       885\n",
      "           2       0.60      0.56      0.58       877\n",
      "           3       0.60      0.60      0.60       897\n",
      "           4       0.57      0.77      0.65       892\n",
      "           5       0.52      0.63      0.57       862\n",
      "           6       0.61      0.70      0.65       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.59      0.58      0.59       892\n",
      "           9       0.58      0.80      0.67       876\n",
      "          10       0.39      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 22400, Loss: 0.5942291021347046, F1: 0.6000792352964625, Accuracy: 0.5295574977634023, Time Elapsed: 10950.045039176941 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.60      0.89      0.71       885\n",
      "           2       0.60      0.46      0.52       877\n",
      "           3       0.58      0.63      0.60       897\n",
      "           4       0.56      0.75      0.64       892\n",
      "           5       0.55      0.54      0.54       862\n",
      "           6       0.62      0.76      0.68       903\n",
      "           7       0.55      0.90      0.68       889\n",
      "           8       0.58      0.53      0.56       892\n",
      "           9       0.59      0.73      0.65       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 22500, Loss: 0.14209580421447754, F1: 0.6015124650163621, Accuracy: 0.5324478700708829, Time Elapsed: 11446.91774725914 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       912\n",
      "           1       0.61      0.61      0.61       885\n",
      "           2       0.61      0.16      0.25       877\n",
      "           3       0.58      0.56      0.57       897\n",
      "           4       0.58      0.79      0.67       892\n",
      "           5       0.53      0.44      0.48       862\n",
      "           6       0.61      0.74      0.67       903\n",
      "           7       0.58      0.84      0.68       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.60      0.50      0.55       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.59      0.56     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 22600, Loss: 0.20129071176052094, F1: 0.5583248488831059, Accuracy: 0.5160690936618264, Time Elapsed: 11462.945260047913 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.62      0.31      0.42       877\n",
      "           3       0.60      0.50      0.55       897\n",
      "           4       0.53      0.90      0.67       892\n",
      "           5       0.49      0.83      0.61       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.60      0.71      0.65       889\n",
      "           8       0.57      0.54      0.56       892\n",
      "           9       0.57      0.82      0.67       876\n",
      "          10       0.39      0.25      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 22700, Loss: 0.5067645311355591, F1: 0.5902872834460814, Accuracy: 0.5274241277269286, Time Elapsed: 11480.043155193329 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.95      0.71       912\n",
      "           1       0.60      0.45      0.52       885\n",
      "           2       0.58      0.73      0.64       877\n",
      "           3       0.57      0.16      0.25       897\n",
      "           4       0.54      0.53      0.54       892\n",
      "           5       0.47      0.86      0.61       862\n",
      "           6       0.61      0.69      0.65       903\n",
      "           7       0.60      0.80      0.69       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.45      0.88      0.60       876\n",
      "          10       0.38      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.54      0.63      0.55     14531\n",
      "weighted avg       0.49      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 22800, Loss: 0.4687442183494568, F1: 0.5523049519350685, Accuracy: 0.5018925056775171, Time Elapsed: 11982.73483800888 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.71       912\n",
      "           1       0.62      0.06      0.11       885\n",
      "           2       0.55      0.79      0.65       877\n",
      "           3       0.61      0.44      0.52       897\n",
      "           4       0.55      0.57      0.56       892\n",
      "           5       0.54      0.51      0.52       862\n",
      "           6       0.61      0.61      0.61       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.61      0.56      0.58       892\n",
      "           9       0.54      0.75      0.63       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.54     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 22900, Loss: 0.16387958824634552, F1: 0.5397426353126558, Accuracy: 0.5076044319042048, Time Elapsed: 12002.646260023117 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.61      0.67      0.64       885\n",
      "           2       0.56      0.77      0.65       877\n",
      "           3       0.63      0.54      0.58       897\n",
      "           4       0.58      0.76      0.66       892\n",
      "           5       0.52      0.70      0.60       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.62      0.58      0.60       889\n",
      "           8       0.58      0.54      0.56       892\n",
      "           9       0.61      0.19      0.29       876\n",
      "          10       0.40      0.34      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.52      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 23000, Loss: 1.115228295326233, F1: 0.575748763091114, Accuracy: 0.5239832083132613, Time Elapsed: 12019.784478902817 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       912\n",
      "           1       0.62      0.47      0.54       885\n",
      "           2       0.61      0.17      0.26       877\n",
      "           3       0.57      0.69      0.63       897\n",
      "           4       0.58      0.74      0.65       892\n",
      "           5       0.55      0.25      0.35       862\n",
      "           6       0.61      0.78      0.68       903\n",
      "           7       0.61      0.68      0.65       889\n",
      "           8       0.59      0.56      0.58       892\n",
      "           9       0.60      0.67      0.63       876\n",
      "          10       0.40      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.57      0.55     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 23100, Loss: 0.7062016725540161, F1: 0.5518490377713653, Accuracy: 0.5171701878742, Time Elapsed: 12036.541394233704 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.72       912\n",
      "           1       0.62      0.38      0.47       885\n",
      "           2       0.59      0.56      0.58       877\n",
      "           3       0.54      0.78      0.64       897\n",
      "           4       0.57      0.61      0.59       892\n",
      "           5       0.55      0.66      0.60       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.61      0.70      0.65       889\n",
      "           8       0.57      0.70      0.63       892\n",
      "           9       0.56      0.79      0.66       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 23200, Loss: 1.3018426895141602, F1: 0.5951015129110336, Accuracy: 0.5287316771041222, Time Elapsed: 12052.206593990326 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.61      0.82      0.70       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.58      0.70      0.64       897\n",
      "           4       0.58      0.74      0.65       892\n",
      "           5       0.56      0.45      0.50       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.61      0.80      0.69       889\n",
      "           8       0.56      0.75      0.64       892\n",
      "           9       0.56      0.84      0.67       876\n",
      "          10       0.39      0.23      0.29      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.57      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.51     14531\n",
      "\n",
      "Epoch 5, Step 23300, Loss: 0.3312917947769165, F1: 0.6113876039087918, Accuracy: 0.5395361640630376, Time Elapsed: 12370.181341171265 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.61      0.57      0.59       885\n",
      "           2       0.59      0.45      0.52       877\n",
      "           3       0.59      0.51      0.55       897\n",
      "           4       0.59      0.44      0.50       892\n",
      "           5       0.56      0.50      0.53       862\n",
      "           6       0.61      0.23      0.33       903\n",
      "           7       0.61      0.73      0.66       889\n",
      "           8       0.59      0.49      0.54       892\n",
      "           9       0.58      0.77      0.66       876\n",
      "          10       0.38      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.55      0.55     14531\n",
      "weighted avg       0.51      0.50      0.50     14531\n",
      "\n",
      "Epoch 5, Step 23400, Loss: 0.6653748750686646, F1: 0.5456051268007236, Accuracy: 0.5049205147615443, Time Elapsed: 12387.652662038803 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.87      0.71       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.59      0.57      0.58       877\n",
      "           3       0.60      0.72      0.65       897\n",
      "           4       0.58      0.38      0.46       892\n",
      "           5       0.50      0.83      0.62       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.59      0.81      0.69       889\n",
      "           8       0.60      0.52      0.56       892\n",
      "           9       0.57      0.82      0.67       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.68      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 23500, Loss: 0.6528385281562805, F1: 0.6035220062404744, Accuracy: 0.5347188768839034, Time Elapsed: 12402.868010044098 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.00      0.00      0.00       877\n",
      "           3       0.61      0.27      0.38       897\n",
      "           4       0.58      0.71      0.64       892\n",
      "           5       0.57      0.35      0.44       862\n",
      "           6       0.59      0.85      0.70       903\n",
      "           7       0.62      0.36      0.46       889\n",
      "           8       0.58      0.31      0.40       892\n",
      "           9       0.58      0.78      0.66       876\n",
      "          10       0.39      0.43      0.41      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.52      0.54      0.50     14531\n",
      "weighted avg       0.48      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 23600, Loss: 5.432952404022217, F1: 0.5015000804698994, Accuracy: 0.501686050512697, Time Elapsed: 12717.574142217636 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.86      0.71       912\n",
      "           1       0.61      0.86      0.71       885\n",
      "           2       0.59      0.55      0.57       877\n",
      "           3       0.58      0.61      0.59       897\n",
      "           4       0.57      0.78      0.66       892\n",
      "           5       0.56      0.32      0.40       862\n",
      "           6       0.61      0.79      0.68       903\n",
      "           7       0.63      0.59      0.61       889\n",
      "           8       0.59      0.27      0.37       892\n",
      "           9       0.51      0.85      0.64       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 23700, Loss: 0.42141810059547424, F1: 0.5735988150521418, Accuracy: 0.5220562934416076, Time Elapsed: 12733.517355918884 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.71       912\n",
      "           1       0.61      0.83      0.70       885\n",
      "           2       0.61      0.27      0.38       877\n",
      "           3       0.57      0.18      0.27       897\n",
      "           4       0.54      0.90      0.68       892\n",
      "           5       0.50      0.53      0.52       862\n",
      "           6       0.57      0.88      0.69       903\n",
      "           7       0.59      0.73      0.66       889\n",
      "           8       0.57      0.61      0.59       892\n",
      "           9       0.55      0.72      0.62       876\n",
      "          10       0.38      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.55      0.62      0.56     14531\n",
      "weighted avg       0.50      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 23800, Loss: 0.4268832206726074, F1: 0.5585647741356808, Accuracy: 0.5131787213543458, Time Elapsed: 12749.039439201355 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.78      0.68       885\n",
      "           2       0.57      0.36      0.44       877\n",
      "           3       0.59      0.30      0.39       897\n",
      "           4       0.57      0.62      0.59       892\n",
      "           5       0.53      0.20      0.30       862\n",
      "           6       0.62      0.66      0.64       903\n",
      "           7       0.61      0.52      0.56       889\n",
      "           8       0.60      0.42      0.49       892\n",
      "           9       0.62      0.40      0.48       876\n",
      "          10       0.39      0.56      0.46      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.52      0.44      0.46     14531\n",
      "weighted avg       0.47      0.48      0.46     14531\n",
      "\n",
      "Epoch 5, Step 23900, Loss: 1.994378924369812, F1: 0.4575584993969311, Accuracy: 0.47856307205285253, Time Elapsed: 13765.972583055496 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.86      0.71       885\n",
      "           2       0.60      0.41      0.49       877\n",
      "           3       0.59      0.78      0.67       897\n",
      "           4       0.53      0.88      0.66       892\n",
      "           5       0.52      0.72      0.61       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.61      0.56      0.58       889\n",
      "           8       0.55      0.10      0.17       892\n",
      "           9       0.60      0.71      0.65       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.56      0.51     14531\n",
      "weighted avg       0.47      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 24000, Loss: 0.149493008852005, F1: 0.5089439126787878, Accuracy: 0.5036817837726241, Time Elapsed: 13786.780714035034 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.57      0.98      0.72       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.58      0.74      0.65       897\n",
      "           4       0.58      0.84      0.68       892\n",
      "           5       0.56      0.51      0.54       862\n",
      "           6       0.59      0.86      0.70       903\n",
      "           7       0.62      0.21      0.31       889\n",
      "           8       0.60      0.30      0.40       892\n",
      "           9       0.59      0.76      0.66       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.56      0.51     14531\n",
      "weighted avg       0.48      0.51      0.47     14531\n",
      "\n",
      "Epoch 5, Step 24100, Loss: 2.9777698516845703, F1: 0.5113873009944817, Accuracy: 0.5069850664097447, Time Elapsed: 13805.816635131836 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63       912\n",
      "           1       0.60      0.88      0.71       885\n",
      "           2       0.59      0.64      0.62       877\n",
      "           3       0.56      0.80      0.66       897\n",
      "           4       0.59      0.74      0.66       892\n",
      "           5       0.58      0.59      0.58       862\n",
      "           6       0.60      0.84      0.70       903\n",
      "           7       0.59      0.81      0.69       889\n",
      "           8       0.58      0.74      0.65       892\n",
      "           9       0.60      0.72      0.66       876\n",
      "          10       0.40      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.55     14531\n",
      "   macro avg       0.57      0.69      0.62     14531\n",
      "weighted avg       0.52      0.55      0.52     14531\n",
      "\n",
      "Epoch 5, Step 24200, Loss: 1.9053289890289307, F1: 0.6228625059289916, Accuracy: 0.5466932764434657, Time Elapsed: 14798.796591997147 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.87      0.71       912\n",
      "           1       0.59      0.58      0.58       885\n",
      "           2       0.58      0.70      0.64       877\n",
      "           3       0.61      0.58      0.60       897\n",
      "           4       0.58      0.78      0.67       892\n",
      "           5       0.57      0.59      0.58       862\n",
      "           6       0.61      0.83      0.70       903\n",
      "           7       0.60      0.67      0.63       889\n",
      "           8       0.56      0.78      0.65       892\n",
      "           9       0.62      0.50      0.56       876\n",
      "          10       0.39      0.29      0.33      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.65      0.60     14531\n",
      "weighted avg       0.51      0.53      0.52     14531\n",
      "\n",
      "Epoch 5, Step 24300, Loss: 0.708714485168457, F1: 0.6039205156887931, Accuracy: 0.5338930562246232, Time Elapsed: 14815.982506990433 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.84      0.72       912\n",
      "           1       0.00      0.00      0.00       885\n",
      "           2       0.59      0.45      0.51       877\n",
      "           3       0.61      0.34      0.44       897\n",
      "           4       0.59      0.68      0.63       892\n",
      "           5       0.55      0.56      0.55       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.64      0.35      0.45       889\n",
      "           8       0.55      0.72      0.63       892\n",
      "           9       0.57      0.05      0.09       876\n",
      "          10       0.40      0.51      0.45      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.52      0.48      0.47     14531\n",
      "weighted avg       0.48      0.49      0.46     14531\n",
      "\n",
      "Epoch 5, Step 24400, Loss: 1.8231043815612793, F1: 0.46958597280053477, Accuracy: 0.4944601197439956, Time Elapsed: 15772.447652101517 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       912\n",
      "           1       0.59      0.95      0.73       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.61      0.45      0.52       897\n",
      "           4       0.56      0.85      0.68       892\n",
      "           5       0.57      0.49      0.53       862\n",
      "           6       0.61      0.82      0.70       903\n",
      "           7       0.59      0.70      0.64       889\n",
      "           8       0.58      0.58      0.58       892\n",
      "           9       0.00      0.00      0.00       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.51      0.61      0.55     14531\n",
      "weighted avg       0.47      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 24500, Loss: 0.7092469930648804, F1: 0.5496940848718119, Accuracy: 0.5212304727823275, Time Elapsed: 15788.359540939331 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.60      0.92      0.73       885\n",
      "           2       0.57      0.77      0.65       877\n",
      "           3       0.61      0.71      0.66       897\n",
      "           4       0.54      0.84      0.66       892\n",
      "           5       0.52      0.72      0.61       862\n",
      "           6       0.59      0.83      0.69       903\n",
      "           7       0.61      0.43      0.50       889\n",
      "           8       0.59      0.71      0.64       892\n",
      "           9       0.58      0.37      0.46       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.68      0.60     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 24600, Loss: 4.741597652435303, F1: 0.6008441137466597, Accuracy: 0.5352006056018168, Time Elapsed: 15805.827757120132 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72       912\n",
      "           1       0.61      0.77      0.68       885\n",
      "           2       0.59      0.49      0.53       877\n",
      "           3       0.54      0.86      0.66       897\n",
      "           4       0.56      0.86      0.68       892\n",
      "           5       0.55      0.47      0.50       862\n",
      "           6       0.61      0.76      0.68       903\n",
      "           7       0.60      0.72      0.66       889\n",
      "           8       0.51      0.87      0.65       892\n",
      "           9       0.61      0.26      0.36       876\n",
      "          10       0.39      0.25      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.58     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 5, Step 24700, Loss: 0.5926722884178162, F1: 0.58433811452583, Accuracy: 0.525497212855275, Time Elapsed: 16729.919668912888 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       912\n",
      "           1       0.60      0.77      0.67       885\n",
      "           2       0.59      0.63      0.61       877\n",
      "           3       0.59      0.55      0.57       897\n",
      "           4       0.55      0.86      0.67       892\n",
      "           5       0.57      0.61      0.59       862\n",
      "           6       0.58      0.85      0.69       903\n",
      "           7       0.58      0.83      0.68       889\n",
      "           8       0.60      0.48      0.54       892\n",
      "           9       0.68      0.05      0.10       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.62      0.56     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 24800, Loss: 2.678128242492676, F1: 0.5628807881839257, Accuracy: 0.5244649370311747, Time Elapsed: 16746.920866012573 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.57      0.96      0.71       885\n",
      "           2       0.58      0.47      0.52       877\n",
      "           3       0.58      0.72      0.64       897\n",
      "           4       0.59      0.72      0.65       892\n",
      "           5       0.58      0.39      0.46       862\n",
      "           6       0.57      0.90      0.70       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.54      0.72      0.62       892\n",
      "           9       0.58      0.74      0.65       876\n",
      "          10       0.39      0.24      0.30      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.67      0.60     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 24900, Loss: 0.2551687955856323, F1: 0.6012028601763569, Accuracy: 0.5333425091184364, Time Elapsed: 16763.685025930405 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.58      0.47      0.52       877\n",
      "           3       0.59      0.67      0.63       897\n",
      "           4       0.56      0.85      0.68       892\n",
      "           5       0.57      0.24      0.33       862\n",
      "           6       0.60      0.33      0.43       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.59      0.52      0.55       892\n",
      "           9       0.63      0.49      0.55       876\n",
      "          10       0.40      0.40      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.57      0.55     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 25000, Loss: 1.4315699338912964, F1: 0.5533371300009365, Accuracy: 0.5146927258963595, Time Elapsed: 16780.105588912964 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.59      0.47      0.52       877\n",
      "           3       0.60      0.41      0.49       897\n",
      "           4       0.56      0.81      0.67       892\n",
      "           5       0.58      0.45      0.51       862\n",
      "           6       0.58      0.88      0.70       903\n",
      "           7       0.61      0.58      0.60       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.59      0.75      0.66       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.64      0.59     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 25100, Loss: 0.4093605875968933, F1: 0.5901070758509243, Accuracy: 0.5281811299979354, Time Elapsed: 16795.538214206696 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.89      0.72       912\n",
      "           1       0.60      0.85      0.70       885\n",
      "           2       0.62      0.36      0.45       877\n",
      "           3       0.61      0.62      0.62       897\n",
      "           4       0.58      0.59      0.58       892\n",
      "           5       0.57      0.56      0.57       862\n",
      "           6       0.61      0.56      0.58       903\n",
      "           7       0.61      0.05      0.09       889\n",
      "           8       0.60      0.27      0.37       892\n",
      "           9       0.44      0.88      0.59       876\n",
      "          10       0.39      0.39      0.39      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.56      0.55      0.51     14531\n",
      "weighted avg       0.51      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 25200, Loss: 0.4436075687408447, F1: 0.5140224453957258, Accuracy: 0.49597412428600923, Time Elapsed: 17800.62890601158 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.69       912\n",
      "           1       0.59      0.48      0.53       885\n",
      "           2       0.65      0.13      0.22       877\n",
      "           3       0.60      0.53      0.56       897\n",
      "           4       0.58      0.61      0.60       892\n",
      "           5       0.55      0.18      0.27       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.64      0.29      0.40       889\n",
      "           8       0.60      0.40      0.48       892\n",
      "           9       0.57      0.19      0.28       876\n",
      "          10       0.39      0.55      0.46      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.45      0.47     14531\n",
      "weighted avg       0.52      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 25300, Loss: 0.2920113801956177, F1: 0.4699144807177213, Accuracy: 0.48510081893882046, Time Elapsed: 17819.915421962738 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69       912\n",
      "           1       0.59      0.81      0.68       885\n",
      "           2       0.62      0.43      0.51       877\n",
      "           3       0.59      0.34      0.43       897\n",
      "           4       0.57      0.85      0.68       892\n",
      "           5       0.57      0.45      0.50       862\n",
      "           6       0.62      0.63      0.63       903\n",
      "           7       0.61      0.54      0.57       889\n",
      "           8       0.59      0.46      0.51       892\n",
      "           9       0.60      0.44      0.50       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.56     14531\n",
      "weighted avg       0.52      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 25400, Loss: 0.4607190489768982, F1: 0.5554526032362368, Accuracy: 0.5103571674351387, Time Elapsed: 17836.020284175873 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.95      0.72       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.59      0.62      0.60       877\n",
      "           3       0.60      0.29      0.39       897\n",
      "           4       0.56      0.91      0.70       892\n",
      "           5       0.53      0.71      0.61       862\n",
      "           6       0.53      0.87      0.66       903\n",
      "           7       0.59      0.62      0.61       889\n",
      "           8       0.57      0.13      0.21       892\n",
      "           9       0.60      0.55      0.57       876\n",
      "          10       0.39      0.30      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.63      0.56     14531\n",
      "weighted avg       0.51      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 25500, Loss: 1.2313469648361206, F1: 0.5589487673546606, Accuracy: 0.5199917417934072, Time Elapsed: 18754.660486221313 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.89      0.71       912\n",
      "           1       0.60      0.94      0.73       885\n",
      "           2       0.58      0.76      0.66       877\n",
      "           3       0.60      0.68      0.64       897\n",
      "           4       0.58      0.74      0.65       892\n",
      "           5       0.51      0.65      0.57       862\n",
      "           6       0.58      0.86      0.70       903\n",
      "           7       0.60      0.54      0.57       889\n",
      "           8       0.59      0.67      0.63       892\n",
      "           9       0.52      0.77      0.62       876\n",
      "          10       0.39      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.50      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 25600, Loss: 1.506417989730835, F1: 0.61256036466059, Accuracy: 0.5372651572500172, Time Elapsed: 18774.859947919846 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.91      0.72       912\n",
      "           1       0.61      0.90      0.72       885\n",
      "           2       0.61      0.48      0.53       877\n",
      "           3       0.60      0.56      0.58       897\n",
      "           4       0.57      0.71      0.64       892\n",
      "           5       0.53      0.42      0.47       862\n",
      "           6       0.59      0.84      0.69       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.58      0.70      0.63       892\n",
      "           9       0.60      0.68      0.64       876\n",
      "          10       0.39      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.57      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 25700, Loss: 0.2905694544315338, F1: 0.6021220895417838, Accuracy: 0.5343747849425367, Time Elapsed: 19064.852283239365 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.70       912\n",
      "           1       0.61      0.78      0.69       885\n",
      "           2       0.60      0.62      0.61       877\n",
      "           3       0.61      0.60      0.60       897\n",
      "           4       0.61      0.46      0.52       892\n",
      "           5       0.49      0.75      0.60       862\n",
      "           6       0.60      0.79      0.68       903\n",
      "           7       0.61      0.26      0.37       889\n",
      "           8       0.58      0.31      0.40       892\n",
      "           9       0.58      0.64      0.61       876\n",
      "          10       0.39      0.37      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 25800, Loss: 2.2426748275756836, F1: 0.5607771481974579, Accuracy: 0.5148991810611796, Time Elapsed: 19083.736708164215 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       912\n",
      "           1       0.60      0.96      0.74       885\n",
      "           2       0.59      0.64      0.61       877\n",
      "           3       0.61      0.66      0.63       897\n",
      "           4       0.59      0.73      0.65       892\n",
      "           5       0.56      0.39      0.46       862\n",
      "           6       0.68      0.11      0.19       903\n",
      "           7       0.59      0.62      0.61       889\n",
      "           8       0.57      0.16      0.26       892\n",
      "           9       0.58      0.78      0.66       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.58      0.56      0.53     14531\n",
      "weighted avg       0.52      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 25900, Loss: 0.8147187829017639, F1: 0.533954343623021, Accuracy: 0.5098754387172253, Time Elapsed: 20066.20873117447 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.57      0.97      0.72       885\n",
      "           2       0.58      0.73      0.64       877\n",
      "           3       0.60      0.66      0.63       897\n",
      "           4       0.60      0.45      0.52       892\n",
      "           5       0.55      0.40      0.47       862\n",
      "           6       0.63      0.62      0.63       903\n",
      "           7       0.57      0.73      0.64       889\n",
      "           8       0.61      0.42      0.49       892\n",
      "           9       0.58      0.71      0.64       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.52      0.55      0.52     14531\n",
      "weighted avg       0.47      0.51      0.48     14531\n",
      "\n",
      "Epoch 5, Step 26000, Loss: 0.4485699534416199, F1: 0.5243253405153473, Accuracy: 0.505058151538091, Time Elapsed: 21130.747053146362 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63       912\n",
      "           1       0.59      0.94      0.73       885\n",
      "           2       0.59      0.70      0.64       877\n",
      "           3       0.59      0.52      0.55       897\n",
      "           4       0.60      0.48      0.53       892\n",
      "           5       0.54      0.64      0.58       862\n",
      "           6       0.62      0.68      0.65       903\n",
      "           7       0.58      0.60      0.59       889\n",
      "           8       0.55      0.74      0.63       892\n",
      "           9       0.58      0.55      0.57       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.59     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 26100, Loss: 1.9095286130905151, F1: 0.5859708094317263, Accuracy: 0.5214369279471475, Time Elapsed: 21151.932127952576 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       912\n",
      "           1       0.60      0.91      0.72       885\n",
      "           2       0.44      0.89      0.59       877\n",
      "           3       0.58      0.75      0.66       897\n",
      "           4       0.60      0.42      0.50       892\n",
      "           5       0.54      0.40      0.46       862\n",
      "           6       0.60      0.82      0.69       903\n",
      "           7       0.57      0.85      0.68       889\n",
      "           8       0.57      0.62      0.60       892\n",
      "           9       0.60      0.56      0.58       876\n",
      "          10       0.39      0.32      0.35      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.50      0.59      0.53     14531\n",
      "weighted avg       0.46      0.50      0.47     14531\n",
      "\n",
      "Epoch 5, Step 26200, Loss: 1.2926077842712402, F1: 0.5298624927689641, Accuracy: 0.5041635124905375, Time Elapsed: 21170.266030073166 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       912\n",
      "           1       0.59      0.91      0.72       885\n",
      "           2       0.51      0.84      0.64       877\n",
      "           3       0.62      0.49      0.54       897\n",
      "           4       0.58      0.80      0.67       892\n",
      "           5       0.55      0.36      0.44       862\n",
      "           6       0.57      0.88      0.69       903\n",
      "           7       0.59      0.77      0.67       889\n",
      "           8       0.56      0.70      0.62       892\n",
      "           9       0.59      0.62      0.61       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.59     14531\n",
      "weighted avg       0.51      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 26300, Loss: 0.49811241030693054, F1: 0.5917712958728061, Accuracy: 0.5269423990090152, Time Elapsed: 21188.217559099197 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.69       912\n",
      "           1       0.59      0.78      0.67       885\n",
      "           2       0.59      0.53      0.56       877\n",
      "           3       0.59      0.36      0.45       897\n",
      "           4       0.58      0.58      0.58       892\n",
      "           5       0.51      0.65      0.57       862\n",
      "           6       0.59      0.84      0.70       903\n",
      "           7       0.56      0.89      0.69       889\n",
      "           8       0.59      0.57      0.58       892\n",
      "           9       0.62      0.56      0.59       876\n",
      "          10       0.39      0.31      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 26400, Loss: 0.9148684740066528, F1: 0.5825777316702045, Accuracy: 0.5212992911706008, Time Elapsed: 21205.50086593628 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62       912\n",
      "           1       0.61      0.48      0.54       885\n",
      "           2       0.59      0.59      0.59       877\n",
      "           3       0.56      0.85      0.68       897\n",
      "           4       0.58      0.41      0.48       892\n",
      "           5       0.53      0.50      0.51       862\n",
      "           6       0.62      0.47      0.54       903\n",
      "           7       0.59      0.83      0.69       889\n",
      "           8       0.55      0.70      0.62       892\n",
      "           9       0.61      0.64      0.62       876\n",
      "          10       0.39      0.36      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.58      0.57     14531\n",
      "weighted avg       0.51      0.51      0.51     14531\n",
      "\n",
      "Epoch 5, Step 26500, Loss: 1.1824448108673096, F1: 0.5692599982148236, Accuracy: 0.5126969926364324, Time Elapsed: 21221.39305996895 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       912\n",
      "           1       0.58      0.95      0.72       885\n",
      "           2       0.58      0.67      0.62       877\n",
      "           3       0.61      0.61      0.61       897\n",
      "           4       0.58      0.83      0.68       892\n",
      "           5       0.48      0.34      0.40       862\n",
      "           6       0.62      0.71      0.66       903\n",
      "           7       0.60      0.62      0.61       889\n",
      "           8       0.53      0.78      0.63       892\n",
      "           9       0.61      0.45      0.52       876\n",
      "          10       0.38      0.28      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.64      0.59     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 26600, Loss: 0.38379985094070435, F1: 0.5892488176716681, Accuracy: 0.5255660312435483, Time Elapsed: 21236.34249997139 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68       912\n",
      "           1       0.60      0.92      0.72       885\n",
      "           2       0.62      0.26      0.36       877\n",
      "           3       0.58      0.62      0.60       897\n",
      "           4       0.59      0.39      0.47       892\n",
      "           5       0.50      0.47      0.48       862\n",
      "           6       0.59      0.02      0.04       903\n",
      "           7       0.61      0.55      0.58       889\n",
      "           8       0.57      0.58      0.57       892\n",
      "           9       0.59      0.26      0.36       876\n",
      "          10       0.38      0.48      0.43      5646\n",
      "\n",
      "    accuracy                           0.48     14531\n",
      "   macro avg       0.57      0.48      0.48     14531\n",
      "weighted avg       0.51      0.48      0.46     14531\n",
      "\n",
      "Epoch 5, Step 26700, Loss: 0.8462793827056885, F1: 0.4812379658573581, Accuracy: 0.48317390406716676, Time Elapsed: 21250.787832021713 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       912\n",
      "           1       0.60      0.95      0.73       885\n",
      "           2       0.62      0.27      0.37       877\n",
      "           3       0.56      0.80      0.66       897\n",
      "           4       0.58      0.73      0.64       892\n",
      "           5       0.52      0.76      0.62       862\n",
      "           6       0.63      0.68      0.65       903\n",
      "           7       0.65      0.20      0.31       889\n",
      "           8       0.59      0.53      0.56       892\n",
      "           9       0.61      0.51      0.56       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.60      0.56     14531\n",
      "weighted avg       0.52      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 26800, Loss: 0.36863043904304504, F1: 0.5605277574652703, Accuracy: 0.5192347395224004, Time Elapsed: 21265.873564243317 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67       912\n",
      "           1       0.59      0.92      0.72       885\n",
      "           2       0.58      0.56      0.57       877\n",
      "           3       0.57      0.78      0.65       897\n",
      "           4       0.56      0.87      0.68       892\n",
      "           5       0.51      0.75      0.60       862\n",
      "           6       0.61      0.57      0.59       903\n",
      "           7       0.66      0.10      0.18       889\n",
      "           8       0.59      0.71      0.64       892\n",
      "           9       0.60      0.31      0.41       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.60      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 26900, Loss: 1.4664981365203857, F1: 0.5521048550618647, Accuracy: 0.5142109971784461, Time Elapsed: 21280.28955411911 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66       912\n",
      "           1       0.58      0.18      0.28       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.60      0.58      0.59       897\n",
      "           4       0.58      0.76      0.66       892\n",
      "           5       0.53      0.67      0.59       862\n",
      "           6       0.61      0.58      0.60       903\n",
      "           7       0.61      0.39      0.48       889\n",
      "           8       0.57      0.72      0.64       892\n",
      "           9       0.61      0.03      0.05       876\n",
      "          10       0.39      0.46      0.42      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.50     14531\n",
      "weighted avg       0.51      0.49      0.47     14531\n",
      "\n",
      "Epoch 5, Step 27000, Loss: 0.5927887558937073, F1: 0.5003819059994954, Accuracy: 0.49301493359025533, Time Elapsed: 21295.005481004715 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64       912\n",
      "           1       0.62      0.65      0.64       885\n",
      "           2       0.60      0.52      0.56       877\n",
      "           3       0.62      0.47      0.53       897\n",
      "           4       0.57      0.81      0.67       892\n",
      "           5       0.51      0.35      0.41       862\n",
      "           6       0.61      0.75      0.67       903\n",
      "           7       0.61      0.59      0.60       889\n",
      "           8       0.57      0.76      0.65       892\n",
      "           9       0.58      0.79      0.67       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.51     14531\n",
      "\n",
      "Epoch 5, Step 27100, Loss: 0.5215721726417542, F1: 0.5815408715279289, Accuracy: 0.5212304727823275, Time Elapsed: 21309.735394001007 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       912\n",
      "           1       0.61      0.42      0.50       885\n",
      "           2       0.54      0.78      0.64       877\n",
      "           3       0.61      0.60      0.61       897\n",
      "           4       0.58      0.53      0.56       892\n",
      "           5       0.50      0.31      0.38       862\n",
      "           6       0.61      0.66      0.64       903\n",
      "           7       0.59      0.82      0.68       889\n",
      "           8       0.57      0.61      0.59       892\n",
      "           9       0.56      0.74      0.64       876\n",
      "          10       0.38      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.58      0.56     14531\n",
      "weighted avg       0.50      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 27200, Loss: 1.003308892250061, F1: 0.5628660453333086, Accuracy: 0.5076044319042048, Time Elapsed: 21324.31584095955 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.68       912\n",
      "           1       0.64      0.07      0.12       885\n",
      "           2       0.58      0.64      0.61       877\n",
      "           3       0.60      0.59      0.60       897\n",
      "           4       0.59      0.48      0.53       892\n",
      "           5       0.51      0.18      0.27       862\n",
      "           6       0.62      0.62      0.62       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.57      0.69      0.62       892\n",
      "           9       0.54      0.70      0.61       876\n",
      "          10       0.39      0.42      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.57      0.54      0.52     14531\n",
      "weighted avg       0.51      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 27300, Loss: 0.7558735013008118, F1: 0.521213836200461, Accuracy: 0.5018925056775171, Time Elapsed: 21339.55431008339 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.61      0.84      0.71       885\n",
      "           2       0.59      0.54      0.56       877\n",
      "           3       0.59      0.65      0.62       897\n",
      "           4       0.56      0.82      0.67       892\n",
      "           5       0.46      0.86      0.60       862\n",
      "           6       0.58      0.84      0.69       903\n",
      "           7       0.60      0.77      0.68       889\n",
      "           8       0.58      0.55      0.57       892\n",
      "           9       0.57      0.65      0.60       876\n",
      "          10       0.39      0.20      0.27      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.50      0.53      0.50     14531\n",
      "\n",
      "Epoch 5, Step 27400, Loss: 0.6578466892242432, F1: 0.6071115548197831, Accuracy: 0.5340306930011699, Time Elapsed: 21354.961810112 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65       912\n",
      "           1       0.61      0.74      0.67       885\n",
      "           2       0.58      0.54      0.56       877\n",
      "           3       0.58      0.81      0.67       897\n",
      "           4       0.59      0.82      0.68       892\n",
      "           5       0.50      0.68      0.57       862\n",
      "           6       0.62      0.54      0.58       903\n",
      "           7       0.58      0.84      0.68       889\n",
      "           8       0.57      0.63      0.60       892\n",
      "           9       0.58      0.53      0.56       876\n",
      "          10       0.38      0.27      0.32      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.65      0.60     14531\n",
      "weighted avg       0.50      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 27500, Loss: 1.0996863842010498, F1: 0.5956002952431819, Accuracy: 0.5250843025256349, Time Elapsed: 21369.370764017105 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.61       912\n",
      "           1       0.60      0.79      0.68       885\n",
      "           2       0.59      0.47      0.52       877\n",
      "           3       0.60      0.36      0.45       897\n",
      "           4       0.58      0.74      0.65       892\n",
      "           5       0.49      0.62      0.55       862\n",
      "           6       0.62      0.52      0.57       903\n",
      "           7       0.60      0.76      0.67       889\n",
      "           8       0.55      0.57      0.56       892\n",
      "           9       0.62      0.46      0.52       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.56     14531\n",
      "weighted avg       0.51      0.51      0.50     14531\n",
      "\n",
      "Epoch 5, Step 27600, Loss: 2.6544604301452637, F1: 0.5608898961544231, Accuracy: 0.5080861606221182, Time Elapsed: 21384.015730142593 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.55      0.75      0.64       877\n",
      "           3       0.58      0.66      0.62       897\n",
      "           4       0.60      0.59      0.60       892\n",
      "           5       0.51      0.42      0.46       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.61      0.69      0.65       889\n",
      "           8       0.56      0.68      0.62       892\n",
      "           9       0.57      0.80      0.67       876\n",
      "          10       0.39      0.26      0.31      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.66      0.60     14531\n",
      "weighted avg       0.51      0.53      0.51     14531\n",
      "\n",
      "Epoch 5, Step 27700, Loss: 1.4080181121826172, F1: 0.6023439453570236, Accuracy: 0.5311403206936893, Time Elapsed: 21399.040920972824 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.67       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.58      0.65      0.62       877\n",
      "           3       0.57      0.33      0.42       897\n",
      "           4       0.56      0.27      0.37       892\n",
      "           5       0.53      0.24      0.33       862\n",
      "           6       0.59      0.81      0.68       903\n",
      "           7       0.59      0.80      0.68       889\n",
      "           8       0.59      0.56      0.58       892\n",
      "           9       0.55      0.80      0.65       876\n",
      "          10       0.38      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 27800, Loss: 0.7285664677619934, F1: 0.5531375471805687, Accuracy: 0.5110453513178721, Time Elapsed: 21414.192034959793 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/penny_varsou/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.37      0.46       912\n",
      "           1       0.61      0.85      0.71       885\n",
      "           2       0.57      0.66      0.61       877\n",
      "           3       0.00      0.00      0.00       897\n",
      "           4       0.57      0.79      0.67       892\n",
      "           5       0.51      0.18      0.26       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.60      0.82      0.69       889\n",
      "           8       0.57      0.60      0.58       892\n",
      "           9       0.58      0.59      0.59       876\n",
      "          10       0.39      0.41      0.40      5646\n",
      "\n",
      "    accuracy                           0.50     14531\n",
      "   macro avg       0.51      0.55      0.51     14531\n",
      "weighted avg       0.47      0.50      0.48     14531\n",
      "\n",
      "Epoch 5, Step 27900, Loss: 0.4729008376598358, F1: 0.5131892583172074, Accuracy: 0.5039570573257174, Time Elapsed: 21428.494715213776 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66       912\n",
      "           1       0.61      0.81      0.69       885\n",
      "           2       0.59      0.43      0.49       877\n",
      "           3       0.58      0.76      0.66       897\n",
      "           4       0.58      0.65      0.62       892\n",
      "           5       0.53      0.10      0.17       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.60      0.66      0.63       889\n",
      "           8       0.58      0.55      0.56       892\n",
      "           9       0.48      0.88      0.62       876\n",
      "          10       0.39      0.34      0.36      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.50      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 28000, Loss: 0.5782322287559509, F1: 0.5511469933138131, Accuracy: 0.5095313467758585, Time Elapsed: 21443.12398004532 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.72       912\n",
      "           1       0.70      0.08      0.15       885\n",
      "           2       0.61      0.42      0.50       877\n",
      "           3       0.58      0.39      0.47       897\n",
      "           4       0.59      0.43      0.49       892\n",
      "           5       0.53      0.23      0.32       862\n",
      "           6       0.62      0.54      0.58       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.60      0.49      0.54       892\n",
      "           9       0.55      0.63      0.59       876\n",
      "          10       0.39      0.49      0.43      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.58      0.49      0.50     14531\n",
      "weighted avg       0.52      0.49      0.48     14531\n",
      "\n",
      "Epoch 5, Step 28100, Loss: 0.6821016073226929, F1: 0.4958636153627639, Accuracy: 0.4908815635537816, Time Elapsed: 21459.597202062607 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.94      0.72       912\n",
      "           1       0.64      0.18      0.28       885\n",
      "           2       0.59      0.66      0.62       877\n",
      "           3       0.58      0.79      0.67       897\n",
      "           4       0.58      0.32      0.41       892\n",
      "           5       0.54      0.40      0.46       862\n",
      "           6       0.61      0.76      0.67       903\n",
      "           7       0.60      0.77      0.67       889\n",
      "           8       0.59      0.51      0.54       892\n",
      "           9       0.51      0.82      0.63       876\n",
      "          10       0.39      0.35      0.37      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.56      0.59      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 28200, Loss: 0.1792227178812027, F1: 0.5499726191580994, Accuracy: 0.511595898424059, Time Elapsed: 21474.73665714264 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.72       912\n",
      "           1       0.60      0.75      0.67       885\n",
      "           2       0.59      0.34      0.43       877\n",
      "           3       0.55      0.84      0.66       897\n",
      "           4       0.58      0.85      0.69       892\n",
      "           5       0.54      0.19      0.28       862\n",
      "           6       0.60      0.76      0.67       903\n",
      "           7       0.60      0.69      0.64       889\n",
      "           8       0.60      0.41      0.48       892\n",
      "           9       0.58      0.71      0.64       876\n",
      "          10       0.39      0.33      0.36      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.57     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 28300, Loss: 1.533300757408142, F1: 0.5669226969406999, Accuracy: 0.5222627486064276, Time Elapsed: 21489.066040992737 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       912\n",
      "           1       0.60      0.91      0.73       885\n",
      "           2       0.60      0.44      0.51       877\n",
      "           3       0.56      0.78      0.65       897\n",
      "           4       0.58      0.67      0.62       892\n",
      "           5       0.55      0.66      0.60       862\n",
      "           6       0.60      0.78      0.68       903\n",
      "           7       0.59      0.75      0.66       889\n",
      "           8       0.59      0.61      0.60       892\n",
      "           9       0.53      0.83      0.65       876\n",
      "          10       0.39      0.22      0.29      5646\n",
      "\n",
      "    accuracy                           0.54     14531\n",
      "   macro avg       0.56      0.69      0.61     14531\n",
      "weighted avg       0.51      0.54      0.50     14531\n",
      "\n",
      "Epoch 5, Step 28400, Loss: 0.7019465565681458, F1: 0.6095501898945282, Accuracy: 0.537815704356204, Time Elapsed: 21503.937901973724 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       912\n",
      "           1       0.62      0.89      0.73       885\n",
      "           2       0.64      0.04      0.08       877\n",
      "           3       0.60      0.49      0.54       897\n",
      "           4       0.56      0.92      0.70       892\n",
      "           5       0.53      0.27      0.36       862\n",
      "           6       0.62      0.58      0.60       903\n",
      "           7       0.60      0.72      0.65       889\n",
      "           8       0.59      0.55      0.57       892\n",
      "           9       0.59      0.66      0.62       876\n",
      "          10       0.39      0.40      0.39      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.58      0.57      0.54     14531\n",
      "weighted avg       0.52      0.52      0.49     14531\n",
      "\n",
      "Epoch 5, Step 28500, Loss: 0.4704922139644623, F1: 0.5390141433109421, Accuracy: 0.5154497281673663, Time Elapsed: 21518.330918073654 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.56      0.68      0.61       877\n",
      "           3       0.59      0.75      0.66       897\n",
      "           4       0.58      0.86      0.69       892\n",
      "           5       0.53      0.65      0.59       862\n",
      "           6       0.62      0.55      0.58       903\n",
      "           7       0.60      0.73      0.66       889\n",
      "           8       0.49      0.85      0.62       892\n",
      "           9       0.57      0.81      0.67       876\n",
      "          10       0.38      0.19      0.25      5646\n",
      "\n",
      "    accuracy                           0.53     14531\n",
      "   macro avg       0.56      0.70      0.61     14531\n",
      "weighted avg       0.50      0.53      0.49     14531\n",
      "\n",
      "Epoch 5, Step 28600, Loss: 1.7322903871536255, F1: 0.6119573107931972, Accuracy: 0.5349253320487234, Time Elapsed: 21533.199156999588 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.61       912\n",
      "           1       0.60      0.88      0.72       885\n",
      "           2       0.59      0.51      0.55       877\n",
      "           3       0.60      0.69      0.64       897\n",
      "           4       0.59      0.61      0.60       892\n",
      "           5       0.54      0.72      0.62       862\n",
      "           6       0.63      0.31      0.42       903\n",
      "           7       0.61      0.60      0.60       889\n",
      "           8       0.53      0.74      0.62       892\n",
      "           9       0.57      0.72      0.64       876\n",
      "          10       0.39      0.33      0.35      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.57      0.61      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 28700, Loss: 0.9619457125663757, F1: 0.5782142774005846, Accuracy: 0.5177895533686601, Time Elapsed: 21549.28889322281 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71       912\n",
      "           1       0.61      0.73      0.66       885\n",
      "           2       0.55      0.65      0.59       877\n",
      "           3       0.60      0.44      0.51       897\n",
      "           4       0.56      0.76      0.64       892\n",
      "           5       0.51      0.78      0.62       862\n",
      "           6       0.61      0.68      0.64       903\n",
      "           7       0.60      0.81      0.69       889\n",
      "           8       0.59      0.54      0.57       892\n",
      "           9       0.60      0.25      0.35       876\n",
      "          10       0.39      0.31      0.34      5646\n",
      "\n",
      "    accuracy                           0.52     14531\n",
      "   macro avg       0.56      0.62      0.58     14531\n",
      "weighted avg       0.51      0.52      0.50     14531\n",
      "\n",
      "Epoch 5, Step 28800, Loss: 1.1038563251495361, F1: 0.5750396893212094, Accuracy: 0.5192347395224004, Time Elapsed: 21572.3914270401 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.55       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.58      0.53      0.55       877\n",
      "           3       0.62      0.12      0.20       897\n",
      "           4       0.57      0.40      0.47       892\n",
      "           5       0.54      0.40      0.46       862\n",
      "           6       0.57      0.85      0.68       903\n",
      "           7       0.61      0.60      0.60       889\n",
      "           8       0.57      0.30      0.39       892\n",
      "           9       0.60      0.53      0.56       876\n",
      "          10       0.38      0.45      0.41      5646\n",
      "\n",
      "    accuracy                           0.49     14531\n",
      "   macro avg       0.57      0.51      0.51     14531\n",
      "weighted avg       0.51      0.49      0.48     14531\n",
      "\n",
      "Epoch 5, Step 28900, Loss: 1.9718773365020752, F1: 0.5093034802797671, Accuracy: 0.49060629000068817, Time Elapsed: 21588.361470222473 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.25      0.36       912\n",
      "           1       0.59      0.96      0.73       885\n",
      "           2       0.58      0.47      0.52       877\n",
      "           3       0.61      0.47      0.53       897\n",
      "           4       0.56      0.69      0.62       892\n",
      "           5       0.56      0.49      0.53       862\n",
      "           6       0.52      0.88      0.66       903\n",
      "           7       0.59      0.73      0.66       889\n",
      "           8       0.57      0.58      0.58       892\n",
      "           9       0.61      0.36      0.45       876\n",
      "          10       0.39      0.38      0.38      5646\n",
      "\n",
      "    accuracy                           0.51     14531\n",
      "   macro avg       0.57      0.57      0.55     14531\n",
      "weighted avg       0.51      0.51      0.49     14531\n",
      "\n",
      "Epoch 5, Step 29000, Loss: 0.5079439282417297, F1: 0.5458065725243504, Accuracy: 0.505058151538091, Time Elapsed: 21603.07672405243 seconds\n",
      "Epoch 5 completed. Time: 21603.51315188408\n",
      "Logger {'time': {0: 0.008355140686035156, 100: 17.889382123947144, 200: 36.68793320655823, 300: 59.79914307594299, 400: 81.29294729232788, 500: 100.26058220863342, 600: 117.6418969631195, 700: 134.5136580467224, 800: 151.62483024597168, 900: 170.70567297935486, 1000: 191.15919399261475, 1100: 209.87046003341675, 1200: 230.71499586105347, 1300: 249.560161113739, 1400: 272.86867809295654, 1500: 290.9991810321808, 1600: 314.4796509742737, 1700: 341.7890889644623, 1800: 364.64948296546936, 1900: 383.69471502304077, 2000: 404.8798019886017, 2100: 425.3296239376068, 2200: 448.37371015548706, 2300: 469.4200990200043, 2400: 487.66367411613464, 2500: 505.84667587280273, 2600: 521.5666689872742, 2700: 537.9679851531982, 2800: 556.6527140140533, 2900: 572.8835740089417, 3000: 589.0665490627289, 3100: 604.0188121795654, 3200: 619.2802810668945, 3300: 634.2968611717224, 3400: 649.6785361766815, 3500: 666.5455729961395, 3600: 682.82768201828, 3700: 697.8987970352173, 3800: 713.518520116806, 3900: 728.7105510234833, 4000: 744.0532331466675, 4100: 759.4525229930878, 4200: 775.6641130447388, 4300: 790.5019881725311, 4400: 805.5723152160645, 4500: 821.8621759414673, 4600: 837.6370742321014, 4700: 853.5421848297119, 4800: 869.6100778579712, 4900: 885.8112280368805, 5000: 901.3510060310364, 5100: 916.7182068824768, 5200: 932.1994190216064, 5300: 948.3853440284729, 5400: 964.5002422332764, 5500: 980.1524910926819, 5600: 995.4825119972229, 5700: 1012.1978390216827, 5800: 1027.9112131595612, 5900: 1043.8941750526428, 6000: 1061.842523097992, 6100: 1077.1303720474243, 6200: 1091.6175000667572, 6300: 1106.9948048591614, 6400: 1121.3012399673462, 6500: 1347.996220111847, 6600: 1364.0637202262878, 6700: 1380.4592969417572, 6800: 1396.163959980011, 6900: 1411.7529120445251, 7000: 1427.0138590335846, 7100: 1442.6146919727325, 7200: 1457.94735622406, 7300: 1474.2122201919556, 7400: 1491.8098940849304, 7500: 1507.8735342025757, 7600: 1523.5704171657562, 7700: 1539.4662692546844, 7800: 1554.9528481960297, 7900: 1570.6614320278168, 8000: 1586.2948551177979, 8100: 1602.0846951007843, 8200: 1618.1680171489716, 8300: 1633.8315241336823, 8400: 1649.5842230319977, 8500: 1664.9945158958435, 8600: 1681.6250190734863, 8700: 1697.6225199699402, 8800: 1713.234554052353, 8900: 1727.839699268341, 9000: 1743.8436501026154, 9100: 1759.4959301948547, 9200: 1775.0793941020966, 9300: 1791.589716911316, 9400: 1807.2588140964508, 9500: 1822.61332821846, 9600: 1838.241760969162, 9700: 1854.3320710659027, 9800: 1870.119395017624, 9900: 1885.7637691497803, 10000: 1901.9373989105225, 10100: 1917.5262429714203, 10200: 1933.204926252365, 10300: 1949.3593621253967, 10400: 2145.025913000107, 10500: 2162.3741660118103, 10600: 2178.0797271728516, 10700: 3106.10285115242, 10800: 3123.845535993576, 10900: 3139.41322016716, 11000: 3155.0692689418793, 11100: 3170.3181891441345, 11200: 3185.8848099708557, 11300: 3200.735733985901, 11400: 3215.2127680778503, 11500: 3230.249256134033, 11600: 3244.528188228607, 11700: 3259.200078010559, 11800: 3273.9673430919647, 11900: 3863.8178930282593, 12000: 3881.403920173645, 12100: 3899.9327511787415, 12200: 4130.321150302887, 12300: 4147.814291238785, 12400: 4164.313425064087, 12500: 5209.0748200416565, 12600: 5227.662297010422, 12700: 5244.38149189949, 12800: 6238.749671220779, 12900: 6257.663494110107, 13000: 7261.64454293251, 13100: 7279.987693071365, 13200: 7297.076245069504, 13300: 7379.831395149231, 13400: 7394.854564189911, 13500: 8337.543812036514, 13600: 8354.651420116425, 13700: 8370.9686191082, 13800: 8641.507963180542, 13900: 8660.787823200226, 14000: 8677.719989061356, 14100: 8693.452895879745, 14200: 8709.177608251572, 14300: 8725.253595113754, 14400: 8742.484637260437, 14500: 8759.49177312851, 14600: 8774.31561589241, 14700: 8790.481379032135, 14800: 8805.834993124008, 14900: 8823.171489953995, 15000: 8838.60984325409, 15100: 8854.25824213028, 15200: 8869.337672233582, 15300: 8885.112596035004, 15400: 8901.098773956299, 15500: 8916.943358182907, 15600: 8931.936771154404, 15700: 8947.566995859146, 15800: 8963.437376976013, 15900: 8978.960212945938, 16000: 8993.513307094574, 16100: 9008.156268119812, 16200: 9024.168634176254, 16300: 9039.404252052307, 16400: 9054.263170003891, 16500: 9069.767129182816, 16600: 9085.29560804367, 16700: 9100.58818411827, 16800: 9115.073956012726, 16900: 9130.558483839035, 17000: 9146.1956179142, 17100: 9161.766707897186, 17200: 9176.389503002167, 17300: 9191.714813232422, 17400: 9206.934588193893, 17500: 9222.321291923523, 17600: 9237.826977014542, 17700: 9253.410252094269, 17800: 9269.815336942673, 17900: 9384.355871915817, 18000: 9400.352025032043, 18100: 9416.090190172195, 18200: 9477.06307721138, 18300: 9494.745110034943, 18400: 9511.232627153397, 18500: 9527.204840183258, 18600: 9543.067923069, 18700: 9558.954196929932, 18800: 9574.773751020432, 18900: 9590.921147108078, 19000: 9607.163945913315, 19100: 9623.244152069092, 19200: 9639.34577202797, 19300: 9655.304280042648, 19400: 9671.239742279053, 19500: 9686.959518909454, 19600: 9702.8217420578, 19700: 9718.540527105331, 19800: 9734.462718248367, 19900: 9750.746717214584, 20000: 9766.336487054825, 20100: 9782.340772151947, 20200: 9798.086045980453, 20300: 9814.070118188858, 20400: 9829.722509145737, 20500: 9845.523009061813, 20600: 9861.109091997147, 20700: 9878.025682210922, 20800: 9893.682559967041, 20900: 9909.432557106018, 21000: 9925.074164867401, 21100: 9941.102508068085, 21200: 9957.034858942032, 21300: 9972.866595029831, 21400: 9989.006905078888, 21500: 10004.83704328537, 21600: 10020.873188018799, 21700: 10037.943551063538, 21800: 10054.216830968857, 21900: 10070.091357946396, 22000: 10152.750833034515, 22100: 10170.288177251816, 22200: 10186.21917104721, 22300: 10917.667705059052, 22400: 10935.082487106323, 22500: 10950.627447128296, 22600: 11447.470633029938, 22700: 11463.523200035095, 22800: 11480.673204898834, 22900: 11983.38186120987, 23000: 12003.511375188828, 23100: 12020.545303106308, 23200: 12037.13384103775, 23300: 12052.773591041565, 23400: 12371.10216999054, 23500: 12388.20244717598, 23600: 12403.415126085281, 23700: 12718.161698102951, 23800: 12734.099117040634, 23900: 12749.58796095848, 24000: 13766.681150197983, 24100: 13787.56026005745, 24200: 13806.361945152283, 24300: 14799.443846225739, 24400: 14816.571782112122, 24500: 15773.090369939804, 24600: 15788.924464225769, 24700: 15806.426963090897, 24800: 16730.738257169724, 24900: 16747.48215699196, 25000: 16764.22470808029, 25100: 16780.694808006287, 25200: 16796.101388931274, 25300: 17801.81734108925, 25400: 17820.45927286148, 25500: 18736.275802135468, 25600: 18755.32990002632, 25700: 18775.518441915512, 25800: 19065.509366989136, 25900: 19084.392631053925, 26000: 20067.360707998276, 26100: 21131.584661006927, 26200: 21152.5964550972, 26300: 21170.907201051712, 26400: 21188.89559006691, 26500: 21206.05913424492, 26600: 21221.962430238724, 26700: 21236.853205919266, 26800: 21251.31376004219, 26900: 21266.407783269882, 27000: 21280.81479215622, 27100: 21295.57408618927, 27200: 21310.2340631485, 27300: 21324.85866999626, 27400: 21340.11744403839, 27500: 21355.526995182037, 27600: 21369.88701415062, 27700: 21384.56825017929, 27800: 21399.59411716461, 27900: 21414.732481002808, 28000: 21429.00877404213, 28100: 21443.68034720421, 28200: 21460.17050218582, 28300: 21475.28161907196, 28400: 21489.5624229908, 28500: 21504.51270222664, 28600: 21518.84782409668, 28700: 21533.76329112053, 28800: 21549.825976133347, 28900: 21572.922022104263, 29000: 21588.934422969818}, 'loss': {0: 1.0368952751159668, 100: 3.6870079040527344, 200: 1.1470634937286377, 300: 0.8406378030776978, 400: 0.7211953997612, 500: 3.424351692199707, 600: 1.1816633939743042, 700: 0.47504228353500366, 800: 1.9441183805465698, 900: 1.2991607189178467, 1000: 0.38353824615478516, 1100: 0.6168524622917175, 1200: 0.6410737037658691, 1300: 1.220293402671814, 1400: 0.47996440529823303, 1500: 0.5934423208236694, 1600: 1.2062389850616455, 1700: 1.871381402015686, 1800: 0.46367090940475464, 1900: 0.8206316828727722, 2000: 1.395002841949463, 2100: 0.5611076354980469, 2200: 1.9787209033966064, 2300: 0.5920916199684143, 2400: 0.4414803385734558, 2500: 0.946103036403656, 2600: 0.5533731579780579, 2700: 5.567961692810059, 2800: 0.23192286491394043, 2900: 1.0858993530273438, 3000: 3.3887457847595215, 3100: 0.5547018051147461, 3200: 0.4036276638507843, 3300: 1.082625150680542, 3400: 0.6694774031639099, 3500: 0.9016716480255127, 3600: 1.658439040184021, 3700: 0.5210442543029785, 3800: 2.6102046966552734, 3900: 0.363847941160202, 4000: 0.34069910645484924, 4100: 1.8406660556793213, 4200: 0.5102787017822266, 4300: 1.445205569267273, 4400: 1.72833251953125, 4500: 3.2000298500061035, 4600: 1.5683125257492065, 4700: 1.5725423097610474, 4800: 0.5776350498199463, 4900: 1.11741304397583, 5000: 1.437002182006836, 5100: 0.18123550713062286, 5200: 1.421303391456604, 5300: 0.777720034122467, 5400: 0.37481772899627686, 5500: 0.690096914768219, 5600: 0.8513081073760986, 5700: 0.18665508925914764, 5800: 1.3353782892227173, 5900: 0.5830173492431641, 6000: 0.8350494503974915, 6100: 0.2476332187652588, 6200: 2.612703323364258, 6300: 0.7907764315605164, 6400: 0.7493202686309814, 6500: 0.4228021204471588, 6600: 1.104318618774414, 6700: 6.899417877197266, 6800: 0.9174237251281738, 6900: 0.7650384306907654, 7000: 1.5144730806350708, 7100: 1.1927369832992554, 7200: 0.8986095786094666, 7300: 5.242473602294922, 7400: 1.0815258026123047, 7500: 1.3565815687179565, 7600: 0.6502033472061157, 7700: 0.14038649201393127, 7800: 1.387485146522522, 7900: 0.3814930021762848, 8000: 0.8046720623970032, 8100: 0.4883030951023102, 8200: 1.276788592338562, 8300: 1.6128880977630615, 8400: 0.3225213587284088, 8500: 0.6232283711433411, 8600: 0.8485133051872253, 8700: 1.331979513168335, 8800: 1.75845468044281, 8900: 1.314175009727478, 9000: 0.472421795129776, 9100: 0.8540314435958862, 9200: 0.35527315735816956, 9300: 1.4312448501586914, 9400: 0.8768149018287659, 9500: 0.6541728377342224, 9600: 2.1929943561553955, 9700: 0.16850338876247406, 9800: 0.37992286682128906, 9900: 1.479903221130371, 10000: 1.9728188514709473, 10100: 0.8039968609809875, 10200: 1.184473991394043, 10300: 1.3687525987625122, 10400: 1.3726774454116821, 10500: 0.41525402665138245, 10600: 1.1544907093048096, 10700: 2.3600118160247803, 10800: 6.015312671661377, 10900: 0.5570440888404846, 11000: 0.6584569811820984, 11100: 1.0865057706832886, 11200: 0.8339076042175293, 11300: 0.7888607978820801, 11400: 1.5776338577270508, 11500: 0.7226693630218506, 11600: 0.15827009081840515, 11700: 5.085559368133545, 11800: 1.147032380104065, 11900: 0.6663716435432434, 12000: 1.1199686527252197, 12100: 0.6920863389968872, 12200: 0.8968850374221802, 12300: 0.7438679933547974, 12400: 0.9191492795944214, 12500: 1.867614507675171, 12600: 0.6911733150482178, 12700: 1.290739893913269, 12800: 2.359943151473999, 12900: 1.0062291622161865, 13000: 1.808629035949707, 13100: 0.5464949011802673, 13200: 0.2937338650226593, 13300: 0.27143386006355286, 13400: 1.6280521154403687, 13500: 1.0992226600646973, 13600: 0.5461771488189697, 13700: 0.6564450860023499, 13800: 0.2529378831386566, 13900: 0.4940299689769745, 14000: 0.3447560667991638, 14100: 1.7241116762161255, 14200: 0.41570982336997986, 14300: 3.1307332515716553, 14400: 5.35407829284668, 14500: 1.1933486461639404, 14600: 6.0112996101379395, 14700: 4.522172451019287, 14800: 1.3245186805725098, 14900: 1.8952088356018066, 15000: 1.1898478269577026, 15100: 0.9679230451583862, 15200: 0.6519365906715393, 15300: 0.519737184047699, 15400: 0.716248095035553, 15500: 1.6922093629837036, 15600: 0.4775589108467102, 15700: 1.361366868019104, 15800: 1.172099232673645, 15900: 0.797914445400238, 16000: 0.47485142946243286, 16100: 2.014955997467041, 16200: 0.667679488658905, 16300: 0.38745200634002686, 16400: 0.3359898030757904, 16500: 0.6281230449676514, 16600: 0.26650741696357727, 16700: 0.7336447834968567, 16800: 0.7468069791793823, 16900: 1.0770998001098633, 17000: 0.6095338463783264, 17100: 0.7696090936660767, 17200: 2.788649082183838, 17300: 0.5916420817375183, 17400: 0.7665290236473083, 17500: 0.2993957996368408, 17600: 0.6948312520980835, 17700: 2.5088906288146973, 17800: 0.6785063743591309, 17900: 1.1116477251052856, 18000: 0.7987124919891357, 18100: 0.6117941737174988, 18200: 0.43763813376426697, 18300: 1.5625200271606445, 18400: 0.9442688226699829, 18500: 0.6262587308883667, 18600: 2.019392251968384, 18700: 0.5769649744033813, 18800: 3.6904122829437256, 18900: 0.5110968351364136, 19000: 0.7500594854354858, 19100: 1.022345781326294, 19200: 0.20762912929058075, 19300: 0.3737369179725647, 19400: 0.3248905539512634, 19500: 4.7795281410217285, 19600: 0.9391541481018066, 19700: 1.0233826637268066, 19800: 0.3934474587440491, 19900: 0.29786360263824463, 20000: 0.2721075415611267, 20100: 1.072468876838684, 20200: 1.2391016483306885, 20300: 0.9203720688819885, 20400: 0.6270086765289307, 20500: 1.0144122838974, 20600: 0.5411919951438904, 20700: 0.6743003726005554, 20800: 1.2614498138427734, 20900: 0.438768595457077, 21000: 0.6154788136482239, 21100: 1.3447275161743164, 21200: 1.1958045959472656, 21300: 0.7686699628829956, 21400: 0.8342468738555908, 21500: 0.8159475922584534, 21600: 1.3327064514160156, 21700: 0.7334817051887512, 21800: 0.9063625335693359, 21900: 0.5336271524429321, 22000: 0.973915696144104, 22100: 0.9603506922721863, 22200: 0.5988246202468872, 22300: 0.8892248868942261, 22400: 0.5942291021347046, 22500: 0.14209580421447754, 22600: 0.20129071176052094, 22700: 0.5067645311355591, 22800: 0.4687442183494568, 22900: 0.16387958824634552, 23000: 1.115228295326233, 23100: 0.7062016725540161, 23200: 1.3018426895141602, 23300: 0.3312917947769165, 23400: 0.6653748750686646, 23500: 0.6528385281562805, 23600: 5.432952404022217, 23700: 0.42141810059547424, 23800: 0.4268832206726074, 23900: 1.994378924369812, 24000: 0.149493008852005, 24100: 2.9777698516845703, 24200: 1.9053289890289307, 24300: 0.708714485168457, 24400: 1.8231043815612793, 24500: 0.7092469930648804, 24600: 4.741597652435303, 24700: 0.5926722884178162, 24800: 2.678128242492676, 24900: 0.2551687955856323, 25000: 1.4315699338912964, 25100: 0.4093605875968933, 25200: 0.4436075687408447, 25300: 0.2920113801956177, 25400: 0.4607190489768982, 25500: 1.2313469648361206, 25600: 1.506417989730835, 25700: 0.2905694544315338, 25800: 2.2426748275756836, 25900: 0.8147187829017639, 26000: 0.4485699534416199, 26100: 1.9095286130905151, 26200: 1.2926077842712402, 26300: 0.49811241030693054, 26400: 0.9148684740066528, 26500: 1.1824448108673096, 26600: 0.38379985094070435, 26700: 0.8462793827056885, 26800: 0.36863043904304504, 26900: 1.4664981365203857, 27000: 0.5927887558937073, 27100: 0.5215721726417542, 27200: 1.003308892250061, 27300: 0.7558735013008118, 27400: 0.6578466892242432, 27500: 1.0996863842010498, 27600: 2.6544604301452637, 27700: 1.4080181121826172, 27800: 0.7285664677619934, 27900: 0.4729008376598358, 28000: 0.5782322287559509, 28100: 0.6821016073226929, 28200: 0.1792227178812027, 28300: 1.533300757408142, 28400: 0.7019465565681458, 28500: 0.4704922139644623, 28600: 1.7322903871536255, 28700: 0.9619457125663757, 28800: 1.1038563251495361, 28900: 1.9718773365020752, 29000: 0.5079439282417297}, 'F1': {0: 0.5825962228505421, 100: 0.5358765746770495, 200: 0.49031723473849986, 300: 0.5777743089607511, 400: 0.5600340514145794, 500: 0.552759593114655, 600: 0.5930111750654806, 700: 0.6098598402825379, 800: 0.5543658573402791, 900: 0.4966320473304725, 1000: 0.5583059470324984, 1100: 0.53606539805782, 1200: 0.5599337827494753, 1300: 0.5832801388151505, 1400: 0.5026784663555443, 1500: 0.5440962252576269, 1600: 0.5850572880670976, 1700: 0.5366224717929269, 1800: 0.5304848911549975, 1900: 0.5798078090751063, 2000: 0.6011706931118763, 2100: 0.5008762252523046, 2200: 0.5874378722987245, 2300: 0.5793957831129192, 2400: 0.5981103784133589, 2500: 0.48930265195272077, 2600: 0.5822176232026867, 2700: 0.5542812904448634, 2800: 0.49642674972683415, 2900: 0.5774197668777715, 3000: 0.6087725791980974, 3100: 0.5634357996206734, 3200: 0.5757315701309729, 3300: 0.5408953960340243, 3400: 0.4754641154322295, 3500: 0.5115239929785167, 3600: 0.5427254890065508, 3700: 0.5742216410795365, 3800: 0.598952558548678, 3900: 0.6107363255740309, 4000: 0.5598954656460751, 4100: 0.4839917065410828, 4200: 0.5475820856220275, 4300: 0.5801639568548193, 4400: 0.4935534001866721, 4500: 0.5399668520021546, 4600: 0.532755636417154, 4700: 0.5269037640995439, 4800: 0.4736322610813666, 4900: 0.522042673401189, 5000: 0.536984811273398, 5100: 0.5615788486690104, 5200: 0.47021424486903646, 5300: 0.5882491245245721, 5400: 0.5831372611857198, 5500: 0.4757109898739188, 5600: 0.5206278413067311, 5700: 0.4935851028655431, 5800: 0.5421250776966858, 5900: 0.509431695801083, 6000: 0.5995324844907935, 6100: 0.4351003256597593, 6200: 0.5361076738172117, 6300: 0.5835252554448216, 6400: 0.47414081137087916, 6500: 0.537421303346059, 6600: 0.567408808622985, 6700: 0.514591062758409, 6800: 0.4882234306923689, 6900: 0.5207604137617817, 7000: 0.5257769285951026, 7100: 0.5492938730889084, 7200: 0.5835356815598552, 7300: 0.5796956871808596, 7400: 0.4514510420358958, 7500: 0.5012763136213282, 7600: 0.5170074753432764, 7700: 0.49866365437220855, 7800: 0.6002497796696008, 7900: 0.5986482982928788, 8000: 0.5522089916869248, 8100: 0.5966280463954777, 8200: 0.5661668506902298, 8300: 0.5482728251897625, 8400: 0.49262256977651214, 8500: 0.49730333191683196, 8600: 0.5521536773186131, 8700: 0.563503558202984, 8800: 0.61422071329087, 8900: 0.6058498829266952, 9000: 0.4904843362422238, 9100: 0.5127401733333201, 9200: 0.5731116263455107, 9300: 0.556181309636425, 9400: 0.4645788055682319, 9500: 0.5168294074743289, 9600: 0.574552238353401, 9700: 0.5690221388917193, 9800: 0.5156551070317608, 9900: 0.5281906010200227, 10000: 0.5440202694468289, 10100: 0.5883034147417384, 10200: 0.5936688096493717, 10300: 0.6134930264478791, 10400: 0.5437281798161324, 10500: 0.533500171679865, 10600: 0.5899366478390259, 10700: 0.5374291184931466, 10800: 0.591800120234952, 10900: 0.6007936442971815, 11000: 0.5089382277524135, 11100: 0.5343499305072661, 11200: 0.581299701267096, 11300: 0.5627220430048839, 11400: 0.5743579750566842, 11500: 0.6006725797961386, 11600: 0.5734809977409229, 11700: 0.5386926226926002, 11800: 0.6166376324971535, 11900: 0.5856687653341748, 12000: 0.436085976950452, 12100: 0.5964101029395033, 12200: 0.582646402370544, 12300: 0.5894860217773178, 12400: 0.595139127885849, 12500: 0.5978023325905981, 12600: 0.5213415336371222, 12700: 0.5478387071081777, 12800: 0.5114404402954933, 12900: 0.5054672248689195, 13000: 0.4857847398254695, 13100: 0.6039612746099217, 13200: 0.5989518331021284, 13300: 0.5291014167928908, 13400: 0.5381473703436307, 13500: 0.5586013857472546, 13600: 0.5034582455999632, 13700: 0.5533139619457165, 13800: 0.5496601653718394, 13900: 0.5791282358496264, 14000: 0.4333470722017944, 14100: 0.6108951745405595, 14200: 0.5535221669832633, 14300: 0.5720365527353318, 14400: 0.5675044589668402, 14500: 0.5303579399015598, 14600: 0.5648797083783955, 14700: 0.5929052070496303, 14800: 0.5950016446955121, 14900: 0.6096903927078254, 15000: 0.4405526815836472, 15100: 0.478654747208609, 15200: 0.5101418270246865, 15300: 0.4740538777591546, 15400: 0.523385176592298, 15500: 0.49470448511804926, 15600: 0.5355351552049539, 15700: 0.538504368019989, 15800: 0.5244232843106629, 15900: 0.5351134568760691, 16000: 0.584047707154641, 16100: 0.47598527150629794, 16200: 0.6057619707265955, 16300: 0.5594745069386534, 16400: 0.5908867512758469, 16500: 0.4696115890265318, 16600: 0.5733371301727694, 16700: 0.5426583520505371, 16800: 0.5314857095428679, 16900: 0.5355017341779962, 17000: 0.5729788065121132, 17100: 0.5297656843983867, 17200: 0.53596944919982, 17300: 0.5648418842232829, 17400: 0.5162931778775053, 17500: 0.6265644686445518, 17600: 0.5820240725044482, 17700: 0.5405623042683901, 17800: 0.5578839614633883, 17900: 0.5896064932005093, 18000: 0.5587851046861864, 18100: 0.5425390906291858, 18200: 0.5063236338039637, 18300: 0.5113786528865524, 18400: 0.5438793657449424, 18500: 0.5827948854522647, 18600: 0.4959330245855872, 18700: 0.4843549453191533, 18800: 0.5762537794257431, 18900: 0.5611595669564284, 19000: 0.5824233425570718, 19100: 0.5973753634253274, 19200: 0.433611571199636, 19300: 0.603091752907027, 19400: 0.5997016294230685, 19500: 0.5819288407416633, 19600: 0.6079443200209697, 19700: 0.620801008823721, 19800: 0.594150929502484, 19900: 0.5882037687631689, 20000: 0.5763074060034533, 20100: 0.5346923222321182, 20200: 0.5886255538402151, 20300: 0.589434653416654, 20400: 0.5305218997507208, 20500: 0.5927876944539232, 20600: 0.5869219301713862, 20700: 0.5342683775971016, 20800: 0.4761422544306692, 20900: 0.5727145032507782, 21000: 0.5958598717071859, 21100: 0.5773127968659147, 21200: 0.6015709277721286, 21300: 0.5509397927656257, 21400: 0.52816101884389, 21500: 0.5105444224718488, 21600: 0.5450083786785097, 21700: 0.5879945543209995, 21800: 0.5729781680847222, 21900: 0.5863169923676795, 22000: 0.5413973604219072, 22100: 0.44164455609914205, 22200: 0.517047808351722, 22300: 0.5323013043084647, 22400: 0.6000792352964625, 22500: 0.6015124650163621, 22600: 0.5583248488831059, 22700: 0.5902872834460814, 22800: 0.5523049519350685, 22900: 0.5397426353126558, 23000: 0.575748763091114, 23100: 0.5518490377713653, 23200: 0.5951015129110336, 23300: 0.6113876039087918, 23400: 0.5456051268007236, 23500: 0.6035220062404744, 23600: 0.5015000804698994, 23700: 0.5735988150521418, 23800: 0.5585647741356808, 23900: 0.4575584993969311, 24000: 0.5089439126787878, 24100: 0.5113873009944817, 24200: 0.6228625059289916, 24300: 0.6039205156887931, 24400: 0.46958597280053477, 24500: 0.5496940848718119, 24600: 0.6008441137466597, 24700: 0.58433811452583, 24800: 0.5628807881839257, 24900: 0.6012028601763569, 25000: 0.5533371300009365, 25100: 0.5901070758509243, 25200: 0.5140224453957258, 25300: 0.4699144807177213, 25400: 0.5554526032362368, 25500: 0.5589487673546606, 25600: 0.61256036466059, 25700: 0.6021220895417838, 25800: 0.5607771481974579, 25900: 0.533954343623021, 26000: 0.5243253405153473, 26100: 0.5859708094317263, 26200: 0.5298624927689641, 26300: 0.5917712958728061, 26400: 0.5825777316702045, 26500: 0.5692599982148236, 26600: 0.5892488176716681, 26700: 0.4812379658573581, 26800: 0.5605277574652703, 26900: 0.5521048550618647, 27000: 0.5003819059994954, 27100: 0.5815408715279289, 27200: 0.5628660453333086, 27300: 0.521213836200461, 27400: 0.6071115548197831, 27500: 0.5956002952431819, 27600: 0.5608898961544231, 27700: 0.6023439453570236, 27800: 0.5531375471805687, 27900: 0.5131892583172074, 28000: 0.5511469933138131, 28100: 0.4958636153627639, 28200: 0.5499726191580994, 28300: 0.5669226969406999, 28400: 0.6095501898945282, 28500: 0.5390141433109421, 28600: 0.6119573107931972, 28700: 0.5782142774005846, 28800: 0.5750396893212094, 28900: 0.5093034802797671, 29000: 0.5458065725243504}, 'Accuracy': {0: 0.5188218291927603, 100: 0.5085678893400316, 200: 0.49907095175830984, 300: 0.5181336453100268, 400: 0.5093248916110384, 500: 0.5094625283875852, 600: 0.5231573876539811, 700: 0.5380909779092974, 800: 0.5049205147615443, 900: 0.49335902553162203, 1000: 0.5122840823067923, 1100: 0.5127658110247058, 1200: 0.5166196407680133, 1300: 0.5217810198885142, 1400: 0.504851696373271, 1500: 0.5069850664097447, 1600: 0.5262542151262818, 1700: 0.5065721560801046, 1800: 0.5105636225999587, 1900: 0.5204046521230473, 2000: 0.5299015897047691, 2100: 0.4954923955680958, 2200: 0.5268735806207419, 2300: 0.5259789415731884, 2400: 0.5281123116096621, 2500: 0.49108801871860164, 2600: 0.5242584818663547, 2700: 0.514004542013626, 2800: 0.4987956782052164, 2900: 0.5175142798155667, 3000: 0.5332048723418897, 3100: 0.5193035579106737, 3200: 0.5260477599614617, 3300: 0.5179271901452068, 3400: 0.49411602780262887, 3500: 0.5018925056775171, 3600: 0.5145550891198128, 3700: 0.5194411946872204, 3800: 0.5314155942467828, 3900: 0.5345124217190833, 4000: 0.5185465556396669, 4100: 0.48448145344436033, 4200: 0.5079485238455715, 4300: 0.5186153740279402, 4400: 0.4923955680957952, 4500: 0.5018925056775171, 4600: 0.506640974468378, 4700: 0.5031312366664372, 4800: 0.48757828091666094, 4900: 0.4998279540293166, 5000: 0.5015484137361503, 5100: 0.5132475397426193, 5200: 0.4814534443603331, 5300: 0.5208175624526874, 5400: 0.5212304727823275, 5500: 0.4827609937375267, 5600: 0.4923955680957952, 5700: 0.49514830362672907, 5800: 0.512008808753699, 5900: 0.4961805794508293, 6000: 0.5305897735875026, 6100: 0.47918243754731266, 6200: 0.49996559080586334, 6300: 0.5197852866285871, 6400: 0.48289863051407333, 6500: 0.5121464455302457, 6600: 0.5188218291927603, 6700: 0.5021677792306104, 6800: 0.48248572018443325, 6900: 0.5028559631133439, 7000: 0.4967999449452894, 7100: 0.5113206248709655, 7200: 0.526116578349735, 7300: 0.5250843025256349, 7400: 0.4809028972541463, 7500: 0.501686050512697, 7600: 0.5025118711719772, 7700: 0.4898492877296814, 7800: 0.5313467758585094, 7900: 0.5309338655288693, 8000: 0.5140733604018994, 8100: 0.5338242378363499, 8200: 0.5219186566650609, 8300: 0.5183401004748469, 8400: 0.5027871447250706, 8500: 0.5058151538090978, 8600: 0.5100818938820453, 8700: 0.5217122015002409, 8800: 0.5375404308031105, 8900: 0.5371963388617439, 9000: 0.4952171220150024, 9100: 0.4958364875094625, 9200: 0.521161654394054, 9300: 0.5172390062624733, 9400: 0.48523845571536717, 9500: 0.4926708416488886, 9600: 0.5215745647236941, 9700: 0.5151744546142729, 9800: 0.5001720459706833, 9900: 0.49838276787557634, 10000: 0.5110453513178721, 10100: 0.5221939302181543, 10200: 0.526116578349735, 10300: 0.5404996214988645, 10400: 0.5160690936618264, 10500: 0.5085678893400316, 10600: 0.523914389924988, 10700: 0.5076044319042048, 10800: 0.5295574977634023, 10900: 0.5354070607666368, 11000: 0.49852040465212305, 11100: 0.4991397701465832, 11200: 0.520542288899594, 11300: 0.5135228132957126, 11400: 0.5246025738077215, 11500: 0.5321725965177896, 11600: 0.5200605601816806, 11700: 0.5091872548344918, 11800: 0.5428394467001583, 11900: 0.5278370380565687, 12000: 0.4787007088293992, 12100: 0.5296263161516758, 12200: 0.5268735806207419, 12300: 0.5293510425985823, 12400: 0.5317596861881495, 12500: 0.5285940403275755, 12600: 0.49796985754593626, 12700: 0.507053884798018, 12800: 0.4908815635537816, 12900: 0.4968687633335627, 13000: 0.49507948523845574, 13100: 0.5327919620122497, 13200: 0.5246025738077215, 13300: 0.5062968825270112, 13400: 0.5085678893400316, 13500: 0.5053334250911844, 13600: 0.49452893813226895, 13700: 0.5113206248709655, 13800: 0.5199229234051338, 13900: 0.5212304727823275, 14000: 0.4724382354965247, 14100: 0.5363016998141904, 14200: 0.511595898424059, 14300: 0.5140733604018994, 14400: 0.5124217190833391, 14500: 0.5001720459706833, 14600: 0.5126969926364324, 14700: 0.5268735806207419, 14800: 0.5290069506572156, 14900: 0.5365081549790104, 15000: 0.4811781708072397, 15100: 0.4864771867042874, 15200: 0.49907095175830984, 15300: 0.4873718257518409, 15400: 0.4992085885348565, 15500: 0.48909228545867456, 15600: 0.5055398802560044, 15700: 0.5069162480214713, 15800: 0.49218911293097517, 15900: 0.507260339962838, 16000: 0.5177207349803867, 16100: 0.4908127451655082, 16200: 0.5339618746128966, 16300: 0.5218498382767875, 16400: 0.5323102332943362, 16500: 0.489780469341408, 16600: 0.5268735806207419, 16700: 0.5107012593765055, 16800: 0.5006537746885968, 16900: 0.5111141697061454, 17000: 0.5124905374716124, 17100: 0.4991397701465832, 17200: 0.5074667951276581, 17300: 0.5165508223797398, 17400: 0.5021677792306104, 17500: 0.5494460119743996, 17600: 0.5193723762989471, 17700: 0.5100818938820453, 17800: 0.508430252563485, 17900: 0.5276305828917487, 18000: 0.5109765329295988, 18100: 0.5089119812813984, 18200: 0.5054022434794577, 18300: 0.5008602298534168, 18400: 0.5133851765191659, 18500: 0.5215745647236941, 18600: 0.4943224829674489, 18700: 0.48950519578831464, 18800: 0.5212304727823275, 18900: 0.5134539949074393, 19000: 0.5236391163718945, 19100: 0.5291445874337622, 19200: 0.4743651503681784, 19300: 0.5343059665542633, 19400: 0.5338242378363499, 19500: 0.5286628587158488, 19600: 0.5381597962975707, 19700: 0.5424265363705182, 19800: 0.529282224210309, 19900: 0.5297639529282224, 20000: 0.5273553093386553, 20100: 0.5040258757139908, 20200: 0.5309338655288693, 20300: 0.5217122015002409, 20400: 0.503475328607804, 20500: 0.5279058564448421, 20600: 0.524327300254628, 20700: 0.5018925056775171, 20800: 0.49501066685018236, 20900: 0.5247402105842681, 21000: 0.5305897735875026, 21100: 0.5215057463354208, 21200: 0.5316908677998762, 21300: 0.5188218291927603, 21400: 0.5064345193035579, 21500: 0.4994838620879499, 21600: 0.5067786112449246, 21700: 0.5210240176175074, 21800: 0.5159314568852797, 21900: 0.5239832083132613, 22000: 0.5021677792306104, 22100: 0.4743651503681784, 22200: 0.5028559631133439, 22300: 0.5020989608423371, 22400: 0.5295574977634023, 22500: 0.5324478700708829, 22600: 0.5160690936618264, 22700: 0.5274241277269286, 22800: 0.5018925056775171, 22900: 0.5076044319042048, 23000: 0.5239832083132613, 23100: 0.5171701878742, 23200: 0.5287316771041222, 23300: 0.5395361640630376, 23400: 0.5049205147615443, 23500: 0.5347188768839034, 23600: 0.501686050512697, 23700: 0.5220562934416076, 23800: 0.5131787213543458, 23900: 0.47856307205285253, 24000: 0.5036817837726241, 24100: 0.5069850664097447, 24200: 0.5466932764434657, 24300: 0.5338930562246232, 24400: 0.4944601197439956, 24500: 0.5212304727823275, 24600: 0.5352006056018168, 24700: 0.525497212855275, 24800: 0.5244649370311747, 24900: 0.5333425091184364, 25000: 0.5146927258963595, 25100: 0.5281811299979354, 25200: 0.49597412428600923, 25300: 0.48510081893882046, 25400: 0.5103571674351387, 25500: 0.5199917417934072, 25600: 0.5372651572500172, 25700: 0.5343747849425367, 25800: 0.5148991810611796, 25900: 0.5098754387172253, 26000: 0.505058151538091, 26100: 0.5214369279471475, 26200: 0.5041635124905375, 26300: 0.5269423990090152, 26400: 0.5212992911706008, 26500: 0.5126969926364324, 26600: 0.5255660312435483, 26700: 0.48317390406716676, 26800: 0.5192347395224004, 26900: 0.5142109971784461, 27000: 0.49301493359025533, 27100: 0.5212304727823275, 27200: 0.5076044319042048, 27300: 0.5018925056775171, 27400: 0.5340306930011699, 27500: 0.5250843025256349, 27600: 0.5080861606221182, 27700: 0.5311403206936893, 27800: 0.5110453513178721, 27900: 0.5039570573257174, 28000: 0.5095313467758585, 28100: 0.4908815635537816, 28200: 0.511595898424059, 28300: 0.5222627486064276, 28400: 0.537815704356204, 28500: 0.5154497281673663, 28600: 0.5349253320487234, 28700: 0.5177895533686601, 28800: 0.5192347395224004, 28900: 0.49060629000068817, 29000: 0.505058151538091}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "def train_model(model, train_data, criterion, optimizer, num_epochs, test_data, eval_interval=100):\n",
    "    logger = {'time': {}, 'loss': {}, 'F1': {}, 'Accuracy': {}}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for i, (sequence, label) in enumerate(train_data):\n",
    "            # Convert sequence and label to tensors if they are not already\n",
    "            if not isinstance(sequence, torch.Tensor):\n",
    "                sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "            if not isinstance(label, torch.Tensor):\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sequence.unsqueeze(0))\n",
    "            loss = criterion(outputs, label.unsqueeze(0))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Logging\n",
    "            if i % 100 == 0:\n",
    "                logger['time'][i] = time.time() - epoch_start_time\n",
    "                logger['loss'][i] = loss.item()\n",
    "\n",
    "                # Evaluate model performance on test data\n",
    "                f1_score_value, accuracy = evaluate_model(model, test_data)\n",
    "                logger['F1'][i] = f1_score_value\n",
    "                logger['Accuracy'][i] = accuracy\n",
    "\n",
    "                print(f\"Epoch {epoch + 1}, Step {i}, Loss: {loss.item()}, F1: {f1_score_value}, Accuracy: {accuracy}, Time Elapsed: {time.time() - epoch_start_time} seconds\")\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        print(f\"Epoch {epoch + 1} completed. Time: {epoch_end_time - epoch_start_time}\")\n",
    "\n",
    "        # Print detailed logger information\n",
    "        print(\"Logger\", logger)\n",
    "        \n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_data):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence, label in test_data:\n",
    "            # Ensure label is a tensor\n",
    "            if not isinstance(label, torch.Tensor):\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            outputs = model(sequence.unsqueeze(0))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_predictions.append(predicted.item())\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "    # Calculate confusion matrix and metrics\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    f1_score_value = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "    return f1_score_value, accuracy\n",
    "\n",
    "# Load and shuffle MNIST dataset\n",
    "train_data, test_data = load_and_shuffle_mnist()\n",
    "\n",
    "# Set LSTM parameters\n",
    "input_size = 784  # 28x28\n",
    "hidden_size = 128\n",
    "num_classes = 11  # Digits 0-9 and 'null'\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "window_size = 10  # Example window size\n",
    "\n",
    "# Create model\n",
    "model = SimpleLSTM(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Example of training with a single data point\n",
    "for size in [32000]:\n",
    "    print(f\"Training with dataset size: {size}\")\n",
    "    sampled_train_data = balanced_sampling(train_data, size)\n",
    "    sampled_test_data = balanced_sampling(test_data, size // 2)\n",
    "\n",
    "    train_sequences, train_labels = create_sequences(sampled_train_data, window_size)\n",
    "    test_sequences, test_labels = create_sequences(sampled_test_data, window_size)\n",
    "\n",
    "    # Convert sequences and labels into a list of tuples for easier iteration\n",
    "    train_data_tuples = list(zip(train_sequences, train_labels))\n",
    "    test_data_tuples = list(zip(test_sequences, test_labels))\n",
    "\n",
    "    train_model(model, train_data_tuples, criterion, optimizer, num_epochs, test_data_tuples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
